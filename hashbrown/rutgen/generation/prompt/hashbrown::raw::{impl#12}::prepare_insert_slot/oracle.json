{
  "system_pt": "As a software testing expert, please generate accurate test oracles code based on the provided information. Follow these guidelines:\n1. Generate executable test oracle codes in plain text format, one per line. Do not output complete test functions, avoid additional explanations, and do not use Markdown.\n2. Combine the given function under test, context, relevant documentation, preconditions, expected return values or types, test input conditions or ranges, and existing test function prefixes to infer and generate corresponding test oracles code.\n3. Only generate necessary test oracles to ensure comprehensive validation.\n",
  "static_pt": "The context for the focal function is as follows:\n// src/raw/mod.rs\n// crate name is hashbrown\nuse crate::alloc::alloc::{handle_alloc_error, Layout};\nuse crate::control::{BitMaskIter, Group, Tag, TagSliceExt};\nuse crate::scopeguard::{guard, ScopeGuard};\nuse crate::util::{invalid_mut, likely, unlikely};\nuse crate::TryReserveError;\nuse core::array;\nuse core::iter::FusedIterator;\nuse core::marker::PhantomData;\nuse core::mem;\nuse core::ptr::NonNull;\nuse core::slice;\nuse core::{hint, ptr};\n#[cfg(test)]\npub(crate) use self::alloc::AllocError;\npub(crate) use self::alloc::{do_alloc, Allocator, Global};\nstruct RawTableInner {\n    bucket_mask: usize,\n    ctrl: NonNull<u8>,\n    growth_left: usize,\n    items: usize,\n}\npub struct InsertSlot {\n    index: usize,\n}\n#[derive(Copy, Clone, PartialEq, Eq)]\n#[repr(transparent)]\npub(crate) struct Tag(pub(super) u8);\nimpl RawTableInner {\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    unsafe fn new_uninitialized<A>(\n        alloc: &A,\n        table_layout: TableLayout,\n        buckets: usize,\n        fallibility: Fallibility,\n    ) -> Result<Self, TryReserveError>\n    where\n        A: Allocator,\n    {\n        debug_assert!(buckets.is_power_of_two());\n        let (layout, ctrl_offset) = match table_layout.calculate_layout_for(buckets) {\n            Some(lco) => lco,\n            None => return Err(fallibility.capacity_overflow()),\n        };\n        let ptr: NonNull<u8> = match do_alloc(alloc, layout) {\n            Ok(block) => block.cast(),\n            Err(_) => return Err(fallibility.alloc_err(layout)),\n        };\n        let ctrl = NonNull::new_unchecked(ptr.as_ptr().add(ctrl_offset));\n        Ok(Self {\n            ctrl,\n            bucket_mask: buckets - 1,\n            items: 0,\n            growth_left: bucket_mask_to_capacity(buckets - 1),\n        })\n    }\n    #[inline]\n    fn fallible_with_capacity<A>(\n        alloc: &A,\n        table_layout: TableLayout,\n        capacity: usize,\n        fallibility: Fallibility,\n    ) -> Result<Self, TryReserveError>\n    where\n        A: Allocator,\n    {\n        if capacity == 0 {\n            Ok(Self::NEW)\n        } else {\n            unsafe {\n                let buckets = capacity_to_buckets(capacity)\n                    .ok_or_else(|| fallibility.capacity_overflow())?;\n                let mut result = Self::new_uninitialized(\n                    alloc,\n                    table_layout,\n                    buckets,\n                    fallibility,\n                )?;\n                result.ctrl_slice().fill_empty();\n                Ok(result)\n            }\n        }\n    }\n    fn with_capacity<A>(alloc: &A, table_layout: TableLayout, capacity: usize) -> Self\n    where\n        A: Allocator,\n    {\n        match Self::fallible_with_capacity(\n            alloc,\n            table_layout,\n            capacity,\n            Fallibility::Infallible,\n        ) {\n            Ok(table_inner) => table_inner,\n            Err(_) => unsafe { hint::unreachable_unchecked() }\n        }\n    }\n    #[inline]\n    unsafe fn fix_insert_slot(&self, mut index: usize) -> InsertSlot {}\n    #[inline]\n    fn find_insert_slot_in_group(\n        &self,\n        group: &Group,\n        probe_seq: &ProbeSeq,\n    ) -> Option<usize> {}\n    #[inline]\n    unsafe fn find_or_find_insert_slot_inner(\n        &self,\n        hash: u64,\n        eq: &mut dyn FnMut(usize) -> bool,\n    ) -> Result<usize, InsertSlot> {}\n    #[inline]\n    unsafe fn prepare_insert_slot(&mut self, hash: u64) -> (usize, Tag) {\n        let index: usize = self.find_insert_slot(hash).index;\n        let old_ctrl = *self.ctrl(index);\n        self.set_ctrl_hash(index, hash);\n        (index, old_ctrl)\n    }\n    #[inline]\n    unsafe fn find_insert_slot(&self, hash: u64) -> InsertSlot {\n        let mut probe_seq = self.probe_seq(hash);\n        loop {\n            let group = unsafe { Group::load(self.ctrl(probe_seq.pos)) };\n            let index = self.find_insert_slot_in_group(&group, &probe_seq);\n            if likely(index.is_some()) {\n                unsafe {\n                    return self.fix_insert_slot(index.unwrap_unchecked());\n                }\n            }\n            probe_seq.move_next(self.bucket_mask);\n        }\n    }\n    #[inline(always)]\n    unsafe fn find_inner(\n        &self,\n        hash: u64,\n        eq: &mut dyn FnMut(usize) -> bool,\n    ) -> Option<usize> {}\n    #[allow(clippy::mut_mut)]\n    #[inline]\n    unsafe fn prepare_rehash_in_place(&mut self) {}\n    #[inline]\n    unsafe fn iter<T>(&self) -> RawIter<T> {}\n    unsafe fn drop_elements<T>(&mut self) {}\n    unsafe fn drop_inner_table<T, A: Allocator>(\n        &mut self,\n        alloc: &A,\n        table_layout: TableLayout,\n    ) {}\n    #[inline]\n    unsafe fn bucket<T>(&self, index: usize) -> Bucket<T> {}\n    #[inline]\n    unsafe fn bucket_ptr(&self, index: usize, size_of: usize) -> *mut u8 {}\n    #[inline]\n    fn data_end<T>(&self) -> NonNull<T> {}\n    #[inline]\n    fn probe_seq(&self, hash: u64) -> ProbeSeq {}\n    #[inline]\n    unsafe fn record_item_insert_at(&mut self, index: usize, old_ctrl: Tag, hash: u64) {}\n    #[inline]\n    fn is_in_same_group(&self, i: usize, new_i: usize, hash: u64) -> bool {}\n    #[inline]\n    unsafe fn set_ctrl_hash(&mut self, index: usize, hash: u64) {\n        self.set_ctrl(index, Tag::full(hash));\n    }\n    #[inline]\n    unsafe fn replace_ctrl_hash(&mut self, index: usize, hash: u64) -> Tag {}\n    #[inline]\n    unsafe fn set_ctrl(&mut self, index: usize, ctrl: Tag) {}\n    #[inline]\n    unsafe fn ctrl(&self, index: usize) -> *mut Tag {\n        debug_assert!(index < self.num_ctrl_bytes());\n        self.ctrl.as_ptr().add(index).cast()\n    }\n    fn ctrl_slice(&mut self) -> &mut [Tag] {}\n    #[inline]\n    fn buckets(&self) -> usize {}\n    #[inline]\n    unsafe fn is_bucket_full(&self, index: usize) -> bool {}\n    #[inline]\n    fn num_ctrl_bytes(&self) -> usize {}\n    #[inline]\n    fn is_empty_singleton(&self) -> bool {}\n    #[allow(clippy::mut_mut)]\n    #[inline]\n    fn prepare_resize<'a, A>(\n        &self,\n        alloc: &'a A,\n        table_layout: TableLayout,\n        capacity: usize,\n        fallibility: Fallibility,\n    ) -> Result<\n        crate::scopeguard::ScopeGuard<Self, impl FnMut(&mut Self) + 'a>,\n        TryReserveError,\n    >\n    where\n        A: Allocator,\n    {\n        debug_assert!(self.items <= capacity);\n        let new_table = RawTableInner::fallible_with_capacity(\n            alloc,\n            table_layout,\n            capacity,\n            fallibility,\n        )?;\n        Ok(\n            guard(\n                new_table,\n                move |self_| {\n                    if !self_.is_empty_singleton() {\n                        unsafe { self_.free_buckets(alloc, table_layout) };\n                    }\n                },\n            ),\n        )\n    }\n    #[allow(clippy::inline_always)]\n    #[inline(always)]\n    unsafe fn reserve_rehash_inner<A>(\n        &mut self,\n        alloc: &A,\n        additional: usize,\n        hasher: &dyn Fn(&mut Self, usize) -> u64,\n        fallibility: Fallibility,\n        layout: TableLayout,\n        drop: Option<unsafe fn(*mut u8)>,\n    ) -> Result<(), TryReserveError>\n    where\n        A: Allocator,\n    {}\n    #[inline(always)]\n    unsafe fn full_buckets_indices(&self) -> FullBucketsIndices {}\n    #[allow(clippy::inline_always)]\n    #[inline(always)]\n    unsafe fn resize_inner<A>(\n        &mut self,\n        alloc: &A,\n        capacity: usize,\n        hasher: &dyn Fn(&mut Self, usize) -> u64,\n        fallibility: Fallibility,\n        layout: TableLayout,\n    ) -> Result<(), TryReserveError>\n    where\n        A: Allocator,\n    {}\n    #[allow(clippy::inline_always)]\n    #[cfg_attr(feature = \"inline-more\", inline(always))]\n    #[cfg_attr(not(feature = \"inline-more\"), inline)]\n    unsafe fn rehash_in_place(\n        &mut self,\n        hasher: &dyn Fn(&mut Self, usize) -> u64,\n        size_of: usize,\n        drop: Option<unsafe fn(*mut u8)>,\n    ) {}\n    #[inline]\n    unsafe fn free_buckets<A>(&mut self, alloc: &A, table_layout: TableLayout)\n    where\n        A: Allocator,\n    {}\n    #[inline]\n    unsafe fn allocation_info(\n        &self,\n        table_layout: TableLayout,\n    ) -> (NonNull<u8>, Layout) {}\n    #[inline]\n    unsafe fn allocation_size_or_zero(&self, table_layout: TableLayout) -> usize {}\n    #[inline]\n    fn clear_no_drop(&mut self) {}\n    #[inline]\n    unsafe fn erase(&mut self, index: usize) {}\n}\n\nThe function to be tested is presented with each line formatted as 'line number + code':\n/// Searches for an empty or deleted bucket which is suitable for inserting a new\n/// element and sets the hash for that slot. Returns an index of that slot and the\n/// old control byte stored in the found index.\n///\n/// This function does not check if the given element exists in the table. Also,\n/// this function does not check if there is enough space in the table to insert\n/// a new element. The caller of the function must make sure that the table has at\n/// least 1 empty or deleted `bucket`, otherwise this function will never return\n/// (will go into an infinite loop) for tables larger than the group width, or\n/// return an index outside of the table indices range if the table is less than\n/// the group width.\n///\n/// If there is at least 1 empty or deleted `bucket` in the table, the function is\n/// guaranteed to return an `index` in the range `0..self.buckets()`, but in any case,\n/// if this function returns an `index` it will be in the range `0..=self.buckets()`.\n///\n/// This function does not make any changes to the `data` parts of the table,\n/// or any changes to the `items` or `growth_left` field of the table.\n///\n/// # Safety\n///\n/// The safety rules are directly derived from the safety rules for the\n/// [`RawTableInner::set_ctrl_hash`] and [`RawTableInner::find_insert_slot`] methods.\n/// Thus, in order to uphold the safety contracts for that methods, as well as for\n/// the correct logic of the work of this crate, you must observe the following rules\n/// when calling this function:\n///\n/// * The [`RawTableInner`] has already been allocated and has properly initialized\n///   control bytes otherwise calling this function results in [`undefined behavior`].\n///\n/// * The caller of this function must ensure that the \"data\" parts of the table\n///   will have an entry in the returned index (matching the given hash) right\n///   after calling this function.\n///\n/// Attempt to write data at the `index` returned by this function when the table is\n/// less than the group width and if there was not at least one empty or deleted bucket in\n/// the table will cause immediate [`undefined behavior`]. This is because in this case the\n/// function will return `self.bucket_mask + 1` as an index due to the trailing [`Tag::EMPTY`]\n/// control bytes outside the table range.\n///\n/// The caller must independently increase the `items` field of the table, and also,\n/// if the old control byte was [`Tag::EMPTY`], then decrease the table's `growth_left`\n/// field, and do not change it if the old control byte was [`Tag::DELETED`].\n///\n/// See also [`Bucket::as_ptr`] method, for more information about of properly removing\n/// or saving `element` from / into the [`RawTable`] / [`RawTableInner`].\n///\n/// [`Bucket::as_ptr`]: Bucket::as_ptr\n/// [`undefined behavior`]: https://doc.rust-lang.org/reference/behavior-considered-undefined.html\n/// [`RawTableInner::ctrl`]: RawTableInner::ctrl\n/// [`RawTableInner::set_ctrl_hash`]: RawTableInner::set_ctrl_hash\n/// [`RawTableInner::find_insert_slot`]: RawTableInner::find_insert_slot\n1764 unsafe fn prepare_insert_slot(&mut self, hash: u64) -> (usize, Tag) {\n1765     // SAFETY: Caller of this function ensures that the control bytes are properly initialized.\n1766     let index: usize = self.find_insert_slot(hash).index;\n1767     // SAFETY:\n1768     // 1. The `find_insert_slot` function either returns an `index` less than or\n1769     //    equal to `self.buckets() = self.bucket_mask + 1` of the table, or never\n1770     //    returns if it cannot find an empty or deleted slot.\n1771     // 2. The caller of this function guarantees that the table has already been\n1772     //    allocated\n1773     let old_ctrl = *self.ctrl(index);\n1774     self.set_ctrl_hash(index, hash);\n1775     (index, old_ctrl)\n1776 }\n\nThe path conditions that the generated test functions should satisfy are as follows:\n"
}