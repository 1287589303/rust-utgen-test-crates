{
  "system_pt": "As a software testing expert, infer the test input conditions or ranges based on the provided information. Follow these guidelines:\n1. Provide test input conditions or ranges in one line in plain text only, without additional explanations or Markdown formatting\n2. Analyze the function under test, context, preconditions, and expected return values or types to determine appropriate test input conditions or ranges\n3. The inferred test input conditions or ranges should comprehensively satisfy all provided preconditions simultaneously.\n4. Ensure the test input conditions or ranges cover boundary cases and edge scenarios\n",
  "static_pt": "The context for the focal function is as follows:\n// src/raw/mod.rs\n// crate name is hashbrown\nuse crate::alloc::alloc::{handle_alloc_error, Layout};\nuse crate::control::{BitMaskIter, Group, Tag, TagSliceExt};\nuse crate::scopeguard::{guard, ScopeGuard};\nuse crate::util::{invalid_mut, likely, unlikely};\nuse crate::TryReserveError;\nuse core::array;\nuse core::iter::FusedIterator;\nuse core::marker::PhantomData;\nuse core::mem;\nuse core::ptr::NonNull;\nuse core::slice;\nuse core::{hint, ptr};\n#[cfg(test)]\npub(crate) use self::alloc::AllocError;\npub(crate) use self::alloc::{do_alloc, Allocator, Global};\npub struct Bucket<T> {\n    ptr: NonNull<T>,\n}\nimpl<T> Bucket<T> {\n    #[inline]\n    unsafe fn from_base_index(base: NonNull<T>, index: usize) -> Self {\n        let ptr = if T::IS_ZERO_SIZED {\n            invalid_mut(index + 1)\n        } else {\n            base.as_ptr().sub(index)\n        };\n        Self {\n            ptr: NonNull::new_unchecked(ptr),\n        }\n    }\n    #[inline]\n    unsafe fn to_base_index(&self, base: NonNull<T>) -> usize {\n        if T::IS_ZERO_SIZED {\n            self.ptr.as_ptr() as usize - 1\n        } else {\n            offset_from(base.as_ptr(), self.ptr.as_ptr())\n        }\n    }\n    #[inline]\n    pub fn as_ptr(&self) -> *mut T {}\n    #[inline]\n    fn as_non_null(&self) -> NonNull<T> {}\n    #[inline]\n    unsafe fn next_n(&self, offset: usize) -> Self {\n        let ptr = if T::IS_ZERO_SIZED {\n            invalid_mut(self.ptr.as_ptr() as usize + offset)\n        } else {\n            self.ptr.as_ptr().sub(offset)\n        };\n        Self {\n            ptr: NonNull::new_unchecked(ptr),\n        }\n    }\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub(crate) unsafe fn drop(&self) {}\n    #[inline]\n    pub(crate) unsafe fn read(&self) -> T {}\n    #[inline]\n    pub(crate) unsafe fn write(&self, val: T) {}\n    #[inline]\n    pub unsafe fn as_ref<'a>(&self) -> &'a T {}\n    #[inline]\n    pub unsafe fn as_mut<'a>(&self) -> &'a mut T {}\n}\n#[inline]\nunsafe fn offset_from<T>(to: *const T, from: *const T) -> usize {\n    to.offset_from(from) as usize\n}\n\nThe function to be tested is presented with each line formatted as 'line number + code':\n/// Calculates the index of a [`Bucket`] as distance between two pointers\n/// (convenience for `base.as_ptr().offset_from(self.ptr.as_ptr()) as usize`).\n/// The returned value is in units of T: the distance in bytes divided by\n/// [`core::mem::size_of::<T>()`].\n///\n/// If the `T` is a ZST, then we return the index of the element in\n/// the table so that `erase` works properly (return `self.ptr.as_ptr() as usize - 1`).\n///\n/// This function is the inverse of [`from_base_index`].\n///\n/// # Safety\n///\n/// If `mem::size_of::<T>() != 0`, then the safety rules are directly derived\n/// from the safety rules for [`<*const T>::offset_from`] method of `*const T`.\n///\n/// Thus, in order to uphold the safety contracts for [`<*const T>::offset_from`]\n/// method, as well as for the correct logic of the work of this crate, the\n/// following rules are necessary and sufficient:\n///\n/// * `base` contained pointer must not be `dangling` and must point to the\n///   end of the first `element` from the `data part` of the table, i.e.\n///   must be a pointer that returns by [`RawTable::data_end`] or by\n///   [`RawTableInner::data_end<T>`];\n///\n/// * `self` also must not contain dangling pointer;\n///\n/// * both `self` and `base` must be created from the same [`RawTable`]\n///   (or [`RawTableInner`]).\n///\n/// If `mem::size_of::<T>() == 0`, this function is always safe.\n///\n/// [`Bucket`]: crate::raw::Bucket\n/// [`from_base_index`]: crate::raw::Bucket::from_base_index\n/// [`RawTable::data_end`]: crate::raw::RawTable::data_end\n/// [`RawTableInner::data_end<T>`]: RawTableInner::data_end<T>\n/// [`RawTable`]: crate::raw::RawTable\n/// [`RawTableInner`]: RawTableInner\n/// [`<*const T>::offset_from`]: https://doc.rust-lang.org/nightly/core/primitive.pointer.html#method.offset_from\n336 unsafe fn to_base_index(&self, base: NonNull<T>) -> usize {\n337     // If mem::size_of::<T>() != 0 then return an index under which we used to store the\n338     // `element` in the data part of the table (we start counting from \"0\", so\n339     // that in the expression T[last], the \"last\" index actually is one less than the\n340     // \"buckets\" number in the table, i.e. \"last = RawTableInner.bucket_mask\").\n341     // For example for 5th element in table calculation is performed like this:\n342     //\n343     //                        mem::size_of::<T>()\n344     //                          |\n345     //                          |         `self = from_base_index(base, 5)` that returns pointer\n346     //                          |         that points here in the data part of the table\n347     //                          |         (to the end of T5)\n348     //                          |           |                    `base: NonNull<T>` must point here\n349     //                          v           |                    (to the end of T0 or to the start of C0)\n350     //                        /???\\         v                      v\n351     // [Padding], Tlast, ..., |T10|, ..., T5|, T4, T3, T2, T1, T0, |C0, C1, C2, C3, C4, C5, ..., C10, ..., Clast\n352     //                                      \\__________  __________/\n353     //                                                 \\/\n354     //                                     `bucket.to_base_index(base)` = 5\n355     //                                     (base.as_ptr() as usize - self.ptr.as_ptr() as usize) / mem::size_of::<T>()\n356     //\n357     // where: T0...Tlast - our stored data; C0...Clast - control bytes or metadata for data.\n358     if T::IS_ZERO_SIZED {\n359         // this can not be UB\n360         self.ptr.as_ptr() as usize - 1\n361     } else {\n362         offset_from(base.as_ptr(), self.ptr.as_ptr())\n363     }\n364 }\n\nWhen inferring test input conditions or ranges, consider the following preconditions and expected return values or types:\n"
}