{
  "system_pt": "As a software testing expert, please generate accurate test oracles code based on the provided information. Follow these guidelines:\n1. Generate executable test oracle codes in plain text format, one per line. Do not output complete test functions, avoid additional explanations, and do not use Markdown.\n2. Combine the given function under test, context, relevant documentation, preconditions, expected return values or types, test input conditions or ranges, and existing test function prefixes to infer and generate corresponding test oracles code.\n3. Only generate necessary test oracles to ensure comprehensive validation.\n",
  "static_pt": "The context for the focal function is as follows:\n// src/raw/mod.rs\n// crate name is hashbrown\nuse crate::alloc::alloc::{handle_alloc_error, Layout};\nuse crate::control::{BitMaskIter, Group, Tag, TagSliceExt};\nuse crate::scopeguard::{guard, ScopeGuard};\nuse crate::util::{invalid_mut, likely, unlikely};\nuse crate::TryReserveError;\nuse core::array;\nuse core::iter::FusedIterator;\nuse core::marker::PhantomData;\nuse core::mem;\nuse core::ptr::NonNull;\nuse core::slice;\nuse core::{hint, ptr};\n#[cfg(test)]\npub(crate) use self::alloc::AllocError;\npub(crate) use self::alloc::{do_alloc, Allocator, Global};\nstruct RawTableInner {\n    bucket_mask: usize,\n    ctrl: NonNull<u8>,\n    growth_left: usize,\n    items: usize,\n}\n#[derive(Copy, Clone)]\nstruct TableLayout {\n    size: usize,\n    ctrl_align: usize,\n}\n#[derive(Copy, Clone)]\nenum Fallibility {\n    Fallible,\n    Infallible,\n}\n#[derive(Clone, PartialEq, Eq, Debug)]\npub enum TryReserveError {\n    /// Error due to the computed capacity exceeding the collection's maximum\n    /// (usually `isize::MAX` bytes).\n    CapacityOverflow,\n    /// The memory allocator returned an error\n    AllocError {\n        /// The layout of the allocation request that failed.\n        layout: alloc::alloc::Layout,\n    },\n}\nimpl RawTableInner {\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    unsafe fn new_uninitialized<A>(\n        alloc: &A,\n        table_layout: TableLayout,\n        buckets: usize,\n        fallibility: Fallibility,\n    ) -> Result<Self, TryReserveError>\n    where\n        A: Allocator,\n    {\n        debug_assert!(buckets.is_power_of_two());\n        let (layout, ctrl_offset) = match table_layout.calculate_layout_for(buckets) {\n            Some(lco) => lco,\n            None => return Err(fallibility.capacity_overflow()),\n        };\n        let ptr: NonNull<u8> = match do_alloc(alloc, layout) {\n            Ok(block) => block.cast(),\n            Err(_) => return Err(fallibility.alloc_err(layout)),\n        };\n        let ctrl = NonNull::new_unchecked(ptr.as_ptr().add(ctrl_offset));\n        Ok(Self {\n            ctrl,\n            bucket_mask: buckets - 1,\n            items: 0,\n            growth_left: bucket_mask_to_capacity(buckets - 1),\n        })\n    }\n    #[inline]\n    fn fallible_with_capacity<A>(\n        alloc: &A,\n        table_layout: TableLayout,\n        capacity: usize,\n        fallibility: Fallibility,\n    ) -> Result<Self, TryReserveError>\n    where\n        A: Allocator,\n    {\n        if capacity == 0 {\n            Ok(Self::NEW)\n        } else {\n            unsafe {\n                let buckets = capacity_to_buckets(capacity)\n                    .ok_or_else(|| fallibility.capacity_overflow())?;\n                let mut result = Self::new_uninitialized(\n                    alloc,\n                    table_layout,\n                    buckets,\n                    fallibility,\n                )?;\n                result.ctrl_slice().fill_empty();\n                Ok(result)\n            }\n        }\n    }\n    fn with_capacity<A>(alloc: &A, table_layout: TableLayout, capacity: usize) -> Self\n    where\n        A: Allocator,\n    {\n        match Self::fallible_with_capacity(\n            alloc,\n            table_layout,\n            capacity,\n            Fallibility::Infallible,\n        ) {\n            Ok(table_inner) => table_inner,\n            Err(_) => unsafe { hint::unreachable_unchecked() }\n        }\n    }\n    #[inline]\n    unsafe fn fix_insert_slot(&self, mut index: usize) -> InsertSlot {}\n    #[inline]\n    fn find_insert_slot_in_group(\n        &self,\n        group: &Group,\n        probe_seq: &ProbeSeq,\n    ) -> Option<usize> {}\n    #[inline]\n    unsafe fn find_or_find_insert_slot_inner(\n        &self,\n        hash: u64,\n        eq: &mut dyn FnMut(usize) -> bool,\n    ) -> Result<usize, InsertSlot> {}\n    #[inline]\n    unsafe fn prepare_insert_slot(&mut self, hash: u64) -> (usize, Tag) {}\n    #[inline]\n    unsafe fn find_insert_slot(&self, hash: u64) -> InsertSlot {}\n    #[inline(always)]\n    unsafe fn find_inner(\n        &self,\n        hash: u64,\n        eq: &mut dyn FnMut(usize) -> bool,\n    ) -> Option<usize> {}\n    #[allow(clippy::mut_mut)]\n    #[inline]\n    unsafe fn prepare_rehash_in_place(&mut self) {}\n    #[inline]\n    unsafe fn iter<T>(&self) -> RawIter<T> {}\n    unsafe fn drop_elements<T>(&mut self) {}\n    unsafe fn drop_inner_table<T, A: Allocator>(\n        &mut self,\n        alloc: &A,\n        table_layout: TableLayout,\n    ) {}\n    #[inline]\n    unsafe fn bucket<T>(&self, index: usize) -> Bucket<T> {}\n    #[inline]\n    unsafe fn bucket_ptr(&self, index: usize, size_of: usize) -> *mut u8 {}\n    #[inline]\n    fn data_end<T>(&self) -> NonNull<T> {}\n    #[inline]\n    fn probe_seq(&self, hash: u64) -> ProbeSeq {}\n    #[inline]\n    unsafe fn record_item_insert_at(&mut self, index: usize, old_ctrl: Tag, hash: u64) {}\n    #[inline]\n    fn is_in_same_group(&self, i: usize, new_i: usize, hash: u64) -> bool {}\n    #[inline]\n    unsafe fn set_ctrl_hash(&mut self, index: usize, hash: u64) {}\n    #[inline]\n    unsafe fn replace_ctrl_hash(&mut self, index: usize, hash: u64) -> Tag {}\n    #[inline]\n    unsafe fn set_ctrl(&mut self, index: usize, ctrl: Tag) {}\n    #[inline]\n    unsafe fn ctrl(&self, index: usize) -> *mut Tag {}\n    fn ctrl_slice(&mut self) -> &mut [Tag] {}\n    #[inline]\n    fn buckets(&self) -> usize {}\n    #[inline]\n    unsafe fn is_bucket_full(&self, index: usize) -> bool {}\n    #[inline]\n    fn num_ctrl_bytes(&self) -> usize {}\n    #[inline]\n    fn is_empty_singleton(&self) -> bool {}\n    #[allow(clippy::mut_mut)]\n    #[inline]\n    fn prepare_resize<'a, A>(\n        &self,\n        alloc: &'a A,\n        table_layout: TableLayout,\n        capacity: usize,\n        fallibility: Fallibility,\n    ) -> Result<\n        crate::scopeguard::ScopeGuard<Self, impl FnMut(&mut Self) + 'a>,\n        TryReserveError,\n    >\n    where\n        A: Allocator,\n    {\n        debug_assert!(self.items <= capacity);\n        let new_table = RawTableInner::fallible_with_capacity(\n            alloc,\n            table_layout,\n            capacity,\n            fallibility,\n        )?;\n        Ok(\n            guard(\n                new_table,\n                move |self_| {\n                    if !self_.is_empty_singleton() {\n                        unsafe { self_.free_buckets(alloc, table_layout) };\n                    }\n                },\n            ),\n        )\n    }\n    #[allow(clippy::inline_always)]\n    #[inline(always)]\n    unsafe fn reserve_rehash_inner<A>(\n        &mut self,\n        alloc: &A,\n        additional: usize,\n        hasher: &dyn Fn(&mut Self, usize) -> u64,\n        fallibility: Fallibility,\n        layout: TableLayout,\n        drop: Option<unsafe fn(*mut u8)>,\n    ) -> Result<(), TryReserveError>\n    where\n        A: Allocator,\n    {\n        let new_items = match self.items.checked_add(additional) {\n            Some(new_items) => new_items,\n            None => return Err(fallibility.capacity_overflow()),\n        };\n        let full_capacity = bucket_mask_to_capacity(self.bucket_mask);\n        if new_items <= full_capacity / 2 {\n            self.rehash_in_place(hasher, layout.size, drop);\n            Ok(())\n        } else {\n            self.resize_inner(\n                alloc,\n                usize::max(new_items, full_capacity + 1),\n                hasher,\n                fallibility,\n                layout,\n            )\n        }\n    }\n    #[inline(always)]\n    unsafe fn full_buckets_indices(&self) -> FullBucketsIndices {}\n    #[allow(clippy::inline_always)]\n    #[inline(always)]\n    unsafe fn resize_inner<A>(\n        &mut self,\n        alloc: &A,\n        capacity: usize,\n        hasher: &dyn Fn(&mut Self, usize) -> u64,\n        fallibility: Fallibility,\n        layout: TableLayout,\n    ) -> Result<(), TryReserveError>\n    where\n        A: Allocator,\n    {\n        let mut new_table = self.prepare_resize(alloc, layout, capacity, fallibility)?;\n        for full_byte_index in self.full_buckets_indices() {\n            let hash = hasher(self, full_byte_index);\n            let (new_index, _) = new_table.prepare_insert_slot(hash);\n            ptr::copy_nonoverlapping(\n                self.bucket_ptr(full_byte_index, layout.size),\n                new_table.bucket_ptr(new_index, layout.size),\n                layout.size,\n            );\n        }\n        new_table.growth_left -= self.items;\n        new_table.items = self.items;\n        mem::swap(self, &mut new_table);\n        Ok(())\n    }\n    #[allow(clippy::inline_always)]\n    #[cfg_attr(feature = \"inline-more\", inline(always))]\n    #[cfg_attr(not(feature = \"inline-more\"), inline)]\n    unsafe fn rehash_in_place(\n        &mut self,\n        hasher: &dyn Fn(&mut Self, usize) -> u64,\n        size_of: usize,\n        drop: Option<unsafe fn(*mut u8)>,\n    ) {\n        self.prepare_rehash_in_place();\n        let mut guard = guard(\n            self,\n            move |self_| {\n                if let Some(drop) = drop {\n                    for i in 0..self_.buckets() {\n                        if *self_.ctrl(i) == Tag::DELETED {\n                            self_.set_ctrl(i, Tag::EMPTY);\n                            drop(self_.bucket_ptr(i, size_of));\n                            self_.items -= 1;\n                        }\n                    }\n                }\n                self_.growth_left = bucket_mask_to_capacity(self_.bucket_mask)\n                    - self_.items;\n            },\n        );\n        'outer: for i in 0..guard.buckets() {\n            if *guard.ctrl(i) != Tag::DELETED {\n                continue;\n            }\n            let i_p = guard.bucket_ptr(i, size_of);\n            'inner: loop {\n                let hash = hasher(*guard, i);\n                let new_i = guard.find_insert_slot(hash).index;\n                if likely(guard.is_in_same_group(i, new_i, hash)) {\n                    guard.set_ctrl_hash(i, hash);\n                    continue 'outer;\n                }\n                let new_i_p = guard.bucket_ptr(new_i, size_of);\n                let prev_ctrl = guard.replace_ctrl_hash(new_i, hash);\n                if prev_ctrl == Tag::EMPTY {\n                    guard.set_ctrl(i, Tag::EMPTY);\n                    ptr::copy_nonoverlapping(i_p, new_i_p, size_of);\n                    continue 'outer;\n                } else {\n                    debug_assert_eq!(prev_ctrl, Tag::DELETED);\n                    ptr::swap_nonoverlapping(i_p, new_i_p, size_of);\n                    continue 'inner;\n                }\n            }\n        }\n        guard.growth_left = bucket_mask_to_capacity(guard.bucket_mask) - guard.items;\n        mem::forget(guard);\n    }\n    #[inline]\n    unsafe fn free_buckets<A>(&mut self, alloc: &A, table_layout: TableLayout)\n    where\n        A: Allocator,\n    {}\n    #[inline]\n    unsafe fn allocation_info(\n        &self,\n        table_layout: TableLayout,\n    ) -> (NonNull<u8>, Layout) {}\n    #[inline]\n    unsafe fn allocation_size_or_zero(&self, table_layout: TableLayout) -> usize {}\n    #[inline]\n    fn clear_no_drop(&mut self) {}\n    #[inline]\n    unsafe fn erase(&mut self, index: usize) {}\n}\nimpl Fallibility {\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn capacity_overflow(self) -> TryReserveError {\n        match self {\n            Fallibility::Fallible => TryReserveError::CapacityOverflow,\n            Fallibility::Infallible => panic!(\"Hash table capacity overflow\"),\n        }\n    }\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn alloc_err(self, layout: Layout) -> TryReserveError {}\n}\n#[inline]\nfn bucket_mask_to_capacity(bucket_mask: usize) -> usize {\n    if bucket_mask < 8 { bucket_mask } else { ((bucket_mask + 1) / 8) * 7 }\n}\n\nThe function to be tested is presented with each line formatted as 'line number + code':\n/// Reserves or rehashes to make room for `additional` more elements.\n///\n/// This uses dynamic dispatch to reduce the amount of\n/// code generated, but it is eliminated by LLVM optimizations when inlined.\n///\n/// # Safety\n///\n/// If any of the following conditions are violated, the result is\n/// [`undefined behavior`]:\n///\n/// * The `alloc` must be the same [`Allocator`] as the `Allocator` used\n///   to allocate this table.\n///\n/// * The `layout` must be the same [`TableLayout`] as the `TableLayout`\n///   used to allocate this table.\n///\n/// * The `drop` function (`fn(*mut u8)`) must be the actual drop function of\n///   the elements stored in the table.\n///\n/// * The [`RawTableInner`] must have properly initialized control bytes.\n///\n/// [`undefined behavior`]: https://doc.rust-lang.org/reference/behavior-considered-undefined.html\n2596 unsafe fn reserve_rehash_inner<A>(\n2597     &mut self,\n2598     alloc: &A,\n2599     additional: usize,\n2600     hasher: &dyn Fn(&mut Self, usize) -> u64,\n2601     fallibility: Fallibility,\n2602     layout: TableLayout,\n2603     drop: Option<unsafe fn(*mut u8)>,\n2604 ) -> Result<(), TryReserveError>\n2605 where\n2606     A: Allocator,\n2607 {\n2608     // Avoid `Option::ok_or_else` because it bloats LLVM IR.\n2609     let new_items = match self.items.checked_add(additional) {\n2610         Some(new_items) => new_items,\n2611         None => return Err(fallibility.capacity_overflow()),\n2612     };\n2613     let full_capacity = bucket_mask_to_capacity(self.bucket_mask);\n2614     if new_items <= full_capacity / 2 {\n2615         // Rehash in-place without re-allocating if we have plenty of spare\n2616         // capacity that is locked up due to DELETED entries.\n2617 \n2618         // SAFETY:\n2619         // 1. We know for sure that `[`RawTableInner`]` has already been allocated\n2620         //    (since new_items <= full_capacity / 2);\n2621         // 2. The caller ensures that `drop` function is the actual drop function of\n2622         //    the elements stored in the table.\n2623         // 3. The caller ensures that `layout` matches the [`TableLayout`] that was\n2624         //    used to allocate this table.\n2625         // 4. The caller ensures that the control bytes of the `RawTableInner`\n2626         //    are already initialized.\n2627         self.rehash_in_place(hasher, layout.size, drop);\n2628         Ok(())\n2629     } else {\n2630         // Otherwise, conservatively resize to at least the next size up\n2631         // to avoid churning deletes into frequent rehashes.\n2632         //\n2633         // SAFETY:\n2634         // 1. We know for sure that `capacity >= self.items`.\n2635         // 2. The caller ensures that `alloc` and `layout` matches the [`Allocator`] and\n2636         //    [`TableLayout`] that were used to allocate this table.\n2637         // 3. The caller ensures that the control bytes of the `RawTableInner`\n2638         //    are already initialized.\n2639         self.resize_inner(\n2640             alloc,\n2641             usize::max(new_items, full_capacity + 1),\n2642             hasher,\n2643             fallibility,\n2644             layout,\n2645         )\n2646     }\n2647 }\n\nThe path conditions that the generated test functions should satisfy are as follows:\n"
}