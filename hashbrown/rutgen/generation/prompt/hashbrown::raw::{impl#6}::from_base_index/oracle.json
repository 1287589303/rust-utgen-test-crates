{
  "system_pt": "As a software testing expert, please generate accurate test oracles code based on the provided information. Follow these guidelines:\n1. Generate executable test oracle codes in plain text format, one per line. Do not output complete test functions, avoid additional explanations, and do not use Markdown.\n2. Combine the given function under test, context, relevant documentation, preconditions, expected return values or types, test input conditions or ranges, and existing test function prefixes to infer and generate corresponding test oracles code.\n3. Only generate necessary test oracles to ensure comprehensive validation.\n",
  "static_pt": "The context for the focal function is as follows:\n// src/raw/mod.rs\n// crate name is hashbrown\nuse crate::alloc::alloc::{handle_alloc_error, Layout};\nuse crate::control::{BitMaskIter, Group, Tag, TagSliceExt};\nuse crate::scopeguard::{guard, ScopeGuard};\nuse crate::util::{invalid_mut, likely, unlikely};\nuse crate::TryReserveError;\nuse core::array;\nuse core::iter::FusedIterator;\nuse core::marker::PhantomData;\nuse core::mem;\nuse core::ptr::NonNull;\nuse core::slice;\nuse core::{hint, ptr};\n#[cfg(test)]\npub(crate) use self::alloc::AllocError;\npub(crate) use self::alloc::{do_alloc, Allocator, Global};\npub struct Bucket<T> {\n    ptr: NonNull<T>,\n}\nimpl<T> Bucket<T> {\n    #[inline]\n    unsafe fn from_base_index(base: NonNull<T>, index: usize) -> Self {\n        let ptr = if T::IS_ZERO_SIZED {\n            invalid_mut(index + 1)\n        } else {\n            base.as_ptr().sub(index)\n        };\n        Self {\n            ptr: NonNull::new_unchecked(ptr),\n        }\n    }\n    #[inline]\n    unsafe fn to_base_index(&self, base: NonNull<T>) -> usize {}\n    #[inline]\n    pub fn as_ptr(&self) -> *mut T {}\n    #[inline]\n    fn as_non_null(&self) -> NonNull<T> {}\n    #[inline]\n    unsafe fn next_n(&self, offset: usize) -> Self {\n        let ptr = if T::IS_ZERO_SIZED {\n            invalid_mut(self.ptr.as_ptr() as usize + offset)\n        } else {\n            self.ptr.as_ptr().sub(offset)\n        };\n        Self {\n            ptr: NonNull::new_unchecked(ptr),\n        }\n    }\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub(crate) unsafe fn drop(&self) {}\n    #[inline]\n    pub(crate) unsafe fn read(&self) -> T {}\n    #[inline]\n    pub(crate) unsafe fn write(&self, val: T) {}\n    #[inline]\n    pub unsafe fn as_ref<'a>(&self) -> &'a T {}\n    #[inline]\n    pub unsafe fn as_mut<'a>(&self) -> &'a mut T {}\n}\n#[inline(always)]\n#[allow(clippy::useless_transmute)]\npub(crate) fn invalid_mut<T>(addr: usize) -> *mut T {\n    unsafe { core::mem::transmute(addr) }\n}\n\nThe function to be tested is presented with each line formatted as 'line number + code':\n/// Creates a [`Bucket`] that contain pointer to the data.\n/// The pointer calculation is performed by calculating the\n/// offset from given `base` pointer (convenience for\n/// `base.as_ptr().sub(index)`).\n///\n/// `index` is in units of `T`; e.g., an `index` of 3 represents a pointer\n/// offset of `3 * size_of::<T>()` bytes.\n///\n/// If the `T` is a ZST, then we instead track the index of the element\n/// in the table so that `erase` works properly (return\n/// `NonNull::new_unchecked((index + 1) as *mut T)`)\n///\n/// # Safety\n///\n/// If `mem::size_of::<T>() != 0`, then the safety rules are directly derived\n/// from the safety rules for [`<*mut T>::sub`] method of `*mut T` and the safety\n/// rules of [`NonNull::new_unchecked`] function.\n///\n/// Thus, in order to uphold the safety contracts for the [`<*mut T>::sub`] method\n/// and [`NonNull::new_unchecked`] function, as well as for the correct\n/// logic of the work of this crate, the following rules are necessary and\n/// sufficient:\n///\n/// * the `base` pointer must not be `dangling` and must points to the\n///   end of the first `value element` from the `data part` of the table, i.e.\n///   must be the pointer that returned by [`RawTable::data_end`] or by\n///   [`RawTableInner::data_end<T>`];\n///\n/// * `index` must not be greater than `RawTableInner.bucket_mask`, i.e.\n///   `index <= RawTableInner.bucket_mask` or, in other words, `(index + 1)`\n///   must be no greater than the number returned by the function\n///   [`RawTable::buckets`] or [`RawTableInner::buckets`].\n///\n/// If `mem::size_of::<T>() == 0`, then the only requirement is that the\n/// `index` must not be greater than `RawTableInner.bucket_mask`, i.e.\n/// `index <= RawTableInner.bucket_mask` or, in other words, `(index + 1)`\n/// must be no greater than the number returned by the function\n/// [`RawTable::buckets`] or [`RawTableInner::buckets`].\n///\n/// [`Bucket`]: crate::raw::Bucket\n/// [`<*mut T>::sub`]: https://doc.rust-lang.org/core/primitive.pointer.html#method.sub-1\n/// [`NonNull::new_unchecked`]: https://doc.rust-lang.org/stable/std/ptr/struct.NonNull.html#method.new_unchecked\n/// [`RawTable::data_end`]: crate::raw::RawTable::data_end\n/// [`RawTableInner::data_end<T>`]: RawTableInner::data_end<T>\n/// [`RawTable::buckets`]: crate::raw::RawTable::buckets\n/// [`RawTableInner::buckets`]: RawTableInner::buckets\n263 unsafe fn from_base_index(base: NonNull<T>, index: usize) -> Self {\n264     // If mem::size_of::<T>() != 0 then return a pointer to an `element` in\n265     // the data part of the table (we start counting from \"0\", so that\n266     // in the expression T[last], the \"last\" index actually one less than the\n267     // \"buckets\" number in the table, i.e. \"last = RawTableInner.bucket_mask\"):\n268     //\n269     //                   `from_base_index(base, 1).as_ptr()` returns a pointer that\n270     //                   points here in the data part of the table\n271     //                   (to the start of T1)\n272     //                        |\n273     //                        |        `base: NonNull<T>` must point here\n274     //                        |         (to the end of T0 or to the start of C0)\n275     //                        v         v\n276     // [Padding], Tlast, ..., |T1|, T0, |C0, C1, ..., Clast\n277     //                           ^\n278     //                           `from_base_index(base, 1)` returns a pointer\n279     //                           that points here in the data part of the table\n280     //                           (to the end of T1)\n281     //\n282     // where: T0...Tlast - our stored data; C0...Clast - control bytes\n283     // or metadata for data.\n284     let ptr = if T::IS_ZERO_SIZED {\n285         // won't overflow because index must be less than length (bucket_mask)\n286         // and bucket_mask is guaranteed to be less than `isize::MAX`\n287         // (see TableLayout::calculate_layout_for method)\n288         invalid_mut(index + 1)\n289     } else {\n290         base.as_ptr().sub(index)\n291     };\n292     Self {\n293         ptr: NonNull::new_unchecked(ptr),\n294     }\n295 }\n\nThe path conditions that the generated test functions should satisfy are as follows:\n"
}