{
  "system_pt": "As a software testing expert, please generate Rust test functions based on the following guidelines:\n1. Provide the code in plain text format, without explanations or Markdown.\n2. If the method under test belongs to a trait, construct appropriate structs within the test function, but avoid method overrides. If the method under test uses generics, instantiate them with suitable types based on the context.\n3. Generate test code with minimal scope: avoid creating external structures or implementations. Instead, define any necessary helper structures or implementations directly within the test function when required.\n4. Whenever possible, initialize the corresponding data structures using the initialization methods provided in the context if exist.\n5. Ensure the generated function is fully implemented and can be compiled and executed directly without any missing parts.\n6. Create a minimal yet complete set of test functions, ensuring they adhere to all provided preconditions and cover boundary conditions.\n7. Do not create a test module, but include intrinsic attributes like #[test] or #[should_panic] where necessary.\n",
  "static_pt": "The context for the focal function is as follows:\n// src/read/decoder.rs\n// crate name is base64\nuse crate::{engine::Engine, DecodeError, DecodeSliceError, PAD_BYTE};\nuse std::{cmp, fmt, io};\npub(crate) const BUF_SIZE: usize = 1024;\nconst BASE64_CHUNK_SIZE: usize = 4;\nconst DECODED_CHUNK_SIZE: usize = 3;\npub trait Engine: Send + Sync {\n    type Config: Config;\n    type DecodeEstimate: DecodeEstimate;\n    fn internal_encode(&self, input: &[u8], output: &mut [u8]) -> usize;\n    fn internal_decoded_len_estimate(&self, input_len: usize) -> Self::DecodeEstimate;\n    fn internal_decode(\n        &self,\n        input: &[u8],\n        output: &mut [u8],\n        decode_estimate: Self::DecodeEstimate,\n    ) -> Result<DecodeMetadata, DecodeSliceError>;\n    fn config(&self) -> &Self::Config;\n    #[cfg(any(feature = \"alloc\", test))]\n    #[inline]\n    fn encode<T: AsRef<[u8]>>(&self, input: T) -> String;\n    #[cfg(any(feature = \"alloc\", test))]\n    #[inline]\n    fn encode_string<T: AsRef<[u8]>>(&self, input: T, output_buf: &mut String);\n    #[cfg_attr(feature = \"alloc\", doc = \"```\")]\n    #[cfg_attr(not(feature = \"alloc\"), doc = \"```ignore\")]\n    #[inline]\n    fn encode_slice<T: AsRef<[u8]>>(\n        &self,\n        input: T,\n        output_buf: &mut [u8],\n    ) -> Result<usize, EncodeSliceError>;\n    #[cfg(any(feature = \"alloc\", test))]\n    #[inline]\n    fn decode<T: AsRef<[u8]>>(&self, input: T) -> Result<Vec<u8>, DecodeError>;\n    #[cfg(any(feature = \"alloc\", test))]\n    #[inline]\n    fn decode_vec<T: AsRef<[u8]>>(\n        &self,\n        input: T,\n        buffer: &mut Vec<u8>,\n    ) -> Result<(), DecodeError>;\n    #[inline]\n    fn decode_slice<T: AsRef<[u8]>>(\n        &self,\n        input: T,\n        output: &mut [u8],\n    ) -> Result<usize, DecodeSliceError>;\n    #[inline]\n    fn decode_slice_unchecked<T: AsRef<[u8]>>(\n        &self,\n        input: T,\n        output: &mut [u8],\n    ) -> Result<usize, DecodeError>;\n}\npub struct DecoderReader<'e, E: Engine, R: io::Read> {\n    engine: &'e E,\n    /// Where b64 data is read from\n    inner: R,\n    /// Holds b64 data read from the delegate reader.\n    b64_buffer: [u8; BUF_SIZE],\n    /// The start of the pending buffered data in `b64_buffer`.\n    b64_offset: usize,\n    /// The amount of buffered b64 data after `b64_offset` in `b64_len`.\n    b64_len: usize,\n    /// Since the caller may provide us with a buffer of size 1 or 2 that's too small to copy a\n    /// decoded chunk in to, we have to be able to hang on to a few decoded bytes.\n    /// Technically we only need to hold 2 bytes, but then we'd need a separate temporary buffer to\n    /// decode 3 bytes into and then juggle copying one byte into the provided read buf and the rest\n    /// into here, which seems like a lot of complexity for 1 extra byte of storage.\n    decoded_chunk_buffer: [u8; DECODED_CHUNK_SIZE],\n    /// Index of start of decoded data in `decoded_chunk_buffer`\n    decoded_offset: usize,\n    /// Length of decoded data after `decoded_offset` in `decoded_chunk_buffer`\n    decoded_len: usize,\n    /// Input length consumed so far.\n    /// Used to provide accurate offsets in errors\n    input_consumed_len: usize,\n    /// offset of previously seen padding, if any\n    padding_offset: Option<usize>,\n}\nimpl<'e, E: Engine, R: io::Read> io::Read for DecoderReader<'e, E, R> {\n    fn read(&mut self, buf: &mut [u8]) -> io::Result<usize> {\n        if buf.is_empty() {\n            return Ok(0);\n        }\n        debug_assert!(self.b64_offset <= BUF_SIZE);\n        debug_assert!(self.b64_offset + self.b64_len <= BUF_SIZE);\n        debug_assert!(\n            if self.b64_offset == BUF_SIZE { self.b64_len == 0 } else { self.b64_len <=\n            BUF_SIZE }\n        );\n        debug_assert!(\n            if self.decoded_len == 0 { self.decoded_offset <= DECODED_CHUNK_SIZE } else {\n            self.decoded_offset < DECODED_CHUNK_SIZE }\n        );\n        debug_assert!(self.decoded_len < DECODED_CHUNK_SIZE);\n        debug_assert!(self.decoded_len + self.decoded_offset <= DECODED_CHUNK_SIZE);\n        if self.decoded_len > 0 {\n            self.flush_decoded_buf(buf)\n        } else {\n            let mut at_eof = false;\n            while self.b64_len < BASE64_CHUNK_SIZE {\n                self.b64_buffer\n                    .copy_within(self.b64_offset..self.b64_offset + self.b64_len, 0);\n                self.b64_offset = 0;\n                let read = self.read_from_delegate()?;\n                if read == 0 {\n                    at_eof = true;\n                    break;\n                }\n            }\n            if self.b64_len == 0 {\n                debug_assert!(at_eof);\n                return Ok(0);\n            }\n            debug_assert!(\n                if at_eof { self.b64_len > 0 } else { self.b64_len >= BASE64_CHUNK_SIZE }\n            );\n            debug_assert_eq!(0, self.decoded_len);\n            if buf.len() < DECODED_CHUNK_SIZE {\n                let mut decoded_chunk = [0_u8; DECODED_CHUNK_SIZE];\n                let to_decode = cmp::min(self.b64_len, BASE64_CHUNK_SIZE);\n                let decoded = self.decode_to_buf(to_decode, &mut decoded_chunk[..])?;\n                self.decoded_chunk_buffer[..decoded]\n                    .copy_from_slice(&decoded_chunk[..decoded]);\n                self.decoded_offset = 0;\n                self.decoded_len = decoded;\n                debug_assert!(decoded <= 3);\n                self.flush_decoded_buf(buf)\n            } else {\n                let b64_bytes_that_can_decode_into_buf = (buf.len() / DECODED_CHUNK_SIZE)\n                    .checked_mul(BASE64_CHUNK_SIZE)\n                    .expect(\"too many chunks\");\n                debug_assert!(b64_bytes_that_can_decode_into_buf >= BASE64_CHUNK_SIZE);\n                let b64_bytes_available_to_decode = if at_eof {\n                    self.b64_len\n                } else {\n                    self.b64_len - self.b64_len % 4\n                };\n                let actual_decode_len = cmp::min(\n                    b64_bytes_that_can_decode_into_buf,\n                    b64_bytes_available_to_decode,\n                );\n                self.decode_to_buf(actual_decode_len, buf)\n            }\n        }\n    }\n}\nimpl<'e, E: Engine, R: io::Read> DecoderReader<'e, E, R> {\n    pub fn new(reader: R, engine: &'e E) -> Self {\n        DecoderReader {\n            engine,\n            inner: reader,\n            b64_buffer: [0; BUF_SIZE],\n            b64_offset: 0,\n            b64_len: 0,\n            decoded_chunk_buffer: [0; DECODED_CHUNK_SIZE],\n            decoded_offset: 0,\n            decoded_len: 0,\n            input_consumed_len: 0,\n            padding_offset: None,\n        }\n    }\n    fn flush_decoded_buf(&mut self, buf: &mut [u8]) -> io::Result<usize> {\n        debug_assert!(self.decoded_len > 0);\n        debug_assert!(! buf.is_empty());\n        let copy_len = cmp::min(self.decoded_len, buf.len());\n        debug_assert!(copy_len > 0);\n        debug_assert!(copy_len <= self.decoded_len);\n        buf[..copy_len]\n            .copy_from_slice(\n                &self\n                    .decoded_chunk_buffer[self\n                    .decoded_offset..self.decoded_offset + copy_len],\n            );\n        self.decoded_offset += copy_len;\n        self.decoded_len -= copy_len;\n        debug_assert!(self.decoded_len < DECODED_CHUNK_SIZE);\n        Ok(copy_len)\n    }\n    fn read_from_delegate(&mut self) -> io::Result<usize> {\n        debug_assert!(self.b64_offset + self.b64_len < BUF_SIZE);\n        let read = self\n            .inner\n            .read(&mut self.b64_buffer[self.b64_offset + self.b64_len..])?;\n        self.b64_len += read;\n        debug_assert!(self.b64_offset + self.b64_len <= BUF_SIZE);\n        Ok(read)\n    }\n    fn decode_to_buf(\n        &mut self,\n        b64_len_to_decode: usize,\n        buf: &mut [u8],\n    ) -> io::Result<usize> {\n        debug_assert!(self.b64_len >= b64_len_to_decode);\n        debug_assert!(self.b64_offset + self.b64_len <= BUF_SIZE);\n        debug_assert!(! buf.is_empty());\n        let b64_to_decode = &self\n            .b64_buffer[self.b64_offset..self.b64_offset + b64_len_to_decode];\n        let decode_metadata = self\n            .engine\n            .internal_decode(\n                b64_to_decode,\n                buf,\n                self.engine.internal_decoded_len_estimate(b64_len_to_decode),\n            )\n            .map_err(|dse| match dse {\n                DecodeSliceError::DecodeError(de) => {\n                    match de {\n                        DecodeError::InvalidByte(offset, byte) => {\n                            match (byte, self.padding_offset) {\n                                (PAD_BYTE, Some(first_pad_offset)) => {\n                                    DecodeError::InvalidByte(first_pad_offset, PAD_BYTE)\n                                }\n                                _ => {\n                                    DecodeError::InvalidByte(\n                                        self.input_consumed_len + offset,\n                                        byte,\n                                    )\n                                }\n                            }\n                        }\n                        DecodeError::InvalidLength(len) => {\n                            DecodeError::InvalidLength(self.input_consumed_len + len)\n                        }\n                        DecodeError::InvalidLastSymbol(offset, byte) => {\n                            DecodeError::InvalidLastSymbol(\n                                self.input_consumed_len + offset,\n                                byte,\n                            )\n                        }\n                        DecodeError::InvalidPadding => DecodeError::InvalidPadding,\n                    }\n                }\n                DecodeSliceError::OutputSliceTooSmall => {\n                    unreachable!(\"buf is sized correctly in calling code\")\n                }\n            })\n            .map_err(|e| io::Error::new(io::ErrorKind::InvalidData, e))?;\n        if let Some(offset) = self.padding_offset {\n            if decode_metadata.decoded_len > 0 {\n                return Err(\n                    io::Error::new(\n                        io::ErrorKind::InvalidData,\n                        DecodeError::InvalidByte(offset, PAD_BYTE),\n                    ),\n                );\n            }\n        }\n        self.padding_offset = self\n            .padding_offset\n            .or(\n                decode_metadata\n                    .padding_offset\n                    .map(|offset| self.input_consumed_len + offset),\n            );\n        self.input_consumed_len += b64_len_to_decode;\n        self.b64_offset += b64_len_to_decode;\n        self.b64_len -= b64_len_to_decode;\n        debug_assert!(self.b64_offset + self.b64_len <= BUF_SIZE);\n        Ok(decode_metadata.decoded_len)\n    }\n    pub fn into_inner(self) -> R {}\n}\n\nThe function to be tested is presented with each line formatted as 'line number + code':\n/// Decode input from the wrapped reader.\n///\n/// Under non-error circumstances, this returns `Ok` with the value being the number of bytes\n/// written in `buf`.\n///\n/// Where possible, this function buffers base64 to minimize the number of `read()` calls to the\n/// delegate reader.\n///\n/// # Errors\n///\n/// Any errors emitted by the delegate reader are returned. Decoding errors due to invalid\n/// base64 are also possible, and will have `io::ErrorKind::InvalidData`.\n232 fn read(&mut self, buf: &mut [u8]) -> io::Result<usize> {\n233     if buf.is_empty() {\n234         return Ok(0);\n235     }\n236 \n237     // offset == BUF_SIZE when we copied it all last time\n238     debug_assert!(self.b64_offset <= BUF_SIZE);\n239     debug_assert!(self.b64_offset + self.b64_len <= BUF_SIZE);\n240     debug_assert!(if self.b64_offset == BUF_SIZE {\n241         self.b64_len == 0\n242     } else {\n243         self.b64_len <= BUF_SIZE\n244     });\n245 \n246     debug_assert!(if self.decoded_len == 0 {\n247         // can be = when we were able to copy the complete chunk\n248         self.decoded_offset <= DECODED_CHUNK_SIZE\n249     } else {\n250         self.decoded_offset < DECODED_CHUNK_SIZE\n251     });\n252 \n253     // We shouldn't ever decode into decoded_buffer when we can't immediately write at least one\n254     // byte into the provided buf, so the effective length should only be 3 momentarily between\n255     // when we decode and when we copy into the target buffer.\n256     debug_assert!(self.decoded_len < DECODED_CHUNK_SIZE);\n257     debug_assert!(self.decoded_len + self.decoded_offset <= DECODED_CHUNK_SIZE);\n258 \n259     if self.decoded_len > 0 {\n260         // we have a few leftover decoded bytes; flush that rather than pull in more b64\n261         self.flush_decoded_buf(buf)\n262     } else {\n263         let mut at_eof = false;\n264         while self.b64_len < BASE64_CHUNK_SIZE {\n265             // Copy any bytes we have to the start of the buffer.\n266             self.b64_buffer\n267                 .copy_within(self.b64_offset..self.b64_offset + self.b64_len, 0);\n268             self.b64_offset = 0;\n269 \n270             // then fill in more data\n271             let read = self.read_from_delegate()?;\n272             if read == 0 {\n273                 // we never read into an empty buf, so 0 => we've hit EOF\n274                 at_eof = true;\n275                 break;\n276             }\n277         }\n278 \n279         if self.b64_len == 0 {\n280             debug_assert!(at_eof);\n281             // we must be at EOF, and we have no data left to decode\n282             return Ok(0);\n283         };\n284 \n285         debug_assert!(if at_eof {\n286             // if we are at eof, we may not have a complete chunk\n287             self.b64_len > 0\n288         } else {\n289             // otherwise, we must have at least one chunk\n290             self.b64_len >= BASE64_CHUNK_SIZE\n291         });\n292 \n293         debug_assert_eq!(0, self.decoded_len);\n294 \n295         if buf.len() < DECODED_CHUNK_SIZE {\n296             // caller requested an annoyingly short read\n297             // have to write to a tmp buf first to avoid double mutable borrow\n298             let mut decoded_chunk = [0_u8; DECODED_CHUNK_SIZE];\n299             // if we are at eof, could have less than BASE64_CHUNK_SIZE, in which case we have\n300             // to assume that these last few tokens are, in fact, valid (i.e. must be 2-4 b64\n301             // tokens, not 1, since 1 token can't decode to 1 byte).\n302             let to_decode = cmp::min(self.b64_len, BASE64_CHUNK_SIZE);\n303 \n304             let decoded = self.decode_to_buf(to_decode, &mut decoded_chunk[..])?;\n305             self.decoded_chunk_buffer[..decoded].copy_from_slice(&decoded_chunk[..decoded]);\n306 \n307             self.decoded_offset = 0;\n308             self.decoded_len = decoded;\n309 \n310             // can be less than 3 on last block due to padding\n311             debug_assert!(decoded <= 3);\n312 \n313             self.flush_decoded_buf(buf)\n314         } else {\n315             let b64_bytes_that_can_decode_into_buf = (buf.len() / DECODED_CHUNK_SIZE)\n316                 .checked_mul(BASE64_CHUNK_SIZE)\n317                 .expect(\"too many chunks\");\n318             debug_assert!(b64_bytes_that_can_decode_into_buf >= BASE64_CHUNK_SIZE);\n319 \n320             let b64_bytes_available_to_decode = if at_eof {\n321                 self.b64_len\n322             } else {\n323                 // only use complete chunks\n324                 self.b64_len - self.b64_len % 4\n325             };\n326 \n327             let actual_decode_len = cmp::min(\n328                 b64_bytes_that_can_decode_into_buf,\n329                 b64_bytes_available_to_decode,\n330             );\n331             self.decode_to_buf(actual_decode_len, buf)\n332         }\n333     }\n334 }\n\n",
  "depend_pt": ""
}