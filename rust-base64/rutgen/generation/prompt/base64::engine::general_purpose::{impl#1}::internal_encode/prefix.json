{
  "system_pt": "As a software testing expert, please generate Rust test functions based on the following guidelines, focusing solely on constructing test inputs and calling the functions under test:\n1. Provide the code in plain text format, without explanations or Markdown.\n2. If the method under test belongs to a trait, construct appropriate structs within the test function, but avoid method overrides. If the method under test uses generics, instantiate them with suitable types based on the context.\n3. Generate test code with minimal scope: avoid creating external structures or implementations. Instead, define any necessary helper structures or implementations directly within the test function when required.\n4. Whenever possible, initialize the corresponding data structures using the initialization methods provided in the context.\n5. Ensure the generated function is fully implemented and can be compiled and executed directly without any missing parts.\n6. Create a minimal yet complete set of test functions, ensuring they adhere to all provided preconditions and cover boundary conditions, and reference the inferred test input conditions or ranges.\n7. Ensure the test inputs are designed to cover the inferred test input conditions or ranges as comprehensively as possible, with particular emphasis on boundary cases.\n8. Focus on crafting test inputs that effectively reveal potential bugs while meeting the specified requirements.\n9. Omit test oracles and assertions; concentrate on generating test inputs and function calls.\n10. Do not create a test module, but include intrinsic attributes like #[test] or #[should_panic] where necessary.\n",
  "static_pt": "The context for the focal function is as follows:\n// src/engine/general_purpose/mod.rs\n// crate name is base64\nuse crate::{\n    alphabet, alphabet::Alphabet, engine::{Config, DecodeMetadata, DecodePaddingMode},\n    DecodeSliceError,\n};\nuse core::convert::TryInto;\npub use decode::GeneralPurposeEstimate;\npub(crate) const INVALID_VALUE: u8 = 255;\npub const STANDARD: GeneralPurpose = GeneralPurpose::new(&alphabet::STANDARD, PAD);\npub const STANDARD_PAD_INDIFFERENT: GeneralPurpose = GeneralPurpose::new(\n    &alphabet::STANDARD,\n    PAD_INDIFFERENT,\n);\npub const STANDARD_NO_PAD: GeneralPurpose = GeneralPurpose::new(\n    &alphabet::STANDARD,\n    NO_PAD,\n);\npub const STANDARD_NO_PAD_INDIFFERENT: GeneralPurpose = GeneralPurpose::new(\n    &alphabet::STANDARD,\n    NO_PAD_INDIFFERENT,\n);\npub const URL_SAFE: GeneralPurpose = GeneralPurpose::new(&alphabet::URL_SAFE, PAD);\npub const URL_SAFE_PAD_INDIFFERENT: GeneralPurpose = GeneralPurpose::new(\n    &alphabet::URL_SAFE,\n    PAD_INDIFFERENT,\n);\npub const URL_SAFE_NO_PAD: GeneralPurpose = GeneralPurpose::new(\n    &alphabet::URL_SAFE,\n    NO_PAD,\n);\npub const URL_SAFE_NO_PAD_INDIFFERENT: GeneralPurpose = GeneralPurpose::new(\n    &alphabet::URL_SAFE,\n    NO_PAD_INDIFFERENT,\n);\npub const PAD: GeneralPurposeConfig = GeneralPurposeConfig::new();\npub const PAD_INDIFFERENT: GeneralPurposeConfig = GeneralPurposeConfig::new()\n    .with_encode_padding(true)\n    .with_decode_padding_mode(DecodePaddingMode::Indifferent);\npub const NO_PAD: GeneralPurposeConfig = GeneralPurposeConfig::new()\n    .with_encode_padding(false)\n    .with_decode_padding_mode(DecodePaddingMode::RequireNone);\npub const NO_PAD_INDIFFERENT: GeneralPurposeConfig = GeneralPurposeConfig::new()\n    .with_encode_padding(false)\n    .with_decode_padding_mode(DecodePaddingMode::Indifferent);\npub trait Engine: Send + Sync {\n    type Config: Config;\n    type DecodeEstimate: DecodeEstimate;\n    fn internal_encode(&self, input: &[u8], output: &mut [u8]) -> usize;\n    fn internal_decoded_len_estimate(&self, input_len: usize) -> Self::DecodeEstimate;\n    fn internal_decode(\n        &self,\n        input: &[u8],\n        output: &mut [u8],\n        decode_estimate: Self::DecodeEstimate,\n    ) -> Result<DecodeMetadata, DecodeSliceError>;\n    fn config(&self) -> &Self::Config;\n    #[cfg(any(feature = \"alloc\", test))]\n    #[inline]\n    fn encode<T: AsRef<[u8]>>(&self, input: T) -> String {\n        fn inner<E>(engine: &E, input_bytes: &[u8]) -> String\n        where\n            E: Engine + ?Sized,\n        {\n            let encoded_size = encoded_len(\n                    input_bytes.len(),\n                    engine.config().encode_padding(),\n                )\n                .expect(\"integer overflow when calculating buffer size\");\n            let mut buf = vec![0; encoded_size];\n            encode_with_padding(input_bytes, &mut buf[..], engine, encoded_size);\n            String::from_utf8(buf).expect(\"Invalid UTF8\")\n        }\n        inner(self, input.as_ref())\n    }\n    #[cfg(any(feature = \"alloc\", test))]\n    #[inline]\n    fn encode_string<T: AsRef<[u8]>>(&self, input: T, output_buf: &mut String) {\n        fn inner<E>(engine: &E, input_bytes: &[u8], output_buf: &mut String)\n        where\n            E: Engine + ?Sized,\n        {\n            let mut sink = chunked_encoder::StringSink::new(output_buf);\n            chunked_encoder::ChunkedEncoder::new(engine)\n                .encode(input_bytes, &mut sink)\n                .expect(\"Writing to a String shouldn't fail\");\n        }\n        inner(self, input.as_ref(), output_buf);\n    }\n    #[cfg_attr(feature = \"alloc\", doc = \"```\")]\n    #[cfg_attr(not(feature = \"alloc\"), doc = \"```ignore\")]\n    #[inline]\n    fn encode_slice<T: AsRef<[u8]>>(\n        &self,\n        input: T,\n        output_buf: &mut [u8],\n    ) -> Result<usize, EncodeSliceError> {\n        fn inner<E>(\n            engine: &E,\n            input_bytes: &[u8],\n            output_buf: &mut [u8],\n        ) -> Result<usize, EncodeSliceError>\n        where\n            E: Engine + ?Sized,\n        {\n            let encoded_size = encoded_len(\n                    input_bytes.len(),\n                    engine.config().encode_padding(),\n                )\n                .expect(\"usize overflow when calculating buffer size\");\n            if output_buf.len() < encoded_size {\n                return Err(EncodeSliceError::OutputSliceTooSmall);\n            }\n            let b64_output = &mut output_buf[0..encoded_size];\n            encode_with_padding(input_bytes, b64_output, engine, encoded_size);\n            Ok(encoded_size)\n        }\n        inner(self, input.as_ref(), output_buf)\n    }\n    #[cfg(any(feature = \"alloc\", test))]\n    #[inline]\n    fn decode<T: AsRef<[u8]>>(&self, input: T) -> Result<Vec<u8>, DecodeError> {\n        fn inner<E>(engine: &E, input_bytes: &[u8]) -> Result<Vec<u8>, DecodeError>\n        where\n            E: Engine + ?Sized,\n        {\n            let estimate = engine.internal_decoded_len_estimate(input_bytes.len());\n            let mut buffer = vec![0; estimate.decoded_len_estimate()];\n            let bytes_written = engine\n                .internal_decode(input_bytes, &mut buffer, estimate)\n                .map_err(|e| match e {\n                    DecodeSliceError::DecodeError(e) => e,\n                    DecodeSliceError::OutputSliceTooSmall => {\n                        unreachable!(\"Vec is sized conservatively\")\n                    }\n                })?\n                .decoded_len;\n            buffer.truncate(bytes_written);\n            Ok(buffer)\n        }\n        inner(self, input.as_ref())\n    }\n    #[cfg(any(feature = \"alloc\", test))]\n    #[inline]\n    fn decode_vec<T: AsRef<[u8]>>(\n        &self,\n        input: T,\n        buffer: &mut Vec<u8>,\n    ) -> Result<(), DecodeError> {\n        fn inner<E>(\n            engine: &E,\n            input_bytes: &[u8],\n            buffer: &mut Vec<u8>,\n        ) -> Result<(), DecodeError>\n        where\n            E: Engine + ?Sized,\n        {\n            let starting_output_len = buffer.len();\n            let estimate = engine.internal_decoded_len_estimate(input_bytes.len());\n            let total_len_estimate = estimate\n                .decoded_len_estimate()\n                .checked_add(starting_output_len)\n                .expect(\"Overflow when calculating output buffer length\");\n            buffer.resize(total_len_estimate, 0);\n            let buffer_slice = &mut buffer.as_mut_slice()[starting_output_len..];\n            let bytes_written = engine\n                .internal_decode(input_bytes, buffer_slice, estimate)\n                .map_err(|e| match e {\n                    DecodeSliceError::DecodeError(e) => e,\n                    DecodeSliceError::OutputSliceTooSmall => {\n                        unreachable!(\"Vec is sized conservatively\")\n                    }\n                })?\n                .decoded_len;\n            buffer.truncate(starting_output_len + bytes_written);\n            Ok(())\n        }\n        inner(self, input.as_ref(), buffer)\n    }\n    #[inline]\n    fn decode_slice<T: AsRef<[u8]>>(\n        &self,\n        input: T,\n        output: &mut [u8],\n    ) -> Result<usize, DecodeSliceError> {\n        fn inner<E>(\n            engine: &E,\n            input_bytes: &[u8],\n            output: &mut [u8],\n        ) -> Result<usize, DecodeSliceError>\n        where\n            E: Engine + ?Sized,\n        {\n            engine\n                .internal_decode(\n                    input_bytes,\n                    output,\n                    engine.internal_decoded_len_estimate(input_bytes.len()),\n                )\n                .map(|dm| dm.decoded_len)\n        }\n        inner(self, input.as_ref(), output)\n    }\n    #[inline]\n    fn decode_slice_unchecked<T: AsRef<[u8]>>(\n        &self,\n        input: T,\n        output: &mut [u8],\n    ) -> Result<usize, DecodeError> {\n        fn inner<E>(\n            engine: &E,\n            input_bytes: &[u8],\n            output: &mut [u8],\n        ) -> Result<usize, DecodeError>\n        where\n            E: Engine + ?Sized,\n        {\n            engine\n                .internal_decode(\n                    input_bytes,\n                    output,\n                    engine.internal_decoded_len_estimate(input_bytes.len()),\n                )\n                .map(|dm| dm.decoded_len)\n                .map_err(|e| match e {\n                    DecodeSliceError::DecodeError(e) => e,\n                    DecodeSliceError::OutputSliceTooSmall => {\n                        panic!(\"Output slice is too small\")\n                    }\n                })\n        }\n        inner(self, input.as_ref(), output)\n    }\n}\n#[derive(Debug, Clone)]\npub struct GeneralPurpose {\n    encode_table: [u8; 64],\n    decode_table: [u8; 256],\n    config: GeneralPurposeConfig,\n}\npub struct GeneralPurposeEstimate {\n    /// input len % 4\n    rem: usize,\n    conservative_decoded_len: usize,\n}\n#[derive(Clone, Copy, Debug)]\npub struct GeneralPurposeConfig {\n    encode_padding: bool,\n    decode_allow_trailing_bits: bool,\n    decode_padding_mode: DecodePaddingMode,\n}\nimpl super::Engine for GeneralPurpose {\n    type Config = GeneralPurposeConfig;\n    type DecodeEstimate = GeneralPurposeEstimate;\n    fn internal_encode(&self, input: &[u8], output: &mut [u8]) -> usize {\n        let mut input_index: usize = 0;\n        const BLOCKS_PER_FAST_LOOP: usize = 4;\n        const LOW_SIX_BITS: u64 = 0x3F;\n        let last_fast_index = input.len().saturating_sub(BLOCKS_PER_FAST_LOOP * 6 + 2);\n        let mut output_index = 0;\n        if last_fast_index > 0 {\n            while input_index <= last_fast_index {\n                let input_chunk = &input[input_index..(input_index\n                    + (BLOCKS_PER_FAST_LOOP * 6 + 2))];\n                let output_chunk = &mut output[output_index..(output_index\n                    + BLOCKS_PER_FAST_LOOP * 8)];\n                let input_u64 = read_u64(&input_chunk[0..]);\n                output_chunk[0] = self\n                    .encode_table[((input_u64 >> 58) & LOW_SIX_BITS) as usize];\n                output_chunk[1] = self\n                    .encode_table[((input_u64 >> 52) & LOW_SIX_BITS) as usize];\n                output_chunk[2] = self\n                    .encode_table[((input_u64 >> 46) & LOW_SIX_BITS) as usize];\n                output_chunk[3] = self\n                    .encode_table[((input_u64 >> 40) & LOW_SIX_BITS) as usize];\n                output_chunk[4] = self\n                    .encode_table[((input_u64 >> 34) & LOW_SIX_BITS) as usize];\n                output_chunk[5] = self\n                    .encode_table[((input_u64 >> 28) & LOW_SIX_BITS) as usize];\n                output_chunk[6] = self\n                    .encode_table[((input_u64 >> 22) & LOW_SIX_BITS) as usize];\n                output_chunk[7] = self\n                    .encode_table[((input_u64 >> 16) & LOW_SIX_BITS) as usize];\n                let input_u64 = read_u64(&input_chunk[6..]);\n                output_chunk[8] = self\n                    .encode_table[((input_u64 >> 58) & LOW_SIX_BITS) as usize];\n                output_chunk[9] = self\n                    .encode_table[((input_u64 >> 52) & LOW_SIX_BITS) as usize];\n                output_chunk[10] = self\n                    .encode_table[((input_u64 >> 46) & LOW_SIX_BITS) as usize];\n                output_chunk[11] = self\n                    .encode_table[((input_u64 >> 40) & LOW_SIX_BITS) as usize];\n                output_chunk[12] = self\n                    .encode_table[((input_u64 >> 34) & LOW_SIX_BITS) as usize];\n                output_chunk[13] = self\n                    .encode_table[((input_u64 >> 28) & LOW_SIX_BITS) as usize];\n                output_chunk[14] = self\n                    .encode_table[((input_u64 >> 22) & LOW_SIX_BITS) as usize];\n                output_chunk[15] = self\n                    .encode_table[((input_u64 >> 16) & LOW_SIX_BITS) as usize];\n                let input_u64 = read_u64(&input_chunk[12..]);\n                output_chunk[16] = self\n                    .encode_table[((input_u64 >> 58) & LOW_SIX_BITS) as usize];\n                output_chunk[17] = self\n                    .encode_table[((input_u64 >> 52) & LOW_SIX_BITS) as usize];\n                output_chunk[18] = self\n                    .encode_table[((input_u64 >> 46) & LOW_SIX_BITS) as usize];\n                output_chunk[19] = self\n                    .encode_table[((input_u64 >> 40) & LOW_SIX_BITS) as usize];\n                output_chunk[20] = self\n                    .encode_table[((input_u64 >> 34) & LOW_SIX_BITS) as usize];\n                output_chunk[21] = self\n                    .encode_table[((input_u64 >> 28) & LOW_SIX_BITS) as usize];\n                output_chunk[22] = self\n                    .encode_table[((input_u64 >> 22) & LOW_SIX_BITS) as usize];\n                output_chunk[23] = self\n                    .encode_table[((input_u64 >> 16) & LOW_SIX_BITS) as usize];\n                let input_u64 = read_u64(&input_chunk[18..]);\n                output_chunk[24] = self\n                    .encode_table[((input_u64 >> 58) & LOW_SIX_BITS) as usize];\n                output_chunk[25] = self\n                    .encode_table[((input_u64 >> 52) & LOW_SIX_BITS) as usize];\n                output_chunk[26] = self\n                    .encode_table[((input_u64 >> 46) & LOW_SIX_BITS) as usize];\n                output_chunk[27] = self\n                    .encode_table[((input_u64 >> 40) & LOW_SIX_BITS) as usize];\n                output_chunk[28] = self\n                    .encode_table[((input_u64 >> 34) & LOW_SIX_BITS) as usize];\n                output_chunk[29] = self\n                    .encode_table[((input_u64 >> 28) & LOW_SIX_BITS) as usize];\n                output_chunk[30] = self\n                    .encode_table[((input_u64 >> 22) & LOW_SIX_BITS) as usize];\n                output_chunk[31] = self\n                    .encode_table[((input_u64 >> 16) & LOW_SIX_BITS) as usize];\n                output_index += BLOCKS_PER_FAST_LOOP * 8;\n                input_index += BLOCKS_PER_FAST_LOOP * 6;\n            }\n        }\n        const LOW_SIX_BITS_U8: u8 = 0x3F;\n        let rem = input.len() % 3;\n        let start_of_rem = input.len() - rem;\n        while input_index < start_of_rem {\n            let input_chunk = &input[input_index..(input_index + 3)];\n            let output_chunk = &mut output[output_index..(output_index + 4)];\n            output_chunk[0] = self.encode_table[(input_chunk[0] >> 2) as usize];\n            output_chunk[1] = self\n                .encode_table[((input_chunk[0] << 4 | input_chunk[1] >> 4)\n                & LOW_SIX_BITS_U8) as usize];\n            output_chunk[2] = self\n                .encode_table[((input_chunk[1] << 2 | input_chunk[2] >> 6)\n                & LOW_SIX_BITS_U8) as usize];\n            output_chunk[3] = self\n                .encode_table[(input_chunk[2] & LOW_SIX_BITS_U8) as usize];\n            input_index += 3;\n            output_index += 4;\n        }\n        if rem == 2 {\n            output[output_index] = self\n                .encode_table[(input[start_of_rem] >> 2) as usize];\n            output[output_index + 1] = self\n                .encode_table[((input[start_of_rem] << 4 | input[start_of_rem + 1] >> 4)\n                & LOW_SIX_BITS_U8) as usize];\n            output[output_index + 2] = self\n                .encode_table[((input[start_of_rem + 1] << 2) & LOW_SIX_BITS_U8)\n                as usize];\n            output_index += 3;\n        } else if rem == 1 {\n            output[output_index] = self\n                .encode_table[(input[start_of_rem] >> 2) as usize];\n            output[output_index + 1] = self\n                .encode_table[((input[start_of_rem] << 4) & LOW_SIX_BITS_U8) as usize];\n            output_index += 2;\n        }\n        output_index\n    }\n    fn internal_decoded_len_estimate(&self, input_len: usize) -> Self::DecodeEstimate {\n        GeneralPurposeEstimate::new(input_len)\n    }\n    fn internal_decode(\n        &self,\n        input: &[u8],\n        output: &mut [u8],\n        estimate: Self::DecodeEstimate,\n    ) -> Result<DecodeMetadata, DecodeSliceError> {}\n    fn config(&self) -> &Self::Config {\n        &self.config\n    }\n}\n#[inline]\nfn read_u64(s: &[u8]) -> u64 {\n    u64::from_be_bytes(s[..8].try_into().unwrap())\n}\n\nThe function to be tested is presented with each line formatted as 'line number + code':\n 51 fn internal_encode(&self, input: &[u8], output: &mut [u8]) -> usize {\n 52     let mut input_index: usize = 0;\n 53 \n 54     const BLOCKS_PER_FAST_LOOP: usize = 4;\n 55     const LOW_SIX_BITS: u64 = 0x3F;\n 56 \n 57     // we read 8 bytes at a time (u64) but only actually consume 6 of those bytes. Thus, we need\n 58     // 2 trailing bytes to be available to read..\n 59     let last_fast_index = input.len().saturating_sub(BLOCKS_PER_FAST_LOOP * 6 + 2);\n 60     let mut output_index = 0;\n 61 \n 62     if last_fast_index > 0 {\n 63         while input_index <= last_fast_index {\n 64             // Major performance wins from letting the optimizer do the bounds check once, mostly\n 65             // on the output side\n 66             let input_chunk =\n 67                 &input[input_index..(input_index + (BLOCKS_PER_FAST_LOOP * 6 + 2))];\n 68             let output_chunk =\n 69                 &mut output[output_index..(output_index + BLOCKS_PER_FAST_LOOP * 8)];\n 70 \n 71             // Hand-unrolling for 32 vs 16 or 8 bytes produces yields performance about equivalent\n 72             // to unsafe pointer code on a Xeon E5-1650v3. 64 byte unrolling was slightly better for\n 73             // large inputs but significantly worse for 50-byte input, unsurprisingly. I suspect\n 74             // that it's a not uncommon use case to encode smallish chunks of data (e.g. a 64-byte\n 75             // SHA-512 digest), so it would be nice if that fit in the unrolled loop at least once.\n 76             // Plus, single-digit percentage performance differences might well be quite different\n 77             // on different hardware.\n 78 \n 79             let input_u64 = read_u64(&input_chunk[0..]);\n 80 \n 81             output_chunk[0] = self.encode_table[((input_u64 >> 58) & LOW_SIX_BITS) as usize];\n 82             output_chunk[1] = self.encode_table[((input_u64 >> 52) & LOW_SIX_BITS) as usize];\n 83             output_chunk[2] = self.encode_table[((input_u64 >> 46) & LOW_SIX_BITS) as usize];\n 84             output_chunk[3] = self.encode_table[((input_u64 >> 40) & LOW_SIX_BITS) as usize];\n 85             output_chunk[4] = self.encode_table[((input_u64 >> 34) & LOW_SIX_BITS) as usize];\n 86             output_chunk[5] = self.encode_table[((input_u64 >> 28) & LOW_SIX_BITS) as usize];\n 87             output_chunk[6] = self.encode_table[((input_u64 >> 22) & LOW_SIX_BITS) as usize];\n 88             output_chunk[7] = self.encode_table[((input_u64 >> 16) & LOW_SIX_BITS) as usize];\n 89 \n 90             let input_u64 = read_u64(&input_chunk[6..]);\n 91 \n 92             output_chunk[8] = self.encode_table[((input_u64 >> 58) & LOW_SIX_BITS) as usize];\n 93             output_chunk[9] = self.encode_table[((input_u64 >> 52) & LOW_SIX_BITS) as usize];\n 94             output_chunk[10] = self.encode_table[((input_u64 >> 46) & LOW_SIX_BITS) as usize];\n 95             output_chunk[11] = self.encode_table[((input_u64 >> 40) & LOW_SIX_BITS) as usize];\n 96             output_chunk[12] = self.encode_table[((input_u64 >> 34) & LOW_SIX_BITS) as usize];\n 97             output_chunk[13] = self.encode_table[((input_u64 >> 28) & LOW_SIX_BITS) as usize];\n 98             output_chunk[14] = self.encode_table[((input_u64 >> 22) & LOW_SIX_BITS) as usize];\n 99             output_chunk[15] = self.encode_table[((input_u64 >> 16) & LOW_SIX_BITS) as usize];\n100 \n101             let input_u64 = read_u64(&input_chunk[12..]);\n102 \n103             output_chunk[16] = self.encode_table[((input_u64 >> 58) & LOW_SIX_BITS) as usize];\n104             output_chunk[17] = self.encode_table[((input_u64 >> 52) & LOW_SIX_BITS) as usize];\n105             output_chunk[18] = self.encode_table[((input_u64 >> 46) & LOW_SIX_BITS) as usize];\n106             output_chunk[19] = self.encode_table[((input_u64 >> 40) & LOW_SIX_BITS) as usize];\n107             output_chunk[20] = self.encode_table[((input_u64 >> 34) & LOW_SIX_BITS) as usize];\n108             output_chunk[21] = self.encode_table[((input_u64 >> 28) & LOW_SIX_BITS) as usize];\n109             output_chunk[22] = self.encode_table[((input_u64 >> 22) & LOW_SIX_BITS) as usize];\n110             output_chunk[23] = self.encode_table[((input_u64 >> 16) & LOW_SIX_BITS) as usize];\n111 \n112             let input_u64 = read_u64(&input_chunk[18..]);\n113 \n114             output_chunk[24] = self.encode_table[((input_u64 >> 58) & LOW_SIX_BITS) as usize];\n115             output_chunk[25] = self.encode_table[((input_u64 >> 52) & LOW_SIX_BITS) as usize];\n116             output_chunk[26] = self.encode_table[((input_u64 >> 46) & LOW_SIX_BITS) as usize];\n117             output_chunk[27] = self.encode_table[((input_u64 >> 40) & LOW_SIX_BITS) as usize];\n118             output_chunk[28] = self.encode_table[((input_u64 >> 34) & LOW_SIX_BITS) as usize];\n119             output_chunk[29] = self.encode_table[((input_u64 >> 28) & LOW_SIX_BITS) as usize];\n120             output_chunk[30] = self.encode_table[((input_u64 >> 22) & LOW_SIX_BITS) as usize];\n121             output_chunk[31] = self.encode_table[((input_u64 >> 16) & LOW_SIX_BITS) as usize];\n122 \n123             output_index += BLOCKS_PER_FAST_LOOP * 8;\n124             input_index += BLOCKS_PER_FAST_LOOP * 6;\n125         }\n126     }\n127 \n128     // Encode what's left after the fast loop.\n129 \n130     const LOW_SIX_BITS_U8: u8 = 0x3F;\n131 \n132     let rem = input.len() % 3;\n133     let start_of_rem = input.len() - rem;\n134 \n135     // start at the first index not handled by fast loop, which may be 0.\n136 \n137     while input_index < start_of_rem {\n138         let input_chunk = &input[input_index..(input_index + 3)];\n139         let output_chunk = &mut output[output_index..(output_index + 4)];\n140 \n141         output_chunk[0] = self.encode_table[(input_chunk[0] >> 2) as usize];\n142         output_chunk[1] = self.encode_table\n143             [((input_chunk[0] << 4 | input_chunk[1] >> 4) & LOW_SIX_BITS_U8) as usize];\n144         output_chunk[2] = self.encode_table\n145             [((input_chunk[1] << 2 | input_chunk[2] >> 6) & LOW_SIX_BITS_U8) as usize];\n146         output_chunk[3] = self.encode_table[(input_chunk[2] & LOW_SIX_BITS_U8) as usize];\n147 \n148         input_index += 3;\n149         output_index += 4;\n150     }\n151 \n152     if rem == 2 {\n153         output[output_index] = self.encode_table[(input[start_of_rem] >> 2) as usize];\n154         output[output_index + 1] =\n155             self.encode_table[((input[start_of_rem] << 4 | input[start_of_rem + 1] >> 4)\n156                 & LOW_SIX_BITS_U8) as usize];\n157         output[output_index + 2] =\n158             self.encode_table[((input[start_of_rem + 1] << 2) & LOW_SIX_BITS_U8) as usize];\n159         output_index += 3;\n160     } else if rem == 1 {\n161         output[output_index] = self.encode_table[(input[start_of_rem] >> 2) as usize];\n162         output[output_index + 1] =\n163             self.encode_table[((input[start_of_rem] << 4) & LOW_SIX_BITS_U8) as usize];\n164         output_index += 2;\n165     }\n166 \n167     output_index\n168 }\n\nGenerate each test function in such a manner that it concurrently satisfies all the following preconditions:\n",
  "depend_pt": ""
}