{
  "system_pt": "As a software testing expert, please generate Rust test functions based on the following guidelines, focusing solely on constructing test inputs and calling the functions under test:\n1. Provide the code in plain text format, without explanations or Markdown.\n2. If the method under test belongs to a trait, construct appropriate structs within the test function, but avoid method overrides. If the method under test uses generics, instantiate them with suitable types based on the context.\n3. Generate test code with minimal scope: avoid creating external structures or implementations. Instead, define any necessary helper structures or implementations directly within the test function when required.\n4. Whenever possible, initialize the corresponding data structures using the initialization methods provided in the context.\n5. Ensure the generated function is fully implemented and can be compiled and executed directly without any missing parts.\n6. Create a minimal yet complete set of test functions, ensuring they adhere to all provided preconditions and cover boundary conditions, and reference the inferred test input conditions or ranges.\n7. Ensure the test inputs are designed to cover the inferred test input conditions or ranges as comprehensively as possible, with particular emphasis on boundary cases.\n8. Focus on crafting test inputs that effectively reveal potential bugs while meeting the specified requirements.\n9. Omit test oracles and assertions; concentrate on generating test inputs and function calls.\n10. Do not create a test module, but include intrinsic attributes like #[test] or #[should_panic] where necessary.\n",
  "static_pt": "The context for the focal function is as follows:\n// regex-automata/src/nfa/thompson/pikevm.rs\n// crate name is regex_automata\n#[cfg(feature = \"internal-instrument-pikevm\")]\nuse core::cell::RefCell;\nuse alloc::{vec, vec::Vec};\nuse crate::{\n    nfa::thompson::{self, BuildError, State, NFA},\n    util::{\n        captures::Captures, empty, iter, prefilter::Prefilter,\n        primitives::{NonMaxUsize, PatternID, SmallIndex, StateID},\n        search::{Anchored, HalfMatch, Input, Match, MatchKind, PatternSet, Span},\n        sparse_set::SparseSet,\n    },\n};\n#[derive(Clone, Debug)]\npub struct PikeVM {\n    config: Config,\n    nfa: NFA,\n}\n#[derive(Clone)]\npub(crate) struct SparseSet {\n    /// The number of elements currently in this set.\n    len: usize,\n    /// Dense contains the ids in the order in which they were inserted.\n    dense: Vec<StateID>,\n    /// Sparse maps ids to their location in dense.\n    ///\n    /// A state ID is in the set if and only if\n    /// sparse[id] < len && id == dense[sparse[id]].\n    ///\n    /// Note that these are indices into 'dense'. It's a little weird to use\n    /// StateID here, but we know our length can never exceed the bounds of\n    /// StateID (enforced by 'resize') and StateID will be at most 4 bytes\n    /// where as a usize is likely double that in most cases.\n    sparse: Vec<StateID>,\n}\n#[derive(Clone, Debug, Default)]\npub struct Config {\n    match_kind: Option<MatchKind>,\n    pre: Option<Option<Prefilter>>,\n}\n#[derive(Clone)]\npub struct Input<'h> {\n    haystack: &'h [u8],\n    span: Span,\n    anchored: Anchored,\n    earliest: bool,\n}\n#[derive(Clone, Debug)]\npub struct Cache {\n    /// Stack used while computing epsilon closure. This effectively lets us\n    /// move what is more naturally expressed through recursion to a stack\n    /// on the heap.\n    stack: Vec<FollowEpsilon>,\n    /// The current active states being explored for the current byte in the\n    /// haystack.\n    curr: ActiveStates,\n    /// The next set of states we're building that will be explored for the\n    /// next byte in the haystack.\n    next: ActiveStates,\n}\n#[cfg(feature = \"alloc\")]\n#[derive(Clone, Debug, Eq, PartialEq)]\npub struct PatternSet {\n    /// The number of patterns set to 'true' in this set.\n    len: usize,\n    /// A map from PatternID to boolean of whether a pattern matches or not.\n    ///\n    /// This should probably be a bitset, but it's probably unlikely to matter\n    /// much in practice.\n    ///\n    /// The main downside of this representation (and similarly for a bitset)\n    /// is that iteration scales with the capacity of the set instead of\n    /// the length of the set. This doesn't seem likely to be a problem in\n    /// practice.\n    ///\n    /// Another alternative is to just use a 'SparseSet' for this. It does use\n    /// more memory (quite a bit more), but that seems fine I think compared\n    /// to the memory being used by the regex engine. The real hiccup with\n    /// it is that it yields pattern IDs in the order they were inserted.\n    /// Which is actually kind of nice, but at the time of writing, pattern\n    /// IDs are yielded in ascending order in the regex crate RegexSet API.\n    /// If we did change to 'SparseSet', we could provide an additional\n    /// 'iter_match_order' iterator, but keep the ascending order one for\n    /// compatibility.\n    which: alloc::boxed::Box<[bool]>,\n}\n#[derive(Clone, Debug, Default)]\npub struct Config {\n    utf8: Option<bool>,\n    reverse: Option<bool>,\n    nfa_size_limit: Option<Option<usize>>,\n    shrink: Option<bool>,\n    which_captures: Option<WhichCaptures>,\n    look_matcher: Option<LookMatcher>,\n    #[cfg(test)]\n    unanchored_prefix: Option<bool>,\n}\n#[derive(Clone, Debug, Default)]\npub struct Config {\n    match_kind: Option<MatchKind>,\n    pre: Option<Option<Prefilter>>,\n    starts_for_each_pattern: Option<bool>,\n    byte_classes: Option<bool>,\n    unicode_word_boundary: Option<bool>,\n    quitset: Option<ByteSet>,\n    specialize_start_states: Option<bool>,\n    cache_capacity: Option<usize>,\n    skip_cache_capacity_check: Option<bool>,\n    minimum_cache_clear_count: Option<Option<usize>>,\n    minimum_bytes_per_state: Option<Option<usize>>,\n}\n#[derive(Clone, Debug, Default)]\npub struct Config {\n    match_kind: Option<MatchKind>,\n    starts_for_each_pattern: Option<bool>,\n    byte_classes: Option<bool>,\n    size_limit: Option<Option<usize>>,\n}\n#[derive(Clone, Debug)]\npub struct Config {\n    look_behind: Option<u8>,\n    anchored: Anchored,\n}\n#[derive(Clone, Debug, Default)]\npub struct Config {\n    pre: Option<Option<Prefilter>>,\n    visited_capacity: Option<usize>,\n}\n#[derive(Clone)]\npub struct NFA(Arc<Inner>);\n#[derive(Clone, Debug, Default)]\npub struct Config {\n    match_kind: Option<MatchKind>,\n    utf8_empty: Option<bool>,\n    autopre: Option<bool>,\n    pre: Option<Option<Prefilter>>,\n    which_captures: Option<WhichCaptures>,\n    nfa_size_limit: Option<Option<usize>>,\n    onepass_size_limit: Option<Option<usize>>,\n    hybrid_cache_capacity: Option<usize>,\n    hybrid: Option<bool>,\n    dfa: Option<bool>,\n    dfa_size_limit: Option<Option<usize>>,\n    dfa_state_limit: Option<Option<usize>>,\n    onepass: Option<bool>,\n    backtrack: Option<bool>,\n    byte_classes: Option<bool>,\n    line_terminator: Option<u8>,\n}\n#[derive(Clone, Debug)]\nstruct ActiveStates {\n    /// The set of active NFA states. This set preserves insertion order, which\n    /// is critical for simulating the match semantics of backtracking regex\n    /// engines.\n    set: SparseSet,\n    /// The slots for every NFA state, where each slot stores a (possibly\n    /// absent) offset. Every capturing group has two slots. One for a start\n    /// offset and one for an end offset.\n    slot_table: SlotTable,\n}\n#[derive(Clone, Copy, Eq, Hash, PartialEq, PartialOrd, Ord)]\n#[repr(transparent)]\npub struct NonMaxUsize(NonZeroUsize);\n#[cfg(feature = \"dfa-build\")]\n#[derive(Clone, Debug, Default)]\npub struct Config {\n    accelerate: Option<bool>,\n    pre: Option<Option<Prefilter>>,\n    minimize: Option<bool>,\n    match_kind: Option<MatchKind>,\n    start_kind: Option<StartKind>,\n    starts_for_each_pattern: Option<bool>,\n    byte_classes: Option<bool>,\n    unicode_word_boundary: Option<bool>,\n    quitset: Option<ByteSet>,\n    specialize_start_states: Option<bool>,\n    dfa_size_limit: Option<Option<usize>>,\n    determinize_size_limit: Option<Option<usize>>,\n}\n#[derive(Clone, Debug)]\npub(crate) struct Config {\n    match_kind: MatchKind,\n    quit: ByteSet,\n    dfa_size_limit: Option<usize>,\n    determinize_size_limit: Option<usize>,\n}\n#[derive(Clone, Copy, Default, Eq, Hash, PartialEq, PartialOrd, Ord)]\n#[repr(transparent)]\npub struct StateID(SmallIndex);\n#[derive(Clone, Copy, Debug)]\npub struct Config {\n    case_insensitive: bool,\n    multi_line: bool,\n    dot_matches_new_line: bool,\n    crlf: bool,\n    line_terminator: u8,\n    swap_greed: bool,\n    ignore_whitespace: bool,\n    unicode: bool,\n    utf8: bool,\n    nest_limit: u32,\n    octal: bool,\n}\n#[non_exhaustive]\n#[derive(Clone, Copy, Debug, Eq, PartialEq)]\npub enum MatchKind {\n    /// Report all possible matches.\n    All,\n    /// Report only the leftmost matches. When multiple leftmost matches exist,\n    /// report the match corresponding to the part of the regex that appears\n    /// first in the syntax.\n    LeftmostFirst,\n}\n#[derive(Clone, Debug)]\nenum FollowEpsilon {\n    /// Explore the epsilon transitions from a state ID.\n    Explore(StateID),\n    /// Reset the given `slot` to the given `offset` (which might be `None`).\n    RestoreCapture { slot: SmallIndex, offset: Option<NonMaxUsize> },\n}\nimpl PikeVM {\n    fn search_imp(\n        &self,\n        cache: &mut Cache,\n        input: &Input<'_>,\n        slots: &mut [Option<NonMaxUsize>],\n    ) -> Option<HalfMatch> {}\n    fn which_overlapping_imp(\n        &self,\n        cache: &mut Cache,\n        input: &Input<'_>,\n        patset: &mut PatternSet,\n    ) {\n        cache.setup_search(0);\n        if input.is_done() {\n            return;\n        }\n        assert!(\n            input.haystack().len() < core::usize::MAX,\n            \"byte slice lengths must be less than usize MAX\",\n        );\n        instrument!(| c | c.reset(& self.nfa));\n        let allmatches = self.config.get_match_kind().continue_past_first_match();\n        let (anchored, start_id) = match self.start_config(input) {\n            None => return,\n            Some(config) => config,\n        };\n        let Cache { ref mut stack, ref mut curr, ref mut next } = cache;\n        for at in input.start()..=input.end() {\n            let any_matches = !patset.is_empty();\n            if curr.set.is_empty() {\n                if any_matches && !allmatches {\n                    break;\n                }\n                if anchored && at > input.start() {\n                    break;\n                }\n            }\n            if !any_matches || allmatches {\n                let slots = &mut [];\n                self.epsilon_closure(stack, slots, curr, input, at, start_id);\n            }\n            self.nexts_overlapping(stack, curr, next, input, at, patset);\n            if patset.is_full() || input.get_earliest() {\n                break;\n            }\n            core::mem::swap(curr, next);\n            next.set.clear();\n        }\n        instrument!(| c | c.eprint(& self.nfa));\n    }\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    fn nexts(\n        &self,\n        stack: &mut Vec<FollowEpsilon>,\n        curr: &mut ActiveStates,\n        next: &mut ActiveStates,\n        input: &Input<'_>,\n        at: usize,\n        slots: &mut [Option<NonMaxUsize>],\n    ) -> Option<PatternID> {}\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    fn nexts_overlapping(\n        &self,\n        stack: &mut Vec<FollowEpsilon>,\n        curr: &mut ActiveStates,\n        next: &mut ActiveStates,\n        input: &Input<'_>,\n        at: usize,\n        patset: &mut PatternSet,\n    ) {\n        instrument!(| c | c.record_state_set(& curr.set));\n        let utf8empty = self.get_nfa().has_empty() && self.get_nfa().is_utf8();\n        let ActiveStates { ref set, ref mut slot_table } = *curr;\n        for sid in set.iter() {\n            let pid = match self.next(stack, slot_table, next, input, at, sid) {\n                None => continue,\n                Some(pid) => pid,\n            };\n            if utf8empty && !input.is_char_boundary(at) {\n                continue;\n            }\n            let _ = patset.try_insert(pid);\n            if !self.config.get_match_kind().continue_past_first_match() {\n                break;\n            }\n        }\n    }\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    fn next(\n        &self,\n        stack: &mut Vec<FollowEpsilon>,\n        curr_slot_table: &mut SlotTable,\n        next: &mut ActiveStates,\n        input: &Input<'_>,\n        at: usize,\n        sid: StateID,\n    ) -> Option<PatternID> {}\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    fn epsilon_closure(\n        &self,\n        stack: &mut Vec<FollowEpsilon>,\n        curr_slots: &mut [Option<NonMaxUsize>],\n        next: &mut ActiveStates,\n        input: &Input<'_>,\n        at: usize,\n        sid: StateID,\n    ) {\n        instrument!(| c | { c.record_closure(sid); c.record_stack_push(sid); });\n        stack.push(FollowEpsilon::Explore(sid));\n        while let Some(frame) = stack.pop() {\n            match frame {\n                FollowEpsilon::RestoreCapture { slot, offset: pos } => {\n                    curr_slots[slot] = pos;\n                }\n                FollowEpsilon::Explore(sid) => {\n                    self.epsilon_closure_explore(\n                        stack,\n                        curr_slots,\n                        next,\n                        input,\n                        at,\n                        sid,\n                    );\n                }\n            }\n        }\n    }\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    fn epsilon_closure_explore(\n        &self,\n        stack: &mut Vec<FollowEpsilon>,\n        curr_slots: &mut [Option<NonMaxUsize>],\n        next: &mut ActiveStates,\n        input: &Input<'_>,\n        at: usize,\n        mut sid: StateID,\n    ) {}\n    fn start_config(&self, input: &Input<'_>) -> Option<(bool, StateID)> {\n        match input.get_anchored() {\n            Anchored::No => {\n                Some((self.nfa.is_always_start_anchored(), self.nfa.start_anchored()))\n            }\n            Anchored::Yes => Some((true, self.nfa.start_anchored())),\n            Anchored::Pattern(pid) => Some((true, self.nfa.start_pattern(pid)?)),\n        }\n    }\n}\nimpl SparseSet {\n    #[inline]\n    pub(crate) fn new(capacity: usize) -> SparseSet {}\n    #[inline]\n    pub(crate) fn resize(&mut self, new_capacity: usize) {}\n    #[inline]\n    pub(crate) fn capacity(&self) -> usize {}\n    #[inline]\n    pub(crate) fn len(&self) -> usize {}\n    #[inline]\n    pub(crate) fn is_empty(&self) -> bool {\n        self.len() == 0\n    }\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    pub(crate) fn insert(&mut self, id: StateID) -> bool {}\n    #[inline]\n    pub(crate) fn contains(&self, id: StateID) -> bool {}\n    #[inline]\n    pub(crate) fn clear(&mut self) {\n        self.len = 0;\n    }\n    #[inline]\n    pub(crate) fn iter(&self) -> SparseSetIter<'_> {}\n    #[inline]\n    pub(crate) fn memory_usage(&self) -> usize {}\n}\nimpl Config {\n    pub fn new() -> Config {}\n    pub fn match_kind(mut self, kind: MatchKind) -> Config {}\n    pub fn prefilter(mut self, pre: Option<Prefilter>) -> Config {}\n    pub fn get_match_kind(&self) -> MatchKind {\n        self.match_kind.unwrap_or(MatchKind::LeftmostFirst)\n    }\n    pub fn get_prefilter(&self) -> Option<&Prefilter> {}\n    pub(crate) fn overwrite(&self, o: Config) -> Config {}\n}\nimpl<'h> Input<'h> {\n    #[inline]\n    pub fn new<H: ?Sized + AsRef<[u8]>>(haystack: &'h H) -> Input<'h> {}\n    #[inline]\n    pub fn span<S: Into<Span>>(mut self, span: S) -> Input<'h> {}\n    #[inline]\n    pub fn range<R: RangeBounds<usize>>(mut self, range: R) -> Input<'h> {}\n    #[inline]\n    pub fn anchored(mut self, mode: Anchored) -> Input<'h> {}\n    #[inline]\n    pub fn earliest(mut self, yes: bool) -> Input<'h> {}\n    #[inline]\n    pub fn set_span<S: Into<Span>>(&mut self, span: S) {}\n    #[inline]\n    pub fn set_range<R: RangeBounds<usize>>(&mut self, range: R) {}\n    #[inline]\n    pub fn set_start(&mut self, start: usize) {}\n    #[inline]\n    pub fn set_end(&mut self, end: usize) {}\n    #[inline]\n    pub fn set_anchored(&mut self, mode: Anchored) {}\n    #[inline]\n    pub fn set_earliest(&mut self, yes: bool) {}\n    #[inline]\n    pub fn haystack(&self) -> &[u8] {\n        self.haystack\n    }\n    #[inline]\n    pub fn start(&self) -> usize {\n        self.get_span().start\n    }\n    #[inline]\n    pub fn end(&self) -> usize {\n        self.get_span().end\n    }\n    #[inline]\n    pub fn get_span(&self) -> Span {}\n    #[inline]\n    pub fn get_range(&self) -> Range<usize> {}\n    #[inline]\n    pub fn get_anchored(&self) -> Anchored {}\n    #[inline]\n    pub fn get_earliest(&self) -> bool {\n        self.earliest\n    }\n    #[inline]\n    pub fn is_done(&self) -> bool {\n        self.get_span().start > self.get_span().end\n    }\n    #[inline]\n    pub fn is_char_boundary(&self, offset: usize) -> bool {}\n}\nimpl MatchKind {\n    #[cfg(feature = \"alloc\")]\n    pub(crate) fn continue_past_first_match(&self) -> bool {\n        *self == MatchKind::All\n    }\n}\nimpl Cache {\n    pub fn new(re: &PikeVM) -> Cache {}\n    pub fn reset(&mut self, re: &PikeVM) {}\n    pub fn memory_usage(&self) -> usize {}\n    fn setup_search(&mut self, captures_slot_len: usize) {\n        self.stack.clear();\n        self.curr.setup_search(captures_slot_len);\n        self.next.setup_search(captures_slot_len);\n    }\n}\n#[cfg(feature = \"alloc\")]\nimpl PatternSet {\n    pub fn new(capacity: usize) -> PatternSet {}\n    pub fn clear(&mut self) {}\n    pub fn contains(&self, pid: PatternID) -> bool {}\n    pub fn insert(&mut self, pid: PatternID) -> bool {}\n    pub fn try_insert(&mut self, pid: PatternID) -> Result<bool, PatternSetInsertError> {}\n    pub fn is_empty(&self) -> bool {\n        self.len() == 0\n    }\n    pub fn is_full(&self) -> bool {\n        self.len() == self.capacity()\n    }\n    pub fn len(&self) -> usize {}\n    pub fn capacity(&self) -> usize {}\n    pub fn iter(&self) -> PatternSetIter<'_> {}\n}\n\nThe function to be tested is presented with each line formatted as 'line number + code':\n/// The implementation for the 'which_overlapping_matches' API. Basically,\n/// we do a single scan through the entire haystack (unless our regex\n/// or search is anchored) and record every pattern that matched. In\n/// particular, when MatchKind::All is used, this supports overlapping\n/// matches. So if we have the regexes 'sam' and 'samwise', they will\n/// *both* be reported in the pattern set when searching the haystack\n/// 'samwise'.\n1392 fn which_overlapping_imp(\n1393     &self,\n1394     cache: &mut Cache,\n1395     input: &Input<'_>,\n1396     patset: &mut PatternSet,\n1397 ) {\n1398     // NOTE: This is effectively a copy of 'search_imp' above, but with no\n1399     // captures support and instead writes patterns that matched directly\n1400     // to 'patset'. See that routine for better commentary about what's\n1401     // going on in this routine. We probably could unify the routines using\n1402     // generics or more helper routines, but I'm not sure it's worth it.\n1403     //\n1404     // NOTE: We somewhat go out of our way here to support things like\n1405     // 'input.get_earliest()' and 'leftmost-first' match semantics. Neither\n1406     // of those seem particularly relevant to this routine, but they are\n1407     // both supported by the DFA analogs of this routine by construction\n1408     // and composition, so it seems like good sense to have the PikeVM\n1409     // match that behavior.\n1410 \n1411     cache.setup_search(0);\n1412     if input.is_done() {\n1413         return;\n1414     }\n1415     assert!(\n1416         input.haystack().len() < core::usize::MAX,\n1417         \"byte slice lengths must be less than usize MAX\",\n1418     );\n1419     instrument!(|c| c.reset(&self.nfa));\n1420 \n1421     let allmatches =\n1422         self.config.get_match_kind().continue_past_first_match();\n1423     let (anchored, start_id) = match self.start_config(input) {\n1424         None => return,\n1425         Some(config) => config,\n1426     };\n1427 \n1428     let Cache { ref mut stack, ref mut curr, ref mut next } = cache;\n1429     for at in input.start()..=input.end() {\n1430         let any_matches = !patset.is_empty();\n1431         if curr.set.is_empty() {\n1432             if any_matches && !allmatches {\n1433                 break;\n1434             }\n1435             if anchored && at > input.start() {\n1436                 break;\n1437             }\n1438         }\n1439         if !any_matches || allmatches {\n1440             let slots = &mut [];\n1441             self.epsilon_closure(stack, slots, curr, input, at, start_id);\n1442         }\n1443         self.nexts_overlapping(stack, curr, next, input, at, patset);\n1444         // If we found a match and filled our set, then there is no more\n1445         // additional info that we can provide. Thus, we can quit. We also\n1446         // quit if the caller asked us to stop at the earliest point that\n1447         // we know a match exists.\n1448         if patset.is_full() || input.get_earliest() {\n1449             break;\n1450         }\n1451         core::mem::swap(curr, next);\n1452         next.set.clear();\n1453     }\n1454     instrument!(|c| c.eprint(&self.nfa));\n1455 }\n\nGenerate each test function in such a manner that it concurrently satisfies all the following preconditions:\n",
  "depend_pt": ""
}