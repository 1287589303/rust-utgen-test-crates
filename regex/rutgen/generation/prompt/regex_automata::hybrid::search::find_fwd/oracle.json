{
  "system_pt": "As a software testing expert, please generate accurate test oracles code based on the provided information. Follow these guidelines:\n1. Generate executable test oracle codes in plain text format, one per line. Do not output complete test functions, avoid additional explanations, and do not use Markdown.\n2. Combine the given function under test, context, relevant documentation, preconditions, expected return values or types, test input conditions or ranges, and existing test function prefixes to infer and generate corresponding test oracles code.\n3. Only generate necessary test oracles to ensure comprehensive validation.\n",
  "static_pt": "The context for the focal function is as follows:\n// regex-automata/src/hybrid/search.rs\n// crate name is regex_automata\nuse crate::{\n    hybrid::{\n        dfa::{Cache, OverlappingState, DFA},\n        id::LazyStateID,\n    },\n    util::{prefilter::Prefilter, search::{HalfMatch, Input, MatchError, Span}},\n};\n#[derive(Clone)]\npub struct Input<'h> {\n    haystack: &'h [u8],\n    span: Span,\n    anchored: Anchored,\n    earliest: bool,\n}\n#[derive(Clone, Debug, Default)]\npub struct Config {\n    match_kind: Option<MatchKind>,\n    pre: Option<Option<Prefilter>>,\n    starts_for_each_pattern: Option<bool>,\n    byte_classes: Option<bool>,\n    unicode_word_boundary: Option<bool>,\n    quitset: Option<ByteSet>,\n    specialize_start_states: Option<bool>,\n    cache_capacity: Option<usize>,\n    skip_cache_capacity_check: Option<bool>,\n    minimum_cache_clear_count: Option<Option<usize>>,\n    minimum_bytes_per_state: Option<Option<usize>>,\n}\n#[derive(Clone, Debug)]\npub struct DFA {\n    config: Config,\n    nfa: thompson::NFA,\n    stride2: usize,\n    start_map: StartByteMap,\n    classes: ByteClasses,\n    quitset: ByteSet,\n    cache_capacity: usize,\n}\n#[derive(Clone, Debug)]\npub struct Cache {\n    /// The transition table.\n    ///\n    /// Given a `current` LazyStateID and an `input` byte, the next state can\n    /// be computed via `trans[untagged(current) + equiv_class(input)]`. Notice\n    /// that no multiplication is used. That's because state identifiers are\n    /// \"premultiplied.\"\n    ///\n    /// Note that the next state may be the \"unknown\" state. In this case, the\n    /// next state is not known and determinization for `current` on `input`\n    /// must be performed.\n    trans: Vec<LazyStateID>,\n    /// The starting states for this DFA.\n    ///\n    /// These are computed lazily. Initially, these are all set to \"unknown\"\n    /// lazy state IDs.\n    ///\n    /// When 'starts_for_each_pattern' is disabled (the default), then the size\n    /// of this is constrained to the possible starting configurations based\n    /// on the search parameters. (At time of writing, that's 4.) However,\n    /// when starting states for each pattern is enabled, then there are N\n    /// additional groups of starting states, where each group reflects the\n    /// different possible configurations and N is the number of patterns.\n    starts: Vec<LazyStateID>,\n    /// A sequence of NFA/DFA powerset states that have been computed for this\n    /// lazy DFA. This sequence is indexable by untagged LazyStateIDs. (Every\n    /// tagged LazyStateID can be used to index this sequence by converting it\n    /// to its untagged form.)\n    states: Vec<State>,\n    /// A map from states to their corresponding IDs. This map may be accessed\n    /// via the raw byte representation of a state, which means that a `State`\n    /// does not need to be allocated to determine whether it already exists\n    /// in this map. Indeed, the existence of such a state is what determines\n    /// whether we allocate a new `State` or not.\n    ///\n    /// The higher level idea here is that we do just enough determinization\n    /// for a state to check whether we've already computed it. If we have,\n    /// then we can save a little (albeit not much) work. The real savings is\n    /// in memory usage. If we never checked for trivially duplicate states,\n    /// then our memory usage would explode to unreasonable levels.\n    states_to_id: StateMap,\n    /// Sparse sets used to track which NFA states have been visited during\n    /// various traversals.\n    sparses: SparseSets,\n    /// Scratch space for traversing the NFA graph. (We use space on the heap\n    /// instead of the call stack.)\n    stack: Vec<NFAStateID>,\n    /// Scratch space for building a NFA/DFA powerset state. This is used to\n    /// help amortize allocation since not every powerset state generated is\n    /// added to the cache. In particular, if it already exists in the cache,\n    /// then there is no need to allocate a new `State` for it.\n    scratch_state_builder: StateBuilderEmpty,\n    /// A simple abstraction for handling the saving of at most a single state\n    /// across a cache clearing. This is required for correctness. Namely, if\n    /// adding a new state after clearing the cache fails, then the caller\n    /// must retain the ability to continue using the state ID given. The\n    /// state corresponding to the state ID is what we preserve across cache\n    /// clearings.\n    state_saver: StateSaver,\n    /// The memory usage, in bytes, used by 'states' and 'states_to_id'. We\n    /// track this as new states are added since states use a variable amount\n    /// of heap. Tracking this as we add states makes it possible to compute\n    /// the total amount of memory used by the determinizer in constant time.\n    memory_usage_state: usize,\n    /// The number of times the cache has been cleared. When a minimum cache\n    /// clear count is set, then the cache will return an error instead of\n    /// clearing the cache if the count has been exceeded.\n    clear_count: usize,\n    /// The total number of bytes searched since the last time this cache was\n    /// cleared, not including the current search.\n    ///\n    /// This can be added to the length of the current search to get the true\n    /// total number of bytes searched.\n    ///\n    /// This is generally only non-zero when the\n    /// `Cache::search_{start,update,finish}` APIs are used to track search\n    /// progress.\n    bytes_searched: usize,\n    /// The progress of the current search.\n    ///\n    /// This is only non-`None` when callers utlize the `Cache::search_start`,\n    /// `Cache::search_update` and `Cache::search_finish` APIs.\n    ///\n    /// The purpose of recording search progress is to be able to make a\n    /// determination about the efficiency of the cache. Namely, by keeping\n    /// track of the\n    progress: Option<SearchProgress>,\n}\n#[derive(Clone, Copy, Debug, Eq, Hash, PartialEq)]\npub struct HalfMatch {\n    /// The pattern ID.\n    pattern: PatternID,\n    /// The offset of the match.\n    ///\n    /// For forward searches, the offset is exclusive. For reverse searches,\n    /// the offset is inclusive.\n    offset: usize,\n}\n#[derive(Clone, Debug)]\npub struct Prefilter {\n    #[cfg(not(feature = \"alloc\"))]\n    _unused: (),\n    #[cfg(feature = \"alloc\")]\n    pre: Arc<dyn PrefilterI>,\n    #[cfg(feature = \"alloc\")]\n    is_fast: bool,\n    #[cfg(feature = \"alloc\")]\n    max_needle_len: usize,\n}\n#[derive(Clone, Debug, Eq, PartialEq)]\npub struct MatchError(\n    #[cfg(feature = \"alloc\")]\n    alloc::boxed::Box<MatchErrorKind>,\n    #[cfg(not(feature = \"alloc\"))]\n    MatchErrorKind,\n);\n#[derive(Clone, Copy, Debug, Eq, PartialEq)]\npub enum Anchored {\n    /// Run an unanchored search. This means a match may occur anywhere at or\n    /// after the start position of the search.\n    ///\n    /// This search can return a match for any pattern in the regex.\n    No,\n    /// Run an anchored search. This means that a match must begin at the\n    /// start position of the search.\n    ///\n    /// This search can return a match for any pattern in the regex.\n    Yes,\n    /// Run an anchored search for a specific pattern. This means that a match\n    /// must be for the given pattern and must begin at the start position of\n    /// the search.\n    Pattern(PatternID),\n}\nimpl<'h> Input<'h> {\n    #[inline]\n    pub fn new<H: ?Sized + AsRef<[u8]>>(haystack: &'h H) -> Input<'h> {}\n    #[inline]\n    pub fn span<S: Into<Span>>(mut self, span: S) -> Input<'h> {}\n    #[inline]\n    pub fn range<R: RangeBounds<usize>>(mut self, range: R) -> Input<'h> {}\n    #[inline]\n    pub fn anchored(mut self, mode: Anchored) -> Input<'h> {}\n    #[inline]\n    pub fn earliest(mut self, yes: bool) -> Input<'h> {}\n    #[inline]\n    pub fn set_span<S: Into<Span>>(&mut self, span: S) {}\n    #[inline]\n    pub fn set_range<R: RangeBounds<usize>>(&mut self, range: R) {}\n    #[inline]\n    pub fn set_start(&mut self, start: usize) {}\n    #[inline]\n    pub fn set_end(&mut self, end: usize) {}\n    #[inline]\n    pub fn set_anchored(&mut self, mode: Anchored) {}\n    #[inline]\n    pub fn set_earliest(&mut self, yes: bool) {}\n    #[inline]\n    pub fn haystack(&self) -> &[u8] {}\n    #[inline]\n    pub fn start(&self) -> usize {}\n    #[inline]\n    pub fn end(&self) -> usize {}\n    #[inline]\n    pub fn get_span(&self) -> Span {}\n    #[inline]\n    pub fn get_range(&self) -> Range<usize> {}\n    #[inline]\n    pub fn get_anchored(&self) -> Anchored {\n        self.anchored\n    }\n    #[inline]\n    pub fn get_earliest(&self) -> bool {\n        self.earliest\n    }\n    #[inline]\n    pub fn is_done(&self) -> bool {\n        self.get_span().start > self.get_span().end\n    }\n    #[inline]\n    pub fn is_char_boundary(&self, offset: usize) -> bool {}\n}\nimpl Config {\n    pub fn new() -> Config {}\n    pub fn match_kind(mut self, kind: MatchKind) -> Config {}\n    pub fn prefilter(mut self, pre: Option<Prefilter>) -> Config {}\n    pub fn starts_for_each_pattern(mut self, yes: bool) -> Config {}\n    pub fn byte_classes(mut self, yes: bool) -> Config {}\n    pub fn unicode_word_boundary(mut self, yes: bool) -> Config {}\n    pub fn quit(mut self, byte: u8, yes: bool) -> Config {}\n    pub fn specialize_start_states(mut self, yes: bool) -> Config {}\n    pub fn cache_capacity(mut self, bytes: usize) -> Config {}\n    pub fn skip_cache_capacity_check(mut self, yes: bool) -> Config {}\n    pub fn minimum_cache_clear_count(mut self, min: Option<usize>) -> Config {}\n    pub fn minimum_bytes_per_state(mut self, min: Option<usize>) -> Config {}\n    pub fn get_match_kind(&self) -> MatchKind {}\n    pub fn get_prefilter(&self) -> Option<&Prefilter> {\n        self.pre.as_ref().unwrap_or(&None).as_ref()\n    }\n    pub fn get_starts_for_each_pattern(&self) -> bool {}\n    pub fn get_byte_classes(&self) -> bool {}\n    pub fn get_unicode_word_boundary(&self) -> bool {}\n    pub fn get_quit(&self, byte: u8) -> bool {}\n    pub fn get_specialize_start_states(&self) -> bool {}\n    pub fn get_cache_capacity(&self) -> usize {}\n    pub fn get_skip_cache_capacity_check(&self) -> bool {}\n    pub fn get_minimum_cache_clear_count(&self) -> Option<usize> {}\n    pub fn get_minimum_bytes_per_state(&self) -> Option<usize> {}\n    pub fn get_minimum_cache_capacity(\n        &self,\n        nfa: &thompson::NFA,\n    ) -> Result<usize, BuildError> {}\n    fn byte_classes_from_nfa(&self, nfa: &thompson::NFA, quit: &ByteSet) -> ByteClasses {}\n    fn quit_set_from_nfa(&self, nfa: &thompson::NFA) -> Result<ByteSet, BuildError> {}\n    fn overwrite(&self, o: Config) -> Config {}\n}\nimpl DFA {\n    #[cfg(feature = \"syntax\")]\n    pub fn new(pattern: &str) -> Result<DFA, BuildError> {}\n    #[cfg(feature = \"syntax\")]\n    pub fn new_many<P: AsRef<str>>(patterns: &[P]) -> Result<DFA, BuildError> {}\n    pub fn always_match() -> Result<DFA, BuildError> {}\n    pub fn never_match() -> Result<DFA, BuildError> {}\n    pub fn config() -> Config {}\n    pub fn builder() -> Builder {}\n    pub fn create_cache(&self) -> Cache {}\n    pub fn reset_cache(&self, cache: &mut Cache) {}\n    pub fn pattern_len(&self) -> usize {}\n    pub fn byte_classes(&self) -> &ByteClasses {}\n    pub fn get_config(&self) -> &Config {\n        &self.config\n    }\n    pub fn get_nfa(&self) -> &thompson::NFA {}\n    fn stride2(&self) -> usize {}\n    fn stride(&self) -> usize {}\n    pub fn memory_usage(&self) -> usize {}\n}\nimpl Anchored {\n    #[inline]\n    pub fn is_anchored(&self) -> bool {\n        matches!(* self, Anchored::Yes | Anchored::Pattern(_))\n    }\n    #[inline]\n    pub fn pattern(&self) -> Option<PatternID> {}\n}\n#[inline(never)]\npub(crate) fn find_fwd(\n    dfa: &DFA,\n    cache: &mut Cache,\n    input: &Input<'_>,\n) -> Result<Option<HalfMatch>, MatchError> {\n    if input.is_done() {\n        return Ok(None);\n    }\n    let pre = if input.get_anchored().is_anchored() {\n        None\n    } else {\n        dfa.get_config().get_prefilter()\n    };\n    if pre.is_some() {\n        if input.get_earliest() {\n            find_fwd_imp(dfa, cache, input, pre, true)\n        } else {\n            find_fwd_imp(dfa, cache, input, pre, false)\n        }\n    } else {\n        if input.get_earliest() {\n            find_fwd_imp(dfa, cache, input, None, true)\n        } else {\n            find_fwd_imp(dfa, cache, input, None, false)\n        }\n    }\n}\n#[cfg_attr(feature = \"perf-inline\", inline(always))]\nfn find_fwd_imp(\n    dfa: &DFA,\n    cache: &mut Cache,\n    input: &Input<'_>,\n    pre: Option<&'_ Prefilter>,\n    earliest: bool,\n) -> Result<Option<HalfMatch>, MatchError> {\n    let universal_start = dfa.get_nfa().look_set_prefix_any().is_empty();\n    let mut mat = None;\n    let mut sid = init_fwd(dfa, cache, input)?;\n    let mut at = input.start();\n    macro_rules! next_unchecked {\n        ($sid:expr, $at:expr) => {\n            { let byte = * input.haystack().get_unchecked($at); dfa\n            .next_state_untagged_unchecked(cache, $sid, byte) }\n        };\n    }\n    if let Some(ref pre) = pre {\n        let span = Span::from(at..input.end());\n        match pre.find(input.haystack(), span) {\n            None => return Ok(mat),\n            Some(ref span) => {\n                at = span.start;\n                if !universal_start {\n                    sid = prefilter_restart(dfa, cache, &input, at)?;\n                }\n            }\n        }\n    }\n    cache.search_start(at);\n    while at < input.end() {\n        if sid.is_tagged() {\n            cache.search_update(at);\n            sid = dfa\n                .next_state(cache, sid, input.haystack()[at])\n                .map_err(|_| gave_up(at))?;\n        } else {\n            let mut prev_sid = sid;\n            while at < input.end() {\n                prev_sid = unsafe { next_unchecked!(sid, at) };\n                if prev_sid.is_tagged() || at + 3 >= input.end() {\n                    core::mem::swap(&mut prev_sid, &mut sid);\n                    break;\n                }\n                at += 1;\n                sid = unsafe { next_unchecked!(prev_sid, at) };\n                if sid.is_tagged() {\n                    break;\n                }\n                at += 1;\n                prev_sid = unsafe { next_unchecked!(sid, at) };\n                if prev_sid.is_tagged() {\n                    core::mem::swap(&mut prev_sid, &mut sid);\n                    break;\n                }\n                at += 1;\n                sid = unsafe { next_unchecked!(prev_sid, at) };\n                if sid.is_tagged() {\n                    break;\n                }\n                at += 1;\n            }\n            if sid.is_unknown() {\n                cache.search_update(at);\n                sid = dfa\n                    .next_state(cache, prev_sid, input.haystack()[at])\n                    .map_err(|_| gave_up(at))?;\n            }\n        }\n        if sid.is_tagged() {\n            if sid.is_start() {\n                if let Some(ref pre) = pre {\n                    let span = Span::from(at..input.end());\n                    match pre.find(input.haystack(), span) {\n                        None => {\n                            cache.search_finish(span.end);\n                            return Ok(mat);\n                        }\n                        Some(ref span) => {\n                            if span.start > at {\n                                at = span.start;\n                                if !universal_start {\n                                    sid = prefilter_restart(dfa, cache, &input, at)?;\n                                }\n                                continue;\n                            }\n                        }\n                    }\n                }\n            } else if sid.is_match() {\n                let pattern = dfa.match_pattern(cache, sid, 0);\n                mat = Some(HalfMatch::new(pattern, at));\n                if earliest {\n                    cache.search_finish(at);\n                    return Ok(mat);\n                }\n            } else if sid.is_dead() {\n                cache.search_finish(at);\n                return Ok(mat);\n            } else if sid.is_quit() {\n                cache.search_finish(at);\n                return Err(MatchError::quit(input.haystack()[at], at));\n            } else {\n                debug_assert!(sid.is_unknown());\n                unreachable!(\"sid being unknown is a bug\");\n            }\n        }\n        at += 1;\n    }\n    eoi_fwd(dfa, cache, input, &mut sid, &mut mat)?;\n    cache.search_finish(input.end());\n    Ok(mat)\n}\n\nThe function to be tested is presented with each line formatted as 'line number + code':\n13 pub(crate) fn find_fwd(\n14     dfa: &DFA,\n15     cache: &mut Cache,\n16     input: &Input<'_>,\n17 ) -> Result<Option<HalfMatch>, MatchError> {\n18     if input.is_done() {\n19         return Ok(None);\n20     }\n21     let pre = if input.get_anchored().is_anchored() {\n22         None\n23     } else {\n24         dfa.get_config().get_prefilter()\n25     };\n26     // So what we do here is specialize four different versions of 'find_fwd':\n27     // one for each of the combinations for 'has prefilter' and 'is earliest\n28     // search'. The reason for doing this is that both of these things require\n29     // branches and special handling in some code that can be very hot,\n30     // and shaving off as much as we can when we don't need it tends to be\n31     // beneficial in ad hoc benchmarks. To see these differences, you often\n32     // need a query with a high match count. In other words, specializing these\n33     // four routines *tends* to help latency more than throughput.\n34     if pre.is_some() {\n35         if input.get_earliest() {\n36             find_fwd_imp(dfa, cache, input, pre, true)\n37         } else {\n38             find_fwd_imp(dfa, cache, input, pre, false)\n39         }\n40     } else {\n41         if input.get_earliest() {\n42             find_fwd_imp(dfa, cache, input, None, true)\n43         } else {\n44             find_fwd_imp(dfa, cache, input, None, false)\n45         }\n46     }\n47 }\n\nThe path conditions that the generated test functions should satisfy are as follows:\n"
}