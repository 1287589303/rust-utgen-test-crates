{
  "system_pt": "As a software testing expert, please generate Rust test functions based on the following guidelines, focusing solely on constructing test inputs and calling the functions under test:\n1. Provide the code in plain text format, without explanations or Markdown.\n2. If the method under test belongs to a trait, construct appropriate structs within the test function, but avoid method overrides. If the method under test uses generics, instantiate them with suitable types based on the context.\n3. Generate test code with minimal scope: avoid creating external structures or implementations. Instead, define any necessary helper structures or implementations directly within the test function when required.\n4. Whenever possible, initialize the corresponding data structures using the initialization methods provided in the context.\n5. Ensure the generated function is fully implemented and can be compiled and executed directly without any missing parts.\n6. Create a minimal yet complete set of test functions, ensuring they adhere to all provided preconditions and cover boundary conditions, and reference the inferred test input conditions or ranges.\n7. Ensure the test inputs are designed to cover the inferred test input conditions or ranges as comprehensively as possible, with particular emphasis on boundary cases.\n8. Focus on crafting test inputs that effectively reveal potential bugs while meeting the specified requirements.\n9. Omit test oracles and assertions; concentrate on generating test inputs and function calls.\n10. Do not create a test module, but include intrinsic attributes like #[test] or #[should_panic] where necessary.\n",
  "static_pt": "The context for the focal function is as follows:\n// regex-automata/src/hybrid/dfa.rs\n// crate name is regex_automata\n#[cfg(feature = \"std\")]\ntype StateMap = std::collections::HashMap<State, LazyStateID>;\n#[cfg(not(feature = \"std\"))]\ntype StateMap = alloc::collections::BTreeMap<State, LazyStateID>;\nuse core::{iter, mem::size_of};\nuse alloc::vec::Vec;\nuse crate::{\n    hybrid::{\n        error::{BuildError, CacheError, StartError},\n        id::{LazyStateID, LazyStateIDError},\n        search,\n    },\n    nfa::thompson,\n    util::{\n        alphabet::{self, ByteClasses, ByteSet},\n        determinize::{self, State, StateBuilderEmpty, StateBuilderNFA},\n        empty, prefilter::Prefilter, primitives::{PatternID, StateID as NFAStateID},\n        search::{Anchored, HalfMatch, Input, MatchError, MatchKind, PatternSet},\n        sparse_set::SparseSets, start::{self, Start, StartByteMap},\n    },\n};\nconst MIN_STATES: usize = SENTINEL_STATES + 2;\nconst SENTINEL_STATES: usize = 3;\n#[derive(Clone, Debug, Default)]\npub struct Config {\n    match_kind: Option<MatchKind>,\n    pre: Option<Option<Prefilter>>,\n    starts_for_each_pattern: Option<bool>,\n    byte_classes: Option<bool>,\n    unicode_word_boundary: Option<bool>,\n    quitset: Option<ByteSet>,\n    specialize_start_states: Option<bool>,\n    cache_capacity: Option<usize>,\n    skip_cache_capacity_check: Option<bool>,\n    minimum_cache_clear_count: Option<Option<usize>>,\n    minimum_bytes_per_state: Option<Option<usize>>,\n}\n#[derive(Clone, Debug)]\npub(crate) struct ByteSet([bool; 256]);\n#[derive(Clone, Copy)]\npub struct ByteClasses([u8; 256]);\n#[derive(Clone, Debug)]\npub struct BuildError {\n    kind: BuildErrorKind,\n}\n#[derive(Clone, Debug)]\npub struct Prefilter {\n    #[cfg(not(feature = \"alloc\"))]\n    _unused: (),\n    #[cfg(feature = \"alloc\")]\n    pre: Arc<dyn PrefilterI>,\n    #[cfg(feature = \"alloc\")]\n    is_fast: bool,\n    #[cfg(feature = \"alloc\")]\n    max_needle_len: usize,\n}\n#[derive(Clone, Copy, Debug, Default, Eq, PartialEq)]\npub(crate) struct ByteSet {\n    bits: BitSet,\n}\n#[derive(Clone)]\npub struct NFA(Arc<Inner>);\n#[non_exhaustive]\n#[derive(Clone, Copy, Debug, Eq, PartialEq)]\npub enum MatchKind {\n    /// Report all possible matches.\n    All,\n    /// Report only the leftmost matches. When multiple leftmost matches exist,\n    /// report the match corresponding to the part of the regex that appears\n    /// first in the syntax.\n    LeftmostFirst,\n}\nimpl Config {\n    pub fn new() -> Config {}\n    pub fn match_kind(mut self, kind: MatchKind) -> Config {}\n    pub fn prefilter(mut self, pre: Option<Prefilter>) -> Config {}\n    pub fn starts_for_each_pattern(mut self, yes: bool) -> Config {}\n    pub fn byte_classes(mut self, yes: bool) -> Config {}\n    pub fn unicode_word_boundary(mut self, yes: bool) -> Config {}\n    pub fn quit(mut self, byte: u8, yes: bool) -> Config {}\n    pub fn specialize_start_states(mut self, yes: bool) -> Config {}\n    pub fn cache_capacity(mut self, bytes: usize) -> Config {}\n    pub fn skip_cache_capacity_check(mut self, yes: bool) -> Config {}\n    pub fn minimum_cache_clear_count(mut self, min: Option<usize>) -> Config {}\n    pub fn minimum_bytes_per_state(mut self, min: Option<usize>) -> Config {}\n    pub fn get_match_kind(&self) -> MatchKind {}\n    pub fn get_prefilter(&self) -> Option<&Prefilter> {}\n    pub fn get_starts_for_each_pattern(&self) -> bool {\n        self.starts_for_each_pattern.unwrap_or(false)\n    }\n    pub fn get_byte_classes(&self) -> bool {}\n    pub fn get_unicode_word_boundary(&self) -> bool {}\n    pub fn get_quit(&self, byte: u8) -> bool {}\n    pub fn get_specialize_start_states(&self) -> bool {}\n    pub fn get_cache_capacity(&self) -> usize {}\n    pub fn get_skip_cache_capacity_check(&self) -> bool {}\n    pub fn get_minimum_cache_clear_count(&self) -> Option<usize> {}\n    pub fn get_minimum_bytes_per_state(&self) -> Option<usize> {}\n    pub fn get_minimum_cache_capacity(\n        &self,\n        nfa: &thompson::NFA,\n    ) -> Result<usize, BuildError> {\n        let quitset = self.quit_set_from_nfa(nfa)?;\n        let classes = self.byte_classes_from_nfa(nfa, &quitset);\n        let starts = self.get_starts_for_each_pattern();\n        Ok(minimum_cache_capacity(nfa, &classes, starts))\n    }\n    fn byte_classes_from_nfa(&self, nfa: &thompson::NFA, quit: &ByteSet) -> ByteClasses {\n        if !self.get_byte_classes() {\n            ByteClasses::singletons()\n        } else {\n            let mut set = nfa.byte_class_set().clone();\n            if !quit.is_empty() {\n                set.add_set(&quit);\n            }\n            set.byte_classes()\n        }\n    }\n    fn quit_set_from_nfa(&self, nfa: &thompson::NFA) -> Result<ByteSet, BuildError> {\n        let mut quit = self.quitset.unwrap_or(ByteSet::empty());\n        if nfa.look_set_any().contains_word_unicode() {\n            if self.get_unicode_word_boundary() {\n                for b in 0x80..=0xFF {\n                    quit.add(b);\n                }\n            } else {\n                if !quit.contains_range(0x80, 0xFF) {\n                    return Err(BuildError::unsupported_dfa_word_boundary_unicode());\n                }\n            }\n        }\n        Ok(quit)\n    }\n    fn overwrite(&self, o: Config) -> Config {}\n}\nfn minimum_cache_capacity(\n    nfa: &thompson::NFA,\n    classes: &ByteClasses,\n    starts_for_each_pattern: bool,\n) -> usize {\n    const ID_SIZE: usize = size_of::<LazyStateID>();\n    const STATE_SIZE: usize = size_of::<State>();\n    let stride = 1 << classes.stride2();\n    let states_len = nfa.states().len();\n    let sparses = 2 * states_len * NFAStateID::SIZE;\n    let trans = MIN_STATES * stride * ID_SIZE;\n    let mut starts = Start::len() * ID_SIZE;\n    if starts_for_each_pattern {\n        starts += (Start::len() * nfa.pattern_len()) * ID_SIZE;\n    }\n    assert!(MIN_STATES >= 5, \"minimum number of states has to be at least 5\");\n    let non_sentinel = MIN_STATES.checked_sub(SENTINEL_STATES).unwrap();\n    let dead_state_size = State::dead().memory_usage();\n    let max_state_size = 5 + 4 + (nfa.pattern_len() * 4) + (states_len * 5);\n    let states = (SENTINEL_STATES * (STATE_SIZE + dead_state_size))\n        + (non_sentinel * (STATE_SIZE + max_state_size));\n    let states_to_sid = (MIN_STATES * STATE_SIZE) + (MIN_STATES * ID_SIZE);\n    let stack = states_len * NFAStateID::SIZE;\n    let scratch_state_builder = max_state_size;\n    trans + starts + states + states_to_sid + sparses + stack + scratch_state_builder\n}\n\nThe function to be tested is presented with each line formatted as 'line number + code':\n/// Returns the minimum lazy DFA cache capacity required for the given NFA.\n///\n/// The cache capacity required for a particular NFA may change without\n/// notice. Callers should not rely on it being stable.\n///\n/// This is useful for informational purposes, but can also be useful for\n/// other reasons. For example, if one wants to check the minimum cache\n/// capacity themselves or if one wants to set the capacity based on the\n/// minimum.\n///\n/// This may return an error if this configuration does not support all of\n/// the instructions used in the given NFA. For example, if the NFA has a\n/// Unicode word boundary but this configuration does not enable heuristic\n/// support for Unicode word boundaries.\n3801 pub fn get_minimum_cache_capacity(\n3802     &self,\n3803     nfa: &thompson::NFA,\n3804 ) -> Result<usize, BuildError> {\n3805     let quitset = self.quit_set_from_nfa(nfa)?;\n3806     let classes = self.byte_classes_from_nfa(nfa, &quitset);\n3807     let starts = self.get_starts_for_each_pattern();\n3808     Ok(minimum_cache_capacity(nfa, &classes, starts))\n3809 }\n\nGenerate each test function in such a manner that it concurrently satisfies all the following preconditions:\n",
  "depend_pt": ""
}