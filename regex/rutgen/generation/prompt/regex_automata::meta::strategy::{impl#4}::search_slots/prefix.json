{
  "system_pt": "As a software testing expert, please generate Rust test functions based on the following guidelines, focusing solely on constructing test inputs and calling the functions under test:\n1. Provide the code in plain text format, without explanations or Markdown.\n2. If the method under test belongs to a trait, construct appropriate structs within the test function, but avoid method overrides. If the method under test uses generics, instantiate them with suitable types based on the context.\n3. Generate test code with minimal scope: avoid creating external structures or implementations. Instead, define any necessary helper structures or implementations directly within the test function when required.\n4. Whenever possible, initialize the corresponding data structures using the initialization methods provided in the context.\n5. Ensure the generated function is fully implemented and can be compiled and executed directly without any missing parts.\n6. Create a minimal yet complete set of test functions, ensuring they adhere to all provided preconditions and cover boundary conditions, and reference the inferred test input conditions or ranges.\n7. Ensure the test inputs are designed to cover the inferred test input conditions or ranges as comprehensively as possible, with particular emphasis on boundary cases.\n8. Focus on crafting test inputs that effectively reveal potential bugs while meeting the specified requirements.\n9. Omit test oracles and assertions; concentrate on generating test inputs and function calls.\n10. Do not create a test module, but include intrinsic attributes like #[test] or #[should_panic] where necessary.\n",
  "static_pt": "The context for the focal function is as follows:\n// regex-automata/src/meta/strategy.rs\n// crate name is regex_automata\nuse core::{fmt::Debug, panic::{RefUnwindSafe, UnwindSafe}};\nuse alloc::sync::Arc;\nuse regex_syntax::hir::{literal, Hir};\nuse crate::{\n    meta::{\n        error::{BuildError, RetryError, RetryFailError, RetryQuadraticError},\n        regex::{Cache, RegexInfo},\n        reverse_inner, wrappers,\n    },\n    nfa::thompson::{self, WhichCaptures, NFA},\n    util::{\n        captures::{Captures, GroupInfo},\n        look::LookMatcher, prefilter::{self, Prefilter, PrefilterI},\n        primitives::{NonMaxUsize, PatternID},\n        search::{Anchored, HalfMatch, Input, Match, MatchKind, PatternSet},\n    },\n};\npub(super) trait Strategy: Debug + Send + Sync + RefUnwindSafe + UnwindSafe + 'static {\n    fn group_info(&self) -> &GroupInfo;\n    fn create_cache(&self) -> Cache;\n    fn reset_cache(&self, cache: &mut Cache);\n    fn is_accelerated(&self) -> bool;\n    fn memory_usage(&self) -> usize;\n    fn search(&self, cache: &mut Cache, input: &Input<'_>) -> Option<Match>;\n    fn search_half(&self, cache: &mut Cache, input: &Input<'_>) -> Option<HalfMatch>;\n    fn is_match(&self, cache: &mut Cache, input: &Input<'_>) -> bool;\n    fn search_slots(\n        &self,\n        cache: &mut Cache,\n        input: &Input<'_>,\n        slots: &mut [Option<NonMaxUsize>],\n    ) -> Option<PatternID>;\n    fn which_overlapping_matches(\n        &self,\n        cache: &mut Cache,\n        input: &Input<'_>,\n        patset: &mut PatternSet,\n    );\n}\n#[derive(Debug)]\nstruct Core {\n    info: RegexInfo,\n    pre: Option<Prefilter>,\n    nfa: NFA,\n    nfarev: Option<NFA>,\n    pikevm: wrappers::PikeVM,\n    backtrack: wrappers::BoundedBacktracker,\n    onepass: wrappers::OnePass,\n    hybrid: wrappers::Hybrid,\n    dfa: wrappers::DFA,\n}\n#[derive(Clone, Copy, Debug, Eq, Hash, PartialEq)]\npub struct Match {\n    /// The pattern ID.\n    pattern: PatternID,\n    /// The underlying match span.\n    span: Span,\n}\n#[derive(Clone)]\npub struct Input<'h> {\n    haystack: &'h [u8],\n    span: Span,\n    anchored: Anchored,\n    earliest: bool,\n}\n#[derive(Debug)]\npub(crate) struct OnePass(Option<OnePassEngine>);\n#[derive(Debug)]\npub(crate) struct DFA(Option<DFAEngine>);\n#[derive(Debug)]\npub(crate) struct PikeVM(PikeVMEngine);\n#[derive(Clone)]\npub struct DFA<T> {\n    /// The transition table for this DFA. This includes the transitions\n    /// themselves, along with the stride, number of states and the equivalence\n    /// class mapping.\n    tt: TransitionTable<T>,\n    /// The set of starting state identifiers for this DFA. The starting state\n    /// IDs act as pointers into the transition table. The specific starting\n    /// state chosen for each search is dependent on the context at which the\n    /// search begins.\n    st: StartTable<T>,\n    /// The set of match states and the patterns that match for each\n    /// corresponding match state.\n    ///\n    /// This structure is technically only needed because of support for\n    /// multi-regexes. Namely, multi-regexes require answering not just whether\n    /// a match exists, but _which_ patterns match. So we need to store the\n    /// matching pattern IDs for each match state. We do this even when there\n    /// is only one pattern for the sake of simplicity. In practice, this uses\n    /// up very little space for the case of one pattern.\n    ms: MatchStates<T>,\n    /// Information about which states are \"special.\" Special states are states\n    /// that are dead, quit, matching, starting or accelerated. For more info,\n    /// see the docs for `Special`.\n    special: Special,\n    /// The accelerators for this DFA.\n    ///\n    /// If a state is accelerated, then there exist only a small number of\n    /// bytes that can cause the DFA to leave the state. This permits searching\n    /// to use optimized routines to find those specific bytes instead of using\n    /// the transition table.\n    ///\n    /// All accelerated states exist in a contiguous range in the DFA's\n    /// transition table. See dfa/special.rs for more details on how states are\n    /// arranged.\n    accels: Accels<T>,\n    /// Any prefilter attached to this DFA.\n    ///\n    /// Note that currently prefilters are not serialized. When deserializing\n    /// a DFA from bytes, this is always set to `None`.\n    pre: Option<Prefilter>,\n    /// The set of \"quit\" bytes for this DFA.\n    ///\n    /// This is only used when computing the start state for a particular\n    /// position in a haystack. Namely, in the case where there is a quit\n    /// byte immediately before the start of the search, this set needs to be\n    /// explicitly consulted. In all other cases, quit bytes are detected by\n    /// the DFA itself, by transitioning all quit bytes to a special \"quit\n    /// state.\"\n    quitset: ByteSet,\n    /// Various flags describing the behavior of this DFA.\n    flags: Flags,\n}\n#[derive(Clone)]\npub struct NFA(Arc<Inner>);\n#[derive(Clone)]\npub struct DFA<T> {\n    tt: Transitions<T>,\n    st: StartTable<T>,\n    special: Special,\n    pre: Option<Prefilter>,\n    quitset: ByteSet,\n    flags: Flags,\n}\n#[derive(Clone, Debug)]\npub(crate) struct RegexInfo(Arc<RegexInfoI>);\n#[derive(Debug)]\npub(crate) struct RetryFailError {\n    offset: usize,\n}\n#[derive(Debug)]\npub(crate) struct BoundedBacktracker(Option<BoundedBacktrackerEngine>);\n#[derive(Clone, Copy, Default, Eq, Hash, PartialEq, PartialOrd, Ord)]\n#[repr(transparent)]\npub struct PatternID(SmallIndex);\n#[derive(Clone, Debug)]\npub struct PikeVM {\n    config: Config,\n    nfa: NFA,\n}\n#[derive(Debug)]\npub(crate) struct Hybrid(Option<HybridEngine>);\n#[derive(Debug)]\npub(crate) struct OnePassEngine(\n    #[cfg(feature = \"dfa-onepass\")]\n    onepass::DFA,\n    #[cfg(not(feature = \"dfa-onepass\"))]\n    (),\n);\n#[derive(Clone)]\npub struct DFA {\n    /// The configuration provided by the caller.\n    config: Config,\n    /// The NFA used to build this DFA.\n    ///\n    /// NOTE: We probably don't need to store the NFA here, but we use enough\n    /// bits from it that it's convenient to do so. And there really isn't much\n    /// cost to doing so either, since an NFA is reference counted internally.\n    nfa: NFA,\n    /// The transition table. Given a state ID 's' and a byte of haystack 'b',\n    /// the next state is `table[sid + classes[byte]]`.\n    ///\n    /// The stride of this table (i.e., the number of columns) is always\n    /// a power of 2, even if the alphabet length is smaller. This makes\n    /// converting between state IDs and state indices very cheap.\n    ///\n    /// Note that the stride always includes room for one extra \"transition\"\n    /// that isn't actually a transition. It is a 'PatternEpsilons' that is\n    /// used for match states only. Because of this, the maximum number of\n    /// active columns in the transition table is 257, which means the maximum\n    /// stride is 512 (the next power of 2 greater than or equal to 257).\n    table: Vec<Transition>,\n    /// The DFA state IDs of the starting states.\n    ///\n    /// `starts[0]` is always present and corresponds to the starting state\n    /// when searching for matches of any pattern in the DFA.\n    ///\n    /// `starts[i]` where i>0 corresponds to the starting state for the pattern\n    /// ID 'i-1'. These starting states are optional.\n    starts: Vec<StateID>,\n    /// Every state ID >= this value corresponds to a match state.\n    ///\n    /// This is what a search uses to detect whether a state is a match state\n    /// or not. It requires only a simple comparison instead of bit-unpacking\n    /// the PatternEpsilons from every state.\n    min_match_id: StateID,\n    /// The alphabet of this DFA, split into equivalence classes. Bytes in the\n    /// same equivalence class can never discriminate between a match and a\n    /// non-match.\n    classes: ByteClasses,\n    /// The number of elements in each state in the transition table. This may\n    /// be less than the stride, since the stride is always a power of 2 and\n    /// the alphabet length can be anything up to and including 256.\n    alphabet_len: usize,\n    /// The number of columns in the transition table, expressed as a power of\n    /// 2.\n    stride2: usize,\n    /// The offset at which the PatternEpsilons for a match state is stored in\n    /// the transition table.\n    ///\n    /// PERF: One wonders whether it would be better to put this in a separate\n    /// allocation, since only match states have a non-empty PatternEpsilons\n    /// and the number of match states tends be dwarfed by the number of\n    /// non-match states. So this would save '8*len(non_match_states)' for each\n    /// DFA. The question is whether moving this to a different allocation will\n    /// lead to a perf hit during searches. You might think dealing with match\n    /// states is rare, but some regexes spend a lot of time in match states\n    /// gobbling up input. But... match state handling is already somewhat\n    /// expensive, so maybe this wouldn't do much? Either way, it's worth\n    /// experimenting.\n    pateps_offset: usize,\n    /// The first explicit slot index. This refers to the first slot appearing\n    /// immediately after the last implicit slot. It is always 'patterns.len()\n    /// * 2'.\n    ///\n    /// We record this because we only store the explicit slots in our DFA\n    /// transition table that need to be saved. Implicit slots are handled\n    /// automatically as part of the search.\n    explicit_slot_start: usize,\n}\n#[derive(Clone, Debug)]\npub struct DFA {\n    config: Config,\n    nfa: thompson::NFA,\n    stride2: usize,\n    start_map: StartByteMap,\n    classes: ByteClasses,\n    quitset: ByteSet,\n    cache_capacity: usize,\n}\n#[derive(Clone, Copy, Eq, Hash, PartialEq, PartialOrd, Ord)]\n#[repr(transparent)]\npub struct NonMaxUsize(NonZeroUsize);\n#[derive(Debug, Clone)]\npub struct Cache {\n    pub(crate) capmatches: Captures,\n    pub(crate) pikevm: wrappers::PikeVMCache,\n    pub(crate) backtrack: wrappers::BoundedBacktrackerCache,\n    pub(crate) onepass: wrappers::OnePassCache,\n    pub(crate) hybrid: wrappers::HybridCache,\n    pub(crate) revhybrid: wrappers::ReverseHybridCache,\n}\n#[derive(Clone, Debug)]\npub struct BoundedBacktracker {\n    config: Config,\n    nfa: NFA,\n}\n#[derive(Clone, Debug)]\npub struct Prefilter {\n    #[cfg(not(feature = \"alloc\"))]\n    _unused: (),\n    #[cfg(feature = \"alloc\")]\n    pre: Arc<dyn PrefilterI>,\n    #[cfg(feature = \"alloc\")]\n    is_fast: bool,\n    #[cfg(feature = \"alloc\")]\n    max_needle_len: usize,\n}\n#[derive(Clone, Copy, Debug, Eq, PartialEq)]\npub enum Anchored {\n    /// Run an unanchored search. This means a match may occur anywhere at or\n    /// after the start position of the search.\n    ///\n    /// This search can return a match for any pattern in the regex.\n    No,\n    /// Run an anchored search. This means that a match must begin at the\n    /// start position of the search.\n    ///\n    /// This search can return a match for any pattern in the regex.\n    Yes,\n    /// Run an anchored search for a specific pattern. This means that a match\n    /// must be for the given pattern and must begin at the start position of\n    /// the search.\n    Pattern(PatternID),\n}\nimpl Strategy for Core {\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    fn group_info(&self) -> &GroupInfo {}\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    fn create_cache(&self) -> Cache {}\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    fn reset_cache(&self, cache: &mut Cache) {}\n    fn is_accelerated(&self) -> bool {}\n    fn memory_usage(&self) -> usize {}\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    fn search(&self, cache: &mut Cache, input: &Input<'_>) -> Option<Match> {}\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    fn search_half(&self, cache: &mut Cache, input: &Input<'_>) -> Option<HalfMatch> {}\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    fn is_match(&self, cache: &mut Cache, input: &Input<'_>) -> bool {}\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    fn search_slots(\n        &self,\n        cache: &mut Cache,\n        input: &Input<'_>,\n        slots: &mut [Option<NonMaxUsize>],\n    ) -> Option<PatternID> {\n        if !self.is_capture_search_needed(slots.len()) {\n            trace!(\"asked for slots unnecessarily, trying fast path\");\n            let m = self.search(cache, input)?;\n            copy_match_to_slots(m, slots);\n            return Some(m.pattern());\n        }\n        if self.onepass.get(&input).is_some() {\n            return self.search_slots_nofail(cache, &input, slots);\n        }\n        let m = match self.try_search_mayfail(cache, input) {\n            Some(Ok(Some(m))) => m,\n            Some(Ok(None)) => return None,\n            Some(Err(_err)) => {\n                trace!(\"fast capture search failed: {}\", _err);\n                return self.search_slots_nofail(cache, input, slots);\n            }\n            None => {\n                return self.search_slots_nofail(cache, input, slots);\n            }\n        };\n        trace!(\n            \"match found at {}..{} in capture search, \\\n\t\t  \t using another engine to find captures\",\n            m.start(), m.end(),\n        );\n        let input = input\n            .clone()\n            .span(m.start()..m.end())\n            .anchored(Anchored::Pattern(m.pattern()));\n        Some(\n            self.search_slots_nofail(cache, &input, slots).expect(\"should find a match\"),\n        )\n    }\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    fn which_overlapping_matches(\n        &self,\n        cache: &mut Cache,\n        input: &Input<'_>,\n        patset: &mut PatternSet,\n    ) {}\n}\nimpl Core {\n    fn new(\n        info: RegexInfo,\n        pre: Option<Prefilter>,\n        hirs: &[&Hir],\n    ) -> Result<Core, BuildError> {}\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    fn try_search_mayfail(\n        &self,\n        cache: &mut Cache,\n        input: &Input<'_>,\n    ) -> Option<Result<Option<Match>, RetryFailError>> {\n        if let Some(e) = self.dfa.get(input) {\n            trace!(\"using full DFA for search at {:?}\", input.get_span());\n            Some(e.try_search(input))\n        } else if let Some(e) = self.hybrid.get(input) {\n            trace!(\"using lazy DFA for search at {:?}\", input.get_span());\n            Some(e.try_search(&mut cache.hybrid, input))\n        } else {\n            None\n        }\n    }\n    fn search_nofail(&self, cache: &mut Cache, input: &Input<'_>) -> Option<Match> {}\n    fn search_half_nofail(\n        &self,\n        cache: &mut Cache,\n        input: &Input<'_>,\n    ) -> Option<HalfMatch> {}\n    fn search_slots_nofail(\n        &self,\n        cache: &mut Cache,\n        input: &Input<'_>,\n        slots: &mut [Option<NonMaxUsize>],\n    ) -> Option<PatternID> {\n        if let Some(ref e) = self.onepass.get(input) {\n            trace!(\"using OnePass for capture search at {:?}\", input.get_span());\n            e.search_slots(&mut cache.onepass, input, slots)\n        } else if let Some(ref e) = self.backtrack.get(input) {\n            trace!(\n                \"using BoundedBacktracker for capture search at {:?}\", input.get_span()\n            );\n            e.search_slots(&mut cache.backtrack, input, slots)\n        } else {\n            trace!(\"using PikeVM for capture search at {:?}\", input.get_span());\n            let e = self.pikevm.get();\n            e.search_slots(&mut cache.pikevm, input, slots)\n        }\n    }\n    fn is_match_nofail(&self, cache: &mut Cache, input: &Input<'_>) -> bool {}\n    fn is_capture_search_needed(&self, slots_len: usize) -> bool {\n        slots_len > self.nfa.group_info().implicit_slot_len()\n    }\n}\nimpl Match {\n    #[inline]\n    pub fn new<S: Into<Span>>(pattern: PatternID, span: S) -> Match {}\n    #[inline]\n    pub fn must<S: Into<Span>>(pattern: usize, span: S) -> Match {}\n    #[inline]\n    pub fn pattern(&self) -> PatternID {\n        self.pattern\n    }\n    #[inline]\n    pub fn start(&self) -> usize {\n        self.span().start\n    }\n    #[inline]\n    pub fn end(&self) -> usize {\n        self.span().end\n    }\n    #[inline]\n    pub fn range(&self) -> core::ops::Range<usize> {}\n    #[inline]\n    pub fn span(&self) -> Span {}\n    #[inline]\n    pub fn is_empty(&self) -> bool {}\n    #[inline]\n    pub fn len(&self) -> usize {}\n}\nimpl<'h> Input<'h> {\n    #[inline]\n    pub fn new<H: ?Sized + AsRef<[u8]>>(haystack: &'h H) -> Input<'h> {}\n    #[inline]\n    pub fn span<S: Into<Span>>(mut self, span: S) -> Input<'h> {}\n    #[inline]\n    pub fn range<R: RangeBounds<usize>>(mut self, range: R) -> Input<'h> {}\n    #[inline]\n    pub fn anchored(mut self, mode: Anchored) -> Input<'h> {\n        self.set_anchored(mode);\n        self\n    }\n    #[inline]\n    pub fn earliest(mut self, yes: bool) -> Input<'h> {}\n    #[inline]\n    pub fn set_span<S: Into<Span>>(&mut self, span: S) {}\n    #[inline]\n    pub fn set_range<R: RangeBounds<usize>>(&mut self, range: R) {}\n    #[inline]\n    pub fn set_start(&mut self, start: usize) {}\n    #[inline]\n    pub fn set_end(&mut self, end: usize) {}\n    #[inline]\n    pub fn set_anchored(&mut self, mode: Anchored) {}\n    #[inline]\n    pub fn set_earliest(&mut self, yes: bool) {}\n    #[inline]\n    pub fn haystack(&self) -> &[u8] {}\n    #[inline]\n    pub fn start(&self) -> usize {}\n    #[inline]\n    pub fn end(&self) -> usize {}\n    #[inline]\n    pub fn get_span(&self) -> Span {}\n    #[inline]\n    pub fn get_range(&self) -> Range<usize> {}\n    #[inline]\n    pub fn get_anchored(&self) -> Anchored {}\n    #[inline]\n    pub fn get_earliest(&self) -> bool {}\n    #[inline]\n    pub fn is_done(&self) -> bool {}\n    #[inline]\n    pub fn is_char_boundary(&self, offset: usize) -> bool {}\n}\nimpl OnePass {\n    pub(crate) fn new(info: &RegexInfo, nfa: &NFA) -> OnePass {}\n    pub(crate) fn create_cache(&self) -> OnePassCache {}\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    pub(crate) fn get(&self, input: &Input<'_>) -> Option<&OnePassEngine> {\n        let engine = self.0.as_ref()?;\n        if !input.get_anchored().is_anchored()\n            && !engine.get_nfa().is_always_start_anchored()\n        {\n            return None;\n        }\n        Some(engine)\n    }\n    pub(crate) fn memory_usage(&self) -> usize {}\n}\n#[cfg_attr(feature = \"perf-inline\", inline(always))]\nfn copy_match_to_slots(m: Match, slots: &mut [Option<NonMaxUsize>]) {\n    let slot_start = m.pattern().as_usize() * 2;\n    let slot_end = slot_start + 1;\n    if let Some(slot) = slots.get_mut(slot_start) {\n        *slot = NonMaxUsize::new(m.start());\n    }\n    if let Some(slot) = slots.get_mut(slot_end) {\n        *slot = NonMaxUsize::new(m.end());\n    }\n}\n\nThe function to be tested is presented with each line formatted as 'line number + code':\n796 fn search_slots(\n797     &self,\n798     cache: &mut Cache,\n799     input: &Input<'_>,\n800     slots: &mut [Option<NonMaxUsize>],\n801 ) -> Option<PatternID> {\n802     // Even if the regex has explicit capture groups, if the caller didn't\n803     // provide any explicit slots, then it doesn't make sense to try and do\n804     // extra work to get offsets for those slots. Ideally the caller should\n805     // realize this and not call this routine in the first place, but alas,\n806     // we try to save the caller from themselves if they do.\n807     if !self.is_capture_search_needed(slots.len()) {\n808         trace!(\"asked for slots unnecessarily, trying fast path\");\n809         let m = self.search(cache, input)?;\n810         copy_match_to_slots(m, slots);\n811         return Some(m.pattern());\n812     }\n813     // If the onepass DFA is available for this search (which only happens\n814     // when it's anchored), then skip running a fallible DFA. The onepass\n815     // DFA isn't as fast as a full or lazy DFA, but it is typically quite\n816     // a bit faster than the backtracker or the PikeVM. So it isn't as\n817     // advantageous to try and do a full/lazy DFA scan first.\n818     //\n819     // We still theorize that it's better to do a full/lazy DFA scan, even\n820     // when it's anchored, because it's usually much faster and permits us\n821     // to say \"no match\" much more quickly. This does hurt the case of,\n822     // say, parsing each line in a log file into capture groups, because\n823     // in that case, the line always matches. So the lazy DFA scan is\n824     // usually just wasted work. But, the lazy DFA is usually quite fast\n825     // and doesn't cost too much here.\n826     if self.onepass.get(&input).is_some() {\n827         return self.search_slots_nofail(cache, &input, slots);\n828     }\n829     let m = match self.try_search_mayfail(cache, input) {\n830         Some(Ok(Some(m))) => m,\n831         Some(Ok(None)) => return None,\n832         Some(Err(_err)) => {\n833             trace!(\"fast capture search failed: {}\", _err);\n834             return self.search_slots_nofail(cache, input, slots);\n835         }\n836         None => {\n837             return self.search_slots_nofail(cache, input, slots);\n838         }\n839     };\n840     // At this point, now that we've found the bounds of the\n841     // match, we need to re-run something that can resolve\n842     // capturing groups. But we only need to run on it on the\n843     // match bounds and not the entire haystack.\n844     trace!(\n845         \"match found at {}..{} in capture search, \\\n846 \t using another engine to find captures\",\n847         m.start(),\n848         m.end(),\n849     );\n850     let input = input\n851         .clone()\n852         .span(m.start()..m.end())\n853         .anchored(Anchored::Pattern(m.pattern()));\n854     Some(\n855         self.search_slots_nofail(cache, &input, slots)\n856             .expect(\"should find a match\"),\n857     )\n858 }\n\nGenerate each test function in such a manner that it concurrently satisfies all the following preconditions:\n",
  "depend_pt": ""
}