{
  "system_pt": "As a software testing expert, please generate accurate test oracles code based on the provided information. Follow these guidelines:\n1. Generate executable test oracle codes in plain text format, one per line. Do not output complete test functions, avoid additional explanations, and do not use Markdown.\n2. Combine the given function under test, context, relevant documentation, preconditions, expected return values or types, test input conditions or ranges, and existing test function prefixes to infer and generate corresponding test oracles code.\n3. Only generate necessary test oracles to ensure comprehensive validation.\n",
  "static_pt": "The context for the focal function is as follows:\n// regex-automata/src/dfa/dense.rs\n// crate name is regex_automata\n#[cfg(feature = \"alloc\")]\npub(crate) type OwnedDFA = DFA<alloc::vec::Vec<u32>>;\n#[cfg(feature = \"dfa-build\")]\nuse core::cmp;\nuse core::{fmt, iter, mem::size_of, slice};\n#[cfg(feature = \"dfa-build\")]\nuse alloc::{\n    collections::{BTreeMap, BTreeSet},\n    vec, vec::Vec,\n};\n#[cfg(feature = \"dfa-build\")]\nuse crate::{\n    dfa::{accel::Accel, determinize, minimize::Minimizer, remapper::Remapper, sparse},\n    nfa::thompson, util::{look::LookMatcher, search::MatchKind},\n};\nuse crate::{\n    dfa::{\n        accel::Accels, automaton::{fmt_state_indicator, Automaton, StartError},\n        special::Special, start::StartKind, DEAD,\n    },\n    util::{\n        alphabet::{self, ByteClasses, ByteSet},\n        int::{Pointer, Usize},\n        prefilter::Prefilter, primitives::{PatternID, StateID},\n        search::Anchored, start::{self, Start, StartByteMap},\n        wire::{self, DeserializeError, Endian, SerializeError},\n    },\n};\nconst LABEL: &str = \"rust-regex-automata-dfa-dense\";\nconst VERSION: u32 = 2;\n#[derive(Clone)]\npub(crate) struct StartTable<T> {\n    /// The initial start state IDs.\n    ///\n    /// In practice, T is either `Vec<u32>` or `&[u32]`.\n    ///\n    /// The first `2 * stride` (currently always 8) entries always correspond\n    /// to the starts states for the entire DFA, with the first 4 entries being\n    /// for unanchored searches and the second 4 entries being for anchored\n    /// searches. To keep things simple, we always use 8 entries even if the\n    /// `StartKind` is not both.\n    ///\n    /// After that, there are `stride * patterns` state IDs, where `patterns`\n    /// may be zero in the case of a DFA with no patterns or in the case where\n    /// the DFA was built without enabling starting states for each pattern.\n    table: T,\n    /// The starting state configuration supported. When 'both', both\n    /// unanchored and anchored searches work. When 'unanchored', anchored\n    /// searches panic. When 'anchored', unanchored searches panic.\n    kind: StartKind,\n    /// The start state configuration for every possible byte.\n    start_map: StartByteMap,\n    /// The number of starting state IDs per pattern.\n    stride: usize,\n    /// The total number of patterns for which starting states are encoded.\n    /// This is `None` for DFAs that were built without start states for each\n    /// pattern. Thus, one cannot use this field to say how many patterns\n    /// are in the DFA in all cases. It is specific to how many patterns are\n    /// represented in this start table.\n    pattern_len: Option<usize>,\n    /// The universal starting state for unanchored searches. This is only\n    /// present when the DFA supports unanchored searches and when all starting\n    /// state IDs for an unanchored search are equivalent.\n    universal_start_unanchored: Option<StateID>,\n    /// The universal starting state for anchored searches. This is only\n    /// present when the DFA supports anchored searches and when all starting\n    /// state IDs for an anchored search are equivalent.\n    universal_start_anchored: Option<StateID>,\n}\n#[derive(Debug)]\npub struct SerializeError {\n    /// The name of the thing that a buffer is too small for.\n    ///\n    /// Currently, the only kind of serialization error is one that is\n    /// committed by a caller: providing a destination buffer that is too\n    /// small to fit the serialized object. This makes sense conceptually,\n    /// since every valid inhabitant of a type should be serializable.\n    ///\n    /// This is somewhat exposed in the public API of this crate. For example,\n    /// the `to_bytes_{big,little}_endian` APIs return a `Vec<u8>` and are\n    /// guaranteed to never panic or error. This is only possible because the\n    /// implementation guarantees that it will allocate a `Vec<u8>` that is\n    /// big enough.\n    ///\n    /// In summary, if a new serialization error kind needs to be added, then\n    /// it will need careful consideration.\n    what: &'static str,\n}\n#[derive(Clone)]\npub(crate) struct StartByteMap {\n    map: [Start; 256],\n}\n#[derive(Clone, Copy, Default, Eq, Hash, PartialEq, PartialOrd, Ord)]\n#[repr(transparent)]\npub struct StateID(SmallIndex);\n#[derive(Clone, Copy, Debug, Eq, PartialEq)]\npub enum StartKind {\n    /// Support both anchored and unanchored searches.\n    Both,\n    /// Support only unanchored searches. Requesting an anchored search will\n    /// panic.\n    ///\n    /// Note that even if an unanchored search is requested, the pattern itself\n    /// may still be anchored. For example, `^abc` will only match `abc` at the\n    /// start of a haystack. This will remain true, even if the regex engine\n    /// only supported unanchored searches.\n    Unanchored,\n    /// Support only anchored searches. Requesting an unanchored search will\n    /// panic.\n    Anchored,\n}\nimpl<T: AsRef<[u32]>> StartTable<T> {\n    fn write_to<E: Endian>(&self, mut dst: &mut [u8]) -> Result<usize, SerializeError> {\n        let nwrite = self.write_to_len();\n        if dst.len() < nwrite {\n            return Err(SerializeError::buffer_too_small(\"starting table ids\"));\n        }\n        dst = &mut dst[..nwrite];\n        let nw = self.kind.write_to::<E>(dst)?;\n        dst = &mut dst[nw..];\n        let nw = self.start_map.write_to(dst)?;\n        dst = &mut dst[nw..];\n        E::write_u32(u32::try_from(self.stride).unwrap(), dst);\n        dst = &mut dst[size_of::<u32>()..];\n        E::write_u32(\n            u32::try_from(self.pattern_len.unwrap_or(0xFFFF_FFFF)).unwrap(),\n            dst,\n        );\n        dst = &mut dst[size_of::<u32>()..];\n        E::write_u32(\n            self.universal_start_unanchored.map_or(u32::MAX, |sid| sid.as_u32()),\n            dst,\n        );\n        dst = &mut dst[size_of::<u32>()..];\n        E::write_u32(\n            self.universal_start_anchored.map_or(u32::MAX, |sid| sid.as_u32()),\n            dst,\n        );\n        dst = &mut dst[size_of::<u32>()..];\n        for &sid in self.table() {\n            let n = wire::write_state_id::<E>(sid, &mut dst);\n            dst = &mut dst[n..];\n        }\n        Ok(nwrite)\n    }\n    fn write_to_len(&self) -> usize {\n        self.kind.write_to_len() + self.start_map.write_to_len() + size_of::<u32>()\n            + size_of::<u32>() + size_of::<u32>() + size_of::<u32>()\n            + (self.table().len() * StateID::SIZE)\n    }\n    fn validate(&self, dfa: &DFA<T>) -> Result<(), DeserializeError> {}\n    fn as_ref(&self) -> StartTable<&'_ [u32]> {}\n    #[cfg(feature = \"alloc\")]\n    fn to_owned(&self) -> StartTable<alloc::vec::Vec<u32>> {}\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    fn start(&self, anchored: Anchored, start: Start) -> Result<StateID, StartError> {}\n    fn iter(&self) -> StartStateIter<'_> {}\n    fn table(&self) -> &[StateID] {\n        wire::u32s_to_state_ids(self.table.as_ref())\n    }\n    fn memory_usage(&self) -> usize {}\n}\nimpl SerializeError {\n    pub(crate) fn buffer_too_small(what: &'static str) -> SerializeError {\n        SerializeError { what }\n    }\n}\nimpl StartKind {\n    pub(crate) fn from_bytes(\n        slice: &[u8],\n    ) -> Result<(StartKind, usize), DeserializeError> {}\n    pub(crate) fn write_to<E: Endian>(\n        &self,\n        dst: &mut [u8],\n    ) -> Result<usize, SerializeError> {\n        let nwrite = self.write_to_len();\n        if dst.len() < nwrite {\n            return Err(SerializeError::buffer_too_small(\"start kind\"));\n        }\n        let n = match *self {\n            StartKind::Both => 0,\n            StartKind::Unanchored => 1,\n            StartKind::Anchored => 2,\n        };\n        E::write_u32(n, dst);\n        Ok(nwrite)\n    }\n    pub(crate) fn write_to_len(&self) -> usize {}\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    pub(crate) fn has_unanchored(&self) -> bool {}\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    pub(crate) fn has_anchored(&self) -> bool {}\n}\nimpl StartByteMap {\n    pub(crate) fn new(lookm: &LookMatcher) -> StartByteMap {}\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    pub(crate) fn get(&self, byte: u8) -> Start {}\n    pub(crate) fn from_bytes(\n        slice: &[u8],\n    ) -> Result<(StartByteMap, usize), DeserializeError> {}\n    pub(crate) fn write_to(&self, dst: &mut [u8]) -> Result<usize, SerializeError> {\n        let nwrite = self.write_to_len();\n        if dst.len() < nwrite {\n            return Err(SerializeError::buffer_too_small(\"start byte map\"));\n        }\n        for (i, &start) in self.map.iter().enumerate() {\n            dst[i] = start.as_u8();\n        }\n        Ok(nwrite)\n    }\n    pub(crate) fn write_to_len(&self) -> usize {}\n}\npub(crate) fn write_state_id<E: Endian>(sid: StateID, dst: &mut [u8]) -> usize {\n    E::write_u32(sid.as_u32(), dst);\n    StateID::SIZE\n}\n\nThe function to be tested is presented with each line formatted as 'line number + code':\n/// Writes a serialized form of this start table to the buffer given. If\n/// the buffer is too small, then an error is returned. To determine how\n/// big the buffer must be, use `write_to_len`.\n4072 fn write_to<E: Endian>(\n4073     &self,\n4074     mut dst: &mut [u8],\n4075 ) -> Result<usize, SerializeError> {\n4076     let nwrite = self.write_to_len();\n4077     if dst.len() < nwrite {\n4078         return Err(SerializeError::buffer_too_small(\n4079             \"starting table ids\",\n4080         ));\n4081     }\n4082     dst = &mut dst[..nwrite];\n4083 \n4084     // write start kind\n4085     let nw = self.kind.write_to::<E>(dst)?;\n4086     dst = &mut dst[nw..];\n4087     // write start byte map\n4088     let nw = self.start_map.write_to(dst)?;\n4089     dst = &mut dst[nw..];\n4090     // write stride\n4091     // Unwrap is OK since the stride is always 4 (currently).\n4092     E::write_u32(u32::try_from(self.stride).unwrap(), dst);\n4093     dst = &mut dst[size_of::<u32>()..];\n4094     // write pattern length\n4095     // Unwrap is OK since number of patterns is guaranteed to fit in a u32.\n4096     E::write_u32(\n4097         u32::try_from(self.pattern_len.unwrap_or(0xFFFF_FFFF)).unwrap(),\n4098         dst,\n4099     );\n4100     dst = &mut dst[size_of::<u32>()..];\n4101     // write universal start unanchored state id, u32::MAX if absent\n4102     E::write_u32(\n4103         self.universal_start_unanchored\n4104             .map_or(u32::MAX, |sid| sid.as_u32()),\n4105         dst,\n4106     );\n4107     dst = &mut dst[size_of::<u32>()..];\n4108     // write universal start anchored state id, u32::MAX if absent\n4109     E::write_u32(\n4110         self.universal_start_anchored.map_or(u32::MAX, |sid| sid.as_u32()),\n4111         dst,\n4112     );\n4113     dst = &mut dst[size_of::<u32>()..];\n4114     // write start IDs\n4115     for &sid in self.table() {\n4116         let n = wire::write_state_id::<E>(sid, &mut dst);\n4117         dst = &mut dst[n..];\n4118     }\n4119     Ok(nwrite)\n4120 }\n\nThe path conditions that the generated test functions should satisfy are as follows:\n"
}