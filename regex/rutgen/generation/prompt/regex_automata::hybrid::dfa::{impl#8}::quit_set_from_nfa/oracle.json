{
  "system_pt": "As a software testing expert, please generate accurate test oracles code based on the provided information. Follow these guidelines:\n1. Generate executable test oracle codes in plain text format, one per line. Do not output complete test functions, avoid additional explanations, and do not use Markdown.\n2. Combine the given function under test, context, relevant documentation, preconditions, expected return values or types, test input conditions or ranges, and existing test function prefixes to infer and generate corresponding test oracles code.\n3. Only generate necessary test oracles to ensure comprehensive validation.\n",
  "static_pt": "The context for the focal function is as follows:\n// regex-automata/src/hybrid/dfa.rs\n// crate name is regex_automata\n#[cfg(feature = \"std\")]\ntype StateMap = std::collections::HashMap<State, LazyStateID>;\n#[cfg(not(feature = \"std\"))]\ntype StateMap = alloc::collections::BTreeMap<State, LazyStateID>;\nuse core::{iter, mem::size_of};\nuse alloc::vec::Vec;\nuse crate::{\n    hybrid::{\n        error::{BuildError, CacheError, StartError},\n        id::{LazyStateID, LazyStateIDError},\n        search,\n    },\n    nfa::thompson,\n    util::{\n        alphabet::{self, ByteClasses, ByteSet},\n        determinize::{self, State, StateBuilderEmpty, StateBuilderNFA},\n        empty, prefilter::Prefilter, primitives::{PatternID, StateID as NFAStateID},\n        search::{Anchored, HalfMatch, Input, MatchError, MatchKind, PatternSet},\n        sparse_set::SparseSets, start::{self, Start, StartByteMap},\n    },\n};\nconst MIN_STATES: usize = SENTINEL_STATES + 2;\nconst SENTINEL_STATES: usize = 3;\n#[derive(Clone, Debug, Default)]\npub struct Config {\n    match_kind: Option<MatchKind>,\n    pre: Option<Option<Prefilter>>,\n    starts_for_each_pattern: Option<bool>,\n    byte_classes: Option<bool>,\n    unicode_word_boundary: Option<bool>,\n    quitset: Option<ByteSet>,\n    specialize_start_states: Option<bool>,\n    cache_capacity: Option<usize>,\n    skip_cache_capacity_check: Option<bool>,\n    minimum_cache_clear_count: Option<Option<usize>>,\n    minimum_bytes_per_state: Option<Option<usize>>,\n}\n#[derive(Clone, Copy, Debug, Default, Eq, PartialEq)]\npub(crate) struct ByteSet {\n    bits: BitSet,\n}\n#[derive(Clone, Copy, Default, Eq, PartialEq)]\npub struct LookSet {\n    /// The underlying representation this set is exposed to make it possible\n    /// to store it somewhere efficiently. The representation is that\n    /// of a bitset, where each assertion occupies bit `i` where\n    /// `i = Look::as_repr()`.\n    ///\n    /// Note that users of this internal representation must permit the full\n    /// range of `u16` values to be represented. For example, even if the\n    /// current implementation only makes use of the 10 least significant bits,\n    /// it may use more bits in a future semver compatible release.\n    pub bits: u32,\n}\n#[derive(Clone, Debug)]\npub struct BuildError {\n    kind: BuildErrorKind,\n}\n#[derive(Clone)]\npub struct NFA(Arc<Inner>);\n#[derive(Clone, Debug)]\npub struct Prefilter {\n    #[cfg(not(feature = \"alloc\"))]\n    _unused: (),\n    #[cfg(feature = \"alloc\")]\n    pre: Arc<dyn PrefilterI>,\n    #[cfg(feature = \"alloc\")]\n    is_fast: bool,\n    #[cfg(feature = \"alloc\")]\n    max_needle_len: usize,\n}\n#[derive(Clone, Debug)]\npub(crate) struct ByteSet([bool; 256]);\n#[non_exhaustive]\n#[derive(Clone, Copy, Debug, Eq, PartialEq)]\npub enum MatchKind {\n    /// Report all possible matches.\n    All,\n    /// Report only the leftmost matches. When multiple leftmost matches exist,\n    /// report the match corresponding to the part of the regex that appears\n    /// first in the syntax.\n    LeftmostFirst,\n}\nimpl Config {\n    pub fn new() -> Config {}\n    pub fn match_kind(mut self, kind: MatchKind) -> Config {}\n    pub fn prefilter(mut self, pre: Option<Prefilter>) -> Config {}\n    pub fn starts_for_each_pattern(mut self, yes: bool) -> Config {}\n    pub fn byte_classes(mut self, yes: bool) -> Config {}\n    pub fn unicode_word_boundary(mut self, yes: bool) -> Config {}\n    pub fn quit(mut self, byte: u8, yes: bool) -> Config {}\n    pub fn specialize_start_states(mut self, yes: bool) -> Config {}\n    pub fn cache_capacity(mut self, bytes: usize) -> Config {}\n    pub fn skip_cache_capacity_check(mut self, yes: bool) -> Config {}\n    pub fn minimum_cache_clear_count(mut self, min: Option<usize>) -> Config {}\n    pub fn minimum_bytes_per_state(mut self, min: Option<usize>) -> Config {}\n    pub fn get_match_kind(&self) -> MatchKind {}\n    pub fn get_prefilter(&self) -> Option<&Prefilter> {}\n    pub fn get_starts_for_each_pattern(&self) -> bool {}\n    pub fn get_byte_classes(&self) -> bool {}\n    pub fn get_unicode_word_boundary(&self) -> bool {\n        self.unicode_word_boundary.unwrap_or(false)\n    }\n    pub fn get_quit(&self, byte: u8) -> bool {}\n    pub fn get_specialize_start_states(&self) -> bool {}\n    pub fn get_cache_capacity(&self) -> usize {}\n    pub fn get_skip_cache_capacity_check(&self) -> bool {}\n    pub fn get_minimum_cache_clear_count(&self) -> Option<usize> {}\n    pub fn get_minimum_bytes_per_state(&self) -> Option<usize> {}\n    pub fn get_minimum_cache_capacity(\n        &self,\n        nfa: &thompson::NFA,\n    ) -> Result<usize, BuildError> {}\n    fn byte_classes_from_nfa(&self, nfa: &thompson::NFA, quit: &ByteSet) -> ByteClasses {}\n    fn quit_set_from_nfa(&self, nfa: &thompson::NFA) -> Result<ByteSet, BuildError> {\n        let mut quit = self.quitset.unwrap_or(ByteSet::empty());\n        if nfa.look_set_any().contains_word_unicode() {\n            if self.get_unicode_word_boundary() {\n                for b in 0x80..=0xFF {\n                    quit.add(b);\n                }\n            } else {\n                if !quit.contains_range(0x80, 0xFF) {\n                    return Err(BuildError::unsupported_dfa_word_boundary_unicode());\n                }\n            }\n        }\n        Ok(quit)\n    }\n    fn overwrite(&self, o: Config) -> Config {}\n}\nimpl ByteSet {\n    pub(crate) fn empty() -> ByteSet {\n        ByteSet { bits: BitSet([0; 2]) }\n    }\n    pub(crate) fn add(&mut self, byte: u8) {\n        let bucket = byte / 128;\n        let bit = byte % 128;\n        self.bits.0[usize::from(bucket)] |= 1 << bit;\n    }\n    pub(crate) fn remove(&mut self, byte: u8) {}\n    pub(crate) fn contains(&self, byte: u8) -> bool {}\n    pub(crate) fn contains_range(&self, start: u8, end: u8) -> bool {\n        (start..=end).all(|b| self.contains(b))\n    }\n    pub(crate) fn iter(&self) -> ByteSetIter {}\n    pub(crate) fn iter_ranges(&self) -> ByteSetRangeIter {}\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    pub(crate) fn is_empty(&self) -> bool {}\n    pub(crate) fn from_bytes(\n        slice: &[u8],\n    ) -> Result<(ByteSet, usize), DeserializeError> {}\n    pub(crate) fn write_to<E: crate::util::wire::Endian>(\n        &self,\n        dst: &mut [u8],\n    ) -> Result<usize, SerializeError> {}\n    pub(crate) fn write_to_len(&self) -> usize {}\n}\nimpl LookSet {\n    #[inline]\n    pub fn empty() -> LookSet {}\n    #[inline]\n    pub fn full() -> LookSet {}\n    #[inline]\n    pub fn singleton(look: Look) -> LookSet {}\n    #[inline]\n    pub fn len(self) -> usize {}\n    #[inline]\n    pub fn is_empty(self) -> bool {}\n    #[inline]\n    pub fn contains(self, look: Look) -> bool {}\n    #[inline]\n    pub fn contains_anchor(&self) -> bool {}\n    #[inline]\n    pub fn contains_anchor_haystack(&self) -> bool {}\n    #[inline]\n    pub fn contains_anchor_line(&self) -> bool {}\n    #[inline]\n    pub fn contains_anchor_lf(&self) -> bool {}\n    #[inline]\n    pub fn contains_anchor_crlf(&self) -> bool {}\n    #[inline]\n    pub fn contains_word(self) -> bool {}\n    #[inline]\n    pub fn contains_word_unicode(self) -> bool {\n        self.contains(Look::WordUnicode) || self.contains(Look::WordUnicodeNegate)\n            || self.contains(Look::WordStartUnicode)\n            || self.contains(Look::WordEndUnicode)\n            || self.contains(Look::WordStartHalfUnicode)\n            || self.contains(Look::WordEndHalfUnicode)\n    }\n    #[inline]\n    pub fn contains_word_ascii(self) -> bool {}\n    #[inline]\n    pub fn iter(self) -> LookSetIter {}\n    #[inline]\n    pub fn insert(self, look: Look) -> LookSet {}\n    #[inline]\n    pub fn set_insert(&mut self, look: Look) {}\n    #[inline]\n    pub fn remove(self, look: Look) -> LookSet {}\n    #[inline]\n    pub fn set_remove(&mut self, look: Look) {}\n    #[inline]\n    pub fn subtract(self, other: LookSet) -> LookSet {}\n    #[inline]\n    pub fn set_subtract(&mut self, other: LookSet) {}\n    #[inline]\n    pub fn union(self, other: LookSet) -> LookSet {}\n    #[inline]\n    pub fn set_union(&mut self, other: LookSet) {}\n    #[inline]\n    pub fn intersect(self, other: LookSet) -> LookSet {}\n    #[inline]\n    pub fn set_intersect(&mut self, other: LookSet) {}\n    #[inline]\n    pub fn read_repr(slice: &[u8]) -> LookSet {}\n    #[inline]\n    pub fn write_repr(self, slice: &mut [u8]) {}\n    pub fn available(self) -> Result<(), UnicodeWordBoundaryError> {}\n}\nimpl BuildError {\n    pub(crate) fn nfa(err: nfa::thompson::BuildError) -> BuildError {}\n    pub(crate) fn insufficient_cache_capacity(\n        minimum: usize,\n        given: usize,\n    ) -> BuildError {}\n    pub(crate) fn insufficient_state_id_capacity(err: LazyStateIDError) -> BuildError {}\n    pub(crate) fn unsupported_dfa_word_boundary_unicode() -> BuildError {\n        let msg = \"cannot build lazy DFAs for regexes with Unicode word \\\n                   boundaries; switch to ASCII word boundaries, or \\\n                   heuristically enable Unicode word boundaries or use a \\\n                   different regex engine\";\n        BuildError {\n            kind: BuildErrorKind::Unsupported(msg),\n        }\n    }\n}\nimpl NFA {\n    #[cfg(feature = \"syntax\")]\n    pub fn new(pattern: &str) -> Result<NFA, BuildError> {}\n    #[cfg(feature = \"syntax\")]\n    pub fn new_many<P: AsRef<str>>(patterns: &[P]) -> Result<NFA, BuildError> {}\n    pub fn always_match() -> NFA {}\n    pub fn never_match() -> NFA {}\n    #[cfg(feature = \"syntax\")]\n    pub fn config() -> Config {}\n    #[cfg(feature = \"syntax\")]\n    pub fn compiler() -> Compiler {}\n    pub fn patterns(&self) -> PatternIter<'_> {}\n    #[inline]\n    pub fn pattern_len(&self) -> usize {}\n    #[inline]\n    pub fn start_anchored(&self) -> StateID {}\n    #[inline]\n    pub fn start_unanchored(&self) -> StateID {}\n    #[inline]\n    pub fn start_pattern(&self, pid: PatternID) -> Option<StateID> {}\n    #[inline]\n    pub(crate) fn byte_class_set(&self) -> &ByteClassSet {}\n    #[inline]\n    pub fn byte_classes(&self) -> &ByteClasses {}\n    #[inline]\n    pub fn state(&self, id: StateID) -> &State {}\n    #[inline]\n    pub fn states(&self) -> &[State] {}\n    #[inline]\n    pub fn group_info(&self) -> &GroupInfo {}\n    #[inline]\n    pub fn has_capture(&self) -> bool {}\n    #[inline]\n    pub fn has_empty(&self) -> bool {}\n    #[inline]\n    pub fn is_utf8(&self) -> bool {}\n    #[inline]\n    pub fn is_reverse(&self) -> bool {}\n    #[inline]\n    pub fn is_always_start_anchored(&self) -> bool {}\n    #[inline]\n    pub fn look_matcher(&self) -> &LookMatcher {}\n    #[inline]\n    pub fn look_set_any(&self) -> LookSet {\n        self.0.look_set_any\n    }\n    #[inline]\n    pub fn look_set_prefix_any(&self) -> LookSet {}\n    #[inline]\n    pub fn memory_usage(&self) -> usize {}\n}\n\nThe function to be tested is presented with each line formatted as 'line number + code':\n/// Return the quit set for this configuration and the given NFA.\n///\n/// This may return an error if the NFA is incompatible with this\n/// configuration's quit set. For example, if the NFA has a Unicode word\n/// boundary and the quit set doesn't include non-ASCII bytes.\n3849 fn quit_set_from_nfa(\n3850     &self,\n3851     nfa: &thompson::NFA,\n3852 ) -> Result<ByteSet, BuildError> {\n3853     let mut quit = self.quitset.unwrap_or(ByteSet::empty());\n3854     if nfa.look_set_any().contains_word_unicode() {\n3855         if self.get_unicode_word_boundary() {\n3856             for b in 0x80..=0xFF {\n3857                 quit.add(b);\n3858             }\n3859         } else {\n3860             // If heuristic support for Unicode word boundaries wasn't\n3861             // enabled, then we can still check if our quit set is correct.\n3862             // If the caller set their quit bytes in a way that causes the\n3863             // DFA to quit on at least all non-ASCII bytes, then that's all\n3864             // we need for heuristic support to work.\n3865             if !quit.contains_range(0x80, 0xFF) {\n3866                 return Err(\n3867                     BuildError::unsupported_dfa_word_boundary_unicode(),\n3868                 );\n3869             }\n3870         }\n3871     }\n3872     Ok(quit)\n3873 }\n\nThe path conditions that the generated test functions should satisfy are as follows:\n"
}