{
  "system_pt": "As a software testing expert, infer the test input conditions or ranges based on the provided information. Follow these guidelines:\n1. Provide test input conditions or ranges in one line in plain text only, without additional explanations or Markdown formatting\n2. Analyze the function under test, context, preconditions, and expected return values or types to determine appropriate test input conditions or ranges\n3. The inferred test input conditions or ranges should comprehensively satisfy all provided preconditions simultaneously.\n4. Ensure the test input conditions or ranges cover boundary cases and edge scenarios\n",
  "static_pt": "The context for the focal function is as follows:\n// regex-automata/src/dfa/dense.rs\n// crate name is regex_automata\n#[cfg(feature = \"alloc\")]\npub(crate) type OwnedDFA = DFA<alloc::vec::Vec<u32>>;\n#[cfg(feature = \"dfa-build\")]\nuse core::cmp;\nuse core::{fmt, iter, mem::size_of, slice};\n#[cfg(feature = \"dfa-build\")]\nuse alloc::{\n    collections::{BTreeMap, BTreeSet},\n    vec, vec::Vec,\n};\n#[cfg(feature = \"dfa-build\")]\nuse crate::{\n    dfa::{accel::Accel, determinize, minimize::Minimizer, remapper::Remapper, sparse},\n    nfa::thompson, util::{look::LookMatcher, search::MatchKind},\n};\nuse crate::{\n    dfa::{\n        accel::Accels, automaton::{fmt_state_indicator, Automaton, StartError},\n        special::Special, start::StartKind, DEAD,\n    },\n    util::{\n        alphabet::{self, ByteClasses, ByteSet},\n        int::{Pointer, Usize},\n        prefilter::Prefilter, primitives::{PatternID, StateID},\n        search::Anchored, start::{self, Start, StartByteMap},\n        wire::{self, DeserializeError, Endian, SerializeError},\n    },\n};\nconst LABEL: &str = \"rust-regex-automata-dfa-dense\";\nconst VERSION: u32 = 2;\npub unsafe trait Automaton {\n    fn next_state(&self, current: StateID, input: u8) -> StateID;\n    unsafe fn next_state_unchecked(&self, current: StateID, input: u8) -> StateID;\n    fn next_eoi_state(&self, current: StateID) -> StateID;\n    fn start_state(&self, config: &start::Config) -> Result<StateID, StartError>;\n    fn start_state_forward(&self, input: &Input<'_>) -> Result<StateID, MatchError>;\n    fn start_state_reverse(&self, input: &Input<'_>) -> Result<StateID, MatchError>;\n    #[inline]\n    fn universal_start_state(&self, _mode: Anchored) -> Option<StateID>;\n    fn is_special_state(&self, id: StateID) -> bool;\n    fn is_dead_state(&self, id: StateID) -> bool;\n    fn is_quit_state(&self, id: StateID) -> bool;\n    fn is_match_state(&self, id: StateID) -> bool;\n    fn is_start_state(&self, id: StateID) -> bool;\n    fn is_accel_state(&self, id: StateID) -> bool;\n    fn pattern_len(&self) -> usize;\n    fn match_len(&self, id: StateID) -> usize;\n    fn match_pattern(&self, id: StateID, index: usize) -> PatternID;\n    fn has_empty(&self) -> bool;\n    fn is_utf8(&self) -> bool;\n    fn is_always_start_anchored(&self) -> bool;\n    #[inline]\n    fn accelerator(&self, _id: StateID) -> &[u8];\n    #[inline]\n    fn get_prefilter(&self) -> Option<&Prefilter>;\n    #[inline]\n    fn try_search_fwd(&self, input: &Input<'_>) -> Result<Option<HalfMatch>, MatchError>;\n    #[inline]\n    fn try_search_rev(&self, input: &Input<'_>) -> Result<Option<HalfMatch>, MatchError>;\n    #[inline]\n    fn try_search_overlapping_fwd(\n        &self,\n        input: &Input<'_>,\n        state: &mut OverlappingState,\n    ) -> Result<(), MatchError>;\n    #[inline]\n    fn try_search_overlapping_rev(\n        &self,\n        input: &Input<'_>,\n        state: &mut OverlappingState,\n    ) -> Result<(), MatchError>;\n    #[cfg(feature = \"alloc\")]\n    #[inline]\n    fn try_which_overlapping_matches(\n        &self,\n        input: &Input<'_>,\n        patset: &mut PatternSet,\n    ) -> Result<(), MatchError>;\n}\n#[derive(Clone)]\npub struct DFA<T> {\n    /// The transition table for this DFA. This includes the transitions\n    /// themselves, along with the stride, number of states and the equivalence\n    /// class mapping.\n    tt: TransitionTable<T>,\n    /// The set of starting state identifiers for this DFA. The starting state\n    /// IDs act as pointers into the transition table. The specific starting\n    /// state chosen for each search is dependent on the context at which the\n    /// search begins.\n    st: StartTable<T>,\n    /// The set of match states and the patterns that match for each\n    /// corresponding match state.\n    ///\n    /// This structure is technically only needed because of support for\n    /// multi-regexes. Namely, multi-regexes require answering not just whether\n    /// a match exists, but _which_ patterns match. So we need to store the\n    /// matching pattern IDs for each match state. We do this even when there\n    /// is only one pattern for the sake of simplicity. In practice, this uses\n    /// up very little space for the case of one pattern.\n    ms: MatchStates<T>,\n    /// Information about which states are \"special.\" Special states are states\n    /// that are dead, quit, matching, starting or accelerated. For more info,\n    /// see the docs for `Special`.\n    special: Special,\n    /// The accelerators for this DFA.\n    ///\n    /// If a state is accelerated, then there exist only a small number of\n    /// bytes that can cause the DFA to leave the state. This permits searching\n    /// to use optimized routines to find those specific bytes instead of using\n    /// the transition table.\n    ///\n    /// All accelerated states exist in a contiguous range in the DFA's\n    /// transition table. See dfa/special.rs for more details on how states are\n    /// arranged.\n    accels: Accels<T>,\n    /// Any prefilter attached to this DFA.\n    ///\n    /// Note that currently prefilters are not serialized. When deserializing\n    /// a DFA from bytes, this is always set to `None`.\n    pre: Option<Prefilter>,\n    /// The set of \"quit\" bytes for this DFA.\n    ///\n    /// This is only used when computing the start state for a particular\n    /// position in a haystack. Namely, in the case where there is a quit\n    /// byte immediately before the start of the search, this set needs to be\n    /// explicitly consulted. In all other cases, quit bytes are detected by\n    /// the DFA itself, by transitioning all quit bytes to a special \"quit\n    /// state.\"\n    quitset: ByteSet,\n    /// Various flags describing the behavior of this DFA.\n    flags: Flags,\n}\n#[derive(Debug)]\npub struct DeserializeError(DeserializeErrorKind);\n#[derive(Clone, Debug)]\nstruct MatchStates<T> {\n    /// Slices is a flattened sequence of pairs, where each pair points to a\n    /// sub-slice of pattern_ids. The first element of the pair is an offset\n    /// into pattern_ids and the second element of the pair is the number\n    /// of 32-bit pattern IDs starting at that position. That is, each pair\n    /// corresponds to a single DFA match state and its corresponding match\n    /// IDs. The number of pairs always corresponds to the number of distinct\n    /// DFA match states.\n    ///\n    /// In practice, T is either Vec<u32> or &[u32].\n    slices: T,\n    /// A flattened sequence of pattern IDs for each DFA match state. The only\n    /// way to correctly read this sequence is indirectly via `slices`.\n    ///\n    /// In practice, T is either Vec<u32> or &[u32].\n    pattern_ids: T,\n    /// The total number of unique patterns represented by these match states.\n    pattern_len: usize,\n}\n#[derive(Clone)]\npub(crate) struct Accels<A> {\n    /// A length prefixed slice of contiguous accelerators. See the top comment\n    /// in this module for more details on how we can jump from a DFA's state\n    /// ID to an accelerator in this list.\n    ///\n    /// The first 4 bytes always correspond to the number of accelerators\n    /// that follow.\n    accels: A,\n}\npub(crate) struct State<'a> {\n    id: StateID,\n    stride2: usize,\n    transitions: &'a [StateID],\n}\n#[derive(Clone)]\npub(crate) struct StartTable<T> {\n    /// The initial start state IDs.\n    ///\n    /// In practice, T is either `Vec<u32>` or `&[u32]`.\n    ///\n    /// The first `2 * stride` (currently always 8) entries always correspond\n    /// to the starts states for the entire DFA, with the first 4 entries being\n    /// for unanchored searches and the second 4 entries being for anchored\n    /// searches. To keep things simple, we always use 8 entries even if the\n    /// `StartKind` is not both.\n    ///\n    /// After that, there are `stride * patterns` state IDs, where `patterns`\n    /// may be zero in the case of a DFA with no patterns or in the case where\n    /// the DFA was built without enabling starting states for each pattern.\n    table: T,\n    /// The starting state configuration supported. When 'both', both\n    /// unanchored and anchored searches work. When 'unanchored', anchored\n    /// searches panic. When 'anchored', unanchored searches panic.\n    kind: StartKind,\n    /// The start state configuration for every possible byte.\n    start_map: StartByteMap,\n    /// The number of starting state IDs per pattern.\n    stride: usize,\n    /// The total number of patterns for which starting states are encoded.\n    /// This is `None` for DFAs that were built without start states for each\n    /// pattern. Thus, one cannot use this field to say how many patterns\n    /// are in the DFA in all cases. It is specific to how many patterns are\n    /// represented in this start table.\n    pattern_len: Option<usize>,\n    /// The universal starting state for unanchored searches. This is only\n    /// present when the DFA supports unanchored searches and when all starting\n    /// state IDs for an unanchored search are equivalent.\n    universal_start_unanchored: Option<StateID>,\n    /// The universal starting state for anchored searches. This is only\n    /// present when the DFA supports anchored searches and when all starting\n    /// state IDs for an anchored search are equivalent.\n    universal_start_anchored: Option<StateID>,\n}\n#[derive(Clone)]\npub(crate) struct TransitionTable<T> {\n    /// A contiguous region of memory representing the transition table in\n    /// row-major order. The representation is dense. That is, every state\n    /// has precisely the same number of transitions. The maximum number of\n    /// transitions per state is 257 (256 for each possible byte value, plus 1\n    /// for the special EOI transition). If a DFA has been instructed to use\n    /// byte classes (the default), then the number of transitions is usually\n    /// substantially fewer.\n    ///\n    /// In practice, T is either `Vec<u32>` or `&[u32]`.\n    table: T,\n    /// A set of equivalence classes, where a single equivalence class\n    /// represents a set of bytes that never discriminate between a match\n    /// and a non-match in the DFA. Each equivalence class corresponds to a\n    /// single character in this DFA's alphabet, where the maximum number of\n    /// characters is 257 (each possible value of a byte plus the special\n    /// EOI transition). Consequently, the number of equivalence classes\n    /// corresponds to the number of transitions for each DFA state. Note\n    /// though that the *space* used by each DFA state in the transition table\n    /// may be larger. The total space used by each DFA state is known as the\n    /// stride.\n    ///\n    /// The only time the number of equivalence classes is fewer than 257 is if\n    /// the DFA's kind uses byte classes (which is the default). Equivalence\n    /// classes should generally only be disabled when debugging, so that\n    /// the transitions themselves aren't obscured. Disabling them has no\n    /// other benefit, since the equivalence class map is always used while\n    /// searching. In the vast majority of cases, the number of equivalence\n    /// classes is substantially smaller than 257, particularly when large\n    /// Unicode classes aren't used.\n    classes: ByteClasses,\n    /// The stride of each DFA state, expressed as a power-of-two exponent.\n    ///\n    /// The stride of a DFA corresponds to the total amount of space used by\n    /// each DFA state in the transition table. This may be bigger than the\n    /// size of a DFA's alphabet, since the stride is always the smallest\n    /// power of two greater than or equal to the alphabet size.\n    ///\n    /// While this wastes space, this avoids the need for integer division\n    /// to convert between premultiplied state IDs and their corresponding\n    /// indices. Instead, we can use simple bit-shifts.\n    ///\n    /// See the docs for the `stride2` method for more details.\n    ///\n    /// The minimum `stride2` value is `1` (corresponding to a stride of `2`)\n    /// while the maximum `stride2` value is `9` (corresponding to a stride of\n    /// `512`). The maximum is not `8` since the maximum alphabet size is `257`\n    /// when accounting for the special EOI transition. However, an alphabet\n    /// length of that size is exceptionally rare since the alphabet is shrunk\n    /// into equivalence classes.\n    stride2: usize,\n}\n#[derive(Clone, Copy, Debug)]\npub(crate) struct Flags {\n    /// Whether the DFA can match the empty string. When this is false, all\n    /// matches returned by this DFA are guaranteed to have non-zero length.\n    pub(crate) has_empty: bool,\n    /// Whether the DFA should only produce matches with spans that correspond\n    /// to valid UTF-8. This also includes omitting any zero-width matches that\n    /// split the UTF-8 encoding of a codepoint.\n    pub(crate) is_utf8: bool,\n    /// Whether the DFA is always anchored or not, regardless of `Input`\n    /// configuration. This is useful for avoiding a reverse scan even when\n    /// executing unanchored searches.\n    pub(crate) is_always_start_anchored: bool,\n}\n#[derive(Clone, Copy, Default, Eq, Hash, PartialEq, PartialOrd, Ord)]\n#[repr(transparent)]\npub struct StateID(SmallIndex);\npub(crate) struct StateIter<'a, T> {\n    tt: &'a TransitionTable<T>,\n    it: iter::Enumerate<slice::Chunks<'a, StateID>>,\n}\n#[derive(Clone, Debug)]\npub(crate) struct ByteSet([bool; 256]);\n#[derive(Clone)]\nstruct StartTable<T> {\n    /// The initial start state IDs as a contiguous table of native endian\n    /// encoded integers, represented by `S`.\n    ///\n    /// In practice, T is either Vec<u8> or &[u8] and has no alignment\n    /// requirements.\n    ///\n    /// The first `2 * stride` (currently always 8) entries always correspond\n    /// to the starts states for the entire DFA, with the first 4 entries being\n    /// for unanchored searches and the second 4 entries being for anchored\n    /// searches. To keep things simple, we always use 8 entries even if the\n    /// `StartKind` is not both.\n    ///\n    /// After that, there are `stride * patterns` state IDs, where `patterns`\n    /// may be zero in the case of a DFA with no patterns or in the case where\n    /// the DFA was built without enabling starting states for each pattern.\n    table: T,\n    /// The starting state configuration supported. When 'both', both\n    /// unanchored and anchored searches work. When 'unanchored', anchored\n    /// searches panic. When 'anchored', unanchored searches panic.\n    kind: StartKind,\n    /// The start state configuration for every possible byte.\n    start_map: StartByteMap,\n    /// The number of starting state IDs per pattern.\n    stride: usize,\n    /// The total number of patterns for which starting states are encoded.\n    /// This is `None` for DFAs that were built without start states for each\n    /// pattern. Thus, one cannot use this field to say how many patterns\n    /// are in the DFA in all cases. It is specific to how many patterns are\n    /// represented in this start table.\n    pattern_len: Option<usize>,\n    /// The universal starting state for unanchored searches. This is only\n    /// present when the DFA supports unanchored searches and when all starting\n    /// state IDs for an unanchored search are equivalent.\n    universal_start_unanchored: Option<StateID>,\n    /// The universal starting state for anchored searches. This is only\n    /// present when the DFA supports anchored searches and when all starting\n    /// state IDs for an anchored search are equivalent.\n    universal_start_anchored: Option<StateID>,\n}\n#[derive(Clone, Copy, Debug, Default, Eq, PartialEq)]\npub(crate) struct ByteSet {\n    bits: BitSet,\n}\n#[derive(Clone, Debug)]\npub struct Prefilter {\n    #[cfg(not(feature = \"alloc\"))]\n    _unused: (),\n    #[cfg(feature = \"alloc\")]\n    pre: Arc<dyn PrefilterI>,\n    #[cfg(feature = \"alloc\")]\n    is_fast: bool,\n    #[cfg(feature = \"alloc\")]\n    max_needle_len: usize,\n}\n#[derive(Clone, Copy, Debug)]\npub(crate) struct Special {\n    /// The identifier of the last special state in a DFA. A state is special\n    /// if and only if its identifier is less than or equal to `max`.\n    pub(crate) max: StateID,\n    /// The identifier of the quit state in a DFA. (There is no analogous field\n    /// for the dead state since the dead state's ID is always zero, regardless\n    /// of state ID size.)\n    pub(crate) quit_id: StateID,\n    /// The identifier of the first match state.\n    pub(crate) min_match: StateID,\n    /// The identifier of the last match state.\n    pub(crate) max_match: StateID,\n    /// The identifier of the first accelerated state.\n    pub(crate) min_accel: StateID,\n    /// The identifier of the last accelerated state.\n    pub(crate) max_accel: StateID,\n    /// The identifier of the first start state.\n    pub(crate) min_start: StateID,\n    /// The identifier of the last start state.\n    pub(crate) max_start: StateID,\n}\nimpl<'a> DFA<&'a [u32]> {\n    pub fn from_bytes(\n        slice: &'a [u8],\n    ) -> Result<(DFA<&'a [u32]>, usize), DeserializeError> {\n        let (dfa, nread) = unsafe { DFA::from_bytes_unchecked(slice)? };\n        dfa.tt.validate(&dfa)?;\n        dfa.st.validate(&dfa)?;\n        dfa.ms.validate(&dfa)?;\n        dfa.accels.validate()?;\n        for state in dfa.states() {\n            if dfa.is_accel_state(state.id()) {\n                let index = dfa.accelerator_index(state.id());\n                if index >= dfa.accels.len() {\n                    return Err(\n                        DeserializeError::generic(\n                            \"found DFA state with invalid accelerator index\",\n                        ),\n                    );\n                }\n                let needles = dfa.accels.needles(index);\n                if !(1 <= needles.len() && needles.len() <= 3) {\n                    return Err(\n                        DeserializeError::generic(\n                            \"accelerator needles has invalid length\",\n                        ),\n                    );\n                }\n            }\n        }\n        Ok((dfa, nread))\n    }\n    pub unsafe fn from_bytes_unchecked(\n        slice: &'a [u8],\n    ) -> Result<(DFA<&'a [u32]>, usize), DeserializeError> {\n        let mut nr = 0;\n        nr += wire::skip_initial_padding(slice);\n        wire::check_alignment::<StateID>(&slice[nr..])?;\n        nr += wire::read_label(&slice[nr..], LABEL)?;\n        nr += wire::read_endianness_check(&slice[nr..])?;\n        nr += wire::read_version(&slice[nr..], VERSION)?;\n        let _unused = wire::try_read_u32(&slice[nr..], \"unused space\")?;\n        nr += size_of::<u32>();\n        let (flags, nread) = Flags::from_bytes(&slice[nr..])?;\n        nr += nread;\n        let (tt, nread) = TransitionTable::from_bytes_unchecked(&slice[nr..])?;\n        nr += nread;\n        let (st, nread) = StartTable::from_bytes_unchecked(&slice[nr..])?;\n        nr += nread;\n        let (ms, nread) = MatchStates::from_bytes_unchecked(&slice[nr..])?;\n        nr += nread;\n        let (special, nread) = Special::from_bytes(&slice[nr..])?;\n        nr += nread;\n        special.validate_state_len(tt.len(), tt.stride2)?;\n        let (accels, nread) = Accels::from_bytes_unchecked(&slice[nr..])?;\n        nr += nread;\n        let (quitset, nread) = ByteSet::from_bytes(&slice[nr..])?;\n        nr += nread;\n        let pre = None;\n        Ok((\n            DFA {\n                tt,\n                st,\n                ms,\n                special,\n                accels,\n                pre,\n                quitset,\n                flags,\n            },\n            nr,\n        ))\n    }\n    fn write_to<E: Endian>(&self, mut dst: &mut [u8]) -> Result<usize, SerializeError> {}\n}\nimpl DeserializeError {\n    pub(crate) fn generic(msg: &'static str) -> DeserializeError {\n        DeserializeError(DeserializeErrorKind::Generic {\n            msg,\n        })\n    }\n    pub(crate) fn buffer_too_small(what: &'static str) -> DeserializeError {}\n    fn invalid_usize(what: &'static str) -> DeserializeError {}\n    fn version_mismatch(expected: u32, found: u32) -> DeserializeError {}\n    fn endian_mismatch(expected: u32, found: u32) -> DeserializeError {}\n    fn alignment_mismatch(alignment: usize, address: usize) -> DeserializeError {}\n    fn label_mismatch(expected: &'static str) -> DeserializeError {}\n    fn arithmetic_overflow(what: &'static str) -> DeserializeError {}\n    fn pattern_id_error(err: PatternIDError, what: &'static str) -> DeserializeError {}\n    pub(crate) fn state_id_error(\n        err: StateIDError,\n        what: &'static str,\n    ) -> DeserializeError {}\n}\nimpl<T: AsRef<[u32]>> MatchStates<T> {\n    fn write_to<E: Endian>(&self, mut dst: &mut [u8]) -> Result<usize, SerializeError> {}\n    fn write_to_len(&self) -> usize {}\n    fn validate(&self, dfa: &DFA<T>) -> Result<(), DeserializeError> {\n        if self.len() != dfa.special.match_len(dfa.stride()) {\n            return Err(DeserializeError::generic(\"match state length mismatch\"));\n        }\n        for si in 0..self.len() {\n            let start = self.slices()[si * 2].as_usize();\n            let len = self.slices()[si * 2 + 1].as_usize();\n            if start >= self.pattern_ids().len() {\n                return Err(DeserializeError::generic(\"invalid pattern ID start offset\"));\n            }\n            if start + len > self.pattern_ids().len() {\n                return Err(DeserializeError::generic(\"invalid pattern ID length\"));\n            }\n            for mi in 0..len {\n                let pid = self.pattern_id(si, mi);\n                if pid.as_usize() >= self.pattern_len {\n                    return Err(DeserializeError::generic(\"invalid pattern ID\"));\n                }\n            }\n        }\n        Ok(())\n    }\n    #[cfg(feature = \"dfa-build\")]\n    fn to_map(&self, dfa: &DFA<T>) -> BTreeMap<StateID, Vec<PatternID>> {}\n    fn as_ref(&self) -> MatchStates<&'_ [u32]> {}\n    #[cfg(feature = \"alloc\")]\n    fn to_owned(&self) -> MatchStates<alloc::vec::Vec<u32>> {}\n    fn match_state_id(&self, dfa: &DFA<T>, index: usize) -> StateID {}\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    fn pattern_id(&self, state_index: usize, match_index: usize) -> PatternID {}\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    fn pattern_len(&self, state_index: usize) -> usize {}\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    fn pattern_id_slice(&self, state_index: usize) -> &[PatternID] {}\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    fn slices(&self) -> &[PatternID] {}\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    fn len(&self) -> usize {}\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    fn pattern_ids(&self) -> &[PatternID] {}\n    fn memory_usage(&self) -> usize {}\n}\nimpl<A: AsRef<[AccelTy]>> Accels<A> {\n    #[cfg(feature = \"alloc\")]\n    pub fn to_owned(&self) -> Accels<alloc::vec::Vec<AccelTy>> {}\n    pub fn as_ref(&self) -> Accels<&[AccelTy]> {}\n    pub fn as_bytes(&self) -> &[u8] {}\n    pub fn memory_usage(&self) -> usize {}\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    pub fn needles(&self, i: usize) -> &[u8] {\n        if i >= self.len() {\n            panic!(\"invalid accelerator index {}\", i);\n        }\n        let bytes = self.as_bytes();\n        let offset = ACCEL_TY_SIZE + i * ACCEL_CAP;\n        let len = usize::from(bytes[offset]);\n        &bytes[offset + 1..offset + 1 + len]\n    }\n    pub fn len(&self) -> usize {\n        usize::try_from(self.accels.as_ref()[0]).unwrap()\n    }\n    fn get(&self, i: usize) -> Option<Accel> {}\n    fn iter(&self) -> IterAccels<'_, A> {}\n    pub fn write_to<E: Endian>(&self, dst: &mut [u8]) -> Result<usize, SerializeError> {}\n    pub fn validate(&self) -> Result<(), DeserializeError> {\n        for chunk in self.as_bytes()[ACCEL_TY_SIZE..].chunks(ACCEL_CAP) {\n            let _ = Accel::from_slice(chunk)?;\n        }\n        Ok(())\n    }\n    pub fn write_to_len(&self) -> usize {}\n}\nimpl<T: AsRef<[u32]>> DFA<T> {\n    pub(crate) fn special(&self) -> &Special {}\n    #[cfg(feature = \"dfa-build\")]\n    pub(crate) fn special_mut(&mut self) -> &mut Special {}\n    pub(crate) fn quitset(&self) -> &ByteSet {}\n    pub(crate) fn flags(&self) -> &Flags {}\n    pub(crate) fn states(&self) -> StateIter<'_, T> {\n        self.tt.states()\n    }\n    pub(crate) fn state_len(&self) -> usize {}\n    #[cfg(feature = \"dfa-build\")]\n    pub(crate) fn pattern_id_slice(&self, id: StateID) -> &[PatternID] {}\n    pub(crate) fn match_pattern_len(&self, id: StateID) -> usize {}\n    pub(crate) fn pattern_len(&self) -> usize {}\n    #[cfg(feature = \"dfa-build\")]\n    pub(crate) fn pattern_map(&self) -> BTreeMap<StateID, Vec<PatternID>> {}\n    #[cfg(feature = \"dfa-build\")]\n    pub(crate) fn quit_id(&self) -> StateID {}\n    pub(crate) fn to_index(&self, id: StateID) -> usize {}\n    #[cfg(feature = \"dfa-build\")]\n    pub(crate) fn to_state_id(&self, index: usize) -> StateID {}\n    pub(crate) fn starts(&self) -> StartStateIter<'_> {}\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    fn match_state_index(&self, id: StateID) -> usize {}\n    fn accelerator_index(&self, id: StateID) -> usize {\n        let min = self.special().min_accel.as_usize();\n        self.to_index(StateID::new_unchecked(id.as_usize() - min))\n    }\n    fn accels(&self) -> Accels<&[u32]> {}\n    fn trans(&self) -> &[StateID] {}\n}\nimpl<'a> State<'a> {\n    pub(crate) fn transitions(&self) -> StateTransitionIter<'_> {}\n    pub(crate) fn sparse_transitions(&self) -> StateSparseTransitionIter<'_> {}\n    pub(crate) fn id(&self) -> StateID {\n        self.id\n    }\n    #[cfg(feature = \"dfa-build\")]\n    fn accelerate(&self, classes: &ByteClasses) -> Option<Accel> {}\n}\nimpl<T: AsRef<[u32]>> StartTable<T> {\n    fn write_to<E: Endian>(&self, mut dst: &mut [u8]) -> Result<usize, SerializeError> {}\n    fn write_to_len(&self) -> usize {}\n    fn validate(&self, dfa: &DFA<T>) -> Result<(), DeserializeError> {\n        let tt = &dfa.tt;\n        if !self.universal_start_unanchored.map_or(true, |s| tt.is_valid(s)) {\n            return Err(\n                DeserializeError::generic(\n                    \"found invalid universal unanchored starting state ID\",\n                ),\n            );\n        }\n        if !self.universal_start_anchored.map_or(true, |s| tt.is_valid(s)) {\n            return Err(\n                DeserializeError::generic(\n                    \"found invalid universal anchored starting state ID\",\n                ),\n            );\n        }\n        for &id in self.table() {\n            if !tt.is_valid(id) {\n                return Err(DeserializeError::generic(\"found invalid starting state ID\"));\n            }\n        }\n        Ok(())\n    }\n    fn as_ref(&self) -> StartTable<&'_ [u32]> {}\n    #[cfg(feature = \"alloc\")]\n    fn to_owned(&self) -> StartTable<alloc::vec::Vec<u32>> {}\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    fn start(&self, anchored: Anchored, start: Start) -> Result<StateID, StartError> {}\n    fn iter(&self) -> StartStateIter<'_> {}\n    fn table(&self) -> &[StateID] {}\n    fn memory_usage(&self) -> usize {}\n}\nimpl<T: AsRef<[u32]>> TransitionTable<T> {\n    fn write_to<E: Endian>(&self, mut dst: &mut [u8]) -> Result<usize, SerializeError> {}\n    fn write_to_len(&self) -> usize {}\n    fn validate(&self, dfa: &DFA<T>) -> Result<(), DeserializeError> {\n        let sp = &dfa.special;\n        for state in self.states() {\n            if sp.is_special_state(state.id()) {\n                let is_actually_special = sp.is_dead_state(state.id())\n                    || sp.is_quit_state(state.id()) || sp.is_match_state(state.id())\n                    || sp.is_start_state(state.id()) || sp.is_accel_state(state.id());\n                if !is_actually_special {\n                    return Err(\n                        DeserializeError::generic(\n                            \"found dense state tagged as special but \\\n                         wasn't actually special\",\n                        ),\n                    );\n                }\n                if sp.is_match_state(state.id()) && dfa.match_len(state.id()) == 0 {\n                    return Err(\n                        DeserializeError::generic(\n                            \"found match state with zero pattern IDs\",\n                        ),\n                    );\n                }\n            }\n            for (_, to) in state.transitions() {\n                if !self.is_valid(to) {\n                    return Err(\n                        DeserializeError::generic(\n                            \"found invalid state ID in transition table\",\n                        ),\n                    );\n                }\n            }\n        }\n        Ok(())\n    }\n    fn as_ref(&self) -> TransitionTable<&'_ [u32]> {}\n    #[cfg(feature = \"alloc\")]\n    fn to_owned(&self) -> TransitionTable<alloc::vec::Vec<u32>> {}\n    fn state(&self, id: StateID) -> State<'_> {}\n    fn states(&self) -> StateIter<'_, T> {}\n    fn to_index(&self, id: StateID) -> usize {}\n    fn to_state_id(&self, index: usize) -> StateID {}\n    #[cfg(feature = \"dfa-build\")]\n    fn next_state_id(&self, id: StateID) -> StateID {}\n    #[cfg(feature = \"dfa-build\")]\n    fn prev_state_id(&self, id: StateID) -> StateID {}\n    fn table(&self) -> &[StateID] {}\n    fn len(&self) -> usize {}\n    fn stride(&self) -> usize {}\n    fn alphabet_len(&self) -> usize {}\n    fn is_valid(&self, id: StateID) -> bool {}\n    fn memory_usage(&self) -> usize {}\n}\n\nThe function to be tested is presented with each line formatted as 'line number + code':\n/// Safely deserialize a DFA with a specific state identifier\n/// representation. Upon success, this returns both the deserialized DFA\n/// and the number of bytes read from the given slice. Namely, the contents\n/// of the slice beyond the DFA are not read.\n///\n/// Deserializing a DFA using this routine will never allocate heap memory.\n/// For safety purposes, the DFA's transition table will be verified such\n/// that every transition points to a valid state. If this verification is\n/// too costly, then a [`DFA::from_bytes_unchecked`] API is provided, which\n/// will always execute in constant time.\n///\n/// The bytes given must be generated by one of the serialization APIs\n/// of a `DFA` using a semver compatible release of this crate. Those\n/// include:\n///\n/// * [`DFA::to_bytes_little_endian`]\n/// * [`DFA::to_bytes_big_endian`]\n/// * [`DFA::to_bytes_native_endian`]\n/// * [`DFA::write_to_little_endian`]\n/// * [`DFA::write_to_big_endian`]\n/// * [`DFA::write_to_native_endian`]\n///\n/// The `to_bytes` methods allocate and return a `Vec<u8>` for you, along\n/// with handling alignment correctly. The `write_to` methods do not\n/// allocate and write to an existing slice (which may be on the stack).\n/// Since deserialization always uses the native endianness of the target\n/// platform, the serialization API you use should match the endianness of\n/// the target platform. (It's often a good idea to generate serialized\n/// DFAs for both forms of endianness and then load the correct one based\n/// on endianness.)\n///\n/// # Errors\n///\n/// Generally speaking, it's easier to state the conditions in which an\n/// error is _not_ returned. All of the following must be true:\n///\n/// * The bytes given must be produced by one of the serialization APIs\n///   on this DFA, as mentioned above.\n/// * The endianness of the target platform matches the endianness used to\n///   serialized the provided DFA.\n/// * The slice given must have the same alignment as `u32`.\n///\n/// If any of the above are not true, then an error will be returned.\n///\n/// # Panics\n///\n/// This routine will never panic for any input.\n///\n/// # Example\n///\n/// This example shows how to serialize a DFA to raw bytes, deserialize it\n/// and then use it for searching.\n///\n/// ```\n/// use regex_automata::{dfa::{Automaton, dense::DFA}, HalfMatch, Input};\n///\n/// let initial = DFA::new(\"foo[0-9]+\")?;\n/// let (bytes, _) = initial.to_bytes_native_endian();\n/// let dfa: DFA<&[u32]> = DFA::from_bytes(&bytes)?.0;\n///\n/// let expected = Some(HalfMatch::must(0, 8));\n/// assert_eq!(expected, dfa.try_search_fwd(&Input::new(\"foo12345\"))?);\n/// # Ok::<(), Box<dyn std::error::Error>>(())\n/// ```\n///\n/// # Example: dealing with alignment and padding\n///\n/// In the above example, we used the `to_bytes_native_endian` method to\n/// serialize a DFA, but we ignored part of its return value corresponding\n/// to padding added to the beginning of the serialized DFA. This is OK\n/// because deserialization will skip this initial padding. What matters\n/// is that the address immediately following the padding has an alignment\n/// that matches `u32`. That is, the following is an equivalent but\n/// alternative way to write the above example:\n///\n/// ```\n/// use regex_automata::{dfa::{Automaton, dense::DFA}, HalfMatch, Input};\n///\n/// let initial = DFA::new(\"foo[0-9]+\")?;\n/// // Serialization returns the number of leading padding bytes added to\n/// // the returned Vec<u8>.\n/// let (bytes, pad) = initial.to_bytes_native_endian();\n/// let dfa: DFA<&[u32]> = DFA::from_bytes(&bytes[pad..])?.0;\n///\n/// let expected = Some(HalfMatch::must(0, 8));\n/// assert_eq!(expected, dfa.try_search_fwd(&Input::new(\"foo12345\"))?);\n/// # Ok::<(), Box<dyn std::error::Error>>(())\n/// ```\n///\n/// This padding is necessary because Rust's standard library does\n/// not expose any safe and robust way of creating a `Vec<u8>` with a\n/// guaranteed alignment other than 1. Now, in practice, the underlying\n/// allocator is likely to provide a `Vec<u8>` that meets our alignment\n/// requirements, which means `pad` is zero in practice most of the time.\n///\n/// The purpose of exposing the padding like this is flexibility for the\n/// caller. For example, if one wants to embed a serialized DFA into a\n/// compiled program, then it's important to guarantee that it starts at a\n/// `u32`-aligned address. The simplest way to do this is to discard the\n/// padding bytes and set it up so that the serialized DFA itself begins at\n/// a properly aligned address. We can show this in two parts. The first\n/// part is serializing the DFA to a file:\n///\n/// ```no_run\n/// use regex_automata::dfa::dense::DFA;\n///\n/// let dfa = DFA::new(\"foo[0-9]+\")?;\n///\n/// let (bytes, pad) = dfa.to_bytes_big_endian();\n/// // Write the contents of the DFA *without* the initial padding.\n/// std::fs::write(\"foo.bigendian.dfa\", &bytes[pad..])?;\n///\n/// // Do it again, but this time for little endian.\n/// let (bytes, pad) = dfa.to_bytes_little_endian();\n/// std::fs::write(\"foo.littleendian.dfa\", &bytes[pad..])?;\n/// # Ok::<(), Box<dyn std::error::Error>>(())\n/// ```\n///\n/// And now the second part is embedding the DFA into the compiled program\n/// and deserializing it at runtime on first use. We use conditional\n/// compilation to choose the correct endianness.\n///\n/// ```no_run\n/// use regex_automata::{\n///     dfa::{Automaton, dense::DFA},\n///     util::{lazy::Lazy, wire::AlignAs},\n///     HalfMatch, Input,\n/// };\n///\n/// // This crate provides its own \"lazy\" type, kind of like\n/// // lazy_static! or once_cell::sync::Lazy. But it works in no-alloc\n/// // no-std environments and let's us write this using completely\n/// // safe code.\n/// static RE: Lazy<DFA<&'static [u32]>> = Lazy::new(|| {\n///     # const _: &str = stringify! {\n///     // This assignment is made possible (implicitly) via the\n///     // CoerceUnsized trait. This is what guarantees that our\n///     // bytes are stored in memory on a 4 byte boundary. You\n///     // *must* do this or something equivalent for correct\n///     // deserialization.\n///     static ALIGNED: &AlignAs<[u8], u32> = &AlignAs {\n///         _align: [],\n///         #[cfg(target_endian = \"big\")]\n///         bytes: *include_bytes!(\"foo.bigendian.dfa\"),\n///         #[cfg(target_endian = \"little\")]\n///         bytes: *include_bytes!(\"foo.littleendian.dfa\"),\n///     };\n///     # };\n///     # static ALIGNED: &AlignAs<[u8], u32> = &AlignAs {\n///     #     _align: [],\n///     #     bytes: [],\n///     # };\n///\n///     let (dfa, _) = DFA::from_bytes(&ALIGNED.bytes)\n///         .expect(\"serialized DFA should be valid\");\n///     dfa\n/// });\n///\n/// let expected = Ok(Some(HalfMatch::must(0, 8)));\n/// assert_eq!(expected, RE.try_search_fwd(&Input::new(\"foo12345\")));\n/// ```\n///\n/// An alternative to [`util::lazy::Lazy`](crate::util::lazy::Lazy)\n/// is [`lazy_static`](https://crates.io/crates/lazy_static) or\n/// [`once_cell`](https://crates.io/crates/once_cell), which provide\n/// stronger guarantees (like the initialization function only being\n/// executed once). And `once_cell` in particular provides a more\n/// expressive API. But a `Lazy` value from this crate is likely just fine\n/// in most circumstances.\n///\n/// Note that regardless of which initialization method you use, you\n/// will still need to use the [`AlignAs`](crate::util::wire::AlignAs)\n/// trick above to force correct alignment, but this is safe to do and\n/// `from_bytes` will return an error if you get it wrong.\n2336 pub fn from_bytes(\n2337     slice: &'a [u8],\n2338 ) -> Result<(DFA<&'a [u32]>, usize), DeserializeError> {\n2339     // SAFETY: This is safe because we validate the transition table, start\n2340     // table, match states and accelerators below. If any validation fails,\n2341     // then we return an error.\n2342     let (dfa, nread) = unsafe { DFA::from_bytes_unchecked(slice)? };\n2343     dfa.tt.validate(&dfa)?;\n2344     dfa.st.validate(&dfa)?;\n2345     dfa.ms.validate(&dfa)?;\n2346     dfa.accels.validate()?;\n2347     // N.B. dfa.special doesn't have a way to do unchecked deserialization,\n2348     // so it has already been validated.\n2349     for state in dfa.states() {\n2350         // If the state is an accel state, then it must have a non-empty\n2351         // accelerator.\n2352         if dfa.is_accel_state(state.id()) {\n2353             let index = dfa.accelerator_index(state.id());\n2354             if index >= dfa.accels.len() {\n2355                 return Err(DeserializeError::generic(\n2356                     \"found DFA state with invalid accelerator index\",\n2357                 ));\n2358             }\n2359             let needles = dfa.accels.needles(index);\n2360             if !(1 <= needles.len() && needles.len() <= 3) {\n2361                 return Err(DeserializeError::generic(\n2362                     \"accelerator needles has invalid length\",\n2363                 ));\n2364             }\n2365         }\n2366     }\n2367     Ok((dfa, nread))\n2368 }\n\nWhen inferring test input conditions or ranges, consider the following preconditions and expected return values or types:\n"
}