{
  "system_pt": "As a software testing expert, please generate Rust test functions based on the following guidelines, focusing solely on constructing test inputs and calling the functions under test:\n1. Provide the code in plain text format, without explanations or Markdown.\n2. If the method under test belongs to a trait, construct appropriate structs within the test function, but avoid method overrides. If the method under test uses generics, instantiate them with suitable types based on the context.\n3. Generate test code with minimal scope: avoid creating external structures or implementations. Instead, define any necessary helper structures or implementations directly within the test function when required.\n4. Whenever possible, initialize the corresponding data structures using the initialization methods provided in the context.\n5. Ensure the generated function is fully implemented and can be compiled and executed directly without any missing parts.\n6. Create a minimal yet complete set of test functions, ensuring they adhere to all provided preconditions and cover boundary conditions, and reference the inferred test input conditions or ranges.\n7. Ensure the test inputs are designed to cover the inferred test input conditions or ranges as comprehensively as possible, with particular emphasis on boundary cases.\n8. Focus on crafting test inputs that effectively reveal potential bugs while meeting the specified requirements.\n9. Omit test oracles and assertions; concentrate on generating test inputs and function calls.\n10. Do not create a test module, but include intrinsic attributes like #[test] or #[should_panic] where necessary.\n",
  "static_pt": "The context for the focal function is as follows:\n// regex-automata/src/nfa/thompson/nfa.rs\n// crate name is regex_automata\nuse core::{fmt, mem};\nuse alloc::{boxed::Box, format, string::String, sync::Arc, vec, vec::Vec};\n#[cfg(feature = \"syntax\")]\nuse crate::nfa::thompson::{\n    compiler::{Compiler, Config},\n    error::BuildError,\n};\nuse crate::{\n    nfa::thompson::builder::Builder,\n    util::{\n        alphabet::{self, ByteClassSet, ByteClasses},\n        captures::{GroupInfo, GroupInfoError},\n        look::{Look, LookMatcher, LookSet},\n        primitives::{IteratorIndexExt, PatternID, PatternIDIter, SmallIndex, StateID},\n        sparse_set::SparseSet,\n    },\n};\n#[derive(Clone)]\npub struct NFA(Arc<Inner>);\n#[derive(Default)]\npub(super) struct Inner {\n    /// The state sequence. This sequence is guaranteed to be indexable by all\n    /// starting state IDs, and it is also guaranteed to contain at most one\n    /// `Match` state for each pattern compiled into this NFA. (A pattern may\n    /// not have a corresponding `Match` state if a `Match` state is impossible\n    /// to reach.)\n    states: Vec<State>,\n    /// The anchored starting state of this NFA.\n    start_anchored: StateID,\n    /// The unanchored starting state of this NFA.\n    start_unanchored: StateID,\n    /// The starting states for each individual pattern. Starting at any\n    /// of these states will result in only an anchored search for the\n    /// corresponding pattern. The vec is indexed by pattern ID. When the NFA\n    /// contains a single regex, then `start_pattern[0]` and `start_anchored`\n    /// are always equivalent.\n    start_pattern: Vec<StateID>,\n    /// Info about the capturing groups in this NFA. This is responsible for\n    /// mapping groups to slots, mapping groups to names and names to groups.\n    group_info: GroupInfo,\n    /// A representation of equivalence classes over the transitions in this\n    /// NFA. Two bytes in the same equivalence class must not discriminate\n    /// between a match or a non-match. This map can be used to shrink the\n    /// total size of a DFA's transition table with a small match-time cost.\n    ///\n    /// Note that the NFA's transitions are *not* defined in terms of these\n    /// equivalence classes. The NFA's transitions are defined on the original\n    /// byte values. For the most part, this is because they wouldn't really\n    /// help the NFA much since the NFA already uses a sparse representation\n    /// to represent transitions. Byte classes are most effective in a dense\n    /// representation.\n    byte_class_set: ByteClassSet,\n    /// This is generated from `byte_class_set`, and essentially represents the\n    /// same thing but supports different access patterns. Namely, this permits\n    /// looking up the equivalence class of a byte very cheaply.\n    ///\n    /// Ideally we would just store this, but because of annoying code\n    /// structure reasons, we keep both this and `byte_class_set` around for\n    /// now. I think I would prefer that `byte_class_set` were computed in the\n    /// `Builder`, but right now, we compute it as states are added to the\n    /// `NFA`.\n    byte_classes: ByteClasses,\n    /// Whether this NFA has a `Capture` state anywhere.\n    has_capture: bool,\n    /// When the empty string is in the language matched by this NFA.\n    has_empty: bool,\n    /// Whether UTF-8 mode is enabled for this NFA. Briefly, this means that\n    /// all non-empty matches produced by this NFA correspond to spans of valid\n    /// UTF-8, and any empty matches produced by this NFA that split a UTF-8\n    /// encoded codepoint should be filtered out by the corresponding regex\n    /// engine.\n    utf8: bool,\n    /// Whether this NFA is meant to be matched in reverse or not.\n    reverse: bool,\n    /// The matcher to be used for look-around assertions.\n    look_matcher: LookMatcher,\n    /// The union of all look-around assertions that occur anywhere within\n    /// this NFA. If this set is empty, then it means there are precisely zero\n    /// conditional epsilon transitions in the NFA.\n    look_set_any: LookSet,\n    /// The union of all look-around assertions that occur as a zero-length\n    /// prefix for any of the patterns in this NFA.\n    look_set_prefix_any: LookSet,\n    /// Heap memory used indirectly by NFA states and other things (like the\n    /// various capturing group representations above). Since each state\n    /// might use a different amount of heap, we need to keep track of this\n    /// incrementally.\n    memory_extra: usize,\n}\nimpl NFA {\n    #[cfg(feature = \"syntax\")]\n    pub fn new(pattern: &str) -> Result<NFA, BuildError> {}\n    #[cfg(feature = \"syntax\")]\n    pub fn new_many<P: AsRef<str>>(patterns: &[P]) -> Result<NFA, BuildError> {}\n    pub fn always_match() -> NFA {}\n    pub fn never_match() -> NFA {}\n    #[cfg(feature = \"syntax\")]\n    pub fn config() -> Config {}\n    #[cfg(feature = \"syntax\")]\n    pub fn compiler() -> Compiler {}\n    pub fn patterns(&self) -> PatternIter<'_> {}\n    #[inline]\n    pub fn pattern_len(&self) -> usize {}\n    #[inline]\n    pub fn start_anchored(&self) -> StateID {}\n    #[inline]\n    pub fn start_unanchored(&self) -> StateID {}\n    #[inline]\n    pub fn start_pattern(&self, pid: PatternID) -> Option<StateID> {}\n    #[inline]\n    pub(crate) fn byte_class_set(&self) -> &ByteClassSet {}\n    #[inline]\n    pub fn byte_classes(&self) -> &ByteClasses {}\n    #[inline]\n    pub fn state(&self, id: StateID) -> &State {}\n    #[inline]\n    pub fn states(&self) -> &[State] {}\n    #[inline]\n    pub fn group_info(&self) -> &GroupInfo {}\n    #[inline]\n    pub fn has_capture(&self) -> bool {}\n    #[inline]\n    pub fn has_empty(&self) -> bool {}\n    #[inline]\n    pub fn is_utf8(&self) -> bool {\n        self.0.utf8\n    }\n    #[inline]\n    pub fn is_reverse(&self) -> bool {}\n    #[inline]\n    pub fn is_always_start_anchored(&self) -> bool {}\n    #[inline]\n    pub fn look_matcher(&self) -> &LookMatcher {}\n    #[inline]\n    pub fn look_set_any(&self) -> LookSet {}\n    #[inline]\n    pub fn look_set_prefix_any(&self) -> LookSet {}\n    #[inline]\n    pub fn memory_usage(&self) -> usize {}\n}\n\nThe function to be tested is presented with each line formatted as 'line number + code':\n/// Whether UTF-8 mode is enabled for this NFA or not.\n///\n/// When UTF-8 mode is enabled, all matches reported by a regex engine\n/// derived from this NFA are guaranteed to correspond to spans of valid\n/// UTF-8. This includes zero-width matches. For example, the regex engine\n/// must guarantee that the empty regex will not match at the positions\n/// between code units in the UTF-8 encoding of a single codepoint.\n///\n/// See [`Config::utf8`] for more information.\n///\n/// This is enabled by default.\n///\n/// # Example\n///\n/// This example shows how UTF-8 mode can impact the match spans that may\n/// be reported in certain cases.\n///\n/// ```\n/// use regex_automata::{\n///     nfa::thompson::{self, pikevm::PikeVM},\n///     Match, Input,\n/// };\n///\n/// let re = PikeVM::new(\"\")?;\n/// let (mut cache, mut caps) = (re.create_cache(), re.create_captures());\n///\n/// // UTF-8 mode is enabled by default.\n/// let mut input = Input::new(\"â˜ƒ\");\n/// re.search(&mut cache, &input, &mut caps);\n/// assert_eq!(Some(Match::must(0, 0..0)), caps.get_match());\n///\n/// // Even though an empty regex matches at 1..1, our next match is\n/// // 3..3 because 1..1 and 2..2 split the snowman codepoint (which is\n/// // three bytes long).\n/// input.set_start(1);\n/// re.search(&mut cache, &input, &mut caps);\n/// assert_eq!(Some(Match::must(0, 3..3)), caps.get_match());\n///\n/// // But if we disable UTF-8, then we'll get matches at 1..1 and 2..2:\n/// let re = PikeVM::builder()\n///     .thompson(thompson::Config::new().utf8(false))\n///     .build(\"\")?;\n/// re.search(&mut cache, &input, &mut caps);\n/// assert_eq!(Some(Match::must(0, 1..1)), caps.get_match());\n///\n/// input.set_start(2);\n/// re.search(&mut cache, &input, &mut caps);\n/// assert_eq!(Some(Match::must(0, 2..2)), caps.get_match());\n///\n/// input.set_start(3);\n/// re.search(&mut cache, &input, &mut caps);\n/// assert_eq!(Some(Match::must(0, 3..3)), caps.get_match());\n///\n/// input.set_start(4);\n/// re.search(&mut cache, &input, &mut caps);\n/// assert_eq!(None, caps.get_match());\n///\n/// # Ok::<(), Box<dyn std::error::Error>>(())\n/// ```\n882 pub fn is_utf8(&self) -> bool {\n883     self.0.utf8\n884 }\n\nGenerate each test function in such a manner that it concurrently satisfies all the following preconditions:\n",
  "depend_pt": ""
}