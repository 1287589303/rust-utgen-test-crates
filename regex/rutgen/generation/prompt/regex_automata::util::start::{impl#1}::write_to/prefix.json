{
  "system_pt": "As a software testing expert, please generate Rust test functions based on the following guidelines, focusing solely on constructing test inputs and calling the functions under test:\n1. Provide the code in plain text format, without explanations or Markdown.\n2. If the method under test belongs to a trait, construct appropriate structs within the test function, but avoid method overrides. If the method under test uses generics, instantiate them with suitable types based on the context.\n3. Generate test code with minimal scope: avoid creating external structures or implementations. Instead, define any necessary helper structures or implementations directly within the test function when required.\n4. Whenever possible, initialize the corresponding data structures using the initialization methods provided in the context.\n5. Ensure the generated function is fully implemented and can be compiled and executed directly without any missing parts.\n6. Create a minimal yet complete set of test functions, ensuring they adhere to all provided preconditions and cover boundary conditions, and reference the inferred test input conditions or ranges.\n7. Ensure the test inputs are designed to cover the inferred test input conditions or ranges as comprehensively as possible, with particular emphasis on boundary cases.\n8. Focus on crafting test inputs that effectively reveal potential bugs while meeting the specified requirements.\n9. Omit test oracles and assertions; concentrate on generating test inputs and function calls.\n10. Do not create a test module, but include intrinsic attributes like #[test] or #[should_panic] where necessary.\n",
  "static_pt": "The context for the focal function is as follows:\n// regex-automata/src/util/start.rs\n// crate name is regex_automata\nuse crate::util::{\n    look::LookMatcher, search::{Anchored, Input},\n    wire::{self, DeserializeError, SerializeError},\n};\n#[derive(Clone)]\npub(crate) struct StartByteMap {\n    map: [Start; 256],\n}\n#[derive(Debug)]\npub struct SerializeError {\n    /// The name of the thing that a buffer is too small for.\n    ///\n    /// Currently, the only kind of serialization error is one that is\n    /// committed by a caller: providing a destination buffer that is too\n    /// small to fit the serialized object. This makes sense conceptually,\n    /// since every valid inhabitant of a type should be serializable.\n    ///\n    /// This is somewhat exposed in the public API of this crate. For example,\n    /// the `to_bytes_{big,little}_endian` APIs return a `Vec<u8>` and are\n    /// guaranteed to never panic or error. This is only possible because the\n    /// implementation guarantees that it will allocate a `Vec<u8>` that is\n    /// big enough.\n    ///\n    /// In summary, if a new serialization error kind needs to be added, then\n    /// it will need careful consideration.\n    what: &'static str,\n}\n#[derive(Clone, Copy, Debug, Eq, PartialEq)]\npub(crate) enum Start {\n    /// This occurs when the starting position is not any of the ones below.\n    NonWordByte = 0,\n    /// This occurs when the byte immediately preceding the start of the search\n    /// is an ASCII word byte.\n    WordByte = 1,\n    /// This occurs when the starting position of the search corresponds to the\n    /// beginning of the haystack.\n    Text = 2,\n    /// This occurs when the byte immediately preceding the start of the search\n    /// is a line terminator. Specifically, `\\n`.\n    LineLF = 3,\n    /// This occurs when the byte immediately preceding the start of the search\n    /// is a line terminator. Specifically, `\\r`.\n    LineCR = 4,\n    /// This occurs when a custom line terminator has been set via a\n    /// `LookMatcher`, and when that line terminator is neither a `\\r` or a\n    /// `\\n`.\n    ///\n    /// If the custom line terminator is a word byte, then this start\n    /// configuration is still selected. DFAs that implement word boundary\n    /// assertions will likely need to check whether the custom line terminator\n    /// is a word byte, in which case, it should behave as if the byte\n    /// satisfies `\\b` in addition to multi-line anchors.\n    CustomLineTerminator = 5,\n}\nimpl StartByteMap {\n    pub(crate) fn new(lookm: &LookMatcher) -> StartByteMap {}\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    pub(crate) fn get(&self, byte: u8) -> Start {}\n    pub(crate) fn from_bytes(\n        slice: &[u8],\n    ) -> Result<(StartByteMap, usize), DeserializeError> {}\n    pub(crate) fn write_to(&self, dst: &mut [u8]) -> Result<usize, SerializeError> {\n        let nwrite = self.write_to_len();\n        if dst.len() < nwrite {\n            return Err(SerializeError::buffer_too_small(\"start byte map\"));\n        }\n        for (i, &start) in self.map.iter().enumerate() {\n            dst[i] = start.as_u8();\n        }\n        Ok(nwrite)\n    }\n    pub(crate) fn write_to_len(&self) -> usize {\n        256\n    }\n}\nimpl SerializeError {\n    pub(crate) fn buffer_too_small(what: &'static str) -> SerializeError {\n        SerializeError { what }\n    }\n}\nimpl Start {\n    pub(crate) fn from_usize(n: usize) -> Option<Start> {}\n    pub(crate) fn len() -> usize {}\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    pub(crate) fn as_u8(&self) -> u8 {\n        *self as u8\n    }\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    pub(crate) fn as_usize(&self) -> usize {}\n}\n\nThe function to be tested is presented with each line formatted as 'line number + code':\n/// Writes this map to the given byte buffer. if the given buffer is too\n/// small, then an error is returned. Upon success, the total number of\n/// bytes written is returned. The number of bytes written is guaranteed to\n/// be a multiple of 8.\n287 pub(crate) fn write_to(\n288     &self,\n289     dst: &mut [u8],\n290 ) -> Result<usize, SerializeError> {\n291     let nwrite = self.write_to_len();\n292     if dst.len() < nwrite {\n293         return Err(SerializeError::buffer_too_small(\"start byte map\"));\n294     }\n295     for (i, &start) in self.map.iter().enumerate() {\n296         dst[i] = start.as_u8();\n297     }\n298     Ok(nwrite)\n299 }\n\nGenerate each test function in such a manner that it concurrently satisfies all the following preconditions:\n",
  "depend_pt": ""
}