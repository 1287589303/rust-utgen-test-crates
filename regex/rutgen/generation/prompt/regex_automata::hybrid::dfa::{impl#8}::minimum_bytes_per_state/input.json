{
  "system_pt": "As a software testing expert, infer the test input conditions or ranges based on the provided information. Follow these guidelines:\n1. Provide test input conditions or ranges in one line in plain text only, without additional explanations or Markdown formatting\n2. Analyze the function under test, context, preconditions, and expected return values or types to determine appropriate test input conditions or ranges\n3. The inferred test input conditions or ranges should comprehensively satisfy all provided preconditions simultaneously.\n4. Ensure the test input conditions or ranges cover boundary cases and edge scenarios\n",
  "static_pt": "The context for the focal function is as follows:\n// regex-automata/src/hybrid/dfa.rs\n// crate name is regex_automata\n#[cfg(feature = \"std\")]\ntype StateMap = std::collections::HashMap<State, LazyStateID>;\n#[cfg(not(feature = \"std\"))]\ntype StateMap = alloc::collections::BTreeMap<State, LazyStateID>;\nuse core::{iter, mem::size_of};\nuse alloc::vec::Vec;\nuse crate::{\n    hybrid::{\n        error::{BuildError, CacheError, StartError},\n        id::{LazyStateID, LazyStateIDError},\n        search,\n    },\n    nfa::thompson,\n    util::{\n        alphabet::{self, ByteClasses, ByteSet},\n        determinize::{self, State, StateBuilderEmpty, StateBuilderNFA},\n        empty, prefilter::Prefilter, primitives::{PatternID, StateID as NFAStateID},\n        search::{Anchored, HalfMatch, Input, MatchError, MatchKind, PatternSet},\n        sparse_set::SparseSets, start::{self, Start, StartByteMap},\n    },\n};\nconst MIN_STATES: usize = SENTINEL_STATES + 2;\nconst SENTINEL_STATES: usize = 3;\n#[derive(Clone, Debug, Default)]\npub struct Config {\n    match_kind: Option<MatchKind>,\n    pre: Option<Option<Prefilter>>,\n    starts_for_each_pattern: Option<bool>,\n    byte_classes: Option<bool>,\n    unicode_word_boundary: Option<bool>,\n    quitset: Option<ByteSet>,\n    specialize_start_states: Option<bool>,\n    cache_capacity: Option<usize>,\n    skip_cache_capacity_check: Option<bool>,\n    minimum_cache_clear_count: Option<Option<usize>>,\n    minimum_bytes_per_state: Option<Option<usize>>,\n}\n#[derive(Clone, Copy, Debug, Default, Eq, PartialEq)]\npub(crate) struct ByteSet {\n    bits: BitSet,\n}\n#[derive(Clone, Debug)]\npub struct Prefilter {\n    #[cfg(not(feature = \"alloc\"))]\n    _unused: (),\n    #[cfg(feature = \"alloc\")]\n    pre: Arc<dyn PrefilterI>,\n    #[cfg(feature = \"alloc\")]\n    is_fast: bool,\n    #[cfg(feature = \"alloc\")]\n    max_needle_len: usize,\n}\n#[derive(Clone, Debug)]\npub(crate) struct ByteSet([bool; 256]);\n#[non_exhaustive]\n#[derive(Clone, Copy, Debug, Eq, PartialEq)]\npub enum MatchKind {\n    /// Report all possible matches.\n    All,\n    /// Report only the leftmost matches. When multiple leftmost matches exist,\n    /// report the match corresponding to the part of the regex that appears\n    /// first in the syntax.\n    LeftmostFirst,\n}\nimpl Config {\n    pub fn new() -> Config {}\n    pub fn match_kind(mut self, kind: MatchKind) -> Config {}\n    pub fn prefilter(mut self, pre: Option<Prefilter>) -> Config {}\n    pub fn starts_for_each_pattern(mut self, yes: bool) -> Config {}\n    pub fn byte_classes(mut self, yes: bool) -> Config {}\n    pub fn unicode_word_boundary(mut self, yes: bool) -> Config {}\n    pub fn quit(mut self, byte: u8, yes: bool) -> Config {}\n    pub fn specialize_start_states(mut self, yes: bool) -> Config {}\n    pub fn cache_capacity(mut self, bytes: usize) -> Config {}\n    pub fn skip_cache_capacity_check(mut self, yes: bool) -> Config {}\n    pub fn minimum_cache_clear_count(mut self, min: Option<usize>) -> Config {}\n    pub fn minimum_bytes_per_state(mut self, min: Option<usize>) -> Config {\n        self.minimum_bytes_per_state = Some(min);\n        self\n    }\n    pub fn get_match_kind(&self) -> MatchKind {}\n    pub fn get_prefilter(&self) -> Option<&Prefilter> {}\n    pub fn get_starts_for_each_pattern(&self) -> bool {}\n    pub fn get_byte_classes(&self) -> bool {}\n    pub fn get_unicode_word_boundary(&self) -> bool {}\n    pub fn get_quit(&self, byte: u8) -> bool {}\n    pub fn get_specialize_start_states(&self) -> bool {}\n    pub fn get_cache_capacity(&self) -> usize {}\n    pub fn get_skip_cache_capacity_check(&self) -> bool {}\n    pub fn get_minimum_cache_clear_count(&self) -> Option<usize> {}\n    pub fn get_minimum_bytes_per_state(&self) -> Option<usize> {}\n    pub fn get_minimum_cache_capacity(\n        &self,\n        nfa: &thompson::NFA,\n    ) -> Result<usize, BuildError> {}\n    fn byte_classes_from_nfa(&self, nfa: &thompson::NFA, quit: &ByteSet) -> ByteClasses {}\n    fn quit_set_from_nfa(&self, nfa: &thompson::NFA) -> Result<ByteSet, BuildError> {}\n    fn overwrite(&self, o: Config) -> Config {}\n}\n\nThe function to be tested is presented with each line formatted as 'line number + code':\n/// Configure a lazy DFA search to quit only when its efficiency drops\n/// below the given minimum.\n///\n/// The efficiency of the cache is determined by the number of DFA states\n/// compiled per byte of haystack searched. For example, if the efficiency\n/// is 2, then it means the lazy DFA is creating a new DFA state after\n/// searching approximately 2 bytes in a haystack. Generally speaking, 2\n/// is quite bad and it's likely that even a slower regex engine like the\n/// [`PikeVM`](crate::nfa::thompson::pikevm::PikeVM) would be faster.\n///\n/// This has no effect if [`Config::minimum_cache_clear_count`] is not set.\n/// Namely, this option only kicks in when the cache has been cleared more\n/// than the minimum number. If no minimum is set, then the cache is simply\n/// cleared whenever it fills up and it is impossible for the lazy DFA to\n/// quit due to ineffective use of the cache.\n///\n/// In general, if one is setting [`Config::minimum_cache_clear_count`],\n/// then one should probably also set this knob as well. The reason is\n/// that the absolute number of times the cache is cleared is generally\n/// not a great predictor of efficiency. For example, if a new DFA state\n/// is created for every 1,000 bytes searched, then it wouldn't be hard\n/// for the cache to get cleared more than `N` times and then cause the\n/// lazy DFA to quit. But a new DFA state every 1,000 bytes is likely quite\n/// good from a performance perspective, and it's likely that the lazy\n/// DFA should continue searching, even if it requires clearing the cache\n/// occasionally.\n///\n/// Finally, note that if you're implementing your own lazy DFA search\n/// routine and also want this efficiency check to work correctly, then\n/// you'll need to use the following routines to record search progress:\n///\n/// * Call [`Cache::search_start`] at the beginning of every search.\n/// * Call [`Cache::search_update`] whenever [`DFA::next_state`] is\n/// called.\n/// * Call [`Cache::search_finish`] before completing a search. (It is\n/// not strictly necessary to call this when an error is returned, as\n/// `Cache::search_start` will automatically finish the previous search\n/// for you. But calling it where possible before returning helps improve\n/// the accuracy of how many bytes have actually been searched.)\n3709 pub fn minimum_bytes_per_state(mut self, min: Option<usize>) -> Config {\n3710     self.minimum_bytes_per_state = Some(min);\n3711     self\n3712 }\n\nWhen inferring test input conditions or ranges, consider the following preconditions and expected return values or types:\n"
}