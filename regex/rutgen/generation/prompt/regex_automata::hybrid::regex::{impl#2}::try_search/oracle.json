{
  "system_pt": "As a software testing expert, please generate accurate test oracles code based on the provided information. Follow these guidelines:\n1. Generate executable test oracle codes in plain text format, one per line. Do not output complete test functions, avoid additional explanations, and do not use Markdown.\n2. Combine the given function under test, context, relevant documentation, preconditions, expected return values or types, test input conditions or ranges, and existing test function prefixes to infer and generate corresponding test oracles code.\n3. Only generate necessary test oracles to ensure comprehensive validation.\n",
  "static_pt": "The context for the focal function is as follows:\n// regex-automata/src/hybrid/regex.rs\n// crate name is regex_automata\nuse crate::{\n    hybrid::{\n        dfa::{self, DFA},\n        error::BuildError,\n    },\n    nfa::thompson, util::{iter, search::{Anchored, Input, Match, MatchError, MatchKind}},\n};\n#[derive(Debug)]\npub struct Regex {\n    /// The forward lazy DFA. This can only find the end of a match.\n    forward: DFA,\n    /// The reverse lazy DFA. This can only find the start of a match.\n    ///\n    /// This is built with 'all' match semantics (instead of leftmost-first)\n    /// so that it always finds the longest possible match (which corresponds\n    /// to the leftmost starting position). It is also compiled as an anchored\n    /// matcher and has 'starts_for_each_pattern' enabled. Including starting\n    /// states for each pattern is necessary to ensure that we only look for\n    /// matches of a pattern that matched in the forward direction. Otherwise,\n    /// we might wind up finding the \"leftmost\" starting position of a totally\n    /// different pattern!\n    reverse: DFA,\n}\n#[derive(Clone, Debug)]\npub struct DFA {\n    config: Config,\n    nfa: thompson::NFA,\n    stride2: usize,\n    start_map: StartByteMap,\n    classes: ByteClasses,\n    quitset: ByteSet,\n    cache_capacity: usize,\n}\n#[derive(Clone)]\npub struct Input<'h> {\n    haystack: &'h [u8],\n    span: Span,\n    anchored: Anchored,\n    earliest: bool,\n}\n#[derive(Clone, Copy, Debug, Eq, Hash, PartialEq)]\npub struct HalfMatch {\n    /// The pattern ID.\n    pattern: PatternID,\n    /// The offset of the match.\n    ///\n    /// For forward searches, the offset is exclusive. For reverse searches,\n    /// the offset is inclusive.\n    offset: usize,\n}\n#[derive(Clone)]\npub struct DFA<T> {\n    tt: Transitions<T>,\n    st: StartTable<T>,\n    special: Special,\n    pre: Option<Prefilter>,\n    quitset: ByteSet,\n    flags: Flags,\n}\n#[derive(Clone, Copy, Default, Eq, Hash, PartialEq, PartialOrd, Ord)]\n#[repr(transparent)]\npub struct PatternID(SmallIndex);\n#[derive(Debug, Clone)]\npub struct Cache {\n    forward: dfa::Cache,\n    reverse: dfa::Cache,\n}\n#[derive(Clone, Debug)]\npub struct Cache {\n    /// The transition table.\n    ///\n    /// Given a `current` LazyStateID and an `input` byte, the next state can\n    /// be computed via `trans[untagged(current) + equiv_class(input)]`. Notice\n    /// that no multiplication is used. That's because state identifiers are\n    /// \"premultiplied.\"\n    ///\n    /// Note that the next state may be the \"unknown\" state. In this case, the\n    /// next state is not known and determinization for `current` on `input`\n    /// must be performed.\n    trans: Vec<LazyStateID>,\n    /// The starting states for this DFA.\n    ///\n    /// These are computed lazily. Initially, these are all set to \"unknown\"\n    /// lazy state IDs.\n    ///\n    /// When 'starts_for_each_pattern' is disabled (the default), then the size\n    /// of this is constrained to the possible starting configurations based\n    /// on the search parameters. (At time of writing, that's 4.) However,\n    /// when starting states for each pattern is enabled, then there are N\n    /// additional groups of starting states, where each group reflects the\n    /// different possible configurations and N is the number of patterns.\n    starts: Vec<LazyStateID>,\n    /// A sequence of NFA/DFA powerset states that have been computed for this\n    /// lazy DFA. This sequence is indexable by untagged LazyStateIDs. (Every\n    /// tagged LazyStateID can be used to index this sequence by converting it\n    /// to its untagged form.)\n    states: Vec<State>,\n    /// A map from states to their corresponding IDs. This map may be accessed\n    /// via the raw byte representation of a state, which means that a `State`\n    /// does not need to be allocated to determine whether it already exists\n    /// in this map. Indeed, the existence of such a state is what determines\n    /// whether we allocate a new `State` or not.\n    ///\n    /// The higher level idea here is that we do just enough determinization\n    /// for a state to check whether we've already computed it. If we have,\n    /// then we can save a little (albeit not much) work. The real savings is\n    /// in memory usage. If we never checked for trivially duplicate states,\n    /// then our memory usage would explode to unreasonable levels.\n    states_to_id: StateMap,\n    /// Sparse sets used to track which NFA states have been visited during\n    /// various traversals.\n    sparses: SparseSets,\n    /// Scratch space for traversing the NFA graph. (We use space on the heap\n    /// instead of the call stack.)\n    stack: Vec<NFAStateID>,\n    /// Scratch space for building a NFA/DFA powerset state. This is used to\n    /// help amortize allocation since not every powerset state generated is\n    /// added to the cache. In particular, if it already exists in the cache,\n    /// then there is no need to allocate a new `State` for it.\n    scratch_state_builder: StateBuilderEmpty,\n    /// A simple abstraction for handling the saving of at most a single state\n    /// across a cache clearing. This is required for correctness. Namely, if\n    /// adding a new state after clearing the cache fails, then the caller\n    /// must retain the ability to continue using the state ID given. The\n    /// state corresponding to the state ID is what we preserve across cache\n    /// clearings.\n    state_saver: StateSaver,\n    /// The memory usage, in bytes, used by 'states' and 'states_to_id'. We\n    /// track this as new states are added since states use a variable amount\n    /// of heap. Tracking this as we add states makes it possible to compute\n    /// the total amount of memory used by the determinizer in constant time.\n    memory_usage_state: usize,\n    /// The number of times the cache has been cleared. When a minimum cache\n    /// clear count is set, then the cache will return an error instead of\n    /// clearing the cache if the count has been exceeded.\n    clear_count: usize,\n    /// The total number of bytes searched since the last time this cache was\n    /// cleared, not including the current search.\n    ///\n    /// This can be added to the length of the current search to get the true\n    /// total number of bytes searched.\n    ///\n    /// This is generally only non-zero when the\n    /// `Cache::search_{start,update,finish}` APIs are used to track search\n    /// progress.\n    bytes_searched: usize,\n    /// The progress of the current search.\n    ///\n    /// This is only non-`None` when callers utlize the `Cache::search_start`,\n    /// `Cache::search_update` and `Cache::search_finish` APIs.\n    ///\n    /// The purpose of recording search progress is to be able to make a\n    /// determination about the efficiency of the cache. Namely, by keeping\n    /// track of the\n    progress: Option<SearchProgress>,\n}\n#[derive(Clone, Debug, Eq, PartialEq)]\npub struct MatchError(\n    #[cfg(feature = \"alloc\")]\n    alloc::boxed::Box<MatchErrorKind>,\n    #[cfg(not(feature = \"alloc\"))]\n    MatchErrorKind,\n);\n#[derive(Clone)]\npub struct DFA<T> {\n    /// The transition table for this DFA. This includes the transitions\n    /// themselves, along with the stride, number of states and the equivalence\n    /// class mapping.\n    tt: TransitionTable<T>,\n    /// The set of starting state identifiers for this DFA. The starting state\n    /// IDs act as pointers into the transition table. The specific starting\n    /// state chosen for each search is dependent on the context at which the\n    /// search begins.\n    st: StartTable<T>,\n    /// The set of match states and the patterns that match for each\n    /// corresponding match state.\n    ///\n    /// This structure is technically only needed because of support for\n    /// multi-regexes. Namely, multi-regexes require answering not just whether\n    /// a match exists, but _which_ patterns match. So we need to store the\n    /// matching pattern IDs for each match state. We do this even when there\n    /// is only one pattern for the sake of simplicity. In practice, this uses\n    /// up very little space for the case of one pattern.\n    ms: MatchStates<T>,\n    /// Information about which states are \"special.\" Special states are states\n    /// that are dead, quit, matching, starting or accelerated. For more info,\n    /// see the docs for `Special`.\n    special: Special,\n    /// The accelerators for this DFA.\n    ///\n    /// If a state is accelerated, then there exist only a small number of\n    /// bytes that can cause the DFA to leave the state. This permits searching\n    /// to use optimized routines to find those specific bytes instead of using\n    /// the transition table.\n    ///\n    /// All accelerated states exist in a contiguous range in the DFA's\n    /// transition table. See dfa/special.rs for more details on how states are\n    /// arranged.\n    accels: Accels<T>,\n    /// Any prefilter attached to this DFA.\n    ///\n    /// Note that currently prefilters are not serialized. When deserializing\n    /// a DFA from bytes, this is always set to `None`.\n    pre: Option<Prefilter>,\n    /// The set of \"quit\" bytes for this DFA.\n    ///\n    /// This is only used when computing the start state for a particular\n    /// position in a haystack. Namely, in the case where there is a quit\n    /// byte immediately before the start of the search, this set needs to be\n    /// explicitly consulted. In all other cases, quit bytes are detected by\n    /// the DFA itself, by transitioning all quit bytes to a special \"quit\n    /// state.\"\n    quitset: ByteSet,\n    /// Various flags describing the behavior of this DFA.\n    flags: Flags,\n}\n#[derive(Clone, Copy, Debug, Eq, Hash, PartialEq)]\npub struct Match {\n    /// The pattern ID.\n    pattern: PatternID,\n    /// The underlying match span.\n    span: Span,\n}\n#[derive(Clone)]\npub struct DFA {\n    /// The configuration provided by the caller.\n    config: Config,\n    /// The NFA used to build this DFA.\n    ///\n    /// NOTE: We probably don't need to store the NFA here, but we use enough\n    /// bits from it that it's convenient to do so. And there really isn't much\n    /// cost to doing so either, since an NFA is reference counted internally.\n    nfa: NFA,\n    /// The transition table. Given a state ID 's' and a byte of haystack 'b',\n    /// the next state is `table[sid + classes[byte]]`.\n    ///\n    /// The stride of this table (i.e., the number of columns) is always\n    /// a power of 2, even if the alphabet length is smaller. This makes\n    /// converting between state IDs and state indices very cheap.\n    ///\n    /// Note that the stride always includes room for one extra \"transition\"\n    /// that isn't actually a transition. It is a 'PatternEpsilons' that is\n    /// used for match states only. Because of this, the maximum number of\n    /// active columns in the transition table is 257, which means the maximum\n    /// stride is 512 (the next power of 2 greater than or equal to 257).\n    table: Vec<Transition>,\n    /// The DFA state IDs of the starting states.\n    ///\n    /// `starts[0]` is always present and corresponds to the starting state\n    /// when searching for matches of any pattern in the DFA.\n    ///\n    /// `starts[i]` where i>0 corresponds to the starting state for the pattern\n    /// ID 'i-1'. These starting states are optional.\n    starts: Vec<StateID>,\n    /// Every state ID >= this value corresponds to a match state.\n    ///\n    /// This is what a search uses to detect whether a state is a match state\n    /// or not. It requires only a simple comparison instead of bit-unpacking\n    /// the PatternEpsilons from every state.\n    min_match_id: StateID,\n    /// The alphabet of this DFA, split into equivalence classes. Bytes in the\n    /// same equivalence class can never discriminate between a match and a\n    /// non-match.\n    classes: ByteClasses,\n    /// The number of elements in each state in the transition table. This may\n    /// be less than the stride, since the stride is always a power of 2 and\n    /// the alphabet length can be anything up to and including 256.\n    alphabet_len: usize,\n    /// The number of columns in the transition table, expressed as a power of\n    /// 2.\n    stride2: usize,\n    /// The offset at which the PatternEpsilons for a match state is stored in\n    /// the transition table.\n    ///\n    /// PERF: One wonders whether it would be better to put this in a separate\n    /// allocation, since only match states have a non-empty PatternEpsilons\n    /// and the number of match states tends be dwarfed by the number of\n    /// non-match states. So this would save '8*len(non_match_states)' for each\n    /// DFA. The question is whether moving this to a different allocation will\n    /// lead to a perf hit during searches. You might think dealing with match\n    /// states is rare, but some regexes spend a lot of time in match states\n    /// gobbling up input. But... match state handling is already somewhat\n    /// expensive, so maybe this wouldn't do much? Either way, it's worth\n    /// experimenting.\n    pateps_offset: usize,\n    /// The first explicit slot index. This refers to the first slot appearing\n    /// immediately after the last implicit slot. It is always 'patterns.len()\n    /// * 2'.\n    ///\n    /// We record this because we only store the explicit slots in our DFA\n    /// transition table that need to be saved. Implicit slots are handled\n    /// automatically as part of the search.\n    explicit_slot_start: usize,\n}\n#[derive(Debug)]\npub(crate) struct DFA(Option<DFAEngine>);\n#[derive(Clone, Copy, Debug, Eq, PartialEq)]\npub enum Anchored {\n    /// Run an unanchored search. This means a match may occur anywhere at or\n    /// after the start position of the search.\n    ///\n    /// This search can return a match for any pattern in the regex.\n    No,\n    /// Run an anchored search. This means that a match must begin at the\n    /// start position of the search.\n    ///\n    /// This search can return a match for any pattern in the regex.\n    Yes,\n    /// Run an anchored search for a specific pattern. This means that a match\n    /// must be for the given pattern and must begin at the start position of\n    /// the search.\n    Pattern(PatternID),\n}\nimpl Regex {\n    #[inline]\n    pub fn try_search(\n        &self,\n        cache: &mut Cache,\n        input: &Input<'_>,\n    ) -> Result<Option<Match>, MatchError> {\n        let (fcache, rcache) = (&mut cache.forward, &mut cache.reverse);\n        let end = match self.forward().try_search_fwd(fcache, input)? {\n            None => return Ok(None),\n            Some(end) => end,\n        };\n        if input.start() == end.offset() {\n            return Ok(Some(Match::new(end.pattern(), end.offset()..end.offset())));\n        }\n        if self.is_anchored(input) {\n            return Ok(Some(Match::new(end.pattern(), input.start()..end.offset())));\n        }\n        let revsearch = input\n            .clone()\n            .span(input.start()..end.offset())\n            .anchored(Anchored::Yes)\n            .earliest(false);\n        let start = self\n            .reverse()\n            .try_search_rev(rcache, &revsearch)?\n            .expect(\"reverse search must match if forward search does\");\n        debug_assert_eq!(\n            start.pattern(), end.pattern(),\n            \"forward and reverse search must match same pattern\",\n        );\n        debug_assert!(start.offset() <= end.offset());\n        Ok(Some(Match::new(end.pattern(), start.offset()..end.offset())))\n    }\n    fn is_anchored(&self, input: &Input<'_>) -> bool {\n        match input.get_anchored() {\n            Anchored::No => self.forward().get_nfa().is_always_start_anchored(),\n            Anchored::Yes | Anchored::Pattern(_) => true,\n        }\n    }\n}\nimpl DFA {\n    #[inline]\n    pub fn try_search_fwd(\n        &self,\n        cache: &mut Cache,\n        input: &Input<'_>,\n    ) -> Result<Option<HalfMatch>, MatchError> {\n        let utf8empty = self.get_nfa().has_empty() && self.get_nfa().is_utf8();\n        let hm = match search::find_fwd(self, cache, input)? {\n            None => return Ok(None),\n            Some(hm) if !utf8empty => return Ok(Some(hm)),\n            Some(hm) => hm,\n        };\n        empty::skip_splits_fwd(\n            input,\n            hm,\n            hm.offset(),\n            |input| {\n                let got = search::find_fwd(self, cache, input)?;\n                Ok(got.map(|hm| (hm, hm.offset())))\n            },\n        )\n    }\n    #[inline]\n    pub fn try_search_rev(\n        &self,\n        cache: &mut Cache,\n        input: &Input<'_>,\n    ) -> Result<Option<HalfMatch>, MatchError> {\n        let utf8empty = self.get_nfa().has_empty() && self.get_nfa().is_utf8();\n        let hm = match search::find_rev(self, cache, input)? {\n            None => return Ok(None),\n            Some(hm) if !utf8empty => return Ok(Some(hm)),\n            Some(hm) => hm,\n        };\n        empty::skip_splits_rev(\n            input,\n            hm,\n            hm.offset(),\n            |input| {\n                let got = search::find_rev(self, cache, input)?;\n                Ok(got.map(|hm| (hm, hm.offset())))\n            },\n        )\n    }\n    #[inline]\n    pub fn try_search_overlapping_fwd(\n        &self,\n        cache: &mut Cache,\n        input: &Input<'_>,\n        state: &mut OverlappingState,\n    ) -> Result<(), MatchError> {}\n    #[inline]\n    pub fn try_search_overlapping_rev(\n        &self,\n        cache: &mut Cache,\n        input: &Input<'_>,\n        state: &mut OverlappingState,\n    ) -> Result<(), MatchError> {}\n    #[inline]\n    pub fn try_which_overlapping_matches(\n        &self,\n        cache: &mut Cache,\n        input: &Input<'_>,\n        patset: &mut PatternSet,\n    ) -> Result<(), MatchError> {}\n}\nimpl<'h> Input<'h> {\n    #[inline]\n    pub fn new<H: ?Sized + AsRef<[u8]>>(haystack: &'h H) -> Input<'h> {}\n    #[inline]\n    pub fn span<S: Into<Span>>(mut self, span: S) -> Input<'h> {}\n    #[inline]\n    pub fn range<R: RangeBounds<usize>>(mut self, range: R) -> Input<'h> {}\n    #[inline]\n    pub fn anchored(mut self, mode: Anchored) -> Input<'h> {\n        self.set_anchored(mode);\n        self\n    }\n    #[inline]\n    pub fn earliest(mut self, yes: bool) -> Input<'h> {\n        self.set_earliest(yes);\n        self\n    }\n    #[inline]\n    pub fn set_span<S: Into<Span>>(&mut self, span: S) {}\n    #[inline]\n    pub fn set_range<R: RangeBounds<usize>>(&mut self, range: R) {}\n    #[inline]\n    pub fn set_start(&mut self, start: usize) {}\n    #[inline]\n    pub fn set_end(&mut self, end: usize) {}\n    #[inline]\n    pub fn set_anchored(&mut self, mode: Anchored) {}\n    #[inline]\n    pub fn set_earliest(&mut self, yes: bool) {}\n    #[inline]\n    pub fn haystack(&self) -> &[u8] {}\n    #[inline]\n    pub fn start(&self) -> usize {\n        self.get_span().start\n    }\n    #[inline]\n    pub fn end(&self) -> usize {}\n    #[inline]\n    pub fn get_span(&self) -> Span {}\n    #[inline]\n    pub fn get_range(&self) -> Range<usize> {}\n    #[inline]\n    pub fn get_anchored(&self) -> Anchored {}\n    #[inline]\n    pub fn get_earliest(&self) -> bool {}\n    #[inline]\n    pub fn is_done(&self) -> bool {}\n    #[inline]\n    pub fn is_char_boundary(&self, offset: usize) -> bool {}\n}\nimpl HalfMatch {\n    #[inline]\n    pub fn new(pattern: PatternID, offset: usize) -> HalfMatch {}\n    #[inline]\n    pub fn must(pattern: usize, offset: usize) -> HalfMatch {}\n    #[inline]\n    pub fn pattern(&self) -> PatternID {\n        self.pattern\n    }\n    #[inline]\n    pub fn offset(&self) -> usize {\n        self.offset\n    }\n}\n\nThe function to be tested is presented with each line formatted as 'line number + code':\n/// Returns the start and end offset of the leftmost match. If no match\n/// exists, then `None` is returned.\n///\n/// This is like [`Regex::find`] but with two differences:\n///\n/// 1. It is not generic over `Into<Input>` and instead accepts a\n/// `&Input`. This permits reusing the same `Input` for multiple searches\n/// without needing to create a new one. This _may_ help with latency.\n/// 2. It returns an error if the search could not complete where as\n/// [`Regex::find`] will panic.\n///\n/// # Errors\n///\n/// This routine errors if the search could not complete. This can occur\n/// in a number of circumstances:\n///\n/// * The configuration of the lazy DFA may permit it to \"quit\" the search.\n/// For example, setting quit bytes or enabling heuristic support for\n/// Unicode word boundaries. The default configuration does not enable any\n/// option that could result in the lazy DFA quitting.\n/// * The configuration of the lazy DFA may also permit it to \"give up\"\n/// on a search if it makes ineffective use of its transition table\n/// cache. The default configuration does not enable this by default,\n/// although it is typically a good idea to.\n/// * When the provided `Input` configuration is not supported. For\n/// example, by providing an unsupported anchor mode.\n///\n/// When a search returns an error, callers cannot know whether a match\n/// exists or not.\n442 pub fn try_search(\n443     &self,\n444     cache: &mut Cache,\n445     input: &Input<'_>,\n446 ) -> Result<Option<Match>, MatchError> {\n447     let (fcache, rcache) = (&mut cache.forward, &mut cache.reverse);\n448     let end = match self.forward().try_search_fwd(fcache, input)? {\n449         None => return Ok(None),\n450         Some(end) => end,\n451     };\n452     // This special cases an empty match at the beginning of the search. If\n453     // our end matches our start, then since a reverse DFA can't match past\n454     // the start, it must follow that our starting position is also our end\n455     // position. So short circuit and skip the reverse search.\n456     if input.start() == end.offset() {\n457         return Ok(Some(Match::new(\n458             end.pattern(),\n459             end.offset()..end.offset(),\n460         )));\n461     }\n462     // We can also skip the reverse search if we know our search was\n463     // anchored. This occurs either when the input config is anchored or\n464     // when we know the regex itself is anchored. In this case, we know the\n465     // start of the match, if one is found, must be the start of the\n466     // search.\n467     if self.is_anchored(input) {\n468         return Ok(Some(Match::new(\n469             end.pattern(),\n470             input.start()..end.offset(),\n471         )));\n472     }\n473     // N.B. I have tentatively convinced myself that it isn't necessary\n474     // to specify the specific pattern for the reverse search since the\n475     // reverse search will always find the same pattern to match as the\n476     // forward search. But I lack a rigorous proof. Why not just provide\n477     // the pattern anyway? Well, if it is needed, then leaving it out\n478     // gives us a chance to find a witness. (Also, if we don't need to\n479     // specify the pattern, then we don't need to build the reverse DFA\n480     // with 'starts_for_each_pattern' enabled. It doesn't matter too much\n481     // for the lazy DFA, but does make the overall DFA bigger.)\n482     //\n483     // We also need to be careful to disable 'earliest' for the reverse\n484     // search, since it could be enabled for the forward search. In the\n485     // reverse case, to satisfy \"leftmost\" criteria, we need to match as\n486     // much as we can. We also need to be careful to make the search\n487     // anchored. We don't want the reverse search to report any matches\n488     // other than the one beginning at the end of our forward search.\n489     let revsearch = input\n490         .clone()\n491         .span(input.start()..end.offset())\n492         .anchored(Anchored::Yes)\n493         .earliest(false);\n494     let start = self\n495         .reverse()\n496         .try_search_rev(rcache, &revsearch)?\n497         .expect(\"reverse search must match if forward search does\");\n498     debug_assert_eq!(\n499         start.pattern(),\n500         end.pattern(),\n501         \"forward and reverse search must match same pattern\",\n502     );\n503     debug_assert!(start.offset() <= end.offset());\n504     Ok(Some(Match::new(end.pattern(), start.offset()..end.offset())))\n505 }\n\nThe path conditions that the generated test functions should satisfy are as follows:\n"
}