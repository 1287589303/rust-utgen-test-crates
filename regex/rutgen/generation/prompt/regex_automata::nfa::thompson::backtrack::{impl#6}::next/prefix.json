{
  "system_pt": "As a software testing expert, please generate Rust test functions based on the following guidelines, focusing solely on constructing test inputs and calling the functions under test:\n1. Provide the code in plain text format, without explanations or Markdown.\n2. If the method under test belongs to a trait, construct appropriate structs within the test function, but avoid method overrides. If the method under test uses generics, instantiate them with suitable types based on the context.\n3. Generate test code with minimal scope: avoid creating external structures or implementations. Instead, define any necessary helper structures or implementations directly within the test function when required.\n4. Whenever possible, initialize the corresponding data structures using the initialization methods provided in the context.\n5. Ensure the generated function is fully implemented and can be compiled and executed directly without any missing parts.\n6. Create a minimal yet complete set of test functions, ensuring they adhere to all provided preconditions and cover boundary conditions, and reference the inferred test input conditions or ranges.\n7. Ensure the test inputs are designed to cover the inferred test input conditions or ranges as comprehensively as possible, with particular emphasis on boundary cases.\n8. Focus on crafting test inputs that effectively reveal potential bugs while meeting the specified requirements.\n9. Omit test oracles and assertions; concentrate on generating test inputs and function calls.\n10. Do not create a test module, but include intrinsic attributes like #[test] or #[should_panic] where necessary.\n",
  "static_pt": "The context for the focal function is as follows:\n// regex-automata/src/nfa/thompson/backtrack.rs\n// crate name is regex_automata\nuse alloc::{vec, vec::Vec};\nuse crate::{\n    nfa::thompson::{self, BuildError, State, NFA},\n    util::{\n        captures::Captures, empty, iter, prefilter::Prefilter,\n        primitives::{NonMaxUsize, PatternID, SmallIndex, StateID},\n        search::{Anchored, HalfMatch, Input, Match, MatchError, Span},\n    },\n};\n#[derive(Debug)]\npub struct TryCapturesMatches<'r, 'c, 'h> {\n    re: &'r BoundedBacktracker,\n    cache: &'c mut Cache,\n    caps: Captures,\n    it: iter::Searcher<'h>,\n}\n#[derive(Clone)]\npub struct Captures {\n    /// The group info that these capture groups are coupled to. This is what\n    /// gives the \"convenience\" of the `Captures` API. Namely, it provides the\n    /// slot mapping and the name|-->index mapping for capture lookups by name.\n    group_info: GroupInfo,\n    /// The ID of the pattern that matched. Regex engines must set this to\n    /// None when no match occurs.\n    pid: Option<PatternID>,\n    /// The slot values, i.e., submatch offsets.\n    ///\n    /// In theory, the smallest sequence of slots would be something like\n    /// `max(groups(pattern) for pattern in regex) * 2`, but instead, we use\n    /// `sum(groups(pattern) for pattern in regex) * 2`. Why?\n    ///\n    /// Well, the former could be used in theory, because we don't generally\n    /// have any overlapping APIs that involve capturing groups. Therefore,\n    /// there's technically never any need to have slots set for multiple\n    /// patterns. However, this might change some day, in which case, we would\n    /// need to have slots available.\n    ///\n    /// The other reason is that during the execution of some regex engines,\n    /// there exists a point in time where multiple slots for different\n    /// patterns may be written to before knowing which pattern has matched.\n    /// Therefore, the regex engines themselves, in order to support multiple\n    /// patterns correctly, must have all slots available. If `Captures`\n    /// doesn't have all slots available, then regex engines can't write\n    /// directly into the caller provided `Captures` and must instead write\n    /// into some other storage and then copy the slots involved in the match\n    /// at the end of the search.\n    ///\n    /// So overall, at least as of the time of writing, it seems like the path\n    /// of least resistance is to just require allocating all possible slots\n    /// instead of the conceptual minimum. Another way to justify this is that\n    /// the most common case is a single pattern, in which case, there is no\n    /// inefficiency here since the 'max' and 'sum' calculations above are\n    /// equivalent in that case.\n    ///\n    /// N.B. The mapping from group index to slot is maintained by `GroupInfo`\n    /// and is considered an API guarantee. See `GroupInfo` for more details on\n    /// that mapping.\n    ///\n    /// N.B. `Option<NonMaxUsize>` has the same size as a `usize`.\n    slots: Vec<Option<NonMaxUsize>>,\n}\n#[derive(Debug, Clone)]\npub struct Cache {\n    pub(crate) capmatches: Captures,\n    pub(crate) pikevm: wrappers::PikeVMCache,\n    pub(crate) backtrack: wrappers::BoundedBacktrackerCache,\n    pub(crate) onepass: wrappers::OnePassCache,\n    pub(crate) hybrid: wrappers::HybridCache,\n    pub(crate) revhybrid: wrappers::ReverseHybridCache,\n}\n#[derive(Debug)]\npub(crate) struct BoundedBacktracker(Option<BoundedBacktrackerEngine>);\n#[derive(Clone, Debug)]\npub struct Cache {\n    /// Scratch space used to store slots during a search. Basically, we use\n    /// the caller provided slots to store slots known when a match occurs.\n    /// But after a match occurs, we might continue a search but ultimately\n    /// fail to extend the match. When continuing the search, we need some\n    /// place to store candidate capture offsets without overwriting the slot\n    /// offsets recorded for the most recently seen match.\n    explicit_slots: Vec<Option<NonMaxUsize>>,\n    /// The number of slots in the caller-provided 'Captures' value for the\n    /// current search. This is always at most 'explicit_slots.len()', but\n    /// might be less than it, if the caller provided fewer slots to fill.\n    explicit_slot_len: usize,\n}\n#[derive(Clone, Debug)]\npub struct Cache {\n    /// Stack used on the heap for doing backtracking instead of the\n    /// traditional recursive approach. We don't want recursion because then\n    /// we're likely to hit a stack overflow for bigger regexes.\n    stack: Vec<Frame>,\n    /// The set of (StateID, HaystackOffset) pairs that have been visited\n    /// by the backtracker within a single search. If such a pair has been\n    /// visited, then we avoid doing the work for that pair again. This is\n    /// what \"bounds\" the backtracking and prevents it from having worst case\n    /// exponential time.\n    visited: Visited,\n}\n#[derive(Clone, Debug)]\npub struct Cache {\n    /// Stack used while computing epsilon closure. This effectively lets us\n    /// move what is more naturally expressed through recursion to a stack\n    /// on the heap.\n    stack: Vec<FollowEpsilon>,\n    /// The current active states being explored for the current byte in the\n    /// haystack.\n    curr: ActiveStates,\n    /// The next set of states we're building that will be explored for the\n    /// next byte in the haystack.\n    next: ActiveStates,\n}\n#[derive(Clone, Debug)]\npub struct Searcher<'h> {\n    /// The input parameters to give to each regex engine call.\n    ///\n    /// The start position of the search is mutated during iteration.\n    input: Input<'h>,\n    /// Records the end offset of the most recent match. This is necessary to\n    /// handle a corner case for preventing empty matches from overlapping with\n    /// the ending bounds of a prior match.\n    last_match_end: Option<usize>,\n}\n#[derive(Clone, Debug)]\npub struct Cache {\n    /// The transition table.\n    ///\n    /// Given a `current` LazyStateID and an `input` byte, the next state can\n    /// be computed via `trans[untagged(current) + equiv_class(input)]`. Notice\n    /// that no multiplication is used. That's because state identifiers are\n    /// \"premultiplied.\"\n    ///\n    /// Note that the next state may be the \"unknown\" state. In this case, the\n    /// next state is not known and determinization for `current` on `input`\n    /// must be performed.\n    trans: Vec<LazyStateID>,\n    /// The starting states for this DFA.\n    ///\n    /// These are computed lazily. Initially, these are all set to \"unknown\"\n    /// lazy state IDs.\n    ///\n    /// When 'starts_for_each_pattern' is disabled (the default), then the size\n    /// of this is constrained to the possible starting configurations based\n    /// on the search parameters. (At time of writing, that's 4.) However,\n    /// when starting states for each pattern is enabled, then there are N\n    /// additional groups of starting states, where each group reflects the\n    /// different possible configurations and N is the number of patterns.\n    starts: Vec<LazyStateID>,\n    /// A sequence of NFA/DFA powerset states that have been computed for this\n    /// lazy DFA. This sequence is indexable by untagged LazyStateIDs. (Every\n    /// tagged LazyStateID can be used to index this sequence by converting it\n    /// to its untagged form.)\n    states: Vec<State>,\n    /// A map from states to their corresponding IDs. This map may be accessed\n    /// via the raw byte representation of a state, which means that a `State`\n    /// does not need to be allocated to determine whether it already exists\n    /// in this map. Indeed, the existence of such a state is what determines\n    /// whether we allocate a new `State` or not.\n    ///\n    /// The higher level idea here is that we do just enough determinization\n    /// for a state to check whether we've already computed it. If we have,\n    /// then we can save a little (albeit not much) work. The real savings is\n    /// in memory usage. If we never checked for trivially duplicate states,\n    /// then our memory usage would explode to unreasonable levels.\n    states_to_id: StateMap,\n    /// Sparse sets used to track which NFA states have been visited during\n    /// various traversals.\n    sparses: SparseSets,\n    /// Scratch space for traversing the NFA graph. (We use space on the heap\n    /// instead of the call stack.)\n    stack: Vec<NFAStateID>,\n    /// Scratch space for building a NFA/DFA powerset state. This is used to\n    /// help amortize allocation since not every powerset state generated is\n    /// added to the cache. In particular, if it already exists in the cache,\n    /// then there is no need to allocate a new `State` for it.\n    scratch_state_builder: StateBuilderEmpty,\n    /// A simple abstraction for handling the saving of at most a single state\n    /// across a cache clearing. This is required for correctness. Namely, if\n    /// adding a new state after clearing the cache fails, then the caller\n    /// must retain the ability to continue using the state ID given. The\n    /// state corresponding to the state ID is what we preserve across cache\n    /// clearings.\n    state_saver: StateSaver,\n    /// The memory usage, in bytes, used by 'states' and 'states_to_id'. We\n    /// track this as new states are added since states use a variable amount\n    /// of heap. Tracking this as we add states makes it possible to compute\n    /// the total amount of memory used by the determinizer in constant time.\n    memory_usage_state: usize,\n    /// The number of times the cache has been cleared. When a minimum cache\n    /// clear count is set, then the cache will return an error instead of\n    /// clearing the cache if the count has been exceeded.\n    clear_count: usize,\n    /// The total number of bytes searched since the last time this cache was\n    /// cleared, not including the current search.\n    ///\n    /// This can be added to the length of the current search to get the true\n    /// total number of bytes searched.\n    ///\n    /// This is generally only non-zero when the\n    /// `Cache::search_{start,update,finish}` APIs are used to track search\n    /// progress.\n    bytes_searched: usize,\n    /// The progress of the current search.\n    ///\n    /// This is only non-`None` when callers utlize the `Cache::search_start`,\n    /// `Cache::search_update` and `Cache::search_finish` APIs.\n    ///\n    /// The purpose of recording search progress is to be able to make a\n    /// determination about the efficiency of the cache. Namely, by keeping\n    /// track of the\n    progress: Option<SearchProgress>,\n}\n#[derive(Clone, Debug)]\npub struct BoundedBacktracker {\n    config: Config,\n    nfa: NFA,\n}\n#[derive(Debug, Clone)]\npub struct Cache {\n    forward: dfa::Cache,\n    reverse: dfa::Cache,\n}\n#[derive(Clone, Debug, Eq, PartialEq)]\npub struct MatchError(\n    #[cfg(feature = \"alloc\")]\n    alloc::boxed::Box<MatchErrorKind>,\n    #[cfg(not(feature = \"alloc\"))]\n    MatchErrorKind,\n);\n#[derive(Clone, Copy, Debug, Eq, Hash, PartialEq)]\npub struct Match {\n    /// The pattern ID.\n    pattern: PatternID,\n    /// The underlying match span.\n    span: Span,\n}\nimpl<'r, 'c, 'h> Iterator for TryCapturesMatches<'r, 'c, 'h> {\n    type Item = Result<Captures, MatchError>;\n    #[inline]\n    fn next(&mut self) -> Option<Result<Captures, MatchError>> {\n        let TryCapturesMatches { re, ref mut cache, ref mut caps, ref mut it } = *self;\n        let _ = it\n            .try_advance(|input| {\n                re.try_search(cache, input, caps)?;\n                Ok(caps.get_match())\n            })\n            .transpose()?;\n        if caps.is_match() { Some(Ok(caps.clone())) } else { None }\n    }\n}\nimpl Captures {\n    pub fn all(group_info: GroupInfo) -> Captures {}\n    pub fn matches(group_info: GroupInfo) -> Captures {}\n    pub fn empty(group_info: GroupInfo) -> Captures {}\n    #[inline]\n    pub fn is_match(&self) -> bool {\n        self.pid.is_some()\n    }\n    #[inline]\n    pub fn pattern(&self) -> Option<PatternID> {}\n    #[inline]\n    pub fn get_match(&self) -> Option<Match> {}\n    #[inline]\n    pub fn get_group(&self, index: usize) -> Option<Span> {}\n    pub fn get_group_by_name(&self, name: &str) -> Option<Span> {}\n    pub fn iter(&self) -> CapturesPatternIter<'_> {}\n    pub fn group_len(&self) -> usize {}\n    pub fn group_info(&self) -> &GroupInfo {}\n    pub fn interpolate_string(&self, haystack: &str, replacement: &str) -> String {}\n    pub fn interpolate_string_into(\n        &self,\n        haystack: &str,\n        replacement: &str,\n        dst: &mut String,\n    ) {}\n    pub fn interpolate_bytes(&self, haystack: &[u8], replacement: &[u8]) -> Vec<u8> {}\n    pub fn interpolate_bytes_into(\n        &self,\n        haystack: &[u8],\n        replacement: &[u8],\n        dst: &mut Vec<u8>,\n    ) {}\n    pub fn extract<'h, const N: usize>(\n        &self,\n        haystack: &'h str,\n    ) -> (&'h str, [&'h str; N]) {}\n    pub fn extract_bytes<'h, const N: usize>(\n        &self,\n        haystack: &'h [u8],\n    ) -> (&'h [u8], [&'h [u8]; N]) {}\n}\n\nThe function to be tested is presented with each line formatted as 'line number + code':\n1621 fn next(&mut self) -> Option<Result<Captures, MatchError>> {\n1622     // Splitting 'self' apart seems necessary to appease borrowck.\n1623     let TryCapturesMatches { re, ref mut cache, ref mut caps, ref mut it } =\n1624         *self;\n1625     let _ = it\n1626         .try_advance(|input| {\n1627             re.try_search(cache, input, caps)?;\n1628             Ok(caps.get_match())\n1629         })\n1630         .transpose()?;\n1631     if caps.is_match() {\n1632         Some(Ok(caps.clone()))\n1633     } else {\n1634         None\n1635     }\n1636 }\n\nGenerate each test function in such a manner that it concurrently satisfies all the following preconditions:\n",
  "depend_pt": ""
}