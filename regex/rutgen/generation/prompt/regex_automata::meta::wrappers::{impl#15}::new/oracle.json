{
  "system_pt": "As a software testing expert, please generate accurate test oracles code based on the provided information. Follow these guidelines:\n1. Generate executable test oracle codes in plain text format, one per line. Do not output complete test functions, avoid additional explanations, and do not use Markdown.\n2. Combine the given function under test, context, relevant documentation, preconditions, expected return values or types, test input conditions or ranges, and existing test function prefixes to infer and generate corresponding test oracles code.\n3. Only generate necessary test oracles to ensure comprehensive validation.\n",
  "static_pt": "The context for the focal function is as follows:\n// regex-automata/src/meta/wrappers.rs\n// crate name is regex_automata\nuse alloc::vec::Vec;\nuse crate::{\n    meta::{\n        error::{BuildError, RetryError, RetryFailError},\n        regex::RegexInfo,\n    },\n    nfa::thompson::{pikevm, NFA},\n    util::{prefilter::Prefilter, primitives::NonMaxUsize},\n    HalfMatch, Input, Match, MatchKind, PatternID, PatternSet,\n};\n#[cfg(feature = \"dfa-build\")]\nuse crate::dfa;\n#[cfg(feature = \"dfa-onepass\")]\nuse crate::dfa::onepass;\n#[cfg(feature = \"hybrid\")]\nuse crate::hybrid;\n#[cfg(feature = \"nfa-backtrack\")]\nuse crate::nfa::thompson::backtrack;\n#[derive(Debug)]\npub(crate) struct ReverseHybridEngine(\n    #[cfg(feature = \"hybrid\")]\n    hybrid::dfa::DFA,\n    #[cfg(not(feature = \"hybrid\"))]\n    (),\n);\n#[derive(Clone, Debug, Default)]\npub struct Config {\n    match_kind: Option<MatchKind>,\n    pre: Option<Option<Prefilter>>,\n    starts_for_each_pattern: Option<bool>,\n    byte_classes: Option<bool>,\n    unicode_word_boundary: Option<bool>,\n    quitset: Option<ByteSet>,\n    specialize_start_states: Option<bool>,\n    cache_capacity: Option<usize>,\n    skip_cache_capacity_check: Option<bool>,\n    minimum_cache_clear_count: Option<Option<usize>>,\n    minimum_bytes_per_state: Option<Option<usize>>,\n}\n#[derive(Clone, Debug, Default)]\npub struct Config {\n    match_kind: Option<MatchKind>,\n    utf8_empty: Option<bool>,\n    autopre: Option<bool>,\n    pre: Option<Option<Prefilter>>,\n    which_captures: Option<WhichCaptures>,\n    nfa_size_limit: Option<Option<usize>>,\n    onepass_size_limit: Option<Option<usize>>,\n    hybrid_cache_capacity: Option<usize>,\n    hybrid: Option<bool>,\n    dfa: Option<bool>,\n    dfa_size_limit: Option<Option<usize>>,\n    dfa_state_limit: Option<Option<usize>>,\n    onepass: Option<bool>,\n    backtrack: Option<bool>,\n    byte_classes: Option<bool>,\n    line_terminator: Option<u8>,\n}\n#[derive(Clone, Debug)]\npub(crate) struct RegexInfo(Arc<RegexInfoI>);\n#[derive(Clone, Debug)]\npub struct Builder {\n    config: Config,\n    #[cfg(feature = \"syntax\")]\n    thompson: thompson::Compiler,\n}\n#[derive(Clone)]\npub struct DFA {\n    /// The configuration provided by the caller.\n    config: Config,\n    /// The NFA used to build this DFA.\n    ///\n    /// NOTE: We probably don't need to store the NFA here, but we use enough\n    /// bits from it that it's convenient to do so. And there really isn't much\n    /// cost to doing so either, since an NFA is reference counted internally.\n    nfa: NFA,\n    /// The transition table. Given a state ID 's' and a byte of haystack 'b',\n    /// the next state is `table[sid + classes[byte]]`.\n    ///\n    /// The stride of this table (i.e., the number of columns) is always\n    /// a power of 2, even if the alphabet length is smaller. This makes\n    /// converting between state IDs and state indices very cheap.\n    ///\n    /// Note that the stride always includes room for one extra \"transition\"\n    /// that isn't actually a transition. It is a 'PatternEpsilons' that is\n    /// used for match states only. Because of this, the maximum number of\n    /// active columns in the transition table is 257, which means the maximum\n    /// stride is 512 (the next power of 2 greater than or equal to 257).\n    table: Vec<Transition>,\n    /// The DFA state IDs of the starting states.\n    ///\n    /// `starts[0]` is always present and corresponds to the starting state\n    /// when searching for matches of any pattern in the DFA.\n    ///\n    /// `starts[i]` where i>0 corresponds to the starting state for the pattern\n    /// ID 'i-1'. These starting states are optional.\n    starts: Vec<StateID>,\n    /// Every state ID >= this value corresponds to a match state.\n    ///\n    /// This is what a search uses to detect whether a state is a match state\n    /// or not. It requires only a simple comparison instead of bit-unpacking\n    /// the PatternEpsilons from every state.\n    min_match_id: StateID,\n    /// The alphabet of this DFA, split into equivalence classes. Bytes in the\n    /// same equivalence class can never discriminate between a match and a\n    /// non-match.\n    classes: ByteClasses,\n    /// The number of elements in each state in the transition table. This may\n    /// be less than the stride, since the stride is always a power of 2 and\n    /// the alphabet length can be anything up to and including 256.\n    alphabet_len: usize,\n    /// The number of columns in the transition table, expressed as a power of\n    /// 2.\n    stride2: usize,\n    /// The offset at which the PatternEpsilons for a match state is stored in\n    /// the transition table.\n    ///\n    /// PERF: One wonders whether it would be better to put this in a separate\n    /// allocation, since only match states have a non-empty PatternEpsilons\n    /// and the number of match states tends be dwarfed by the number of\n    /// non-match states. So this would save '8*len(non_match_states)' for each\n    /// DFA. The question is whether moving this to a different allocation will\n    /// lead to a perf hit during searches. You might think dealing with match\n    /// states is rare, but some regexes spend a lot of time in match states\n    /// gobbling up input. But... match state handling is already somewhat\n    /// expensive, so maybe this wouldn't do much? Either way, it's worth\n    /// experimenting.\n    pateps_offset: usize,\n    /// The first explicit slot index. This refers to the first slot appearing\n    /// immediately after the last implicit slot. It is always 'patterns.len()\n    /// * 2'.\n    ///\n    /// We record this because we only store the explicit slots in our DFA\n    /// transition table that need to be saved. Implicit slots are handled\n    /// automatically as part of the search.\n    explicit_slot_start: usize,\n}\n#[derive(Clone, Debug)]\npub struct DFA {\n    config: Config,\n    nfa: thompson::NFA,\n    stride2: usize,\n    start_map: StartByteMap,\n    classes: ByteClasses,\n    quitset: ByteSet,\n    cache_capacity: usize,\n}\n#[derive(Clone, Debug)]\npub struct BuildError {\n    kind: BuildErrorKind,\n}\n#[derive(Clone)]\npub struct NFA(Arc<Inner>);\n#[derive(Debug)]\npub(crate) struct DFA(Option<DFAEngine>);\n#[derive(Clone, Debug)]\npub struct Prefilter {\n    #[cfg(not(feature = \"alloc\"))]\n    _unused: (),\n    #[cfg(feature = \"alloc\")]\n    pre: Arc<dyn PrefilterI>,\n    #[cfg(feature = \"alloc\")]\n    is_fast: bool,\n    #[cfg(feature = \"alloc\")]\n    max_needle_len: usize,\n}\n#[derive(Clone)]\npub struct DFA<T> {\n    /// The transition table for this DFA. This includes the transitions\n    /// themselves, along with the stride, number of states and the equivalence\n    /// class mapping.\n    tt: TransitionTable<T>,\n    /// The set of starting state identifiers for this DFA. The starting state\n    /// IDs act as pointers into the transition table. The specific starting\n    /// state chosen for each search is dependent on the context at which the\n    /// search begins.\n    st: StartTable<T>,\n    /// The set of match states and the patterns that match for each\n    /// corresponding match state.\n    ///\n    /// This structure is technically only needed because of support for\n    /// multi-regexes. Namely, multi-regexes require answering not just whether\n    /// a match exists, but _which_ patterns match. So we need to store the\n    /// matching pattern IDs for each match state. We do this even when there\n    /// is only one pattern for the sake of simplicity. In practice, this uses\n    /// up very little space for the case of one pattern.\n    ms: MatchStates<T>,\n    /// Information about which states are \"special.\" Special states are states\n    /// that are dead, quit, matching, starting or accelerated. For more info,\n    /// see the docs for `Special`.\n    special: Special,\n    /// The accelerators for this DFA.\n    ///\n    /// If a state is accelerated, then there exist only a small number of\n    /// bytes that can cause the DFA to leave the state. This permits searching\n    /// to use optimized routines to find those specific bytes instead of using\n    /// the transition table.\n    ///\n    /// All accelerated states exist in a contiguous range in the DFA's\n    /// transition table. See dfa/special.rs for more details on how states are\n    /// arranged.\n    accels: Accels<T>,\n    /// Any prefilter attached to this DFA.\n    ///\n    /// Note that currently prefilters are not serialized. When deserializing\n    /// a DFA from bytes, this is always set to `None`.\n    pre: Option<Prefilter>,\n    /// The set of \"quit\" bytes for this DFA.\n    ///\n    /// This is only used when computing the start state for a particular\n    /// position in a haystack. Namely, in the case where there is a quit\n    /// byte immediately before the start of the search, this set needs to be\n    /// explicitly consulted. In all other cases, quit bytes are detected by\n    /// the DFA itself, by transitioning all quit bytes to a special \"quit\n    /// state.\"\n    quitset: ByteSet,\n    /// Various flags describing the behavior of this DFA.\n    flags: Flags,\n}\n#[derive(Clone)]\npub struct DFA<T> {\n    tt: Transitions<T>,\n    st: StartTable<T>,\n    special: Special,\n    pre: Option<Prefilter>,\n    quitset: ByteSet,\n    flags: Flags,\n}\n#[non_exhaustive]\n#[derive(Clone, Copy, Debug, Eq, PartialEq)]\npub enum MatchKind {\n    /// Report all possible matches.\n    All,\n    /// Report only the leftmost matches. When multiple leftmost matches exist,\n    /// report the match corresponding to the part of the regex that appears\n    /// first in the syntax.\n    LeftmostFirst,\n}\nimpl ReverseHybridEngine {\n    pub(crate) fn new(info: &RegexInfo, nfarev: &NFA) -> Option<ReverseHybridEngine> {\n        #[cfg(feature = \"hybrid\")]\n        {\n            if !info.config().get_hybrid() {\n                return None;\n            }\n            let dfa_config = hybrid::dfa::Config::new()\n                .match_kind(MatchKind::All)\n                .prefilter(None)\n                .starts_for_each_pattern(false)\n                .byte_classes(info.config().get_byte_classes())\n                .unicode_word_boundary(true)\n                .specialize_start_states(false)\n                .cache_capacity(info.config().get_hybrid_cache_capacity())\n                .skip_cache_capacity_check(false)\n                .minimum_cache_clear_count(Some(3))\n                .minimum_bytes_per_state(Some(10));\n            let result = hybrid::dfa::Builder::new()\n                .configure(dfa_config)\n                .build_from_nfa(nfarev.clone());\n            let rev = match result {\n                Ok(rev) => rev,\n                Err(_err) => {\n                    debug!(\"lazy reverse DFA failed to build: {}\", _err);\n                    return None;\n                }\n            };\n            debug!(\"lazy reverse DFA built\");\n            Some(ReverseHybridEngine(rev))\n        }\n        #[cfg(not(feature = \"hybrid\"))] { None }\n    }\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    pub(crate) fn try_search_half_rev_limited(\n        &self,\n        cache: &mut ReverseHybridCache,\n        input: &Input<'_>,\n        min_start: usize,\n    ) -> Result<Option<HalfMatch>, RetryError> {}\n}\nimpl Config {\n    pub fn new() -> Config {\n        Config::default()\n    }\n    pub fn match_kind(mut self, kind: MatchKind) -> Config {\n        self.match_kind = Some(kind);\n        self\n    }\n    pub fn prefilter(mut self, pre: Option<Prefilter>) -> Config {\n        self.pre = Some(pre);\n        if self.specialize_start_states.is_none() {\n            self.specialize_start_states = Some(self.get_prefilter().is_some());\n        }\n        self\n    }\n    pub fn starts_for_each_pattern(mut self, yes: bool) -> Config {\n        self.starts_for_each_pattern = Some(yes);\n        self\n    }\n    pub fn byte_classes(mut self, yes: bool) -> Config {\n        self.byte_classes = Some(yes);\n        self\n    }\n    pub fn unicode_word_boundary(mut self, yes: bool) -> Config {\n        self.unicode_word_boundary = Some(yes);\n        self\n    }\n    pub fn quit(mut self, byte: u8, yes: bool) -> Config {}\n    pub fn specialize_start_states(mut self, yes: bool) -> Config {\n        self.specialize_start_states = Some(yes);\n        self\n    }\n    pub fn cache_capacity(mut self, bytes: usize) -> Config {\n        self.cache_capacity = Some(bytes);\n        self\n    }\n    pub fn skip_cache_capacity_check(mut self, yes: bool) -> Config {\n        self.skip_cache_capacity_check = Some(yes);\n        self\n    }\n    pub fn minimum_cache_clear_count(mut self, min: Option<usize>) -> Config {\n        self.minimum_cache_clear_count = Some(min);\n        self\n    }\n    pub fn minimum_bytes_per_state(mut self, min: Option<usize>) -> Config {\n        self.minimum_bytes_per_state = Some(min);\n        self\n    }\n    pub fn get_match_kind(&self) -> MatchKind {}\n    pub fn get_prefilter(&self) -> Option<&Prefilter> {}\n    pub fn get_starts_for_each_pattern(&self) -> bool {}\n    pub fn get_byte_classes(&self) -> bool {\n        self.byte_classes.unwrap_or(true)\n    }\n    pub fn get_unicode_word_boundary(&self) -> bool {}\n    pub fn get_quit(&self, byte: u8) -> bool {}\n    pub fn get_specialize_start_states(&self) -> bool {}\n    pub fn get_cache_capacity(&self) -> usize {}\n    pub fn get_skip_cache_capacity_check(&self) -> bool {}\n    pub fn get_minimum_cache_clear_count(&self) -> Option<usize> {}\n    pub fn get_minimum_bytes_per_state(&self) -> Option<usize> {}\n    pub fn get_minimum_cache_capacity(\n        &self,\n        nfa: &thompson::NFA,\n    ) -> Result<usize, BuildError> {}\n    fn byte_classes_from_nfa(&self, nfa: &thompson::NFA, quit: &ByteSet) -> ByteClasses {}\n    fn quit_set_from_nfa(&self, nfa: &thompson::NFA) -> Result<ByteSet, BuildError> {}\n    fn overwrite(&self, o: Config) -> Config {}\n}\nimpl RegexInfo {\n    fn new(config: Config, hirs: &[&Hir]) -> RegexInfo {}\n    pub(crate) fn config(&self) -> &Config {\n        &self.0.config\n    }\n    pub(crate) fn props(&self) -> &[hir::Properties] {}\n    pub(crate) fn props_union(&self) -> &hir::Properties {}\n    pub(crate) fn pattern_len(&self) -> usize {}\n    pub(crate) fn memory_usage(&self) -> usize {}\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    pub(crate) fn is_anchored_start(&self, input: &Input<'_>) -> bool {}\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    pub(crate) fn is_always_anchored_start(&self) -> bool {}\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    pub(crate) fn is_always_anchored_end(&self) -> bool {}\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    fn is_impossible(&self, input: &Input<'_>) -> bool {}\n}\nimpl Builder {\n    pub fn new() -> Builder {\n        Builder {\n            config: Config::default(),\n            #[cfg(feature = \"syntax\")]\n            thompson: thompson::Compiler::new(),\n        }\n    }\n    #[cfg(feature = \"syntax\")]\n    pub fn build(&self, pattern: &str) -> Result<DFA, BuildError> {}\n    #[cfg(feature = \"syntax\")]\n    pub fn build_many<P: AsRef<str>>(&self, patterns: &[P]) -> Result<DFA, BuildError> {}\n    pub fn build_from_nfa(&self, nfa: thompson::NFA) -> Result<DFA, BuildError> {\n        let quitset = self.config.quit_set_from_nfa(&nfa)?;\n        let classes = self.config.byte_classes_from_nfa(&nfa, &quitset);\n        let min_cache = minimum_cache_capacity(\n            &nfa,\n            &classes,\n            self.config.get_starts_for_each_pattern(),\n        );\n        let mut cache_capacity = self.config.get_cache_capacity();\n        if cache_capacity < min_cache {\n            if self.config.get_skip_cache_capacity_check() {\n                debug!(\n                    \"given capacity ({}) is too small, \\\n                     since skip_cache_capacity_check is enabled, \\\n                     setting cache capacity to minimum ({})\",\n                    cache_capacity, min_cache,\n                );\n                cache_capacity = min_cache;\n            } else {\n                return Err(\n                    BuildError::insufficient_cache_capacity(min_cache, cache_capacity),\n                );\n            }\n        }\n        if let Err(err) = minimum_lazy_state_id(&classes) {\n            return Err(BuildError::insufficient_state_id_capacity(err));\n        }\n        let stride2 = classes.stride2();\n        let start_map = StartByteMap::new(nfa.look_matcher());\n        Ok(DFA {\n            config: self.config.clone(),\n            nfa,\n            stride2,\n            start_map,\n            classes,\n            quitset,\n            cache_capacity,\n        })\n    }\n    pub fn configure(&mut self, config: Config) -> &mut Builder {\n        self.config = self.config.overwrite(config);\n        self\n    }\n    #[cfg(feature = \"syntax\")]\n    pub fn syntax(&mut self, config: crate::util::syntax::Config) -> &mut Builder {}\n    #[cfg(feature = \"syntax\")]\n    pub fn thompson(&mut self, config: thompson::Config) -> &mut Builder {}\n}\n\nThe function to be tested is presented with each line formatted as 'line number + code':\n1106 pub(crate) fn new(\n1107     info: &RegexInfo,\n1108     nfarev: &NFA,\n1109 ) -> Option<ReverseHybridEngine> {\n1110     #[cfg(feature = \"hybrid\")]\n1111     {\n1112         if !info.config().get_hybrid() {\n1113             return None;\n1114         }\n1115         // Since we only use this for reverse searches, we can hard-code\n1116         // a number of things like match semantics, prefilters, starts\n1117         // for each pattern and so on.\n1118         let dfa_config = hybrid::dfa::Config::new()\n1119             .match_kind(MatchKind::All)\n1120             .prefilter(None)\n1121             .starts_for_each_pattern(false)\n1122             .byte_classes(info.config().get_byte_classes())\n1123             .unicode_word_boundary(true)\n1124             .specialize_start_states(false)\n1125             .cache_capacity(info.config().get_hybrid_cache_capacity())\n1126             .skip_cache_capacity_check(false)\n1127             .minimum_cache_clear_count(Some(3))\n1128             .minimum_bytes_per_state(Some(10));\n1129         let result = hybrid::dfa::Builder::new()\n1130             .configure(dfa_config)\n1131             .build_from_nfa(nfarev.clone());\n1132         let rev = match result {\n1133             Ok(rev) => rev,\n1134             Err(_err) => {\n1135                 debug!(\"lazy reverse DFA failed to build: {}\", _err);\n1136                 return None;\n1137             }\n1138         };\n1139         debug!(\"lazy reverse DFA built\");\n1140         Some(ReverseHybridEngine(rev))\n1141     }\n1142     #[cfg(not(feature = \"hybrid\"))]\n1143     {\n1144         None\n1145     }\n1146 }\n\nThe path conditions that the generated test functions should satisfy are as follows:\n"
}