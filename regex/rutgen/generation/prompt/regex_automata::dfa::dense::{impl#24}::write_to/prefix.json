{
  "system_pt": "As a software testing expert, please generate Rust test functions based on the following guidelines, focusing solely on constructing test inputs and calling the functions under test:\n1. Provide the code in plain text format, without explanations or Markdown.\n2. If the method under test belongs to a trait, construct appropriate structs within the test function, but avoid method overrides. If the method under test uses generics, instantiate them with suitable types based on the context.\n3. Generate test code with minimal scope: avoid creating external structures or implementations. Instead, define any necessary helper structures or implementations directly within the test function when required.\n4. Whenever possible, initialize the corresponding data structures using the initialization methods provided in the context.\n5. Ensure the generated function is fully implemented and can be compiled and executed directly without any missing parts.\n6. Create a minimal yet complete set of test functions, ensuring they adhere to all provided preconditions and cover boundary conditions, and reference the inferred test input conditions or ranges.\n7. Ensure the test inputs are designed to cover the inferred test input conditions or ranges as comprehensively as possible, with particular emphasis on boundary cases.\n8. Focus on crafting test inputs that effectively reveal potential bugs while meeting the specified requirements.\n9. Omit test oracles and assertions; concentrate on generating test inputs and function calls.\n10. Do not create a test module, but include intrinsic attributes like #[test] or #[should_panic] where necessary.\n",
  "static_pt": "The context for the focal function is as follows:\n// regex-automata/src/dfa/dense.rs\n// crate name is regex_automata\n#[cfg(feature = \"alloc\")]\npub(crate) type OwnedDFA = DFA<alloc::vec::Vec<u32>>;\n#[cfg(feature = \"dfa-build\")]\nuse core::cmp;\nuse core::{fmt, iter, mem::size_of, slice};\n#[cfg(feature = \"dfa-build\")]\nuse alloc::{\n    collections::{BTreeMap, BTreeSet},\n    vec, vec::Vec,\n};\n#[cfg(feature = \"dfa-build\")]\nuse crate::{\n    dfa::{accel::Accel, determinize, minimize::Minimizer, remapper::Remapper, sparse},\n    nfa::thompson, util::{look::LookMatcher, search::MatchKind},\n};\nuse crate::{\n    dfa::{\n        accel::Accels, automaton::{fmt_state_indicator, Automaton, StartError},\n        special::Special, start::StartKind, DEAD,\n    },\n    util::{\n        alphabet::{self, ByteClasses, ByteSet},\n        int::{Pointer, Usize},\n        prefilter::Prefilter, primitives::{PatternID, StateID},\n        search::Anchored, start::{self, Start, StartByteMap},\n        wire::{self, DeserializeError, Endian, SerializeError},\n    },\n};\nconst LABEL: &str = \"rust-regex-automata-dfa-dense\";\nconst VERSION: u32 = 2;\n#[derive(Clone, Debug)]\nstruct MatchStates<T> {\n    /// Slices is a flattened sequence of pairs, where each pair points to a\n    /// sub-slice of pattern_ids. The first element of the pair is an offset\n    /// into pattern_ids and the second element of the pair is the number\n    /// of 32-bit pattern IDs starting at that position. That is, each pair\n    /// corresponds to a single DFA match state and its corresponding match\n    /// IDs. The number of pairs always corresponds to the number of distinct\n    /// DFA match states.\n    ///\n    /// In practice, T is either Vec<u32> or &[u32].\n    slices: T,\n    /// A flattened sequence of pattern IDs for each DFA match state. The only\n    /// way to correctly read this sequence is indirectly via `slices`.\n    ///\n    /// In practice, T is either Vec<u32> or &[u32].\n    pattern_ids: T,\n    /// The total number of unique patterns represented by these match states.\n    pattern_len: usize,\n}\n#[derive(Debug)]\npub struct SerializeError {\n    /// The name of the thing that a buffer is too small for.\n    ///\n    /// Currently, the only kind of serialization error is one that is\n    /// committed by a caller: providing a destination buffer that is too\n    /// small to fit the serialized object. This makes sense conceptually,\n    /// since every valid inhabitant of a type should be serializable.\n    ///\n    /// This is somewhat exposed in the public API of this crate. For example,\n    /// the `to_bytes_{big,little}_endian` APIs return a `Vec<u8>` and are\n    /// guaranteed to never panic or error. This is only possible because the\n    /// implementation guarantees that it will allocate a `Vec<u8>` that is\n    /// big enough.\n    ///\n    /// In summary, if a new serialization error kind needs to be added, then\n    /// it will need careful consideration.\n    what: &'static str,\n}\n#[derive(Clone, Copy, Default, Eq, Hash, PartialEq, PartialOrd, Ord)]\n#[repr(transparent)]\npub struct PatternID(SmallIndex);\nimpl<T: AsRef<[u32]>> MatchStates<T> {\n    fn write_to<E: Endian>(&self, mut dst: &mut [u8]) -> Result<usize, SerializeError> {\n        let nwrite = self.write_to_len();\n        if dst.len() < nwrite {\n            return Err(SerializeError::buffer_too_small(\"match states\"));\n        }\n        dst = &mut dst[..nwrite];\n        E::write_u32(u32::try_from(self.len()).unwrap(), dst);\n        dst = &mut dst[size_of::<u32>()..];\n        for &pid in self.slices() {\n            let n = wire::write_pattern_id::<E>(pid, &mut dst);\n            dst = &mut dst[n..];\n        }\n        E::write_u32(u32::try_from(self.pattern_len).unwrap(), dst);\n        dst = &mut dst[size_of::<u32>()..];\n        E::write_u32(u32::try_from(self.pattern_ids().len()).unwrap(), dst);\n        dst = &mut dst[size_of::<u32>()..];\n        for &pid in self.pattern_ids() {\n            let n = wire::write_pattern_id::<E>(pid, &mut dst);\n            dst = &mut dst[n..];\n        }\n        Ok(nwrite)\n    }\n    fn write_to_len(&self) -> usize {\n        size_of::<u32>() + (self.slices().len() * PatternID::SIZE) + size_of::<u32>()\n            + size_of::<u32>() + (self.pattern_ids().len() * PatternID::SIZE)\n    }\n    fn validate(&self, dfa: &DFA<T>) -> Result<(), DeserializeError> {}\n    #[cfg(feature = \"dfa-build\")]\n    fn to_map(&self, dfa: &DFA<T>) -> BTreeMap<StateID, Vec<PatternID>> {}\n    fn as_ref(&self) -> MatchStates<&'_ [u32]> {}\n    #[cfg(feature = \"alloc\")]\n    fn to_owned(&self) -> MatchStates<alloc::vec::Vec<u32>> {}\n    fn match_state_id(&self, dfa: &DFA<T>, index: usize) -> StateID {}\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    fn pattern_id(&self, state_index: usize, match_index: usize) -> PatternID {}\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    fn pattern_len(&self, state_index: usize) -> usize {}\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    fn pattern_id_slice(&self, state_index: usize) -> &[PatternID] {}\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    fn slices(&self) -> &[PatternID] {\n        wire::u32s_to_pattern_ids(self.slices.as_ref())\n    }\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    fn len(&self) -> usize {\n        assert_eq!(0, self.slices().len() % 2);\n        self.slices().len() / 2\n    }\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    fn pattern_ids(&self) -> &[PatternID] {\n        wire::u32s_to_pattern_ids(self.pattern_ids.as_ref())\n    }\n    fn memory_usage(&self) -> usize {}\n}\nimpl SerializeError {\n    pub(crate) fn buffer_too_small(what: &'static str) -> SerializeError {\n        SerializeError { what }\n    }\n}\npub(crate) fn write_pattern_id<E: Endian>(pid: PatternID, dst: &mut [u8]) -> usize {\n    E::write_u32(pid.as_u32(), dst);\n    PatternID::SIZE\n}\n\nThe function to be tested is presented with each line formatted as 'line number + code':\n/// Writes a serialized form of these match states to the buffer given. If\n/// the buffer is too small, then an error is returned. To determine how\n/// big the buffer must be, use `write_to_len`.\n4467 fn write_to<E: Endian>(\n4468     &self,\n4469     mut dst: &mut [u8],\n4470 ) -> Result<usize, SerializeError> {\n4471     let nwrite = self.write_to_len();\n4472     if dst.len() < nwrite {\n4473         return Err(SerializeError::buffer_too_small(\"match states\"));\n4474     }\n4475     dst = &mut dst[..nwrite];\n4476 \n4477     // write state ID length\n4478     // Unwrap is OK since number of states is guaranteed to fit in a u32.\n4479     E::write_u32(u32::try_from(self.len()).unwrap(), dst);\n4480     dst = &mut dst[size_of::<u32>()..];\n4481 \n4482     // write slice offset pairs\n4483     for &pid in self.slices() {\n4484         let n = wire::write_pattern_id::<E>(pid, &mut dst);\n4485         dst = &mut dst[n..];\n4486     }\n4487 \n4488     // write unique pattern ID length\n4489     // Unwrap is OK since number of patterns is guaranteed to fit in a u32.\n4490     E::write_u32(u32::try_from(self.pattern_len).unwrap(), dst);\n4491     dst = &mut dst[size_of::<u32>()..];\n4492 \n4493     // write pattern ID length\n4494     // Unwrap is OK since we check at construction (and deserialization)\n4495     // that the number of patterns is representable as a u32.\n4496     E::write_u32(u32::try_from(self.pattern_ids().len()).unwrap(), dst);\n4497     dst = &mut dst[size_of::<u32>()..];\n4498 \n4499     // write pattern IDs\n4500     for &pid in self.pattern_ids() {\n4501         let n = wire::write_pattern_id::<E>(pid, &mut dst);\n4502         dst = &mut dst[n..];\n4503     }\n4504 \n4505     Ok(nwrite)\n4506 }\n\nGenerate each test function in such a manner that it concurrently satisfies all the following preconditions:\n",
  "depend_pt": ""
}