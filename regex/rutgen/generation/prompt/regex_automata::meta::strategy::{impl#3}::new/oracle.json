{
  "system_pt": "As a software testing expert, please generate accurate test oracles code based on the provided information. Follow these guidelines:\n1. Generate executable test oracle codes in plain text format, one per line. Do not output complete test functions, avoid additional explanations, and do not use Markdown.\n2. Combine the given function under test, context, relevant documentation, preconditions, expected return values or types, test input conditions or ranges, and existing test function prefixes to infer and generate corresponding test oracles code.\n3. Only generate necessary test oracles to ensure comprehensive validation.\n",
  "static_pt": "The context for the focal function is as follows:\n// regex-automata/src/meta/strategy.rs\n// crate name is regex_automata\nuse core::{fmt::Debug, panic::{RefUnwindSafe, UnwindSafe}};\nuse alloc::sync::Arc;\nuse regex_syntax::hir::{literal, Hir};\nuse crate::{\n    meta::{\n        error::{BuildError, RetryError, RetryFailError, RetryQuadraticError},\n        regex::{Cache, RegexInfo},\n        reverse_inner, wrappers,\n    },\n    nfa::thompson::{self, WhichCaptures, NFA},\n    util::{\n        captures::{Captures, GroupInfo},\n        look::LookMatcher, prefilter::{self, Prefilter, PrefilterI},\n        primitives::{NonMaxUsize, PatternID},\n        search::{Anchored, HalfMatch, Input, Match, MatchKind, PatternSet},\n    },\n};\npub(super) trait Strategy: Debug + Send + Sync + RefUnwindSafe + UnwindSafe + 'static {\n    fn group_info(&self) -> &GroupInfo;\n    fn create_cache(&self) -> Cache;\n    fn reset_cache(&self, cache: &mut Cache);\n    fn is_accelerated(&self) -> bool;\n    fn memory_usage(&self) -> usize;\n    fn search(&self, cache: &mut Cache, input: &Input<'_>) -> Option<Match>;\n    fn search_half(&self, cache: &mut Cache, input: &Input<'_>) -> Option<HalfMatch>;\n    fn is_match(&self, cache: &mut Cache, input: &Input<'_>) -> bool;\n    fn search_slots(\n        &self,\n        cache: &mut Cache,\n        input: &Input<'_>,\n        slots: &mut [Option<NonMaxUsize>],\n    ) -> Option<PatternID>;\n    fn which_overlapping_matches(\n        &self,\n        cache: &mut Cache,\n        input: &Input<'_>,\n        patset: &mut PatternSet,\n    );\n}\n#[derive(Debug)]\nstruct Core {\n    info: RegexInfo,\n    pre: Option<Prefilter>,\n    nfa: NFA,\n    nfarev: Option<NFA>,\n    pikevm: wrappers::PikeVM,\n    backtrack: wrappers::BoundedBacktracker,\n    onepass: wrappers::OnePass,\n    hybrid: wrappers::Hybrid,\n    dfa: wrappers::DFA,\n}\n#[derive(Clone, Debug)]\npub struct LookMatcher {\n    lineterm: DebugByte,\n}\n#[derive(Clone, Debug, Default)]\npub struct Config {\n    match_kind: Option<MatchKind>,\n    utf8_empty: Option<bool>,\n    autopre: Option<bool>,\n    pre: Option<Option<Prefilter>>,\n    which_captures: Option<WhichCaptures>,\n    nfa_size_limit: Option<Option<usize>>,\n    onepass_size_limit: Option<Option<usize>>,\n    hybrid_cache_capacity: Option<usize>,\n    hybrid: Option<bool>,\n    dfa: Option<bool>,\n    dfa_size_limit: Option<Option<usize>>,\n    dfa_state_limit: Option<Option<usize>>,\n    onepass: Option<bool>,\n    backtrack: Option<bool>,\n    byte_classes: Option<bool>,\n    line_terminator: Option<u8>,\n}\n#[derive(Debug)]\npub(crate) struct Hybrid(Option<HybridEngine>);\n#[derive(Clone, Debug, Default)]\npub struct Config {\n    utf8: Option<bool>,\n    reverse: Option<bool>,\n    nfa_size_limit: Option<Option<usize>>,\n    shrink: Option<bool>,\n    which_captures: Option<WhichCaptures>,\n    look_matcher: Option<LookMatcher>,\n    #[cfg(test)]\n    unanchored_prefix: Option<bool>,\n}\n#[derive(Debug)]\npub(crate) struct DFA(Option<DFAEngine>);\n#[derive(Clone, Debug)]\npub struct Compiler {\n    /// A regex parser, used when compiling an NFA directly from a pattern\n    /// string.\n    parser: ParserBuilder,\n    /// The compiler configuration.\n    config: Config,\n    /// The builder for actually constructing an NFA. This provides a\n    /// convenient abstraction for writing a compiler.\n    builder: RefCell<Builder>,\n    /// State used for compiling character classes to UTF-8 byte automata.\n    /// State is not retained between character class compilations. This just\n    /// serves to amortize allocation to the extent possible.\n    utf8_state: RefCell<Utf8State>,\n    /// State used for arranging character classes in reverse into a trie.\n    trie_state: RefCell<RangeTrie>,\n    /// State used for caching common suffixes when compiling reverse UTF-8\n    /// automata (for Unicode character classes).\n    utf8_suffix: RefCell<Utf8SuffixMap>,\n}\n#[derive(Debug)]\npub(crate) struct PikeVM(PikeVMEngine);\n#[derive(Clone, Debug)]\npub(crate) struct RegexInfo(Arc<RegexInfoI>);\n#[derive(Debug)]\npub(crate) struct OnePass(Option<OnePassEngine>);\n#[derive(Debug)]\npub(crate) struct BoundedBacktracker(Option<BoundedBacktrackerEngine>);\n#[derive(Clone, Debug)]\npub struct Prefilter {\n    #[cfg(not(feature = \"alloc\"))]\n    _unused: (),\n    #[cfg(feature = \"alloc\")]\n    pre: Arc<dyn PrefilterI>,\n    #[cfg(feature = \"alloc\")]\n    is_fast: bool,\n    #[cfg(feature = \"alloc\")]\n    max_needle_len: usize,\n}\n#[derive(Clone)]\npub struct NFA(Arc<Inner>);\n#[derive(Clone, Debug)]\npub struct BuildError {\n    kind: BuildErrorKind,\n}\n#[derive(Clone, Debug)]\npub struct PikeVM {\n    config: Config,\n    nfa: NFA,\n}\n#[derive(Clone)]\npub struct DFA<T> {\n    tt: Transitions<T>,\n    st: StartTable<T>,\n    special: Special,\n    pre: Option<Prefilter>,\n    quitset: ByteSet,\n    flags: Flags,\n}\n#[derive(Clone)]\npub struct DFA<T> {\n    /// The transition table for this DFA. This includes the transitions\n    /// themselves, along with the stride, number of states and the equivalence\n    /// class mapping.\n    tt: TransitionTable<T>,\n    /// The set of starting state identifiers for this DFA. The starting state\n    /// IDs act as pointers into the transition table. The specific starting\n    /// state chosen for each search is dependent on the context at which the\n    /// search begins.\n    st: StartTable<T>,\n    /// The set of match states and the patterns that match for each\n    /// corresponding match state.\n    ///\n    /// This structure is technically only needed because of support for\n    /// multi-regexes. Namely, multi-regexes require answering not just whether\n    /// a match exists, but _which_ patterns match. So we need to store the\n    /// matching pattern IDs for each match state. We do this even when there\n    /// is only one pattern for the sake of simplicity. In practice, this uses\n    /// up very little space for the case of one pattern.\n    ms: MatchStates<T>,\n    /// Information about which states are \"special.\" Special states are states\n    /// that are dead, quit, matching, starting or accelerated. For more info,\n    /// see the docs for `Special`.\n    special: Special,\n    /// The accelerators for this DFA.\n    ///\n    /// If a state is accelerated, then there exist only a small number of\n    /// bytes that can cause the DFA to leave the state. This permits searching\n    /// to use optimized routines to find those specific bytes instead of using\n    /// the transition table.\n    ///\n    /// All accelerated states exist in a contiguous range in the DFA's\n    /// transition table. See dfa/special.rs for more details on how states are\n    /// arranged.\n    accels: Accels<T>,\n    /// Any prefilter attached to this DFA.\n    ///\n    /// Note that currently prefilters are not serialized. When deserializing\n    /// a DFA from bytes, this is always set to `None`.\n    pre: Option<Prefilter>,\n    /// The set of \"quit\" bytes for this DFA.\n    ///\n    /// This is only used when computing the start state for a particular\n    /// position in a haystack. Namely, in the case where there is a quit\n    /// byte immediately before the start of the search, this set needs to be\n    /// explicitly consulted. In all other cases, quit bytes are detected by\n    /// the DFA itself, by transitioning all quit bytes to a special \"quit\n    /// state.\"\n    quitset: ByteSet,\n    /// Various flags describing the behavior of this DFA.\n    flags: Flags,\n}\n#[derive(Clone)]\npub struct DFA {\n    /// The configuration provided by the caller.\n    config: Config,\n    /// The NFA used to build this DFA.\n    ///\n    /// NOTE: We probably don't need to store the NFA here, but we use enough\n    /// bits from it that it's convenient to do so. And there really isn't much\n    /// cost to doing so either, since an NFA is reference counted internally.\n    nfa: NFA,\n    /// The transition table. Given a state ID 's' and a byte of haystack 'b',\n    /// the next state is `table[sid + classes[byte]]`.\n    ///\n    /// The stride of this table (i.e., the number of columns) is always\n    /// a power of 2, even if the alphabet length is smaller. This makes\n    /// converting between state IDs and state indices very cheap.\n    ///\n    /// Note that the stride always includes room for one extra \"transition\"\n    /// that isn't actually a transition. It is a 'PatternEpsilons' that is\n    /// used for match states only. Because of this, the maximum number of\n    /// active columns in the transition table is 257, which means the maximum\n    /// stride is 512 (the next power of 2 greater than or equal to 257).\n    table: Vec<Transition>,\n    /// The DFA state IDs of the starting states.\n    ///\n    /// `starts[0]` is always present and corresponds to the starting state\n    /// when searching for matches of any pattern in the DFA.\n    ///\n    /// `starts[i]` where i>0 corresponds to the starting state for the pattern\n    /// ID 'i-1'. These starting states are optional.\n    starts: Vec<StateID>,\n    /// Every state ID >= this value corresponds to a match state.\n    ///\n    /// This is what a search uses to detect whether a state is a match state\n    /// or not. It requires only a simple comparison instead of bit-unpacking\n    /// the PatternEpsilons from every state.\n    min_match_id: StateID,\n    /// The alphabet of this DFA, split into equivalence classes. Bytes in the\n    /// same equivalence class can never discriminate between a match and a\n    /// non-match.\n    classes: ByteClasses,\n    /// The number of elements in each state in the transition table. This may\n    /// be less than the stride, since the stride is always a power of 2 and\n    /// the alphabet length can be anything up to and including 256.\n    alphabet_len: usize,\n    /// The number of columns in the transition table, expressed as a power of\n    /// 2.\n    stride2: usize,\n    /// The offset at which the PatternEpsilons for a match state is stored in\n    /// the transition table.\n    ///\n    /// PERF: One wonders whether it would be better to put this in a separate\n    /// allocation, since only match states have a non-empty PatternEpsilons\n    /// and the number of match states tends be dwarfed by the number of\n    /// non-match states. So this would save '8*len(non_match_states)' for each\n    /// DFA. The question is whether moving this to a different allocation will\n    /// lead to a perf hit during searches. You might think dealing with match\n    /// states is rare, but some regexes spend a lot of time in match states\n    /// gobbling up input. But... match state handling is already somewhat\n    /// expensive, so maybe this wouldn't do much? Either way, it's worth\n    /// experimenting.\n    pateps_offset: usize,\n    /// The first explicit slot index. This refers to the first slot appearing\n    /// immediately after the last implicit slot. It is always 'patterns.len()\n    /// * 2'.\n    ///\n    /// We record this because we only store the explicit slots in our DFA\n    /// transition table that need to be saved. Implicit slots are handled\n    /// automatically as part of the search.\n    explicit_slot_start: usize,\n}\n#[derive(Clone, Debug)]\npub struct DFA {\n    config: Config,\n    nfa: thompson::NFA,\n    stride2: usize,\n    start_map: StartByteMap,\n    classes: ByteClasses,\n    quitset: ByteSet,\n    cache_capacity: usize,\n}\n#[derive(Clone, Debug)]\npub struct BuildError {\n    kind: BuildErrorKind,\n}\n#[derive(Clone, Debug)]\npub struct BoundedBacktracker {\n    config: Config,\n    nfa: NFA,\n}\n#[derive(Clone, Copy, Debug)]\npub enum WhichCaptures {\n    /// All capture states, including those corresponding to both implicit and\n    /// explicit capture groups, are included in the Thompson NFA.\n    All,\n    /// Only capture states corresponding to implicit capture groups are\n    /// included. Implicit capture groups appear in every pattern implicitly\n    /// and correspond to the overall match of a pattern.\n    ///\n    /// This is useful when one only cares about the overall match of a\n    /// pattern. By excluding capture states from explicit capture groups,\n    /// one might be able to reduce the memory usage of a multi-pattern regex\n    /// substantially if it was otherwise written to have many explicit capture\n    /// groups.\n    Implicit,\n    /// No capture states are compiled into the Thompson NFA.\n    ///\n    /// This is useful when capture states are either not needed (for example,\n    /// if one is only trying to build a DFA) or if they aren't supported (for\n    /// example, a reverse NFA).\n    None,\n}\nimpl Core {\n    fn new(\n        info: RegexInfo,\n        pre: Option<Prefilter>,\n        hirs: &[&Hir],\n    ) -> Result<Core, BuildError> {\n        let mut lookm = LookMatcher::new();\n        lookm.set_line_terminator(info.config().get_line_terminator());\n        let thompson_config = thompson::Config::new()\n            .utf8(info.config().get_utf8_empty())\n            .nfa_size_limit(info.config().get_nfa_size_limit())\n            .shrink(false)\n            .which_captures(info.config().get_which_captures())\n            .look_matcher(lookm);\n        let nfa = thompson::Compiler::new()\n            .configure(thompson_config.clone())\n            .build_many_from_hir(hirs)\n            .map_err(BuildError::nfa)?;\n        let pikevm = wrappers::PikeVM::new(&info, pre.clone(), &nfa)?;\n        let backtrack = wrappers::BoundedBacktracker::new(&info, pre.clone(), &nfa)?;\n        let onepass = wrappers::OnePass::new(&info, &nfa);\n        let (nfarev, hybrid, dfa) = if !info.config().get_hybrid()\n            && !info.config().get_dfa()\n        {\n            (None, wrappers::Hybrid::none(), wrappers::DFA::none())\n        } else {\n            let nfarev = thompson::Compiler::new()\n                .configure(\n                    thompson_config\n                        .clone()\n                        .which_captures(WhichCaptures::None)\n                        .reverse(true),\n                )\n                .build_many_from_hir(hirs)\n                .map_err(BuildError::nfa)?;\n            let dfa = if !info.config().get_dfa() {\n                wrappers::DFA::none()\n            } else {\n                wrappers::DFA::new(&info, pre.clone(), &nfa, &nfarev)\n            };\n            let hybrid = if !info.config().get_hybrid() {\n                wrappers::Hybrid::none()\n            } else if dfa.is_some() {\n                debug!(\"skipping lazy DFA because we have a full DFA\");\n                wrappers::Hybrid::none()\n            } else {\n                wrappers::Hybrid::new(&info, pre.clone(), &nfa, &nfarev)\n            };\n            (Some(nfarev), hybrid, dfa)\n        };\n        Ok(Core {\n            info,\n            pre,\n            nfa,\n            nfarev,\n            pikevm,\n            backtrack,\n            onepass,\n            hybrid,\n            dfa,\n        })\n    }\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    fn try_search_mayfail(\n        &self,\n        cache: &mut Cache,\n        input: &Input<'_>,\n    ) -> Option<Result<Option<Match>, RetryFailError>> {}\n    fn search_nofail(&self, cache: &mut Cache, input: &Input<'_>) -> Option<Match> {}\n    fn search_half_nofail(\n        &self,\n        cache: &mut Cache,\n        input: &Input<'_>,\n    ) -> Option<HalfMatch> {}\n    fn search_slots_nofail(\n        &self,\n        cache: &mut Cache,\n        input: &Input<'_>,\n        slots: &mut [Option<NonMaxUsize>],\n    ) -> Option<PatternID> {}\n    fn is_match_nofail(&self, cache: &mut Cache, input: &Input<'_>) -> bool {}\n    fn is_capture_search_needed(&self, slots_len: usize) -> bool {}\n}\nimpl LookMatcher {\n    pub fn new() -> LookMatcher {\n        LookMatcher {\n            lineterm: DebugByte(b'\\n'),\n        }\n    }\n    pub fn set_line_terminator(&mut self, byte: u8) -> &mut LookMatcher {\n        self.lineterm.0 = byte;\n        self\n    }\n    pub fn get_line_terminator(&self) -> u8 {}\n    #[inline]\n    pub fn matches(&self, look: Look, haystack: &[u8], at: usize) -> bool {}\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    pub(crate) fn matches_inline(&self, look: Look, haystack: &[u8], at: usize) -> bool {}\n    #[inline]\n    pub fn matches_set(&self, set: LookSet, haystack: &[u8], at: usize) -> bool {}\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    pub(crate) fn matches_set_inline(\n        &self,\n        set: LookSet,\n        haystack: &[u8],\n        at: usize,\n    ) -> bool {}\n    #[cfg(feature = \"alloc\")]\n    pub(crate) fn add_to_byteset(\n        &self,\n        look: Look,\n        set: &mut crate::util::alphabet::ByteClassSet,\n    ) {}\n    #[inline]\n    pub fn is_start(&self, _haystack: &[u8], at: usize) -> bool {}\n    #[inline]\n    pub fn is_end(&self, haystack: &[u8], at: usize) -> bool {}\n    #[inline]\n    pub fn is_start_lf(&self, haystack: &[u8], at: usize) -> bool {}\n    #[inline]\n    pub fn is_end_lf(&self, haystack: &[u8], at: usize) -> bool {}\n    #[inline]\n    pub fn is_start_crlf(&self, haystack: &[u8], at: usize) -> bool {}\n    #[inline]\n    pub fn is_end_crlf(&self, haystack: &[u8], at: usize) -> bool {}\n    #[inline]\n    pub fn is_word_ascii(&self, haystack: &[u8], at: usize) -> bool {}\n    #[inline]\n    pub fn is_word_ascii_negate(&self, haystack: &[u8], at: usize) -> bool {}\n    #[inline]\n    pub fn is_word_unicode(\n        &self,\n        haystack: &[u8],\n        at: usize,\n    ) -> Result<bool, UnicodeWordBoundaryError> {}\n    #[inline]\n    pub fn is_word_unicode_negate(\n        &self,\n        haystack: &[u8],\n        at: usize,\n    ) -> Result<bool, UnicodeWordBoundaryError> {}\n    #[inline]\n    pub fn is_word_start_ascii(&self, haystack: &[u8], at: usize) -> bool {}\n    #[inline]\n    pub fn is_word_end_ascii(&self, haystack: &[u8], at: usize) -> bool {}\n    #[inline]\n    pub fn is_word_start_unicode(\n        &self,\n        haystack: &[u8],\n        at: usize,\n    ) -> Result<bool, UnicodeWordBoundaryError> {}\n    #[inline]\n    pub fn is_word_end_unicode(\n        &self,\n        haystack: &[u8],\n        at: usize,\n    ) -> Result<bool, UnicodeWordBoundaryError> {}\n    #[inline]\n    pub fn is_word_start_half_ascii(&self, haystack: &[u8], at: usize) -> bool {}\n    #[inline]\n    pub fn is_word_end_half_ascii(&self, haystack: &[u8], at: usize) -> bool {}\n    #[inline]\n    pub fn is_word_start_half_unicode(\n        &self,\n        haystack: &[u8],\n        at: usize,\n    ) -> Result<bool, UnicodeWordBoundaryError> {}\n    #[inline]\n    pub fn is_word_end_half_unicode(\n        &self,\n        haystack: &[u8],\n        at: usize,\n    ) -> Result<bool, UnicodeWordBoundaryError> {}\n}\nimpl Config {\n    pub fn new() -> Config {\n        Config::default()\n    }\n    pub fn match_kind(self, kind: MatchKind) -> Config {}\n    pub fn utf8_empty(self, yes: bool) -> Config {}\n    pub fn auto_prefilter(self, yes: bool) -> Config {}\n    pub fn prefilter(self, pre: Option<Prefilter>) -> Config {}\n    pub fn which_captures(mut self, which_captures: WhichCaptures) -> Config {\n        self.which_captures = Some(which_captures);\n        self\n    }\n    pub fn nfa_size_limit(mut self, bytes: Option<usize>) -> Config {\n        self.nfa_size_limit = Some(bytes);\n        self\n    }\n    pub fn onepass_size_limit(self, limit: Option<usize>) -> Config {}\n    pub fn hybrid_cache_capacity(self, limit: usize) -> Config {}\n    pub fn dfa_size_limit(self, limit: Option<usize>) -> Config {}\n    pub fn dfa_state_limit(self, limit: Option<usize>) -> Config {}\n    pub fn byte_classes(self, yes: bool) -> Config {}\n    pub fn line_terminator(self, byte: u8) -> Config {}\n    pub fn hybrid(self, yes: bool) -> Config {}\n    pub fn dfa(self, yes: bool) -> Config {}\n    pub fn onepass(self, yes: bool) -> Config {}\n    pub fn backtrack(self, yes: bool) -> Config {}\n    pub fn get_match_kind(&self) -> MatchKind {}\n    pub fn get_utf8_empty(&self) -> bool {\n        self.utf8_empty.unwrap_or(true)\n    }\n    pub fn get_auto_prefilter(&self) -> bool {}\n    pub fn get_prefilter(&self) -> Option<&Prefilter> {}\n    pub fn get_which_captures(&self) -> WhichCaptures {\n        self.which_captures.unwrap_or(WhichCaptures::All)\n    }\n    pub fn get_nfa_size_limit(&self) -> Option<usize> {\n        self.nfa_size_limit.unwrap_or(Some(10 * (1 << 20)))\n    }\n    pub fn get_onepass_size_limit(&self) -> Option<usize> {}\n    pub fn get_hybrid_cache_capacity(&self) -> usize {}\n    pub fn get_dfa_size_limit(&self) -> Option<usize> {}\n    pub fn get_dfa_state_limit(&self) -> Option<usize> {}\n    pub fn get_byte_classes(&self) -> bool {}\n    pub fn get_line_terminator(&self) -> u8 {\n        self.line_terminator.unwrap_or(b'\\n')\n    }\n    pub fn get_hybrid(&self) -> bool {\n        #[cfg(feature = \"hybrid\")] { self.hybrid.unwrap_or(true) }\n        #[cfg(not(feature = \"hybrid\"))] { false }\n    }\n    pub fn get_dfa(&self) -> bool {\n        #[cfg(feature = \"dfa-build\")] { self.dfa.unwrap_or(true) }\n        #[cfg(not(feature = \"dfa-build\"))] { false }\n    }\n    pub fn get_onepass(&self) -> bool {}\n    pub fn get_backtrack(&self) -> bool {}\n    pub(crate) fn overwrite(&self, o: Config) -> Config {}\n}\nimpl Hybrid {\n    pub(crate) fn none() -> Hybrid {\n        Hybrid(None)\n    }\n    pub(crate) fn new(\n        info: &RegexInfo,\n        pre: Option<Prefilter>,\n        nfa: &NFA,\n        nfarev: &NFA,\n    ) -> Hybrid {\n        Hybrid(HybridEngine::new(info, pre, nfa, nfarev))\n    }\n    pub(crate) fn create_cache(&self) -> HybridCache {}\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    pub(crate) fn get(&self, _input: &Input<'_>) -> Option<&HybridEngine> {}\n    pub(crate) fn is_some(&self) -> bool {}\n}\nimpl DFA {\n    pub(crate) fn none() -> DFA {\n        DFA(None)\n    }\n    pub(crate) fn new(\n        info: &RegexInfo,\n        pre: Option<Prefilter>,\n        nfa: &NFA,\n        nfarev: &NFA,\n    ) -> DFA {\n        DFA(DFAEngine::new(info, pre, nfa, nfarev))\n    }\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    pub(crate) fn get(&self, _input: &Input<'_>) -> Option<&DFAEngine> {}\n    pub(crate) fn is_some(&self) -> bool {\n        self.0.is_some()\n    }\n    pub(crate) fn memory_usage(&self) -> usize {}\n}\nimpl Compiler {\n    pub fn new() -> Compiler {\n        Compiler {\n            parser: ParserBuilder::new(),\n            config: Config::default(),\n            builder: RefCell::new(Builder::new()),\n            utf8_state: RefCell::new(Utf8State::new()),\n            trie_state: RefCell::new(RangeTrie::new()),\n            utf8_suffix: RefCell::new(Utf8SuffixMap::new(1000)),\n        }\n    }\n    pub fn build(&self, pattern: &str) -> Result<NFA, BuildError> {}\n    pub fn build_many<P: AsRef<str>>(&self, patterns: &[P]) -> Result<NFA, BuildError> {}\n    pub fn build_from_hir(&self, expr: &Hir) -> Result<NFA, BuildError> {}\n    pub fn build_many_from_hir<H: Borrow<Hir>>(\n        &self,\n        exprs: &[H],\n    ) -> Result<NFA, BuildError> {\n        self.compile(exprs)\n    }\n    pub fn configure(&mut self, config: Config) -> &mut Compiler {\n        self.config = self.config.overwrite(config);\n        self\n    }\n    pub fn syntax(&mut self, config: crate::util::syntax::Config) -> &mut Compiler {}\n}\nimpl PikeVM {\n    pub(crate) fn new(\n        info: &RegexInfo,\n        pre: Option<Prefilter>,\n        nfa: &NFA,\n    ) -> Result<PikeVM, BuildError> {\n        PikeVMEngine::new(info, pre, nfa).map(PikeVM)\n    }\n    pub(crate) fn create_cache(&self) -> PikeVMCache {}\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    pub(crate) fn get(&self) -> &PikeVMEngine {}\n}\nimpl RegexInfo {\n    fn new(config: Config, hirs: &[&Hir]) -> RegexInfo {}\n    pub(crate) fn config(&self) -> &Config {\n        &self.0.config\n    }\n    pub(crate) fn props(&self) -> &[hir::Properties] {}\n    pub(crate) fn props_union(&self) -> &hir::Properties {}\n    pub(crate) fn pattern_len(&self) -> usize {}\n    pub(crate) fn memory_usage(&self) -> usize {}\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    pub(crate) fn is_anchored_start(&self, input: &Input<'_>) -> bool {}\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    pub(crate) fn is_always_anchored_start(&self) -> bool {}\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    pub(crate) fn is_always_anchored_end(&self) -> bool {}\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    fn is_impossible(&self, input: &Input<'_>) -> bool {}\n}\nimpl OnePass {\n    pub(crate) fn new(info: &RegexInfo, nfa: &NFA) -> OnePass {\n        OnePass(OnePassEngine::new(info, nfa))\n    }\n    pub(crate) fn create_cache(&self) -> OnePassCache {}\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    pub(crate) fn get(&self, input: &Input<'_>) -> Option<&OnePassEngine> {}\n    pub(crate) fn memory_usage(&self) -> usize {}\n}\nimpl BoundedBacktracker {\n    pub(crate) fn new(\n        info: &RegexInfo,\n        pre: Option<Prefilter>,\n        nfa: &NFA,\n    ) -> Result<BoundedBacktracker, BuildError> {\n        BoundedBacktrackerEngine::new(info, pre, nfa).map(BoundedBacktracker)\n    }\n    pub(crate) fn create_cache(&self) -> BoundedBacktrackerCache {}\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    pub(crate) fn get(&self, input: &Input<'_>) -> Option<&BoundedBacktrackerEngine> {}\n}\n\nThe function to be tested is presented with each line formatted as 'line number + code':\n456 fn new(\n457     info: RegexInfo,\n458     pre: Option<Prefilter>,\n459     hirs: &[&Hir],\n460 ) -> Result<Core, BuildError> {\n461     let mut lookm = LookMatcher::new();\n462     lookm.set_line_terminator(info.config().get_line_terminator());\n463     let thompson_config = thompson::Config::new()\n464         .utf8(info.config().get_utf8_empty())\n465         .nfa_size_limit(info.config().get_nfa_size_limit())\n466         .shrink(false)\n467         .which_captures(info.config().get_which_captures())\n468         .look_matcher(lookm);\n469     let nfa = thompson::Compiler::new()\n470         .configure(thompson_config.clone())\n471         .build_many_from_hir(hirs)\n472         .map_err(BuildError::nfa)?;\n473     // It's possible for the PikeVM or the BB to fail to build, even though\n474     // at this point, we already have a full NFA in hand. They can fail\n475     // when a Unicode word boundary is used but where Unicode word boundary\n476     // support is disabled at compile time, thus making it impossible to\n477     // match. (Construction can also fail if the NFA was compiled without\n478     // captures, but we always enable that above.)\n479     let pikevm = wrappers::PikeVM::new(&info, pre.clone(), &nfa)?;\n480     let backtrack =\n481         wrappers::BoundedBacktracker::new(&info, pre.clone(), &nfa)?;\n482     // The onepass engine can of course fail to build, but we expect it to\n483     // fail in many cases because it is an optimization that doesn't apply\n484     // to all regexes. The 'OnePass' wrapper encapsulates this failure (and\n485     // logs a message if it occurs).\n486     let onepass = wrappers::OnePass::new(&info, &nfa);\n487     // We try to encapsulate whether a particular regex engine should be\n488     // used within each respective wrapper, but the DFAs need a reverse NFA\n489     // to build itself, and we really do not want to build a reverse NFA if\n490     // we know we aren't going to use the lazy DFA. So we do a config check\n491     // up front, which is in practice the only way we won't try to use the\n492     // DFA.\n493     let (nfarev, hybrid, dfa) =\n494         if !info.config().get_hybrid() && !info.config().get_dfa() {\n495             (None, wrappers::Hybrid::none(), wrappers::DFA::none())\n496         } else {\n497             // FIXME: Technically, we don't quite yet KNOW that we need\n498             // a reverse NFA. It's possible for the DFAs below to both\n499             // fail to build just based on the forward NFA. In which case,\n500             // building the reverse NFA was totally wasted work. But...\n501             // fixing this requires breaking DFA construction apart into\n502             // two pieces: one for the forward part and another for the\n503             // reverse part. Quite annoying. Making it worse, when building\n504             // both DFAs fails, it's quite likely that the NFA is large and\n505             // that it will take quite some time to build the reverse NFA\n506             // too. So... it's really probably worth it to do this!\n507             let nfarev = thompson::Compiler::new()\n508                 // Currently, reverse NFAs don't support capturing groups,\n509                 // so we MUST disable them. But even if we didn't have to,\n510                 // we would, because nothing in this crate does anything\n511                 // useful with capturing groups in reverse. And of course,\n512                 // the lazy DFA ignores capturing groups in all cases.\n513                 .configure(\n514                     thompson_config\n515                         .clone()\n516                         .which_captures(WhichCaptures::None)\n517                         .reverse(true),\n518                 )\n519                 .build_many_from_hir(hirs)\n520                 .map_err(BuildError::nfa)?;\n521             let dfa = if !info.config().get_dfa() {\n522                 wrappers::DFA::none()\n523             } else {\n524                 wrappers::DFA::new(&info, pre.clone(), &nfa, &nfarev)\n525             };\n526             let hybrid = if !info.config().get_hybrid() {\n527                 wrappers::Hybrid::none()\n528             } else if dfa.is_some() {\n529                 debug!(\"skipping lazy DFA because we have a full DFA\");\n530                 wrappers::Hybrid::none()\n531             } else {\n532                 wrappers::Hybrid::new(&info, pre.clone(), &nfa, &nfarev)\n533             };\n534             (Some(nfarev), hybrid, dfa)\n535         };\n536     Ok(Core {\n537         info,\n538         pre,\n539         nfa,\n540         nfarev,\n541         pikevm,\n542         backtrack,\n543         onepass,\n544         hybrid,\n545         dfa,\n546     })\n547 }\n\nThe path conditions that the generated test functions should satisfy are as follows:\n"
}