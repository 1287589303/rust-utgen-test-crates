{
  "system_pt": "As a software testing expert, infer the test input conditions or ranges based on the provided information. Follow these guidelines:\n1. Provide test input conditions or ranges in one line in plain text only, without additional explanations or Markdown formatting\n2. Analyze the function under test, context, preconditions, and expected return values or types to determine appropriate test input conditions or ranges\n3. The inferred test input conditions or ranges should comprehensively satisfy all provided preconditions simultaneously.\n4. Ensure the test input conditions or ranges cover boundary cases and edge scenarios\n",
  "static_pt": "The context for the focal function is as follows:\n// regex-automata/src/dfa/dense.rs\n// crate name is regex_automata\n#[cfg(feature = \"alloc\")]\npub(crate) type OwnedDFA = DFA<alloc::vec::Vec<u32>>;\n#[cfg(feature = \"dfa-build\")]\nuse core::cmp;\nuse core::{fmt, iter, mem::size_of, slice};\n#[cfg(feature = \"dfa-build\")]\nuse alloc::{\n    collections::{BTreeMap, BTreeSet},\n    vec, vec::Vec,\n};\n#[cfg(feature = \"dfa-build\")]\nuse crate::{\n    dfa::{accel::Accel, determinize, minimize::Minimizer, remapper::Remapper, sparse},\n    nfa::thompson, util::{look::LookMatcher, search::MatchKind},\n};\nuse crate::{\n    dfa::{\n        accel::Accels, automaton::{fmt_state_indicator, Automaton, StartError},\n        special::Special, start::StartKind, DEAD,\n    },\n    util::{\n        alphabet::{self, ByteClasses, ByteSet},\n        int::{Pointer, Usize},\n        prefilter::Prefilter, primitives::{PatternID, StateID},\n        search::Anchored, start::{self, Start, StartByteMap},\n        wire::{self, DeserializeError, Endian, SerializeError},\n    },\n};\nconst LABEL: &str = \"rust-regex-automata-dfa-dense\";\nconst VERSION: u32 = 2;\n#[cfg(feature = \"dfa-build\")]\n#[derive(Clone, Debug, Default)]\npub struct Config {\n    accelerate: Option<bool>,\n    pre: Option<Option<Prefilter>>,\n    minimize: Option<bool>,\n    match_kind: Option<MatchKind>,\n    start_kind: Option<StartKind>,\n    starts_for_each_pattern: Option<bool>,\n    byte_classes: Option<bool>,\n    unicode_word_boundary: Option<bool>,\n    quitset: Option<ByteSet>,\n    specialize_start_states: Option<bool>,\n    dfa_size_limit: Option<Option<usize>>,\n    determinize_size_limit: Option<Option<usize>>,\n}\n#[derive(Clone, Debug)]\npub(crate) struct ByteSet([bool; 256]);\n#[derive(Clone, Debug)]\npub struct Prefilter {\n    #[cfg(not(feature = \"alloc\"))]\n    _unused: (),\n    #[cfg(feature = \"alloc\")]\n    pre: Arc<dyn PrefilterI>,\n    #[cfg(feature = \"alloc\")]\n    is_fast: bool,\n    #[cfg(feature = \"alloc\")]\n    max_needle_len: usize,\n}\n#[derive(Clone, Copy, Debug, Default, Eq, PartialEq)]\npub(crate) struct ByteSet {\n    bits: BitSet,\n}\n#[non_exhaustive]\n#[derive(Clone, Copy, Debug, Eq, PartialEq)]\npub enum MatchKind {\n    /// Report all possible matches.\n    All,\n    /// Report only the leftmost matches. When multiple leftmost matches exist,\n    /// report the match corresponding to the part of the regex that appears\n    /// first in the syntax.\n    LeftmostFirst,\n}\n#[derive(Clone, Copy, Debug, Eq, PartialEq)]\npub enum StartKind {\n    /// Support both anchored and unanchored searches.\n    Both,\n    /// Support only unanchored searches. Requesting an anchored search will\n    /// panic.\n    ///\n    /// Note that even if an unanchored search is requested, the pattern itself\n    /// may still be anchored. For example, `^abc` will only match `abc` at the\n    /// start of a haystack. This will remain true, even if the regex engine\n    /// only supported unanchored searches.\n    Unanchored,\n    /// Support only anchored searches. Requesting an unanchored search will\n    /// panic.\n    Anchored,\n}\n#[cfg(feature = \"dfa-build\")]\nimpl Config {\n    pub fn new() -> Config {}\n    pub fn accelerate(mut self, yes: bool) -> Config {}\n    pub fn prefilter(mut self, pre: Option<Prefilter>) -> Config {}\n    pub fn minimize(mut self, yes: bool) -> Config {}\n    pub fn match_kind(mut self, kind: MatchKind) -> Config {}\n    pub fn start_kind(mut self, kind: StartKind) -> Config {}\n    pub fn starts_for_each_pattern(mut self, yes: bool) -> Config {}\n    pub fn byte_classes(mut self, yes: bool) -> Config {}\n    pub fn unicode_word_boundary(mut self, yes: bool) -> Config {\n        self.unicode_word_boundary = Some(yes);\n        self\n    }\n    pub fn quit(mut self, byte: u8, yes: bool) -> Config {}\n    pub fn specialize_start_states(mut self, yes: bool) -> Config {}\n    pub fn dfa_size_limit(mut self, bytes: Option<usize>) -> Config {}\n    pub fn determinize_size_limit(mut self, bytes: Option<usize>) -> Config {}\n    pub fn get_accelerate(&self) -> bool {}\n    pub fn get_prefilter(&self) -> Option<&Prefilter> {}\n    pub fn get_minimize(&self) -> bool {}\n    pub fn get_match_kind(&self) -> MatchKind {}\n    pub fn get_starts(&self) -> StartKind {}\n    pub fn get_starts_for_each_pattern(&self) -> bool {}\n    pub fn get_byte_classes(&self) -> bool {}\n    pub fn get_unicode_word_boundary(&self) -> bool {}\n    pub fn get_quit(&self, byte: u8) -> bool {}\n    pub fn get_specialize_start_states(&self) -> bool {}\n    pub fn get_dfa_size_limit(&self) -> Option<usize> {}\n    pub fn get_determinize_size_limit(&self) -> Option<usize> {}\n    pub(crate) fn overwrite(&self, o: Config) -> Config {}\n}\n\nThe function to be tested is presented with each line formatted as 'line number + code':\n/// Heuristically enable Unicode word boundaries.\n///\n/// When set, this will attempt to implement Unicode word boundaries as if\n/// they were ASCII word boundaries. This only works when the search input\n/// is ASCII only. If a non-ASCII byte is observed while searching, then a\n/// [`MatchError::quit`](crate::MatchError::quit) error is returned.\n///\n/// A possible alternative to enabling this option is to simply use an\n/// ASCII word boundary, e.g., via `(?-u:\\b)`. The main reason to use this\n/// option is if you absolutely need Unicode support. This option lets one\n/// use a fast search implementation (a DFA) for some potentially very\n/// common cases, while providing the option to fall back to some other\n/// regex engine to handle the general case when an error is returned.\n///\n/// If the pattern provided has no Unicode word boundary in it, then this\n/// option has no effect. (That is, quitting on a non-ASCII byte only\n/// occurs when this option is enabled _and_ a Unicode word boundary is\n/// present in the pattern.)\n///\n/// This is almost equivalent to setting all non-ASCII bytes to be quit\n/// bytes. The only difference is that this will cause non-ASCII bytes to\n/// be quit bytes _only_ when a Unicode word boundary is present in the\n/// pattern.\n///\n/// When enabling this option, callers _must_ be prepared to handle\n/// a [`MatchError`](crate::MatchError) error during search.\n/// When using a [`Regex`](crate::dfa::regex::Regex), this corresponds\n/// to using the `try_` suite of methods. Alternatively, if\n/// callers can guarantee that their input is ASCII only, then a\n/// [`MatchError::quit`](crate::MatchError::quit) error will never be\n/// returned while searching.\n///\n/// This is disabled by default.\n///\n/// # Example\n///\n/// This example shows how to heuristically enable Unicode word boundaries\n/// in a pattern. It also shows what happens when a search comes across a\n/// non-ASCII byte.\n///\n/// ```\n/// use regex_automata::{\n///     dfa::{Automaton, dense},\n///     HalfMatch, Input, MatchError,\n/// };\n///\n/// let dfa = dense::Builder::new()\n///     .configure(dense::Config::new().unicode_word_boundary(true))\n///     .build(r\"\\b[0-9]+\\b\")?;\n///\n/// // The match occurs before the search ever observes the snowman\n/// // character, so no error occurs.\n/// let haystack = \"foo 123  ☃\".as_bytes();\n/// let expected = Some(HalfMatch::must(0, 7));\n/// let got = dfa.try_search_fwd(&Input::new(haystack))?;\n/// assert_eq!(expected, got);\n///\n/// // Notice that this search fails, even though the snowman character\n/// // occurs after the ending match offset. This is because search\n/// // routines read one byte past the end of the search to account for\n/// // look-around, and indeed, this is required here to determine whether\n/// // the trailing \\b matches.\n/// let haystack = \"foo 123 ☃\".as_bytes();\n/// let expected = MatchError::quit(0xE2, 8);\n/// let got = dfa.try_search_fwd(&Input::new(haystack));\n/// assert_eq!(Err(expected), got);\n///\n/// // Another example is executing a search where the span of the haystack\n/// // we specify is all ASCII, but there is non-ASCII just before it. This\n/// // correctly also reports an error.\n/// let input = Input::new(\"β123\").range(2..);\n/// let expected = MatchError::quit(0xB2, 1);\n/// let got = dfa.try_search_fwd(&input);\n/// assert_eq!(Err(expected), got);\n///\n/// // And similarly for the trailing word boundary.\n/// let input = Input::new(\"123β\").range(..3);\n/// let expected = MatchError::quit(0xCE, 3);\n/// let got = dfa.try_search_fwd(&input);\n/// assert_eq!(Err(expected), got);\n///\n/// # Ok::<(), Box<dyn std::error::Error>>(())\n/// ```\n596 pub fn unicode_word_boundary(mut self, yes: bool) -> Config {\n597     // We have a separate option for this instead of just setting the\n598     // appropriate quit bytes here because we don't want to set quit bytes\n599     // for every regex. We only want to set them when the regex contains a\n600     // Unicode word boundary.\n601     self.unicode_word_boundary = Some(yes);\n602     self\n603 }\n\nWhen inferring test input conditions or ranges, consider the following preconditions and expected return values or types:\n"
}