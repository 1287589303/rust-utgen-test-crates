{
  "system_pt": "As a software testing expert, infer the test input conditions or ranges based on the provided information. Follow these guidelines:\n1. Provide test input conditions or ranges in one line in plain text only, without additional explanations or Markdown formatting\n2. Analyze the function under test, context, preconditions, and expected return values or types to determine appropriate test input conditions or ranges\n3. The inferred test input conditions or ranges should comprehensively satisfy all provided preconditions simultaneously.\n4. Ensure the test input conditions or ranges cover boundary cases and edge scenarios\n",
  "static_pt": "The context for the focal function is as follows:\n// regex-automata/src/hybrid/dfa.rs\n// crate name is regex_automata\n#[cfg(feature = \"std\")]\ntype StateMap = std::collections::HashMap<State, LazyStateID>;\n#[cfg(not(feature = \"std\"))]\ntype StateMap = alloc::collections::BTreeMap<State, LazyStateID>;\nuse core::{iter, mem::size_of};\nuse alloc::vec::Vec;\nuse crate::{\n    hybrid::{\n        error::{BuildError, CacheError, StartError},\n        id::{LazyStateID, LazyStateIDError},\n        search,\n    },\n    nfa::thompson,\n    util::{\n        alphabet::{self, ByteClasses, ByteSet},\n        determinize::{self, State, StateBuilderEmpty, StateBuilderNFA},\n        empty, prefilter::Prefilter, primitives::{PatternID, StateID as NFAStateID},\n        search::{Anchored, HalfMatch, Input, MatchError, MatchKind, PatternSet},\n        sparse_set::SparseSets, start::{self, Start, StartByteMap},\n    },\n};\nconst MIN_STATES: usize = SENTINEL_STATES + 2;\nconst SENTINEL_STATES: usize = 3;\n#[derive(Clone, Debug)]\npub struct DFA {\n    config: Config,\n    nfa: thompson::NFA,\n    stride2: usize,\n    start_map: StartByteMap,\n    classes: ByteClasses,\n    quitset: ByteSet,\n    cache_capacity: usize,\n}\n#[derive(Clone, Copy, Debug, Eq, Hash, PartialEq)]\npub struct HalfMatch {\n    /// The pattern ID.\n    pattern: PatternID,\n    /// The offset of the match.\n    ///\n    /// For forward searches, the offset is exclusive. For reverse searches,\n    /// the offset is inclusive.\n    offset: usize,\n}\n#[derive(Clone)]\npub struct NFA(Arc<Inner>);\n#[derive(Clone, Debug, Default)]\npub struct Config {\n    match_kind: Option<MatchKind>,\n    pre: Option<Option<Prefilter>>,\n}\n#[derive(Clone, Debug)]\npub(crate) struct ByteSet([bool; 256]);\n#[derive(Clone, Copy, Debug)]\npub struct Config {\n    case_insensitive: bool,\n    multi_line: bool,\n    dot_matches_new_line: bool,\n    crlf: bool,\n    line_terminator: u8,\n    swap_greed: bool,\n    ignore_whitespace: bool,\n    unicode: bool,\n    utf8: bool,\n    nest_limit: u32,\n    octal: bool,\n}\n#[derive(Clone, Debug, Default)]\npub struct Config {\n    utf8: Option<bool>,\n    reverse: Option<bool>,\n    nfa_size_limit: Option<Option<usize>>,\n    shrink: Option<bool>,\n    which_captures: Option<WhichCaptures>,\n    look_matcher: Option<LookMatcher>,\n    #[cfg(test)]\n    unanchored_prefix: Option<bool>,\n}\n#[derive(Clone, Copy)]\npub struct ByteClasses([u8; 256]);\n#[cfg(feature = \"dfa-build\")]\n#[derive(Clone, Debug, Default)]\npub struct Config {\n    accelerate: Option<bool>,\n    pre: Option<Option<Prefilter>>,\n    minimize: Option<bool>,\n    match_kind: Option<MatchKind>,\n    start_kind: Option<StartKind>,\n    starts_for_each_pattern: Option<bool>,\n    byte_classes: Option<bool>,\n    unicode_word_boundary: Option<bool>,\n    quitset: Option<ByteSet>,\n    specialize_start_states: Option<bool>,\n    dfa_size_limit: Option<Option<usize>>,\n    determinize_size_limit: Option<Option<usize>>,\n}\n#[derive(Clone)]\npub struct Input<'h> {\n    haystack: &'h [u8],\n    span: Span,\n    anchored: Anchored,\n    earliest: bool,\n}\n#[derive(Clone, Debug, Default)]\npub struct Config {\n    match_kind: Option<MatchKind>,\n    pre: Option<Option<Prefilter>>,\n    starts_for_each_pattern: Option<bool>,\n    byte_classes: Option<bool>,\n    unicode_word_boundary: Option<bool>,\n    quitset: Option<ByteSet>,\n    specialize_start_states: Option<bool>,\n    cache_capacity: Option<usize>,\n    skip_cache_capacity_check: Option<bool>,\n    minimum_cache_clear_count: Option<Option<usize>>,\n    minimum_bytes_per_state: Option<Option<usize>>,\n}\n#[derive(Clone, Debug, Default)]\npub struct Config {\n    match_kind: Option<MatchKind>,\n    utf8_empty: Option<bool>,\n    autopre: Option<bool>,\n    pre: Option<Option<Prefilter>>,\n    which_captures: Option<WhichCaptures>,\n    nfa_size_limit: Option<Option<usize>>,\n    onepass_size_limit: Option<Option<usize>>,\n    hybrid_cache_capacity: Option<usize>,\n    hybrid: Option<bool>,\n    dfa: Option<bool>,\n    dfa_size_limit: Option<Option<usize>>,\n    dfa_state_limit: Option<Option<usize>>,\n    onepass: Option<bool>,\n    backtrack: Option<bool>,\n    byte_classes: Option<bool>,\n    line_terminator: Option<u8>,\n}\n#[derive(Clone, Copy, Debug, Default, Eq, PartialEq)]\npub(crate) struct ByteSet {\n    bits: BitSet,\n}\n#[derive(Clone, Debug)]\npub struct Config {\n    look_behind: Option<u8>,\n    anchored: Anchored,\n}\n#[derive(Clone)]\npub(crate) struct StartByteMap {\n    map: [Start; 256],\n}\n#[derive(Clone, Debug, Default)]\npub struct Config {\n    pre: Option<Option<Prefilter>>,\n    visited_capacity: Option<usize>,\n}\n#[derive(Clone, Debug)]\npub(crate) struct Config {\n    match_kind: MatchKind,\n    quit: ByteSet,\n    dfa_size_limit: Option<usize>,\n    determinize_size_limit: Option<usize>,\n}\n#[derive(Clone, Debug, Default)]\npub struct Config {\n    match_kind: Option<MatchKind>,\n    starts_for_each_pattern: Option<bool>,\n    byte_classes: Option<bool>,\n    size_limit: Option<Option<usize>>,\n}\n#[derive(Clone, Debug)]\npub struct Cache {\n    /// The transition table.\n    ///\n    /// Given a `current` LazyStateID and an `input` byte, the next state can\n    /// be computed via `trans[untagged(current) + equiv_class(input)]`. Notice\n    /// that no multiplication is used. That's because state identifiers are\n    /// \"premultiplied.\"\n    ///\n    /// Note that the next state may be the \"unknown\" state. In this case, the\n    /// next state is not known and determinization for `current` on `input`\n    /// must be performed.\n    trans: Vec<LazyStateID>,\n    /// The starting states for this DFA.\n    ///\n    /// These are computed lazily. Initially, these are all set to \"unknown\"\n    /// lazy state IDs.\n    ///\n    /// When 'starts_for_each_pattern' is disabled (the default), then the size\n    /// of this is constrained to the possible starting configurations based\n    /// on the search parameters. (At time of writing, that's 4.) However,\n    /// when starting states for each pattern is enabled, then there are N\n    /// additional groups of starting states, where each group reflects the\n    /// different possible configurations and N is the number of patterns.\n    starts: Vec<LazyStateID>,\n    /// A sequence of NFA/DFA powerset states that have been computed for this\n    /// lazy DFA. This sequence is indexable by untagged LazyStateIDs. (Every\n    /// tagged LazyStateID can be used to index this sequence by converting it\n    /// to its untagged form.)\n    states: Vec<State>,\n    /// A map from states to their corresponding IDs. This map may be accessed\n    /// via the raw byte representation of a state, which means that a `State`\n    /// does not need to be allocated to determine whether it already exists\n    /// in this map. Indeed, the existence of such a state is what determines\n    /// whether we allocate a new `State` or not.\n    ///\n    /// The higher level idea here is that we do just enough determinization\n    /// for a state to check whether we've already computed it. If we have,\n    /// then we can save a little (albeit not much) work. The real savings is\n    /// in memory usage. If we never checked for trivially duplicate states,\n    /// then our memory usage would explode to unreasonable levels.\n    states_to_id: StateMap,\n    /// Sparse sets used to track which NFA states have been visited during\n    /// various traversals.\n    sparses: SparseSets,\n    /// Scratch space for traversing the NFA graph. (We use space on the heap\n    /// instead of the call stack.)\n    stack: Vec<NFAStateID>,\n    /// Scratch space for building a NFA/DFA powerset state. This is used to\n    /// help amortize allocation since not every powerset state generated is\n    /// added to the cache. In particular, if it already exists in the cache,\n    /// then there is no need to allocate a new `State` for it.\n    scratch_state_builder: StateBuilderEmpty,\n    /// A simple abstraction for handling the saving of at most a single state\n    /// across a cache clearing. This is required for correctness. Namely, if\n    /// adding a new state after clearing the cache fails, then the caller\n    /// must retain the ability to continue using the state ID given. The\n    /// state corresponding to the state ID is what we preserve across cache\n    /// clearings.\n    state_saver: StateSaver,\n    /// The memory usage, in bytes, used by 'states' and 'states_to_id'. We\n    /// track this as new states are added since states use a variable amount\n    /// of heap. Tracking this as we add states makes it possible to compute\n    /// the total amount of memory used by the determinizer in constant time.\n    memory_usage_state: usize,\n    /// The number of times the cache has been cleared. When a minimum cache\n    /// clear count is set, then the cache will return an error instead of\n    /// clearing the cache if the count has been exceeded.\n    clear_count: usize,\n    /// The total number of bytes searched since the last time this cache was\n    /// cleared, not including the current search.\n    ///\n    /// This can be added to the length of the current search to get the true\n    /// total number of bytes searched.\n    ///\n    /// This is generally only non-zero when the\n    /// `Cache::search_{start,update,finish}` APIs are used to track search\n    /// progress.\n    bytes_searched: usize,\n    /// The progress of the current search.\n    ///\n    /// This is only non-`None` when callers utlize the `Cache::search_start`,\n    /// `Cache::search_update` and `Cache::search_finish` APIs.\n    ///\n    /// The purpose of recording search progress is to be able to make a\n    /// determination about the efficiency of the cache. Namely, by keeping\n    /// track of the\n    progress: Option<SearchProgress>,\n}\n#[derive(Clone, Debug, Eq, PartialEq)]\npub struct MatchError(\n    #[cfg(feature = \"alloc\")]\n    alloc::boxed::Box<MatchErrorKind>,\n    #[cfg(not(feature = \"alloc\"))]\n    MatchErrorKind,\n);\nimpl DFA {\n    #[inline]\n    pub fn try_search_fwd(\n        &self,\n        cache: &mut Cache,\n        input: &Input<'_>,\n    ) -> Result<Option<HalfMatch>, MatchError> {\n        let utf8empty = self.get_nfa().has_empty() && self.get_nfa().is_utf8();\n        let hm = match search::find_fwd(self, cache, input)? {\n            None => return Ok(None),\n            Some(hm) if !utf8empty => return Ok(Some(hm)),\n            Some(hm) => hm,\n        };\n        empty::skip_splits_fwd(\n            input,\n            hm,\n            hm.offset(),\n            |input| {\n                let got = search::find_fwd(self, cache, input)?;\n                Ok(got.map(|hm| (hm, hm.offset())))\n            },\n        )\n    }\n    #[inline]\n    pub fn try_search_rev(\n        &self,\n        cache: &mut Cache,\n        input: &Input<'_>,\n    ) -> Result<Option<HalfMatch>, MatchError> {}\n    #[inline]\n    pub fn try_search_overlapping_fwd(\n        &self,\n        cache: &mut Cache,\n        input: &Input<'_>,\n        state: &mut OverlappingState,\n    ) -> Result<(), MatchError> {}\n    #[inline]\n    pub fn try_search_overlapping_rev(\n        &self,\n        cache: &mut Cache,\n        input: &Input<'_>,\n        state: &mut OverlappingState,\n    ) -> Result<(), MatchError> {}\n    #[inline]\n    pub fn try_which_overlapping_matches(\n        &self,\n        cache: &mut Cache,\n        input: &Input<'_>,\n        patset: &mut PatternSet,\n    ) -> Result<(), MatchError> {}\n}\nimpl HalfMatch {\n    #[inline]\n    pub fn new(pattern: PatternID, offset: usize) -> HalfMatch {}\n    #[inline]\n    pub fn must(pattern: usize, offset: usize) -> HalfMatch {}\n    #[inline]\n    pub fn pattern(&self) -> PatternID {}\n    #[inline]\n    pub fn offset(&self) -> usize {\n        self.offset\n    }\n}\nimpl NFA {\n    #[cfg(feature = \"syntax\")]\n    pub fn new(pattern: &str) -> Result<NFA, BuildError> {}\n    #[cfg(feature = \"syntax\")]\n    pub fn new_many<P: AsRef<str>>(patterns: &[P]) -> Result<NFA, BuildError> {}\n    pub fn always_match() -> NFA {}\n    pub fn never_match() -> NFA {}\n    #[cfg(feature = \"syntax\")]\n    pub fn config() -> Config {}\n    #[cfg(feature = \"syntax\")]\n    pub fn compiler() -> Compiler {}\n    pub fn patterns(&self) -> PatternIter<'_> {}\n    #[inline]\n    pub fn pattern_len(&self) -> usize {}\n    #[inline]\n    pub fn start_anchored(&self) -> StateID {}\n    #[inline]\n    pub fn start_unanchored(&self) -> StateID {}\n    #[inline]\n    pub fn start_pattern(&self, pid: PatternID) -> Option<StateID> {}\n    #[inline]\n    pub(crate) fn byte_class_set(&self) -> &ByteClassSet {}\n    #[inline]\n    pub fn byte_classes(&self) -> &ByteClasses {}\n    #[inline]\n    pub fn state(&self, id: StateID) -> &State {}\n    #[inline]\n    pub fn states(&self) -> &[State] {}\n    #[inline]\n    pub fn group_info(&self) -> &GroupInfo {}\n    #[inline]\n    pub fn has_capture(&self) -> bool {}\n    #[inline]\n    pub fn has_empty(&self) -> bool {\n        self.0.has_empty\n    }\n    #[inline]\n    pub fn is_utf8(&self) -> bool {\n        self.0.utf8\n    }\n    #[inline]\n    pub fn is_reverse(&self) -> bool {}\n    #[inline]\n    pub fn is_always_start_anchored(&self) -> bool {}\n    #[inline]\n    pub fn look_matcher(&self) -> &LookMatcher {}\n    #[inline]\n    pub fn look_set_any(&self) -> LookSet {}\n    #[inline]\n    pub fn look_set_prefix_any(&self) -> LookSet {}\n    #[inline]\n    pub fn memory_usage(&self) -> usize {}\n}\n#[inline(never)]\npub(crate) fn find_fwd(\n    dfa: &DFA,\n    cache: &mut Cache,\n    input: &Input<'_>,\n) -> Result<Option<HalfMatch>, MatchError> {\n    if input.is_done() {\n        return Ok(None);\n    }\n    let pre = if input.get_anchored().is_anchored() {\n        None\n    } else {\n        dfa.get_config().get_prefilter()\n    };\n    if pre.is_some() {\n        if input.get_earliest() {\n            find_fwd_imp(dfa, cache, input, pre, true)\n        } else {\n            find_fwd_imp(dfa, cache, input, pre, false)\n        }\n    } else {\n        if input.get_earliest() {\n            find_fwd_imp(dfa, cache, input, None, true)\n        } else {\n            find_fwd_imp(dfa, cache, input, None, false)\n        }\n    }\n}\n#[cold]\n#[inline(never)]\npub(crate) fn skip_splits_fwd<T, F>(\n    input: &Input<'_>,\n    init_value: T,\n    match_offset: usize,\n    find: F,\n) -> Result<Option<T>, MatchError>\nwhere\n    F: FnMut(&Input<'_>) -> Result<Option<(T, usize)>, MatchError>,\n{\n    skip_splits(true, input, init_value, match_offset, find)\n}\n\nThe function to be tested is presented with each line formatted as 'line number + code':\n/// Executes a forward search and returns the end position of the leftmost\n/// match that is found. If no match exists, then `None` is returned.\n///\n/// In particular, this method continues searching even after it enters\n/// a match state. The search only terminates once it has reached the\n/// end of the input or when it has entered a dead or quit state. Upon\n/// termination, the position of the last byte seen while still in a match\n/// state is returned.\n///\n/// # Errors\n///\n/// This routine errors if the search could not complete. This can occur\n/// in a number of circumstances:\n///\n/// * The configuration of the lazy DFA may permit it to \"quit\" the search.\n/// For example, setting quit bytes or enabling heuristic support for\n/// Unicode word boundaries. The default configuration does not enable any\n/// option that could result in the lazy DFA quitting.\n/// * The configuration of the lazy DFA may also permit it to \"give up\"\n/// on a search if it makes ineffective use of its transition table\n/// cache. The default configuration does not enable this by default,\n/// although it is typically a good idea to.\n/// * When the provided `Input` configuration is not supported. For\n/// example, by providing an unsupported anchor mode.\n///\n/// When a search returns an error, callers cannot know whether a match\n/// exists or not.\n///\n/// # Example\n///\n/// This example shows how to run a basic search.\n///\n/// ```\n/// use regex_automata::{hybrid::dfa::DFA, HalfMatch, Input};\n///\n/// let dfa = DFA::new(\"foo[0-9]+\")?;\n/// let mut cache = dfa.create_cache();\n/// let expected = HalfMatch::must(0, 8);\n/// assert_eq!(Some(expected), dfa.try_search_fwd(\n///     &mut cache, &Input::new(\"foo12345\"))?,\n/// );\n///\n/// // Even though a match is found after reading the first byte (`a`),\n/// // the leftmost first match semantics demand that we find the earliest\n/// // match that prefers earlier parts of the pattern over later parts.\n/// let dfa = DFA::new(\"abc|a\")?;\n/// let mut cache = dfa.create_cache();\n/// let expected = HalfMatch::must(0, 3);\n/// assert_eq!(Some(expected), dfa.try_search_fwd(\n///     &mut cache, &Input::new(\"abc\"))?,\n/// );\n///\n/// # Ok::<(), Box<dyn std::error::Error>>(())\n/// ```\n///\n/// # Example: specific pattern search\n///\n/// This example shows how to build a lazy multi-DFA that permits searching\n/// for specific patterns.\n///\n/// ```\n/// use regex_automata::{\n///     hybrid::dfa::DFA,\n///     Anchored, HalfMatch, PatternID, Input,\n/// };\n///\n/// let dfa = DFA::builder()\n///     .configure(DFA::config().starts_for_each_pattern(true))\n///     .build_many(&[\"[a-z0-9]{6}\", \"[a-z][a-z0-9]{5}\"])?;\n/// let mut cache = dfa.create_cache();\n/// let haystack = \"foo123\";\n///\n/// // Since we are using the default leftmost-first match and both\n/// // patterns match at the same starting position, only the first pattern\n/// // will be returned in this case when doing a search for any of the\n/// // patterns.\n/// let expected = Some(HalfMatch::must(0, 6));\n/// let got = dfa.try_search_fwd(&mut cache, &Input::new(haystack))?;\n/// assert_eq!(expected, got);\n///\n/// // But if we want to check whether some other pattern matches, then we\n/// // can provide its pattern ID.\n/// let expected = Some(HalfMatch::must(1, 6));\n/// let input = Input::new(haystack)\n///     .anchored(Anchored::Pattern(PatternID::must(1)));\n/// let got = dfa.try_search_fwd(&mut cache, &input)?;\n/// assert_eq!(expected, got);\n///\n/// # Ok::<(), Box<dyn std::error::Error>>(())\n/// ```\n///\n/// # Example: specifying the bounds of a search\n///\n/// This example shows how providing the bounds of a search can produce\n/// different results than simply sub-slicing the haystack.\n///\n/// ```\n/// use regex_automata::{hybrid::dfa::DFA, HalfMatch, Input};\n///\n/// // N.B. We disable Unicode here so that we use a simple ASCII word\n/// // boundary. Alternatively, we could enable heuristic support for\n/// // Unicode word boundaries since our haystack is pure ASCII.\n/// let dfa = DFA::new(r\"(?-u)\\b[0-9]{3}\\b\")?;\n/// let mut cache = dfa.create_cache();\n/// let haystack = \"foo123bar\";\n///\n/// // Since we sub-slice the haystack, the search doesn't know about the\n/// // larger context and assumes that `123` is surrounded by word\n/// // boundaries. And of course, the match position is reported relative\n/// // to the sub-slice as well, which means we get `3` instead of `6`.\n/// let expected = Some(HalfMatch::must(0, 3));\n/// let got = dfa.try_search_fwd(\n///     &mut cache,\n///     &Input::new(&haystack[3..6]),\n/// )?;\n/// assert_eq!(expected, got);\n///\n/// // But if we provide the bounds of the search within the context of the\n/// // entire haystack, then the search can take the surrounding context\n/// // into account. (And if we did find a match, it would be reported\n/// // as a valid offset into `haystack` instead of its sub-slice.)\n/// let expected = None;\n/// let got = dfa.try_search_fwd(\n///     &mut cache,\n///     &Input::new(haystack).range(3..6),\n/// )?;\n/// assert_eq!(expected, got);\n///\n/// # Ok::<(), Box<dyn std::error::Error>>(())\n/// ```\n589 pub fn try_search_fwd(\n590     &self,\n591     cache: &mut Cache,\n592     input: &Input<'_>,\n593 ) -> Result<Option<HalfMatch>, MatchError> {\n594     let utf8empty = self.get_nfa().has_empty() && self.get_nfa().is_utf8();\n595     let hm = match search::find_fwd(self, cache, input)? {\n596         None => return Ok(None),\n597         Some(hm) if !utf8empty => return Ok(Some(hm)),\n598         Some(hm) => hm,\n599     };\n600     // We get to this point when we know our DFA can match the empty string\n601     // AND when UTF-8 mode is enabled. In this case, we skip any matches\n602     // whose offset splits a codepoint. Such a match is necessarily a\n603     // zero-width match, because UTF-8 mode requires the underlying NFA\n604     // to be built such that all non-empty matches span valid UTF-8.\n605     // Therefore, any match that ends in the middle of a codepoint cannot\n606     // be part of a span of valid UTF-8 and thus must be an empty match.\n607     // In such cases, we skip it, so as not to report matches that split a\n608     // codepoint.\n609     //\n610     // Note that this is not a checked assumption. Callers *can* provide an\n611     // NFA with UTF-8 mode enabled but produces non-empty matches that span\n612     // invalid UTF-8. But doing so is documented to result in unspecified\n613     // behavior.\n614     empty::skip_splits_fwd(input, hm, hm.offset(), |input| {\n615         let got = search::find_fwd(self, cache, input)?;\n616         Ok(got.map(|hm| (hm, hm.offset())))\n617     })\n618 }\n\nWhen inferring test input conditions or ranges, consider the following preconditions and expected return values or types:\n"
}