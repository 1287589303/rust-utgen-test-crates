{
  "system_pt": "As a software testing expert, infer the test input conditions or ranges based on the provided information. Follow these guidelines:\n1. Provide test input conditions or ranges in one line in plain text only, without additional explanations or Markdown formatting\n2. Analyze the function under test, context, preconditions, and expected return values or types to determine appropriate test input conditions or ranges\n3. The inferred test input conditions or ranges should comprehensively satisfy all provided preconditions simultaneously.\n4. Ensure the test input conditions or ranges cover boundary cases and edge scenarios\n",
  "static_pt": "The context for the focal function is as follows:\n// regex-automata/src/dfa/sparse.rs\n// crate name is regex_automata\n#[cfg(feature = \"dfa-build\")]\nuse core::iter;\nuse core::{fmt, mem::size_of};\n#[cfg(feature = \"dfa-build\")]\nuse alloc::{vec, vec::Vec};\n#[cfg(feature = \"dfa-build\")]\nuse crate::dfa::dense::{self, BuildError};\nuse crate::{\n    dfa::{\n        automaton::{fmt_state_indicator, Automaton, StartError},\n        dense::Flags, special::Special, StartKind, DEAD,\n    },\n    util::{\n        alphabet::{ByteClasses, ByteSet},\n        escape::DebugByte, int::{Pointer, Usize, U16, U32},\n        prefilter::Prefilter, primitives::{PatternID, StateID},\n        search::Anchored, start::{self, Start, StartByteMap},\n        wire::{self, DeserializeError, Endian, SerializeError},\n    },\n};\nconst LABEL: &str = \"rust-regex-automata-dfa-sparse\";\nconst VERSION: u32 = 2;\npub unsafe trait Automaton {\n    fn next_state(&self, current: StateID, input: u8) -> StateID;\n    unsafe fn next_state_unchecked(&self, current: StateID, input: u8) -> StateID;\n    fn next_eoi_state(&self, current: StateID) -> StateID;\n    fn start_state(&self, config: &start::Config) -> Result<StateID, StartError>;\n    fn start_state_forward(&self, input: &Input<'_>) -> Result<StateID, MatchError>;\n    fn start_state_reverse(&self, input: &Input<'_>) -> Result<StateID, MatchError>;\n    #[inline]\n    fn universal_start_state(&self, _mode: Anchored) -> Option<StateID>;\n    fn is_special_state(&self, id: StateID) -> bool;\n    fn is_dead_state(&self, id: StateID) -> bool;\n    fn is_quit_state(&self, id: StateID) -> bool;\n    fn is_match_state(&self, id: StateID) -> bool;\n    fn is_start_state(&self, id: StateID) -> bool;\n    fn is_accel_state(&self, id: StateID) -> bool;\n    fn pattern_len(&self) -> usize;\n    fn match_len(&self, id: StateID) -> usize;\n    fn match_pattern(&self, id: StateID, index: usize) -> PatternID;\n    fn has_empty(&self) -> bool;\n    fn is_utf8(&self) -> bool;\n    fn is_always_start_anchored(&self) -> bool;\n    #[inline]\n    fn accelerator(&self, _id: StateID) -> &[u8];\n    #[inline]\n    fn get_prefilter(&self) -> Option<&Prefilter>;\n    #[inline]\n    fn try_search_fwd(&self, input: &Input<'_>) -> Result<Option<HalfMatch>, MatchError>;\n    #[inline]\n    fn try_search_rev(&self, input: &Input<'_>) -> Result<Option<HalfMatch>, MatchError>;\n    #[inline]\n    fn try_search_overlapping_fwd(\n        &self,\n        input: &Input<'_>,\n        state: &mut OverlappingState,\n    ) -> Result<(), MatchError>;\n    #[inline]\n    fn try_search_overlapping_rev(\n        &self,\n        input: &Input<'_>,\n        state: &mut OverlappingState,\n    ) -> Result<(), MatchError>;\n    #[cfg(feature = \"alloc\")]\n    #[inline]\n    fn try_which_overlapping_matches(\n        &self,\n        input: &Input<'_>,\n        patset: &mut PatternSet,\n    ) -> Result<(), MatchError>;\n}\n#[derive(Clone)]\npub struct DFA<T> {\n    tt: Transitions<T>,\n    st: StartTable<T>,\n    special: Special,\n    pre: Option<Prefilter>,\n    quitset: ByteSet,\n    flags: Flags,\n}\n#[derive(Clone, Copy, Debug)]\npub(crate) struct Special {\n    /// The identifier of the last special state in a DFA. A state is special\n    /// if and only if its identifier is less than or equal to `max`.\n    pub(crate) max: StateID,\n    /// The identifier of the quit state in a DFA. (There is no analogous field\n    /// for the dead state since the dead state's ID is always zero, regardless\n    /// of state ID size.)\n    pub(crate) quit_id: StateID,\n    /// The identifier of the first match state.\n    pub(crate) min_match: StateID,\n    /// The identifier of the last match state.\n    pub(crate) max_match: StateID,\n    /// The identifier of the first accelerated state.\n    pub(crate) min_accel: StateID,\n    /// The identifier of the last accelerated state.\n    pub(crate) max_accel: StateID,\n    /// The identifier of the first start state.\n    pub(crate) min_start: StateID,\n    /// The identifier of the last start state.\n    pub(crate) max_start: StateID,\n}\n#[derive(Clone, Copy, Debug)]\npub(crate) struct Flags {\n    /// Whether the DFA can match the empty string. When this is false, all\n    /// matches returned by this DFA are guaranteed to have non-zero length.\n    pub(crate) has_empty: bool,\n    /// Whether the DFA should only produce matches with spans that correspond\n    /// to valid UTF-8. This also includes omitting any zero-width matches that\n    /// split the UTF-8 encoding of a codepoint.\n    pub(crate) is_utf8: bool,\n    /// Whether the DFA is always anchored or not, regardless of `Input`\n    /// configuration. This is useful for avoiding a reverse scan even when\n    /// executing unanchored searches.\n    pub(crate) is_always_start_anchored: bool,\n}\n#[derive(Clone, Copy, Debug, Default, Eq, PartialEq)]\npub(crate) struct ByteSet {\n    bits: BitSet,\n}\n#[derive(Clone)]\nstruct Transitions<T> {\n    /// The raw encoding of each state in this DFA.\n    ///\n    /// Each state has the following information:\n    ///\n    /// * A set of transitions to subsequent states. Transitions to the dead\n    ///   state are omitted.\n    /// * If the state can be accelerated, then any additional accelerator\n    ///   information.\n    /// * If the state is a match state, then the state contains all pattern\n    ///   IDs that match when in that state.\n    ///\n    /// To decode a state, use Transitions::state.\n    ///\n    /// In practice, T is either Vec<u8> or &[u8].\n    sparse: T,\n    /// A set of equivalence classes, where a single equivalence class\n    /// represents a set of bytes that never discriminate between a match\n    /// and a non-match in the DFA. Each equivalence class corresponds to a\n    /// single character in this DFA's alphabet, where the maximum number of\n    /// characters is 257 (each possible value of a byte plus the special\n    /// EOI transition). Consequently, the number of equivalence classes\n    /// corresponds to the number of transitions for each DFA state. Note\n    /// though that the *space* used by each DFA state in the transition table\n    /// may be larger. The total space used by each DFA state is known as the\n    /// stride and is documented above.\n    ///\n    /// The only time the number of equivalence classes is fewer than 257 is\n    /// if the DFA's kind uses byte classes which is the default. Equivalence\n    /// classes should generally only be disabled when debugging, so that\n    /// the transitions themselves aren't obscured. Disabling them has no\n    /// other benefit, since the equivalence class map is always used while\n    /// searching. In the vast majority of cases, the number of equivalence\n    /// classes is substantially smaller than 257, particularly when large\n    /// Unicode classes aren't used.\n    ///\n    /// N.B. Equivalence classes aren't particularly useful in a sparse DFA\n    /// in the current implementation, since equivalence classes generally tend\n    /// to correspond to continuous ranges of bytes that map to the same\n    /// transition. So in a sparse DFA, equivalence classes don't really lead\n    /// to a space savings. In the future, it would be good to try and remove\n    /// them from sparse DFAs entirely, but requires a bit of work since sparse\n    /// DFAs are built from dense DFAs, which are in turn built on top of\n    /// equivalence classes.\n    classes: ByteClasses,\n    /// The total number of states in this DFA. Note that a DFA always has at\n    /// least one state---the dead state---even the empty DFA. In particular,\n    /// the dead state always has ID 0 and is correspondingly always the first\n    /// state. The dead state is never a match state.\n    state_len: usize,\n    /// The total number of unique patterns represented by these match states.\n    pattern_len: usize,\n}\n#[derive(Clone)]\nstruct StartTable<T> {\n    /// The initial start state IDs as a contiguous table of native endian\n    /// encoded integers, represented by `S`.\n    ///\n    /// In practice, T is either Vec<u8> or &[u8] and has no alignment\n    /// requirements.\n    ///\n    /// The first `2 * stride` (currently always 8) entries always correspond\n    /// to the starts states for the entire DFA, with the first 4 entries being\n    /// for unanchored searches and the second 4 entries being for anchored\n    /// searches. To keep things simple, we always use 8 entries even if the\n    /// `StartKind` is not both.\n    ///\n    /// After that, there are `stride * patterns` state IDs, where `patterns`\n    /// may be zero in the case of a DFA with no patterns or in the case where\n    /// the DFA was built without enabling starting states for each pattern.\n    table: T,\n    /// The starting state configuration supported. When 'both', both\n    /// unanchored and anchored searches work. When 'unanchored', anchored\n    /// searches panic. When 'anchored', unanchored searches panic.\n    kind: StartKind,\n    /// The start state configuration for every possible byte.\n    start_map: StartByteMap,\n    /// The number of starting state IDs per pattern.\n    stride: usize,\n    /// The total number of patterns for which starting states are encoded.\n    /// This is `None` for DFAs that were built without start states for each\n    /// pattern. Thus, one cannot use this field to say how many patterns\n    /// are in the DFA in all cases. It is specific to how many patterns are\n    /// represented in this start table.\n    pattern_len: Option<usize>,\n    /// The universal starting state for unanchored searches. This is only\n    /// present when the DFA supports unanchored searches and when all starting\n    /// state IDs for an unanchored search are equivalent.\n    universal_start_unanchored: Option<StateID>,\n    /// The universal starting state for anchored searches. This is only\n    /// present when the DFA supports anchored searches and when all starting\n    /// state IDs for an anchored search are equivalent.\n    universal_start_anchored: Option<StateID>,\n}\n#[derive(Clone)]\npub(crate) struct StartTable<T> {\n    /// The initial start state IDs.\n    ///\n    /// In practice, T is either `Vec<u32>` or `&[u32]`.\n    ///\n    /// The first `2 * stride` (currently always 8) entries always correspond\n    /// to the starts states for the entire DFA, with the first 4 entries being\n    /// for unanchored searches and the second 4 entries being for anchored\n    /// searches. To keep things simple, we always use 8 entries even if the\n    /// `StartKind` is not both.\n    ///\n    /// After that, there are `stride * patterns` state IDs, where `patterns`\n    /// may be zero in the case of a DFA with no patterns or in the case where\n    /// the DFA was built without enabling starting states for each pattern.\n    table: T,\n    /// The starting state configuration supported. When 'both', both\n    /// unanchored and anchored searches work. When 'unanchored', anchored\n    /// searches panic. When 'anchored', unanchored searches panic.\n    kind: StartKind,\n    /// The start state configuration for every possible byte.\n    start_map: StartByteMap,\n    /// The number of starting state IDs per pattern.\n    stride: usize,\n    /// The total number of patterns for which starting states are encoded.\n    /// This is `None` for DFAs that were built without start states for each\n    /// pattern. Thus, one cannot use this field to say how many patterns\n    /// are in the DFA in all cases. It is specific to how many patterns are\n    /// represented in this start table.\n    pattern_len: Option<usize>,\n    /// The universal starting state for unanchored searches. This is only\n    /// present when the DFA supports unanchored searches and when all starting\n    /// state IDs for an unanchored search are equivalent.\n    universal_start_unanchored: Option<StateID>,\n    /// The universal starting state for anchored searches. This is only\n    /// present when the DFA supports anchored searches and when all starting\n    /// state IDs for an anchored search are equivalent.\n    universal_start_anchored: Option<StateID>,\n}\n#[derive(Clone, Debug)]\npub(crate) struct ByteSet([bool; 256]);\n#[derive(Debug)]\npub struct SerializeError {\n    /// The name of the thing that a buffer is too small for.\n    ///\n    /// Currently, the only kind of serialization error is one that is\n    /// committed by a caller: providing a destination buffer that is too\n    /// small to fit the serialized object. This makes sense conceptually,\n    /// since every valid inhabitant of a type should be serializable.\n    ///\n    /// This is somewhat exposed in the public API of this crate. For example,\n    /// the `to_bytes_{big,little}_endian` APIs return a `Vec<u8>` and are\n    /// guaranteed to never panic or error. This is only possible because the\n    /// implementation guarantees that it will allocate a `Vec<u8>` that is\n    /// big enough.\n    ///\n    /// In summary, if a new serialization error kind needs to be added, then\n    /// it will need careful consideration.\n    what: &'static str,\n}\n#[derive(Clone, Debug)]\npub struct Prefilter {\n    #[cfg(not(feature = \"alloc\"))]\n    _unused: (),\n    #[cfg(feature = \"alloc\")]\n    pre: Arc<dyn PrefilterI>,\n    #[cfg(feature = \"alloc\")]\n    is_fast: bool,\n    #[cfg(feature = \"alloc\")]\n    max_needle_len: usize,\n}\nimpl<T: AsRef<[u8]>> DFA<T> {\n    #[cfg(feature = \"dfa-build\")]\n    pub fn to_bytes_little_endian(&self) -> Vec<u8> {}\n    #[cfg(feature = \"dfa-build\")]\n    pub fn to_bytes_big_endian(&self) -> Vec<u8> {}\n    #[cfg(feature = \"dfa-build\")]\n    pub fn to_bytes_native_endian(&self) -> Vec<u8> {}\n    #[cfg(feature = \"dfa-build\")]\n    fn to_bytes<E: Endian>(&self) -> Vec<u8> {\n        let mut buf = vec![0; self.write_to_len()];\n        self.write_to::<E>(&mut buf).unwrap();\n        buf\n    }\n    pub fn write_to_little_endian(\n        &self,\n        dst: &mut [u8],\n    ) -> Result<usize, SerializeError> {}\n    pub fn write_to_big_endian(&self, dst: &mut [u8]) -> Result<usize, SerializeError> {}\n    pub fn write_to_native_endian(\n        &self,\n        dst: &mut [u8],\n    ) -> Result<usize, SerializeError> {}\n    fn write_to<E: Endian>(&self, dst: &mut [u8]) -> Result<usize, SerializeError> {}\n    pub fn write_to_len(&self) -> usize {\n        wire::write_label_len(LABEL) + wire::write_endianness_check_len()\n            + wire::write_version_len() + size_of::<u32>() + self.flags.write_to_len()\n            + self.tt.write_to_len() + self.st.write_to_len()\n            + self.special.write_to_len() + self.quitset.write_to_len()\n    }\n}\n\nThe function to be tested is presented with each line formatted as 'line number + code':\n/// The implementation of the public `to_bytes` serialization methods,\n/// which is generic over endianness.\n626 fn to_bytes<E: Endian>(&self) -> Vec<u8> {\n627     let mut buf = vec![0; self.write_to_len()];\n628     // This should always succeed since the only possible serialization\n629     // error is providing a buffer that's too small, but we've ensured that\n630     // `buf` is big enough here.\n631     self.write_to::<E>(&mut buf).unwrap();\n632     buf\n633 }\n\nWhen inferring test input conditions or ranges, consider the following preconditions and expected return values or types:\n"
}