{
  "system_pt": "As a software testing expert, infer the test input conditions or ranges based on the provided information. Follow these guidelines:\n1. Provide test input conditions or ranges in one line in plain text only, without additional explanations or Markdown formatting\n2. Analyze the function under test, context, preconditions, and expected return values or types to determine appropriate test input conditions or ranges\n3. The inferred test input conditions or ranges should comprehensively satisfy all provided preconditions simultaneously.\n4. Ensure the test input conditions or ranges cover boundary cases and edge scenarios\n",
  "static_pt": "The context for the focal function is as follows:\n// regex-automata/src/dfa/dense.rs\n// crate name is regex_automata\n#[cfg(feature = \"alloc\")]\npub(crate) type OwnedDFA = DFA<alloc::vec::Vec<u32>>;\n#[cfg(feature = \"dfa-build\")]\nuse core::cmp;\nuse core::{fmt, iter, mem::size_of, slice};\n#[cfg(feature = \"dfa-build\")]\nuse alloc::{\n    collections::{BTreeMap, BTreeSet},\n    vec, vec::Vec,\n};\n#[cfg(feature = \"dfa-build\")]\nuse crate::{\n    dfa::{accel::Accel, determinize, minimize::Minimizer, remapper::Remapper, sparse},\n    nfa::thompson, util::{look::LookMatcher, search::MatchKind},\n};\nuse crate::{\n    dfa::{\n        accel::Accels, automaton::{fmt_state_indicator, Automaton, StartError},\n        special::Special, start::StartKind, DEAD,\n    },\n    util::{\n        alphabet::{self, ByteClasses, ByteSet},\n        int::{Pointer, Usize},\n        prefilter::Prefilter, primitives::{PatternID, StateID},\n        search::Anchored, start::{self, Start, StartByteMap},\n        wire::{self, DeserializeError, Endian, SerializeError},\n    },\n};\nconst LABEL: &str = \"rust-regex-automata-dfa-dense\";\nconst VERSION: u32 = 2;\npub unsafe trait Automaton {\n    fn next_state(&self, current: StateID, input: u8) -> StateID;\n    unsafe fn next_state_unchecked(&self, current: StateID, input: u8) -> StateID;\n    fn next_eoi_state(&self, current: StateID) -> StateID;\n    fn start_state(&self, config: &start::Config) -> Result<StateID, StartError>;\n    fn start_state_forward(&self, input: &Input<'_>) -> Result<StateID, MatchError>;\n    fn start_state_reverse(&self, input: &Input<'_>) -> Result<StateID, MatchError>;\n    #[inline]\n    fn universal_start_state(&self, _mode: Anchored) -> Option<StateID>;\n    fn is_special_state(&self, id: StateID) -> bool;\n    fn is_dead_state(&self, id: StateID) -> bool;\n    fn is_quit_state(&self, id: StateID) -> bool;\n    fn is_match_state(&self, id: StateID) -> bool;\n    fn is_start_state(&self, id: StateID) -> bool;\n    fn is_accel_state(&self, id: StateID) -> bool;\n    fn pattern_len(&self) -> usize;\n    fn match_len(&self, id: StateID) -> usize;\n    fn match_pattern(&self, id: StateID, index: usize) -> PatternID;\n    fn has_empty(&self) -> bool;\n    fn is_utf8(&self) -> bool;\n    fn is_always_start_anchored(&self) -> bool;\n    #[inline]\n    fn accelerator(&self, _id: StateID) -> &[u8];\n    #[inline]\n    fn get_prefilter(&self) -> Option<&Prefilter>;\n    #[inline]\n    fn try_search_fwd(&self, input: &Input<'_>) -> Result<Option<HalfMatch>, MatchError>;\n    #[inline]\n    fn try_search_rev(&self, input: &Input<'_>) -> Result<Option<HalfMatch>, MatchError>;\n    #[inline]\n    fn try_search_overlapping_fwd(\n        &self,\n        input: &Input<'_>,\n        state: &mut OverlappingState,\n    ) -> Result<(), MatchError>;\n    #[inline]\n    fn try_search_overlapping_rev(\n        &self,\n        input: &Input<'_>,\n        state: &mut OverlappingState,\n    ) -> Result<(), MatchError>;\n    #[cfg(feature = \"alloc\")]\n    #[inline]\n    fn try_which_overlapping_matches(\n        &self,\n        input: &Input<'_>,\n        patset: &mut PatternSet,\n    ) -> Result<(), MatchError>;\n}\n#[derive(Clone)]\npub struct DFA<T> {\n    /// The transition table for this DFA. This includes the transitions\n    /// themselves, along with the stride, number of states and the equivalence\n    /// class mapping.\n    tt: TransitionTable<T>,\n    /// The set of starting state identifiers for this DFA. The starting state\n    /// IDs act as pointers into the transition table. The specific starting\n    /// state chosen for each search is dependent on the context at which the\n    /// search begins.\n    st: StartTable<T>,\n    /// The set of match states and the patterns that match for each\n    /// corresponding match state.\n    ///\n    /// This structure is technically only needed because of support for\n    /// multi-regexes. Namely, multi-regexes require answering not just whether\n    /// a match exists, but _which_ patterns match. So we need to store the\n    /// matching pattern IDs for each match state. We do this even when there\n    /// is only one pattern for the sake of simplicity. In practice, this uses\n    /// up very little space for the case of one pattern.\n    ms: MatchStates<T>,\n    /// Information about which states are \"special.\" Special states are states\n    /// that are dead, quit, matching, starting or accelerated. For more info,\n    /// see the docs for `Special`.\n    special: Special,\n    /// The accelerators for this DFA.\n    ///\n    /// If a state is accelerated, then there exist only a small number of\n    /// bytes that can cause the DFA to leave the state. This permits searching\n    /// to use optimized routines to find those specific bytes instead of using\n    /// the transition table.\n    ///\n    /// All accelerated states exist in a contiguous range in the DFA's\n    /// transition table. See dfa/special.rs for more details on how states are\n    /// arranged.\n    accels: Accels<T>,\n    /// Any prefilter attached to this DFA.\n    ///\n    /// Note that currently prefilters are not serialized. When deserializing\n    /// a DFA from bytes, this is always set to `None`.\n    pre: Option<Prefilter>,\n    /// The set of \"quit\" bytes for this DFA.\n    ///\n    /// This is only used when computing the start state for a particular\n    /// position in a haystack. Namely, in the case where there is a quit\n    /// byte immediately before the start of the search, this set needs to be\n    /// explicitly consulted. In all other cases, quit bytes are detected by\n    /// the DFA itself, by transitioning all quit bytes to a special \"quit\n    /// state.\"\n    quitset: ByteSet,\n    /// Various flags describing the behavior of this DFA.\n    flags: Flags,\n}\n#[derive(Clone)]\npub(crate) struct TransitionTable<T> {\n    /// A contiguous region of memory representing the transition table in\n    /// row-major order. The representation is dense. That is, every state\n    /// has precisely the same number of transitions. The maximum number of\n    /// transitions per state is 257 (256 for each possible byte value, plus 1\n    /// for the special EOI transition). If a DFA has been instructed to use\n    /// byte classes (the default), then the number of transitions is usually\n    /// substantially fewer.\n    ///\n    /// In practice, T is either `Vec<u32>` or `&[u32]`.\n    table: T,\n    /// A set of equivalence classes, where a single equivalence class\n    /// represents a set of bytes that never discriminate between a match\n    /// and a non-match in the DFA. Each equivalence class corresponds to a\n    /// single character in this DFA's alphabet, where the maximum number of\n    /// characters is 257 (each possible value of a byte plus the special\n    /// EOI transition). Consequently, the number of equivalence classes\n    /// corresponds to the number of transitions for each DFA state. Note\n    /// though that the *space* used by each DFA state in the transition table\n    /// may be larger. The total space used by each DFA state is known as the\n    /// stride.\n    ///\n    /// The only time the number of equivalence classes is fewer than 257 is if\n    /// the DFA's kind uses byte classes (which is the default). Equivalence\n    /// classes should generally only be disabled when debugging, so that\n    /// the transitions themselves aren't obscured. Disabling them has no\n    /// other benefit, since the equivalence class map is always used while\n    /// searching. In the vast majority of cases, the number of equivalence\n    /// classes is substantially smaller than 257, particularly when large\n    /// Unicode classes aren't used.\n    classes: ByteClasses,\n    /// The stride of each DFA state, expressed as a power-of-two exponent.\n    ///\n    /// The stride of a DFA corresponds to the total amount of space used by\n    /// each DFA state in the transition table. This may be bigger than the\n    /// size of a DFA's alphabet, since the stride is always the smallest\n    /// power of two greater than or equal to the alphabet size.\n    ///\n    /// While this wastes space, this avoids the need for integer division\n    /// to convert between premultiplied state IDs and their corresponding\n    /// indices. Instead, we can use simple bit-shifts.\n    ///\n    /// See the docs for the `stride2` method for more details.\n    ///\n    /// The minimum `stride2` value is `1` (corresponding to a stride of `2`)\n    /// while the maximum `stride2` value is `9` (corresponding to a stride of\n    /// `512`). The maximum is not `8` since the maximum alphabet size is `257`\n    /// when accounting for the special EOI transition. However, an alphabet\n    /// length of that size is exceptionally rare since the alphabet is shrunk\n    /// into equivalence classes.\n    stride2: usize,\n}\n#[derive(Clone, Copy, Debug, Default, Eq, PartialEq)]\npub(crate) struct ByteSet {\n    bits: BitSet,\n}\n#[derive(Clone)]\npub(crate) struct Accels<A> {\n    /// A length prefixed slice of contiguous accelerators. See the top comment\n    /// in this module for more details on how we can jump from a DFA's state\n    /// ID to an accelerator in this list.\n    ///\n    /// The first 4 bytes always correspond to the number of accelerators\n    /// that follow.\n    accels: A,\n}\n#[derive(Clone)]\npub(crate) struct StartTable<T> {\n    /// The initial start state IDs.\n    ///\n    /// In practice, T is either `Vec<u32>` or `&[u32]`.\n    ///\n    /// The first `2 * stride` (currently always 8) entries always correspond\n    /// to the starts states for the entire DFA, with the first 4 entries being\n    /// for unanchored searches and the second 4 entries being for anchored\n    /// searches. To keep things simple, we always use 8 entries even if the\n    /// `StartKind` is not both.\n    ///\n    /// After that, there are `stride * patterns` state IDs, where `patterns`\n    /// may be zero in the case of a DFA with no patterns or in the case where\n    /// the DFA was built without enabling starting states for each pattern.\n    table: T,\n    /// The starting state configuration supported. When 'both', both\n    /// unanchored and anchored searches work. When 'unanchored', anchored\n    /// searches panic. When 'anchored', unanchored searches panic.\n    kind: StartKind,\n    /// The start state configuration for every possible byte.\n    start_map: StartByteMap,\n    /// The number of starting state IDs per pattern.\n    stride: usize,\n    /// The total number of patterns for which starting states are encoded.\n    /// This is `None` for DFAs that were built without start states for each\n    /// pattern. Thus, one cannot use this field to say how many patterns\n    /// are in the DFA in all cases. It is specific to how many patterns are\n    /// represented in this start table.\n    pattern_len: Option<usize>,\n    /// The universal starting state for unanchored searches. This is only\n    /// present when the DFA supports unanchored searches and when all starting\n    /// state IDs for an unanchored search are equivalent.\n    universal_start_unanchored: Option<StateID>,\n    /// The universal starting state for anchored searches. This is only\n    /// present when the DFA supports anchored searches and when all starting\n    /// state IDs for an anchored search are equivalent.\n    universal_start_anchored: Option<StateID>,\n}\n#[derive(Clone, Copy, Debug)]\npub(crate) struct Special {\n    /// The identifier of the last special state in a DFA. A state is special\n    /// if and only if its identifier is less than or equal to `max`.\n    pub(crate) max: StateID,\n    /// The identifier of the quit state in a DFA. (There is no analogous field\n    /// for the dead state since the dead state's ID is always zero, regardless\n    /// of state ID size.)\n    pub(crate) quit_id: StateID,\n    /// The identifier of the first match state.\n    pub(crate) min_match: StateID,\n    /// The identifier of the last match state.\n    pub(crate) max_match: StateID,\n    /// The identifier of the first accelerated state.\n    pub(crate) min_accel: StateID,\n    /// The identifier of the last accelerated state.\n    pub(crate) max_accel: StateID,\n    /// The identifier of the first start state.\n    pub(crate) min_start: StateID,\n    /// The identifier of the last start state.\n    pub(crate) max_start: StateID,\n}\n#[derive(Clone, Copy, Debug)]\npub(crate) struct Flags {\n    /// Whether the DFA can match the empty string. When this is false, all\n    /// matches returned by this DFA are guaranteed to have non-zero length.\n    pub(crate) has_empty: bool,\n    /// Whether the DFA should only produce matches with spans that correspond\n    /// to valid UTF-8. This also includes omitting any zero-width matches that\n    /// split the UTF-8 encoding of a codepoint.\n    pub(crate) is_utf8: bool,\n    /// Whether the DFA is always anchored or not, regardless of `Input`\n    /// configuration. This is useful for avoiding a reverse scan even when\n    /// executing unanchored searches.\n    pub(crate) is_always_start_anchored: bool,\n}\n#[derive(Clone, Debug)]\nstruct MatchStates<T> {\n    /// Slices is a flattened sequence of pairs, where each pair points to a\n    /// sub-slice of pattern_ids. The first element of the pair is an offset\n    /// into pattern_ids and the second element of the pair is the number\n    /// of 32-bit pattern IDs starting at that position. That is, each pair\n    /// corresponds to a single DFA match state and its corresponding match\n    /// IDs. The number of pairs always corresponds to the number of distinct\n    /// DFA match states.\n    ///\n    /// In practice, T is either Vec<u32> or &[u32].\n    slices: T,\n    /// A flattened sequence of pattern IDs for each DFA match state. The only\n    /// way to correctly read this sequence is indirectly via `slices`.\n    ///\n    /// In practice, T is either Vec<u32> or &[u32].\n    pattern_ids: T,\n    /// The total number of unique patterns represented by these match states.\n    pattern_len: usize,\n}\n#[derive(Debug)]\npub struct DeserializeError(DeserializeErrorKind);\n#[derive(Clone, Debug)]\npub struct Prefilter {\n    #[cfg(not(feature = \"alloc\"))]\n    _unused: (),\n    #[cfg(feature = \"alloc\")]\n    pre: Arc<dyn PrefilterI>,\n    #[cfg(feature = \"alloc\")]\n    is_fast: bool,\n    #[cfg(feature = \"alloc\")]\n    max_needle_len: usize,\n}\n#[derive(Clone, Debug)]\npub(crate) struct ByteSet([bool; 256]);\n#[derive(Clone)]\nstruct StartTable<T> {\n    /// The initial start state IDs as a contiguous table of native endian\n    /// encoded integers, represented by `S`.\n    ///\n    /// In practice, T is either Vec<u8> or &[u8] and has no alignment\n    /// requirements.\n    ///\n    /// The first `2 * stride` (currently always 8) entries always correspond\n    /// to the starts states for the entire DFA, with the first 4 entries being\n    /// for unanchored searches and the second 4 entries being for anchored\n    /// searches. To keep things simple, we always use 8 entries even if the\n    /// `StartKind` is not both.\n    ///\n    /// After that, there are `stride * patterns` state IDs, where `patterns`\n    /// may be zero in the case of a DFA with no patterns or in the case where\n    /// the DFA was built without enabling starting states for each pattern.\n    table: T,\n    /// The starting state configuration supported. When 'both', both\n    /// unanchored and anchored searches work. When 'unanchored', anchored\n    /// searches panic. When 'anchored', unanchored searches panic.\n    kind: StartKind,\n    /// The start state configuration for every possible byte.\n    start_map: StartByteMap,\n    /// The number of starting state IDs per pattern.\n    stride: usize,\n    /// The total number of patterns for which starting states are encoded.\n    /// This is `None` for DFAs that were built without start states for each\n    /// pattern. Thus, one cannot use this field to say how many patterns\n    /// are in the DFA in all cases. It is specific to how many patterns are\n    /// represented in this start table.\n    pattern_len: Option<usize>,\n    /// The universal starting state for unanchored searches. This is only\n    /// present when the DFA supports unanchored searches and when all starting\n    /// state IDs for an unanchored search are equivalent.\n    universal_start_unanchored: Option<StateID>,\n    /// The universal starting state for anchored searches. This is only\n    /// present when the DFA supports anchored searches and when all starting\n    /// state IDs for an anchored search are equivalent.\n    universal_start_anchored: Option<StateID>,\n}\nimpl<'a> DFA<&'a [u32]> {\n    pub fn from_bytes(\n        slice: &'a [u8],\n    ) -> Result<(DFA<&'a [u32]>, usize), DeserializeError> {}\n    pub unsafe fn from_bytes_unchecked(\n        slice: &'a [u8],\n    ) -> Result<(DFA<&'a [u32]>, usize), DeserializeError> {\n        let mut nr = 0;\n        nr += wire::skip_initial_padding(slice);\n        wire::check_alignment::<StateID>(&slice[nr..])?;\n        nr += wire::read_label(&slice[nr..], LABEL)?;\n        nr += wire::read_endianness_check(&slice[nr..])?;\n        nr += wire::read_version(&slice[nr..], VERSION)?;\n        let _unused = wire::try_read_u32(&slice[nr..], \"unused space\")?;\n        nr += size_of::<u32>();\n        let (flags, nread) = Flags::from_bytes(&slice[nr..])?;\n        nr += nread;\n        let (tt, nread) = TransitionTable::from_bytes_unchecked(&slice[nr..])?;\n        nr += nread;\n        let (st, nread) = StartTable::from_bytes_unchecked(&slice[nr..])?;\n        nr += nread;\n        let (ms, nread) = MatchStates::from_bytes_unchecked(&slice[nr..])?;\n        nr += nread;\n        let (special, nread) = Special::from_bytes(&slice[nr..])?;\n        nr += nread;\n        special.validate_state_len(tt.len(), tt.stride2)?;\n        let (accels, nread) = Accels::from_bytes_unchecked(&slice[nr..])?;\n        nr += nread;\n        let (quitset, nread) = ByteSet::from_bytes(&slice[nr..])?;\n        nr += nread;\n        let pre = None;\n        Ok((\n            DFA {\n                tt,\n                st,\n                ms,\n                special,\n                accels,\n                pre,\n                quitset,\n                flags,\n            },\n            nr,\n        ))\n    }\n    fn write_to<E: Endian>(&self, mut dst: &mut [u8]) -> Result<usize, SerializeError> {}\n}\nimpl<T: AsRef<[u32]>> TransitionTable<T> {\n    fn write_to<E: Endian>(&self, mut dst: &mut [u8]) -> Result<usize, SerializeError> {}\n    fn write_to_len(&self) -> usize {}\n    fn validate(&self, dfa: &DFA<T>) -> Result<(), DeserializeError> {}\n    fn as_ref(&self) -> TransitionTable<&'_ [u32]> {}\n    #[cfg(feature = \"alloc\")]\n    fn to_owned(&self) -> TransitionTable<alloc::vec::Vec<u32>> {}\n    fn state(&self, id: StateID) -> State<'_> {}\n    fn states(&self) -> StateIter<'_, T> {}\n    fn to_index(&self, id: StateID) -> usize {}\n    fn to_state_id(&self, index: usize) -> StateID {}\n    #[cfg(feature = \"dfa-build\")]\n    fn next_state_id(&self, id: StateID) -> StateID {}\n    #[cfg(feature = \"dfa-build\")]\n    fn prev_state_id(&self, id: StateID) -> StateID {}\n    fn table(&self) -> &[StateID] {}\n    fn len(&self) -> usize {\n        self.table().len() >> self.stride2\n    }\n    fn stride(&self) -> usize {}\n    fn alphabet_len(&self) -> usize {}\n    fn is_valid(&self, id: StateID) -> bool {}\n    fn memory_usage(&self) -> usize {}\n}\nimpl ByteSet {\n    pub(crate) fn empty() -> ByteSet {}\n    pub(crate) fn add(&mut self, byte: u8) {}\n    pub(crate) fn remove(&mut self, byte: u8) {}\n    pub(crate) fn contains(&self, byte: u8) -> bool {}\n    pub(crate) fn contains_range(&self, start: u8, end: u8) -> bool {}\n    pub(crate) fn iter(&self) -> ByteSetIter {}\n    pub(crate) fn iter_ranges(&self) -> ByteSetRangeIter {}\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    pub(crate) fn is_empty(&self) -> bool {}\n    pub(crate) fn from_bytes(\n        slice: &[u8],\n    ) -> Result<(ByteSet, usize), DeserializeError> {\n        use core::mem::size_of;\n        wire::check_slice_len(slice, 2 * size_of::<u128>(), \"byte set\")?;\n        let mut nread = 0;\n        let (low, nr) = wire::try_read_u128(slice, \"byte set low bucket\")?;\n        nread += nr;\n        let (high, nr) = wire::try_read_u128(slice, \"byte set high bucket\")?;\n        nread += nr;\n        Ok((\n            ByteSet {\n                bits: BitSet([low, high]),\n            },\n            nread,\n        ))\n    }\n    pub(crate) fn write_to<E: crate::util::wire::Endian>(\n        &self,\n        dst: &mut [u8],\n    ) -> Result<usize, SerializeError> {}\n    pub(crate) fn write_to_len(&self) -> usize {}\n}\nimpl<'a> Accels<&'a [AccelTy]> {\n    pub fn from_bytes_unchecked(\n        mut slice: &'a [u8],\n    ) -> Result<(Accels<&'a [AccelTy]>, usize), DeserializeError> {\n        let slice_start = slice.as_ptr().as_usize();\n        let (accel_len, _) = wire::try_read_u32_as_usize(slice, \"accelerators length\")?;\n        let accel_tys_len = wire::add(\n            wire::mul(accel_len, 2, \"total number of accelerator accel_tys\")?,\n            1,\n            \"total number of accel_tys\",\n        )?;\n        let accel_tys_bytes_len = wire::mul(\n            ACCEL_TY_SIZE,\n            accel_tys_len,\n            \"total number of bytes in accelerators\",\n        )?;\n        wire::check_slice_len(slice, accel_tys_bytes_len, \"accelerators\")?;\n        wire::check_alignment::<AccelTy>(slice)?;\n        let accel_tys = &slice[..accel_tys_bytes_len];\n        slice = &slice[accel_tys_bytes_len..];\n        let accels = unsafe {\n            core::slice::from_raw_parts(\n                accel_tys.as_ptr().cast::<AccelTy>(),\n                accel_tys_len,\n            )\n        };\n        Ok((Accels { accels }, slice.as_ptr().as_usize() - slice_start))\n    }\n}\nimpl<'a> StartTable<&'a [u32]> {\n    unsafe fn from_bytes_unchecked(\n        mut slice: &'a [u8],\n    ) -> Result<(StartTable<&'a [u32]>, usize), DeserializeError> {\n        let slice_start = slice.as_ptr().as_usize();\n        let (kind, nr) = StartKind::from_bytes(slice)?;\n        slice = &slice[nr..];\n        let (start_map, nr) = StartByteMap::from_bytes(slice)?;\n        slice = &slice[nr..];\n        let (stride, nr) = wire::try_read_u32_as_usize(slice, \"start table stride\")?;\n        slice = &slice[nr..];\n        if stride != Start::len() {\n            return Err(DeserializeError::generic(\"invalid starting table stride\"));\n        }\n        let (maybe_pattern_len, nr) = wire::try_read_u32_as_usize(\n            slice,\n            \"start table patterns\",\n        )?;\n        slice = &slice[nr..];\n        let pattern_len = if maybe_pattern_len.as_u32() == u32::MAX {\n            None\n        } else {\n            Some(maybe_pattern_len)\n        };\n        if pattern_len.map_or(false, |len| len > PatternID::LIMIT) {\n            return Err(DeserializeError::generic(\"invalid number of patterns\"));\n        }\n        let (universal_unanchored, nr) = wire::try_read_u32(\n            slice,\n            \"universal unanchored start\",\n        )?;\n        slice = &slice[nr..];\n        let universal_start_unanchored = if universal_unanchored == u32::MAX {\n            None\n        } else {\n            Some(\n                StateID::try_from(universal_unanchored)\n                    .map_err(|e| {\n                        DeserializeError::state_id_error(e, \"universal unanchored start\")\n                    })?,\n            )\n        };\n        let (universal_anchored, nr) = wire::try_read_u32(\n            slice,\n            \"universal anchored start\",\n        )?;\n        slice = &slice[nr..];\n        let universal_start_anchored = if universal_anchored == u32::MAX {\n            None\n        } else {\n            Some(\n                StateID::try_from(universal_anchored)\n                    .map_err(|e| {\n                        DeserializeError::state_id_error(e, \"universal anchored start\")\n                    })?,\n            )\n        };\n        let pattern_table_size = wire::mul(\n            stride,\n            pattern_len.unwrap_or(0),\n            \"invalid pattern length\",\n        )?;\n        let start_state_len = wire::add(\n            wire::mul(2, stride, \"start state stride too big\")?,\n            pattern_table_size,\n            \"invalid 'any' pattern starts size\",\n        )?;\n        let table_bytes_len = wire::mul(\n            start_state_len,\n            StateID::SIZE,\n            \"pattern table bytes length\",\n        )?;\n        wire::check_slice_len(slice, table_bytes_len, \"start ID table\")?;\n        wire::check_alignment::<StateID>(slice)?;\n        let table_bytes = &slice[..table_bytes_len];\n        slice = &slice[table_bytes_len..];\n        let table = core::slice::from_raw_parts(\n            table_bytes.as_ptr().cast::<u32>(),\n            start_state_len,\n        );\n        let st = StartTable {\n            table,\n            kind,\n            start_map,\n            stride,\n            pattern_len,\n            universal_start_unanchored,\n            universal_start_anchored,\n        };\n        Ok((st, slice.as_ptr().as_usize() - slice_start))\n    }\n}\nimpl Special {\n    #[cfg(feature = \"dfa-build\")]\n    pub(crate) fn new() -> Special {}\n    #[cfg(feature = \"dfa-build\")]\n    pub(crate) fn remap(&self, map: impl Fn(StateID) -> StateID) -> Special {}\n    pub(crate) fn from_bytes(\n        mut slice: &[u8],\n    ) -> Result<(Special, usize), DeserializeError> {\n        wire::check_slice_len(slice, 8 * StateID::SIZE, \"special states\")?;\n        let mut nread = 0;\n        let mut read_id = |what| -> Result<StateID, DeserializeError> {\n            let (id, nr) = wire::try_read_state_id(slice, what)?;\n            nread += nr;\n            slice = &slice[StateID::SIZE..];\n            Ok(id)\n        };\n        let max = read_id(\"special max id\")?;\n        let quit_id = read_id(\"special quit id\")?;\n        let min_match = read_id(\"special min match id\")?;\n        let max_match = read_id(\"special max match id\")?;\n        let min_accel = read_id(\"special min accel id\")?;\n        let max_accel = read_id(\"special max accel id\")?;\n        let min_start = read_id(\"special min start id\")?;\n        let max_start = read_id(\"special max start id\")?;\n        let special = Special {\n            max,\n            quit_id,\n            min_match,\n            max_match,\n            min_accel,\n            max_accel,\n            min_start,\n            max_start,\n        };\n        special.validate()?;\n        assert_eq!(nread, special.write_to_len());\n        Ok((special, nread))\n    }\n    pub(crate) fn validate(&self) -> Result<(), DeserializeError> {}\n    pub(crate) fn validate_state_len(\n        &self,\n        len: usize,\n        stride2: usize,\n    ) -> Result<(), DeserializeError> {\n        if (self.max.as_usize() >> stride2) >= len {\n            err!(\"max should not be greater than or equal to state length\");\n        }\n        Ok(())\n    }\n    pub(crate) fn write_to<E: Endian>(\n        &self,\n        dst: &mut [u8],\n    ) -> Result<usize, SerializeError> {}\n    pub(crate) fn write_to_len(&self) -> usize {}\n    #[cfg(feature = \"dfa-build\")]\n    pub(crate) fn set_max(&mut self) {}\n    #[cfg(feature = \"dfa-build\")]\n    pub(crate) fn set_no_special_start_states(&mut self) {}\n    #[inline]\n    pub(crate) fn is_special_state(&self, id: StateID) -> bool {}\n    #[inline]\n    pub(crate) fn is_dead_state(&self, id: StateID) -> bool {}\n    #[inline]\n    pub(crate) fn is_quit_state(&self, id: StateID) -> bool {}\n    #[inline]\n    pub(crate) fn is_match_state(&self, id: StateID) -> bool {}\n    #[inline]\n    pub(crate) fn is_accel_state(&self, id: StateID) -> bool {}\n    #[inline]\n    pub(crate) fn is_start_state(&self, id: StateID) -> bool {}\n    #[inline]\n    pub(crate) fn match_len(&self, stride: usize) -> usize {}\n    #[inline]\n    pub(crate) fn matches(&self) -> bool {}\n    #[cfg(feature = \"dfa-build\")]\n    pub(crate) fn accel_len(&self, stride: usize) -> usize {}\n    #[inline]\n    pub(crate) fn accels(&self) -> bool {}\n    #[inline]\n    pub(crate) fn starts(&self) -> bool {}\n}\nimpl Flags {\n    #[cfg(feature = \"dfa-build\")]\n    fn from_nfa(nfa: &thompson::NFA) -> Flags {}\n    pub(crate) fn from_bytes(slice: &[u8]) -> Result<(Flags, usize), DeserializeError> {\n        let (bits, nread) = wire::try_read_u32(slice, \"flag bitset\")?;\n        let flags = Flags {\n            has_empty: bits & (1 << 0) != 0,\n            is_utf8: bits & (1 << 1) != 0,\n            is_always_start_anchored: bits & (1 << 2) != 0,\n        };\n        Ok((flags, nread))\n    }\n    pub(crate) fn write_to<E: Endian>(\n        &self,\n        dst: &mut [u8],\n    ) -> Result<usize, SerializeError> {}\n    pub(crate) fn write_to_len(&self) -> usize {}\n}\nimpl<'a> MatchStates<&'a [u32]> {\n    unsafe fn from_bytes_unchecked(\n        mut slice: &'a [u8],\n    ) -> Result<(MatchStates<&'a [u32]>, usize), DeserializeError> {\n        let slice_start = slice.as_ptr().as_usize();\n        let (state_len, nr) = wire::try_read_u32_as_usize(slice, \"match state length\")?;\n        slice = &slice[nr..];\n        let pair_len = wire::mul(2, state_len, \"match state offset pairs\")?;\n        let slices_bytes_len = wire::mul(\n            pair_len,\n            PatternID::SIZE,\n            \"match state slice offset byte length\",\n        )?;\n        wire::check_slice_len(slice, slices_bytes_len, \"match state slices\")?;\n        wire::check_alignment::<PatternID>(slice)?;\n        let slices_bytes = &slice[..slices_bytes_len];\n        slice = &slice[slices_bytes_len..];\n        let slices = core::slice::from_raw_parts(\n            slices_bytes.as_ptr().cast::<u32>(),\n            pair_len,\n        );\n        let (pattern_len, nr) = wire::try_read_u32_as_usize(slice, \"pattern length\")?;\n        slice = &slice[nr..];\n        let (idlen, nr) = wire::try_read_u32_as_usize(slice, \"pattern ID length\")?;\n        slice = &slice[nr..];\n        let pattern_ids_len = wire::mul(\n            idlen,\n            PatternID::SIZE,\n            \"pattern ID byte length\",\n        )?;\n        wire::check_slice_len(slice, pattern_ids_len, \"match pattern IDs\")?;\n        wire::check_alignment::<PatternID>(slice)?;\n        let pattern_ids_bytes = &slice[..pattern_ids_len];\n        slice = &slice[pattern_ids_len..];\n        let pattern_ids = core::slice::from_raw_parts(\n            pattern_ids_bytes.as_ptr().cast::<u32>(),\n            idlen,\n        );\n        let ms = MatchStates {\n            slices,\n            pattern_ids,\n            pattern_len,\n        };\n        Ok((ms, slice.as_ptr().as_usize() - slice_start))\n    }\n}\nimpl<'a> TransitionTable<&'a [u32]> {\n    unsafe fn from_bytes_unchecked(\n        mut slice: &'a [u8],\n    ) -> Result<(TransitionTable<&'a [u32]>, usize), DeserializeError> {\n        let slice_start = slice.as_ptr().as_usize();\n        let (state_len, nr) = wire::try_read_u32_as_usize(slice, \"state length\")?;\n        slice = &slice[nr..];\n        let (stride2, nr) = wire::try_read_u32_as_usize(slice, \"stride2\")?;\n        slice = &slice[nr..];\n        let (classes, nr) = ByteClasses::from_bytes(slice)?;\n        slice = &slice[nr..];\n        if stride2 > 9 {\n            return Err(\n                DeserializeError::generic(\"dense DFA has invalid stride2 (too big)\"),\n            );\n        }\n        if stride2 < 1 {\n            return Err(\n                DeserializeError::generic(\"dense DFA has invalid stride2 (too small)\"),\n            );\n        }\n        let stride = 1usize.checked_shl(u32::try_from(stride2).unwrap()).unwrap();\n        if classes.alphabet_len() > stride {\n            return Err(\n                DeserializeError::generic(\n                    \"alphabet size cannot be bigger than transition table stride\",\n                ),\n            );\n        }\n        let trans_len = wire::shl(state_len, stride2, \"dense table transition length\")?;\n        let table_bytes_len = wire::mul(\n            trans_len,\n            StateID::SIZE,\n            \"dense table state byte length\",\n        )?;\n        wire::check_slice_len(slice, table_bytes_len, \"transition table\")?;\n        wire::check_alignment::<StateID>(slice)?;\n        let table_bytes = &slice[..table_bytes_len];\n        slice = &slice[table_bytes_len..];\n        let table = core::slice::from_raw_parts(\n            table_bytes.as_ptr().cast::<u32>(),\n            trans_len,\n        );\n        let tt = TransitionTable {\n            table,\n            classes,\n            stride2,\n        };\n        Ok((tt, slice.as_ptr().as_usize() - slice_start))\n    }\n}\npub(crate) fn skip_initial_padding(slice: &[u8]) -> usize {\n    let mut nread = 0;\n    while nread < 7 && nread < slice.len() && slice[nread] == 0 {\n        nread += 1;\n    }\n    nread\n}\npub(crate) fn read_version(\n    slice: &[u8],\n    expected_version: u32,\n) -> Result<usize, DeserializeError> {\n    let (n, nr) = try_read_u32(slice, \"version\")?;\n    assert_eq!(nr, write_version_len());\n    if n != expected_version {\n        return Err(DeserializeError::version_mismatch(expected_version, n));\n    }\n    Ok(nr)\n}\npub(crate) fn read_label(\n    slice: &[u8],\n    expected_label: &'static str,\n) -> Result<usize, DeserializeError> {\n    let first_nul = slice[..cmp::min(slice.len(), 256)].iter().position(|&b| b == 0);\n    let first_nul = match first_nul {\n        Some(first_nul) => first_nul,\n        None => {\n            return Err(\n                DeserializeError::generic(\n                    \"could not find NUL terminated label \\\n                 at start of serialized object\",\n                ),\n            );\n        }\n    };\n    let len = first_nul + padding_len(first_nul);\n    if slice.len() < len {\n        return Err(\n            DeserializeError::generic(\n                \"could not find properly sized label at start of serialized object\",\n            ),\n        );\n    }\n    if expected_label.as_bytes() != &slice[..first_nul] {\n        return Err(DeserializeError::label_mismatch(expected_label));\n    }\n    Ok(len)\n}\npub(crate) fn check_alignment<T>(slice: &[u8]) -> Result<(), DeserializeError> {\n    let alignment = core::mem::align_of::<T>();\n    let address = slice.as_ptr().as_usize();\n    if address % alignment == 0 {\n        return Ok(());\n    }\n    Err(DeserializeError::alignment_mismatch(alignment, address))\n}\npub(crate) fn try_read_u32(\n    slice: &[u8],\n    what: &'static str,\n) -> Result<(u32, usize), DeserializeError> {\n    check_slice_len(slice, size_of::<u32>(), what)?;\n    Ok((read_u32(slice), size_of::<u32>()))\n}\npub(crate) fn read_endianness_check(slice: &[u8]) -> Result<usize, DeserializeError> {\n    let (n, nr) = try_read_u32(slice, \"endianness check\")?;\n    assert_eq!(nr, write_endianness_check_len());\n    if n != 0xFEFF {\n        return Err(DeserializeError::endian_mismatch(0xFEFF, n));\n    }\n    Ok(nr)\n}\n\nThe function to be tested is presented with each line formatted as 'line number + code':\n/// Deserialize a DFA with a specific state identifier representation in\n/// constant time by omitting the verification of the validity of the\n/// transition table and other data inside the DFA.\n///\n/// This is just like [`DFA::from_bytes`], except it can potentially return\n/// a DFA that exhibits undefined behavior if its transition table contains\n/// invalid state identifiers.\n///\n/// This routine is useful if you need to deserialize a DFA cheaply\n/// and cannot afford the transition table validation performed by\n/// `from_bytes`.\n///\n/// # Example\n///\n/// ```\n/// use regex_automata::{dfa::{Automaton, dense::DFA}, HalfMatch, Input};\n///\n/// let initial = DFA::new(\"foo[0-9]+\")?;\n/// let (bytes, _) = initial.to_bytes_native_endian();\n/// // SAFETY: This is guaranteed to be safe since the bytes given come\n/// // directly from a compatible serialization routine.\n/// let dfa: DFA<&[u32]> = unsafe { DFA::from_bytes_unchecked(&bytes)?.0 };\n///\n/// let expected = Some(HalfMatch::must(0, 8));\n/// assert_eq!(expected, dfa.try_search_fwd(&Input::new(\"foo12345\"))?);\n/// # Ok::<(), Box<dyn std::error::Error>>(())\n/// ```\n2397 pub unsafe fn from_bytes_unchecked(\n2398     slice: &'a [u8],\n2399 ) -> Result<(DFA<&'a [u32]>, usize), DeserializeError> {\n2400     let mut nr = 0;\n2401 \n2402     nr += wire::skip_initial_padding(slice);\n2403     wire::check_alignment::<StateID>(&slice[nr..])?;\n2404     nr += wire::read_label(&slice[nr..], LABEL)?;\n2405     nr += wire::read_endianness_check(&slice[nr..])?;\n2406     nr += wire::read_version(&slice[nr..], VERSION)?;\n2407 \n2408     let _unused = wire::try_read_u32(&slice[nr..], \"unused space\")?;\n2409     nr += size_of::<u32>();\n2410 \n2411     let (flags, nread) = Flags::from_bytes(&slice[nr..])?;\n2412     nr += nread;\n2413 \n2414     let (tt, nread) = TransitionTable::from_bytes_unchecked(&slice[nr..])?;\n2415     nr += nread;\n2416 \n2417     let (st, nread) = StartTable::from_bytes_unchecked(&slice[nr..])?;\n2418     nr += nread;\n2419 \n2420     let (ms, nread) = MatchStates::from_bytes_unchecked(&slice[nr..])?;\n2421     nr += nread;\n2422 \n2423     let (special, nread) = Special::from_bytes(&slice[nr..])?;\n2424     nr += nread;\n2425     special.validate_state_len(tt.len(), tt.stride2)?;\n2426 \n2427     let (accels, nread) = Accels::from_bytes_unchecked(&slice[nr..])?;\n2428     nr += nread;\n2429 \n2430     let (quitset, nread) = ByteSet::from_bytes(&slice[nr..])?;\n2431     nr += nread;\n2432 \n2433     // Prefilters don't support serialization, so they're always absent.\n2434     let pre = None;\n2435     Ok((DFA { tt, st, ms, special, accels, pre, quitset, flags }, nr))\n2436 }\n\nWhen inferring test input conditions or ranges, consider the following preconditions and expected return values or types:\n"
}