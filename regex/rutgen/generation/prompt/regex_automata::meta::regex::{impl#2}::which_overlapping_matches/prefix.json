{
  "system_pt": "As a software testing expert, please generate Rust test functions based on the following guidelines, focusing solely on constructing test inputs and calling the functions under test:\n1. Provide the code in plain text format, without explanations or Markdown.\n2. If the method under test belongs to a trait, construct appropriate structs within the test function, but avoid method overrides. If the method under test uses generics, instantiate them with suitable types based on the context.\n3. Generate test code with minimal scope: avoid creating external structures or implementations. Instead, define any necessary helper structures or implementations directly within the test function when required.\n4. Whenever possible, initialize the corresponding data structures using the initialization methods provided in the context.\n5. Ensure the generated function is fully implemented and can be compiled and executed directly without any missing parts.\n6. Create a minimal yet complete set of test functions, ensuring they adhere to all provided preconditions and cover boundary conditions, and reference the inferred test input conditions or ranges.\n7. Ensure the test inputs are designed to cover the inferred test input conditions or ranges as comprehensively as possible, with particular emphasis on boundary cases.\n8. Focus on crafting test inputs that effectively reveal potential bugs while meeting the specified requirements.\n9. Omit test oracles and assertions; concentrate on generating test inputs and function calls.\n10. Do not create a test module, but include intrinsic attributes like #[test] or #[should_panic] where necessary.\n",
  "static_pt": "The context for the focal function is as follows:\n// regex-automata/src/meta/regex.rs\n// crate name is regex_automata\ntype CachePool = Pool<Cache, CachePoolFn>;\ntype CachePoolGuard<'a> = PoolGuard<'a, Cache, CachePoolFn>;\ntype CachePoolFn = Box<dyn Fn() -> Cache + Send + Sync + UnwindSafe + RefUnwindSafe>;\nuse core::{borrow::Borrow, panic::{RefUnwindSafe, UnwindSafe}};\nuse alloc::{boxed::Box, sync::Arc, vec, vec::Vec};\nuse regex_syntax::{ast, hir::{self, Hir}};\nuse crate::{\n    meta::{\n        error::BuildError, strategy::{self, Strategy},\n        wrappers,\n    },\n    nfa::thompson::WhichCaptures,\n    util::{\n        captures::{Captures, GroupInfo},\n        iter, pool::{Pool, PoolGuard},\n        prefilter::Prefilter, primitives::{NonMaxUsize, PatternID},\n        search::{HalfMatch, Input, Match, MatchKind, PatternSet, Span},\n    },\n};\n#[derive(Debug)]\npub struct Regex {\n    /// The actual regex implementation.\n    imp: Arc<RegexI>,\n    /// A thread safe pool of caches.\n    ///\n    /// For the higher level search APIs, a `Cache` is automatically plucked\n    /// from this pool before running a search. The lower level `with` methods\n    /// permit the caller to provide their own cache, thereby bypassing\n    /// accesses to this pool.\n    ///\n    /// Note that we put this outside the `Arc` so that cloning a `Regex`\n    /// results in creating a fresh `CachePool`. This in turn permits callers\n    /// to clone regexes into separate threads where each such regex gets\n    /// the pool's \"thread owner\" optimization. Otherwise, if one shares the\n    /// `Regex` directly, then the pool will go through a slower mutex path for\n    /// all threads except for the \"owner.\"\n    pool: CachePool,\n}\n#[derive(Clone, Debug)]\npub(crate) struct RegexInfo(Arc<RegexInfoI>);\n#[derive(Debug, Clone)]\npub struct Cache {\n    pub(crate) capmatches: Captures,\n    pub(crate) pikevm: wrappers::PikeVMCache,\n    pub(crate) backtrack: wrappers::BoundedBacktrackerCache,\n    pub(crate) onepass: wrappers::OnePassCache,\n    pub(crate) hybrid: wrappers::HybridCache,\n    pub(crate) revhybrid: wrappers::ReverseHybridCache,\n}\n#[derive(Debug)]\nstruct RegexI {\n    /// The core matching engine.\n    ///\n    /// Why is this reference counted when RegexI is already wrapped in an Arc?\n    /// Well, we need to capture this in a closure to our `Pool` below in order\n    /// to create new `Cache` values when needed. So since it needs to be in\n    /// two places, we make it reference counted.\n    ///\n    /// We make `RegexI` itself reference counted too so that `Regex` itself\n    /// stays extremely small and very cheap to clone.\n    strat: Arc<dyn Strategy>,\n    /// Metadata about the regexes driving the strategy. The metadata is also\n    /// usually stored inside the strategy too, but we put it here as well\n    /// so that we can get quick access to it (without virtual calls) before\n    /// executing the regex engine. For example, we use this metadata to\n    /// detect a subset of cases where we know a match is impossible, and can\n    /// thus avoid calling into the strategy at all.\n    ///\n    /// Since `RegexInfo` is stored in multiple places, it is also reference\n    /// counted.\n    info: RegexInfo,\n}\n#[derive(Clone)]\npub struct Input<'h> {\n    haystack: &'h [u8],\n    span: Span,\n    anchored: Anchored,\n    earliest: bool,\n}\n#[cfg(feature = \"alloc\")]\n#[derive(Clone, Debug, Eq, PartialEq)]\npub struct PatternSet {\n    /// The number of patterns set to 'true' in this set.\n    len: usize,\n    /// A map from PatternID to boolean of whether a pattern matches or not.\n    ///\n    /// This should probably be a bitset, but it's probably unlikely to matter\n    /// much in practice.\n    ///\n    /// The main downside of this representation (and similarly for a bitset)\n    /// is that iteration scales with the capacity of the set instead of\n    /// the length of the set. This doesn't seem likely to be a problem in\n    /// practice.\n    ///\n    /// Another alternative is to just use a 'SparseSet' for this. It does use\n    /// more memory (quite a bit more), but that seems fine I think compared\n    /// to the memory being used by the regex engine. The real hiccup with\n    /// it is that it yields pattern IDs in the order they were inserted.\n    /// Which is actually kind of nice, but at the time of writing, pattern\n    /// IDs are yielded in ascending order in the regex crate RegexSet API.\n    /// If we did change to 'SparseSet', we could provide an additional\n    /// 'iter_match_order' iterator, but keep the ascending order one for\n    /// compatibility.\n    which: alloc::boxed::Box<[bool]>,\n}\nimpl Regex {\n    #[inline]\n    pub fn search(&self, input: &Input<'_>) -> Option<Match> {}\n    #[inline]\n    pub fn search_half(&self, input: &Input<'_>) -> Option<HalfMatch> {}\n    #[inline]\n    pub fn search_captures(&self, input: &Input<'_>, caps: &mut Captures) {}\n    #[inline]\n    pub fn search_slots(\n        &self,\n        input: &Input<'_>,\n        slots: &mut [Option<NonMaxUsize>],\n    ) -> Option<PatternID> {}\n    #[inline]\n    pub fn which_overlapping_matches(&self, input: &Input<'_>, patset: &mut PatternSet) {\n        if self.imp.info.is_impossible(input) {\n            return;\n        }\n        let mut guard = self.pool.get();\n        let result = self.imp.strat.which_overlapping_matches(&mut guard, input, patset);\n        PoolGuard::put(guard);\n        result\n    }\n}\nimpl RegexInfo {\n    fn new(config: Config, hirs: &[&Hir]) -> RegexInfo {}\n    pub(crate) fn config(&self) -> &Config {}\n    pub(crate) fn props(&self) -> &[hir::Properties] {}\n    pub(crate) fn props_union(&self) -> &hir::Properties {}\n    pub(crate) fn pattern_len(&self) -> usize {}\n    pub(crate) fn memory_usage(&self) -> usize {}\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    pub(crate) fn is_anchored_start(&self, input: &Input<'_>) -> bool {}\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    pub(crate) fn is_always_anchored_start(&self) -> bool {}\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    pub(crate) fn is_always_anchored_end(&self) -> bool {}\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    fn is_impossible(&self, input: &Input<'_>) -> bool {\n        if input.start() > 0 && self.is_always_anchored_start() {\n            return true;\n        }\n        if input.end() < input.haystack().len() && self.is_always_anchored_end() {\n            return true;\n        }\n        let minlen = match self.props_union().minimum_len() {\n            None => return false,\n            Some(minlen) => minlen,\n        };\n        if input.get_span().len() < minlen {\n            return true;\n        }\n        if self.is_anchored_start(input) && self.is_always_anchored_end() {\n            let maxlen = match self.props_union().maximum_len() {\n                None => return false,\n                Some(maxlen) => maxlen,\n            };\n            if input.get_span().len() > maxlen {\n                return true;\n            }\n        }\n        false\n    }\n}\n\nThe function to be tested is presented with each line formatted as 'line number + code':\n/// Writes the set of patterns that match anywhere in the given search\n/// configuration to `patset`. If multiple patterns match at the same\n/// position and this `Regex` was configured with [`MatchKind::All`]\n/// semantics, then all matching patterns are written to the given set.\n///\n/// Unless all of the patterns in this `Regex` are anchored, then generally\n/// speaking, this will scan the entire haystack.\n///\n/// This search routine *does not* clear the pattern set. This gives some\n/// flexibility to the caller (e.g., running multiple searches with the\n/// same pattern set), but does make the API bug-prone if you're reusing\n/// the same pattern set for multiple searches but intended them to be\n/// independent.\n///\n/// If a pattern ID matched but the given `PatternSet` does not have\n/// sufficient capacity to store it, then it is not inserted and silently\n/// dropped.\n///\n/// # Example\n///\n/// This example shows how to find all matching patterns in a haystack,\n/// even when some patterns match at the same position as other patterns.\n/// It is important that we configure the `Regex` with [`MatchKind::All`]\n/// semantics here, or else overlapping matches will not be reported.\n///\n/// ```\n/// # if cfg!(miri) { return Ok(()); } // miri takes too long\n/// use regex_automata::{meta::Regex, Input, MatchKind, PatternSet};\n///\n/// let patterns = &[\n///     r\"\\w+\", r\"\\d+\", r\"\\pL+\", r\"foo\", r\"bar\", r\"barfoo\", r\"foobar\",\n/// ];\n/// let re = Regex::builder()\n///     .configure(Regex::config().match_kind(MatchKind::All))\n///     .build_many(patterns)?;\n///\n/// let input = Input::new(\"foobar\");\n/// let mut patset = PatternSet::new(re.pattern_len());\n/// re.which_overlapping_matches(&input, &mut patset);\n/// let expected = vec![0, 2, 3, 4, 6];\n/// let got: Vec<usize> = patset.iter().map(|p| p.as_usize()).collect();\n/// assert_eq!(expected, got);\n///\n/// # Ok::<(), Box<dyn std::error::Error>>(())\n/// ```\n1187 pub fn which_overlapping_matches(\n1188     &self,\n1189     input: &Input<'_>,\n1190     patset: &mut PatternSet,\n1191 ) {\n1192     if self.imp.info.is_impossible(input) {\n1193         return;\n1194     }\n1195     let mut guard = self.pool.get();\n1196     let result = self\n1197         .imp\n1198         .strat\n1199         .which_overlapping_matches(&mut guard, input, patset);\n1200     // See 'Regex::search' for why we put the guard back explicitly.\n1201     PoolGuard::put(guard);\n1202     result\n1203 }\n\nGenerate each test function in such a manner that it concurrently satisfies all the following preconditions:\n",
  "depend_pt": ""
}