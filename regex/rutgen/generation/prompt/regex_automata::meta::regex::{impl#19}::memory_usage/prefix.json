{
  "system_pt": "As a software testing expert, please generate Rust test functions based on the following guidelines, focusing solely on constructing test inputs and calling the functions under test:\n1. Provide the code in plain text format, without explanations or Markdown.\n2. If the method under test belongs to a trait, construct appropriate structs within the test function, but avoid method overrides. If the method under test uses generics, instantiate them with suitable types based on the context.\n3. Generate test code with minimal scope: avoid creating external structures or implementations. Instead, define any necessary helper structures or implementations directly within the test function when required.\n4. Whenever possible, initialize the corresponding data structures using the initialization methods provided in the context.\n5. Ensure the generated function is fully implemented and can be compiled and executed directly without any missing parts.\n6. Create a minimal yet complete set of test functions, ensuring they adhere to all provided preconditions and cover boundary conditions, and reference the inferred test input conditions or ranges.\n7. Ensure the test inputs are designed to cover the inferred test input conditions or ranges as comprehensively as possible, with particular emphasis on boundary cases.\n8. Focus on crafting test inputs that effectively reveal potential bugs while meeting the specified requirements.\n9. Omit test oracles and assertions; concentrate on generating test inputs and function calls.\n10. Do not create a test module, but include intrinsic attributes like #[test] or #[should_panic] where necessary.\n",
  "static_pt": "The context for the focal function is as follows:\n// regex-automata/src/meta/regex.rs\n// crate name is regex_automata\ntype CachePool = Pool<Cache, CachePoolFn>;\ntype CachePoolGuard<'a> = PoolGuard<'a, Cache, CachePoolFn>;\ntype CachePoolFn = Box<dyn Fn() -> Cache + Send + Sync + UnwindSafe + RefUnwindSafe>;\nuse core::{borrow::Borrow, panic::{RefUnwindSafe, UnwindSafe}};\nuse alloc::{boxed::Box, sync::Arc, vec, vec::Vec};\nuse regex_syntax::{ast, hir::{self, Hir}};\nuse crate::{\n    meta::{\n        error::BuildError, strategy::{self, Strategy},\n        wrappers,\n    },\n    nfa::thompson::WhichCaptures,\n    util::{\n        captures::{Captures, GroupInfo},\n        iter, pool::{Pool, PoolGuard},\n        prefilter::Prefilter, primitives::{NonMaxUsize, PatternID},\n        search::{HalfMatch, Input, Match, MatchKind, PatternSet, Span},\n    },\n};\n#[derive(Debug, Clone)]\npub struct Cache {\n    pub(crate) capmatches: Captures,\n    pub(crate) pikevm: wrappers::PikeVMCache,\n    pub(crate) backtrack: wrappers::BoundedBacktrackerCache,\n    pub(crate) onepass: wrappers::OnePassCache,\n    pub(crate) hybrid: wrappers::HybridCache,\n    pub(crate) revhybrid: wrappers::ReverseHybridCache,\n}\n#[derive(Clone, Debug)]\npub(crate) struct PikeVMCache(Option<pikevm::Cache>);\n#[derive(Clone, Debug)]\npub(crate) struct ReverseHybridCache(\n    #[cfg(feature = \"hybrid\")]\n    Option<hybrid::dfa::Cache>,\n    #[cfg(not(feature = \"hybrid\"))]\n    (),\n);\n#[derive(Clone, Debug)]\npub(crate) struct HybridCache(\n    #[cfg(feature = \"hybrid\")]\n    Option<hybrid::regex::Cache>,\n    #[cfg(not(feature = \"hybrid\"))]\n    (),\n);\n#[derive(Clone, Debug)]\npub(crate) struct BoundedBacktrackerCache(\n    #[cfg(feature = \"nfa-backtrack\")]\n    Option<backtrack::Cache>,\n    #[cfg(not(feature = \"nfa-backtrack\"))]\n    (),\n);\n#[derive(Clone, Debug)]\npub(crate) struct OnePassCache(\n    #[cfg(feature = \"dfa-onepass\")]\n    Option<onepass::Cache>,\n    #[cfg(not(feature = \"dfa-onepass\"))]\n    (),\n);\n#[derive(Clone)]\npub struct Captures {\n    /// The group info that these capture groups are coupled to. This is what\n    /// gives the \"convenience\" of the `Captures` API. Namely, it provides the\n    /// slot mapping and the name|-->index mapping for capture lookups by name.\n    group_info: GroupInfo,\n    /// The ID of the pattern that matched. Regex engines must set this to\n    /// None when no match occurs.\n    pid: Option<PatternID>,\n    /// The slot values, i.e., submatch offsets.\n    ///\n    /// In theory, the smallest sequence of slots would be something like\n    /// `max(groups(pattern) for pattern in regex) * 2`, but instead, we use\n    /// `sum(groups(pattern) for pattern in regex) * 2`. Why?\n    ///\n    /// Well, the former could be used in theory, because we don't generally\n    /// have any overlapping APIs that involve capturing groups. Therefore,\n    /// there's technically never any need to have slots set for multiple\n    /// patterns. However, this might change some day, in which case, we would\n    /// need to have slots available.\n    ///\n    /// The other reason is that during the execution of some regex engines,\n    /// there exists a point in time where multiple slots for different\n    /// patterns may be written to before knowing which pattern has matched.\n    /// Therefore, the regex engines themselves, in order to support multiple\n    /// patterns correctly, must have all slots available. If `Captures`\n    /// doesn't have all slots available, then regex engines can't write\n    /// directly into the caller provided `Captures` and must instead write\n    /// into some other storage and then copy the slots involved in the match\n    /// at the end of the search.\n    ///\n    /// So overall, at least as of the time of writing, it seems like the path\n    /// of least resistance is to just require allocating all possible slots\n    /// instead of the conceptual minimum. Another way to justify this is that\n    /// the most common case is a single pattern, in which case, there is no\n    /// inefficiency here since the 'max' and 'sum' calculations above are\n    /// equivalent in that case.\n    ///\n    /// N.B. The mapping from group index to slot is maintained by `GroupInfo`\n    /// and is considered an API guarantee. See `GroupInfo` for more details on\n    /// that mapping.\n    ///\n    /// N.B. `Option<NonMaxUsize>` has the same size as a `usize`.\n    slots: Vec<Option<NonMaxUsize>>,\n}\nimpl Cache {\n    pub fn new(re: &Regex) -> Cache {}\n    pub fn reset(&mut self, re: &Regex) {}\n    pub fn memory_usage(&self) -> usize {\n        let mut bytes = 0;\n        bytes += self.pikevm.memory_usage();\n        bytes += self.backtrack.memory_usage();\n        bytes += self.onepass.memory_usage();\n        bytes += self.hybrid.memory_usage();\n        bytes += self.revhybrid.memory_usage();\n        bytes\n    }\n}\nimpl PikeVMCache {\n    pub(crate) fn none() -> PikeVMCache {}\n    pub(crate) fn new(builder: &PikeVM) -> PikeVMCache {}\n    pub(crate) fn reset(&mut self, builder: &PikeVM) {}\n    pub(crate) fn memory_usage(&self) -> usize {\n        self.0.as_ref().map_or(0, |c| c.memory_usage())\n    }\n}\nimpl ReverseHybridCache {\n    pub(crate) fn none() -> ReverseHybridCache {}\n    pub(crate) fn new(builder: &ReverseHybrid) -> ReverseHybridCache {}\n    pub(crate) fn reset(&mut self, builder: &ReverseHybrid) {}\n    pub(crate) fn memory_usage(&self) -> usize {\n        #[cfg(feature = \"hybrid\")] { self.0.as_ref().map_or(0, |c| c.memory_usage()) }\n        #[cfg(not(feature = \"hybrid\"))] { 0 }\n    }\n}\nimpl HybridCache {\n    pub(crate) fn none() -> HybridCache {}\n    pub(crate) fn new(builder: &Hybrid) -> HybridCache {}\n    pub(crate) fn reset(&mut self, builder: &Hybrid) {}\n    pub(crate) fn memory_usage(&self) -> usize {\n        #[cfg(feature = \"hybrid\")] { self.0.as_ref().map_or(0, |c| c.memory_usage()) }\n        #[cfg(not(feature = \"hybrid\"))] { 0 }\n    }\n}\nimpl BoundedBacktrackerCache {\n    pub(crate) fn none() -> BoundedBacktrackerCache {}\n    pub(crate) fn new(builder: &BoundedBacktracker) -> BoundedBacktrackerCache {}\n    pub(crate) fn reset(&mut self, builder: &BoundedBacktracker) {}\n    pub(crate) fn memory_usage(&self) -> usize {\n        #[cfg(feature = \"nfa-backtrack\")]\n        { self.0.as_ref().map_or(0, |c| c.memory_usage()) }\n        #[cfg(not(feature = \"nfa-backtrack\"))] { 0 }\n    }\n}\nimpl OnePassCache {\n    pub(crate) fn none() -> OnePassCache {}\n    pub(crate) fn new(builder: &OnePass) -> OnePassCache {}\n    pub(crate) fn reset(&mut self, builder: &OnePass) {}\n    pub(crate) fn memory_usage(&self) -> usize {\n        #[cfg(feature = \"dfa-onepass\")]\n        { self.0.as_ref().map_or(0, |c| c.memory_usage()) }\n        #[cfg(not(feature = \"dfa-onepass\"))] { 0 }\n    }\n}\n\nThe function to be tested is presented with each line formatted as 'line number + code':\n/// Returns the heap memory usage, in bytes, of this cache.\n///\n/// This does **not** include the stack size used up by this cache. To\n/// compute that, use `std::mem::size_of::<Cache>()`.\n2392 pub fn memory_usage(&self) -> usize {\n2393     let mut bytes = 0;\n2394     bytes += self.pikevm.memory_usage();\n2395     bytes += self.backtrack.memory_usage();\n2396     bytes += self.onepass.memory_usage();\n2397     bytes += self.hybrid.memory_usage();\n2398     bytes += self.revhybrid.memory_usage();\n2399     bytes\n2400 }\n\nGenerate each test function in such a manner that it concurrently satisfies all the following preconditions:\n",
  "depend_pt": ""
}