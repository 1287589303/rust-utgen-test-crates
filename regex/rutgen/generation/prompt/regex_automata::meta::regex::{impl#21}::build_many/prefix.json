{
  "system_pt": "As a software testing expert, please generate Rust test functions based on the following guidelines, focusing solely on constructing test inputs and calling the functions under test:\n1. Provide the code in plain text format, without explanations or Markdown.\n2. If the method under test belongs to a trait, construct appropriate structs within the test function, but avoid method overrides. If the method under test uses generics, instantiate them with suitable types based on the context.\n3. Generate test code with minimal scope: avoid creating external structures or implementations. Instead, define any necessary helper structures or implementations directly within the test function when required.\n4. Whenever possible, initialize the corresponding data structures using the initialization methods provided in the context.\n5. Ensure the generated function is fully implemented and can be compiled and executed directly without any missing parts.\n6. Create a minimal yet complete set of test functions, ensuring they adhere to all provided preconditions and cover boundary conditions, and reference the inferred test input conditions or ranges.\n7. Ensure the test inputs are designed to cover the inferred test input conditions or ranges as comprehensively as possible, with particular emphasis on boundary cases.\n8. Focus on crafting test inputs that effectively reveal potential bugs while meeting the specified requirements.\n9. Omit test oracles and assertions; concentrate on generating test inputs and function calls.\n10. Do not create a test module, but include intrinsic attributes like #[test] or #[should_panic] where necessary.\n",
  "static_pt": "The context for the focal function is as follows:\n// regex-automata/src/meta/regex.rs\n// crate name is regex_automata\ntype CachePool = Pool<Cache, CachePoolFn>;\ntype CachePoolGuard<'a> = PoolGuard<'a, Cache, CachePoolFn>;\ntype CachePoolFn = Box<dyn Fn() -> Cache + Send + Sync + UnwindSafe + RefUnwindSafe>;\nuse core::{borrow::Borrow, panic::{RefUnwindSafe, UnwindSafe}};\nuse alloc::{boxed::Box, sync::Arc, vec, vec::Vec};\nuse regex_syntax::{ast, hir::{self, Hir}};\nuse crate::{\n    meta::{\n        error::BuildError, strategy::{self, Strategy},\n        wrappers,\n    },\n    nfa::thompson::WhichCaptures,\n    util::{\n        captures::{Captures, GroupInfo},\n        iter, pool::{Pool, PoolGuard},\n        prefilter::Prefilter, primitives::{NonMaxUsize, PatternID},\n        search::{HalfMatch, Input, Match, MatchKind, PatternSet, Span},\n    },\n};\n#[derive(Clone, Debug)]\npub struct Builder {\n    config: Config,\n    ast: ast::parse::ParserBuilder,\n    hir: hir::translate::TranslatorBuilder,\n}\n#[derive(Clone, Copy, Debug)]\npub struct Config {\n    case_insensitive: bool,\n    multi_line: bool,\n    dot_matches_new_line: bool,\n    crlf: bool,\n    line_terminator: u8,\n    swap_greed: bool,\n    ignore_whitespace: bool,\n    unicode: bool,\n    utf8: bool,\n    nest_limit: u32,\n    octal: bool,\n}\n#[derive(Clone, Copy, Default, Eq, Hash, PartialEq, PartialOrd, Ord)]\n#[repr(transparent)]\npub struct PatternID(SmallIndex);\n#[derive(Clone, Debug, Default)]\npub struct Config {\n    match_kind: Option<MatchKind>,\n    utf8_empty: Option<bool>,\n    autopre: Option<bool>,\n    pre: Option<Option<Prefilter>>,\n    which_captures: Option<WhichCaptures>,\n    nfa_size_limit: Option<Option<usize>>,\n    onepass_size_limit: Option<Option<usize>>,\n    hybrid_cache_capacity: Option<usize>,\n    hybrid: Option<bool>,\n    dfa: Option<bool>,\n    dfa_size_limit: Option<Option<usize>>,\n    dfa_state_limit: Option<Option<usize>>,\n    onepass: Option<bool>,\n    backtrack: Option<bool>,\n    byte_classes: Option<bool>,\n    line_terminator: Option<u8>,\n}\n#[derive(Clone, Debug)]\npub struct BuildError {\n    kind: BuildErrorKind,\n}\n#[derive(Debug)]\npub struct Regex {\n    /// The actual regex implementation.\n    imp: Arc<RegexI>,\n    /// A thread safe pool of caches.\n    ///\n    /// For the higher level search APIs, a `Cache` is automatically plucked\n    /// from this pool before running a search. The lower level `with` methods\n    /// permit the caller to provide their own cache, thereby bypassing\n    /// accesses to this pool.\n    ///\n    /// Note that we put this outside the `Arc` so that cloning a `Regex`\n    /// results in creating a fresh `CachePool`. This in turn permits callers\n    /// to clone regexes into separate threads where each such regex gets\n    /// the pool's \"thread owner\" optimization. Otherwise, if one shares the\n    /// `Regex` directly, then the pool will go through a slower mutex path for\n    /// all threads except for the \"owner.\"\n    pool: CachePool,\n}\n#[derive(Clone, Debug, Default)]\npub struct Config {\n    utf8: Option<bool>,\n    reverse: Option<bool>,\n    nfa_size_limit: Option<Option<usize>>,\n    shrink: Option<bool>,\n    which_captures: Option<WhichCaptures>,\n    look_matcher: Option<LookMatcher>,\n    #[cfg(test)]\n    unanchored_prefix: Option<bool>,\n}\n#[derive(Clone, Debug)]\npub(crate) struct Config {\n    match_kind: MatchKind,\n    quit: ByteSet,\n    dfa_size_limit: Option<usize>,\n    determinize_size_limit: Option<usize>,\n}\n#[cfg(feature = \"dfa-build\")]\n#[derive(Clone, Debug, Default)]\npub struct Config {\n    accelerate: Option<bool>,\n    pre: Option<Option<Prefilter>>,\n    minimize: Option<bool>,\n    match_kind: Option<MatchKind>,\n    start_kind: Option<StartKind>,\n    starts_for_each_pattern: Option<bool>,\n    byte_classes: Option<bool>,\n    unicode_word_boundary: Option<bool>,\n    quitset: Option<ByteSet>,\n    specialize_start_states: Option<bool>,\n    dfa_size_limit: Option<Option<usize>>,\n    determinize_size_limit: Option<Option<usize>>,\n}\n#[derive(Clone, Debug, Default)]\npub struct Config {\n    match_kind: Option<MatchKind>,\n    pre: Option<Option<Prefilter>>,\n    starts_for_each_pattern: Option<bool>,\n    byte_classes: Option<bool>,\n    unicode_word_boundary: Option<bool>,\n    quitset: Option<ByteSet>,\n    specialize_start_states: Option<bool>,\n    cache_capacity: Option<usize>,\n    skip_cache_capacity_check: Option<bool>,\n    minimum_cache_clear_count: Option<Option<usize>>,\n    minimum_bytes_per_state: Option<Option<usize>>,\n}\n#[derive(Clone, Debug)]\npub struct Config {\n    look_behind: Option<u8>,\n    anchored: Anchored,\n}\n#[derive(Clone, Debug, Default)]\npub struct Config {\n    match_kind: Option<MatchKind>,\n    starts_for_each_pattern: Option<bool>,\n    byte_classes: Option<bool>,\n    size_limit: Option<Option<usize>>,\n}\n#[derive(Clone, Debug, Default)]\npub struct Config {\n    match_kind: Option<MatchKind>,\n    pre: Option<Option<Prefilter>>,\n}\n#[derive(Clone, Debug, Default)]\npub struct Config {\n    pre: Option<Option<Prefilter>>,\n    visited_capacity: Option<usize>,\n}\nimpl Builder {\n    pub fn new() -> Builder {}\n    pub fn build(&self, pattern: &str) -> Result<Regex, BuildError> {}\n    pub fn build_many<P: AsRef<str>>(\n        &self,\n        patterns: &[P],\n    ) -> Result<Regex, BuildError> {\n        use crate::util::primitives::IteratorIndexExt;\n        log! {\n            debug!(\"building meta regex with {} patterns:\", patterns.len()); for (pid, p)\n            in patterns.iter().with_pattern_ids() { let p = p.as_ref(); let maxoff = p\n            .char_indices().map(| (i, ch) | i + ch.len_utf8()).take(1000).last()\n            .unwrap_or(0); if maxoff < p.len() { debug!(\"{:?}: {}[... snip ...]\", pid, &\n            p[..maxoff]); } else { debug!(\"{:?}: {}\", pid, p); } }\n        }\n        let (mut asts, mut hirs) = (vec![], vec![]);\n        for (pid, p) in patterns.iter().with_pattern_ids() {\n            let ast = self\n                .ast\n                .build()\n                .parse(p.as_ref())\n                .map_err(|err| BuildError::ast(pid, err))?;\n            asts.push(ast);\n        }\n        for ((pid, p), ast) in patterns.iter().with_pattern_ids().zip(asts.iter()) {\n            let hir = self\n                .hir\n                .build()\n                .translate(p.as_ref(), ast)\n                .map_err(|err| BuildError::hir(pid, err))?;\n            hirs.push(hir);\n        }\n        self.build_many_from_hir(&hirs)\n    }\n    pub fn build_from_hir(&self, hir: &Hir) -> Result<Regex, BuildError> {}\n    pub fn build_many_from_hir<H: Borrow<Hir>>(\n        &self,\n        hirs: &[H],\n    ) -> Result<Regex, BuildError> {\n        let config = self.config.clone();\n        let hirs: Vec<&Hir> = hirs.iter().map(|hir| hir.borrow()).collect();\n        let info = RegexInfo::new(config, &hirs);\n        let strat = strategy::new(&info, &hirs)?;\n        let pool = {\n            let strat = Arc::clone(&strat);\n            let create: CachePoolFn = Box::new(move || strat.create_cache());\n            Pool::new(create)\n        };\n        Ok(Regex {\n            imp: Arc::new(RegexI { strat, info }),\n            pool,\n        })\n    }\n    pub fn configure(&mut self, config: Config) -> &mut Builder {}\n    pub fn syntax(&mut self, config: crate::util::syntax::Config) -> &mut Builder {}\n}\n\nThe function to be tested is presented with each line formatted as 'line number + code':\n/// Builds a `Regex` from many pattern strings.\n///\n/// If there was a problem parsing any of the patterns or a problem turning\n/// them into a regex matcher, then an error is returned.\n///\n/// # Example: finding the pattern that caused an error\n///\n/// When a syntax error occurs, it is possible to ask which pattern\n/// caused the syntax error.\n///\n/// ```\n/// use regex_automata::{meta::Regex, PatternID};\n///\n/// let err = Regex::builder()\n///     .build_many(&[\"a\", \"b\", r\"\\p{Foo}\", \"c\"])\n///     .unwrap_err();\n/// assert_eq!(Some(PatternID::must(2)), err.pattern());\n/// ```\n///\n/// # Example: zero patterns is valid\n///\n/// Building a regex with zero patterns results in a regex that never\n/// matches anything. Because this routine is generic, passing an empty\n/// slice usually requires a turbo-fish (or something else to help type\n/// inference).\n///\n/// ```\n/// use regex_automata::{meta::Regex, util::syntax, Match};\n///\n/// let re = Regex::builder()\n///     .build_many::<&str>(&[])?;\n/// assert_eq!(None, re.find(\"\"));\n///\n/// # Ok::<(), Box<dyn std::error::Error>>(())\n/// ```\n3398 pub fn build_many<P: AsRef<str>>(\n3399     &self,\n3400     patterns: &[P],\n3401 ) -> Result<Regex, BuildError> {\n3402     use crate::util::primitives::IteratorIndexExt;\n3403     log! {\n3404         debug!(\"building meta regex with {} patterns:\", patterns.len());\n3405         for (pid, p) in patterns.iter().with_pattern_ids() {\n3406             let p = p.as_ref();\n3407             // We might split a grapheme with this truncation logic, but\n3408             // that's fine. We at least avoid splitting a codepoint.\n3409             let maxoff = p\n3410                 .char_indices()\n3411                 .map(|(i, ch)| i + ch.len_utf8())\n3412                 .take(1000)\n3413                 .last()\n3414                 .unwrap_or(0);\n3415             if maxoff < p.len() {\n3416                 debug!(\"{:?}: {}[... snip ...]\", pid, &p[..maxoff]);\n3417             } else {\n3418                 debug!(\"{:?}: {}\", pid, p);\n3419             }\n3420         }\n3421     }\n3422     let (mut asts, mut hirs) = (vec![], vec![]);\n3423     for (pid, p) in patterns.iter().with_pattern_ids() {\n3424         let ast = self\n3425             .ast\n3426             .build()\n3427             .parse(p.as_ref())\n3428             .map_err(|err| BuildError::ast(pid, err))?;\n3429         asts.push(ast);\n3430     }\n3431     for ((pid, p), ast) in\n3432         patterns.iter().with_pattern_ids().zip(asts.iter())\n3433     {\n3434         let hir = self\n3435             .hir\n3436             .build()\n3437             .translate(p.as_ref(), ast)\n3438             .map_err(|err| BuildError::hir(pid, err))?;\n3439         hirs.push(hir);\n3440     }\n3441     self.build_many_from_hir(&hirs)\n3442 }\n\nGenerate each test function in such a manner that it concurrently satisfies all the following preconditions:\n",
  "depend_pt": ""
}