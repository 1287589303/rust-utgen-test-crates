{
  "system_pt": "As a software testing expert, please generate Rust test functions based on the following guidelines, focusing solely on constructing test inputs and calling the functions under test:\n1. Provide the code in plain text format, without explanations or Markdown.\n2. If the method under test belongs to a trait, construct appropriate structs within the test function, but avoid method overrides. If the method under test uses generics, instantiate them with suitable types based on the context.\n3. Generate test code with minimal scope: avoid creating external structures or implementations. Instead, define any necessary helper structures or implementations directly within the test function when required.\n4. Whenever possible, initialize the corresponding data structures using the initialization methods provided in the context.\n5. Ensure the generated function is fully implemented and can be compiled and executed directly without any missing parts.\n6. Create a minimal yet complete set of test functions, ensuring they adhere to all provided preconditions and cover boundary conditions, and reference the inferred test input conditions or ranges.\n7. Ensure the test inputs are designed to cover the inferred test input conditions or ranges as comprehensively as possible, with particular emphasis on boundary cases.\n8. Focus on crafting test inputs that effectively reveal potential bugs while meeting the specified requirements.\n9. Omit test oracles and assertions; concentrate on generating test inputs and function calls.\n10. Do not create a test module, but include intrinsic attributes like #[test] or #[should_panic] where necessary.\n",
  "static_pt": "The context for the focal function is as follows:\n// regex-automata/src/dfa/onepass.rs\n// crate name is regex_automata\nuse alloc::{vec, vec::Vec};\nuse crate::{\n    dfa::{remapper::Remapper, DEAD},\n    nfa::thompson::{self, NFA},\n    util::{\n        alphabet::ByteClasses, captures::Captures, escape::DebugByte,\n        int::{Usize, U32, U64, U8},\n        look::{Look, LookSet, UnicodeWordBoundaryError},\n        primitives::{NonMaxUsize, PatternID, StateID},\n        search::{Anchored, Input, Match, MatchError, MatchKind, Span},\n        sparse_set::SparseSet,\n    },\n};\npub(super) trait Remappable: core::fmt::Debug {\n    fn state_len(&self) -> usize;\n    fn stride2(&self) -> usize;\n    fn swap_states(&mut self, id1: StateID, id2: StateID);\n    fn remap(&mut self, map: impl Fn(StateID) -> StateID);\n}\n#[derive(Clone)]\npub struct DFA {\n    /// The configuration provided by the caller.\n    config: Config,\n    /// The NFA used to build this DFA.\n    ///\n    /// NOTE: We probably don't need to store the NFA here, but we use enough\n    /// bits from it that it's convenient to do so. And there really isn't much\n    /// cost to doing so either, since an NFA is reference counted internally.\n    nfa: NFA,\n    /// The transition table. Given a state ID 's' and a byte of haystack 'b',\n    /// the next state is `table[sid + classes[byte]]`.\n    ///\n    /// The stride of this table (i.e., the number of columns) is always\n    /// a power of 2, even if the alphabet length is smaller. This makes\n    /// converting between state IDs and state indices very cheap.\n    ///\n    /// Note that the stride always includes room for one extra \"transition\"\n    /// that isn't actually a transition. It is a 'PatternEpsilons' that is\n    /// used for match states only. Because of this, the maximum number of\n    /// active columns in the transition table is 257, which means the maximum\n    /// stride is 512 (the next power of 2 greater than or equal to 257).\n    table: Vec<Transition>,\n    /// The DFA state IDs of the starting states.\n    ///\n    /// `starts[0]` is always present and corresponds to the starting state\n    /// when searching for matches of any pattern in the DFA.\n    ///\n    /// `starts[i]` where i>0 corresponds to the starting state for the pattern\n    /// ID 'i-1'. These starting states are optional.\n    starts: Vec<StateID>,\n    /// Every state ID >= this value corresponds to a match state.\n    ///\n    /// This is what a search uses to detect whether a state is a match state\n    /// or not. It requires only a simple comparison instead of bit-unpacking\n    /// the PatternEpsilons from every state.\n    min_match_id: StateID,\n    /// The alphabet of this DFA, split into equivalence classes. Bytes in the\n    /// same equivalence class can never discriminate between a match and a\n    /// non-match.\n    classes: ByteClasses,\n    /// The number of elements in each state in the transition table. This may\n    /// be less than the stride, since the stride is always a power of 2 and\n    /// the alphabet length can be anything up to and including 256.\n    alphabet_len: usize,\n    /// The number of columns in the transition table, expressed as a power of\n    /// 2.\n    stride2: usize,\n    /// The offset at which the PatternEpsilons for a match state is stored in\n    /// the transition table.\n    ///\n    /// PERF: One wonders whether it would be better to put this in a separate\n    /// allocation, since only match states have a non-empty PatternEpsilons\n    /// and the number of match states tends be dwarfed by the number of\n    /// non-match states. So this would save '8*len(non_match_states)' for each\n    /// DFA. The question is whether moving this to a different allocation will\n    /// lead to a perf hit during searches. You might think dealing with match\n    /// states is rare, but some regexes spend a lot of time in match states\n    /// gobbling up input. But... match state handling is already somewhat\n    /// expensive, so maybe this wouldn't do much? Either way, it's worth\n    /// experimenting.\n    pateps_offset: usize,\n    /// The first explicit slot index. This refers to the first slot appearing\n    /// immediately after the last implicit slot. It is always 'patterns.len()\n    /// * 2'.\n    ///\n    /// We record this because we only store the explicit slots in our DFA\n    /// transition table that need to be saved. Implicit slots are handled\n    /// automatically as part of the search.\n    explicit_slot_start: usize,\n}\n#[derive(Clone)]\npub struct Captures {\n    /// The group info that these capture groups are coupled to. This is what\n    /// gives the \"convenience\" of the `Captures` API. Namely, it provides the\n    /// slot mapping and the name|-->index mapping for capture lookups by name.\n    group_info: GroupInfo,\n    /// The ID of the pattern that matched. Regex engines must set this to\n    /// None when no match occurs.\n    pid: Option<PatternID>,\n    /// The slot values, i.e., submatch offsets.\n    ///\n    /// In theory, the smallest sequence of slots would be something like\n    /// `max(groups(pattern) for pattern in regex) * 2`, but instead, we use\n    /// `sum(groups(pattern) for pattern in regex) * 2`. Why?\n    ///\n    /// Well, the former could be used in theory, because we don't generally\n    /// have any overlapping APIs that involve capturing groups. Therefore,\n    /// there's technically never any need to have slots set for multiple\n    /// patterns. However, this might change some day, in which case, we would\n    /// need to have slots available.\n    ///\n    /// The other reason is that during the execution of some regex engines,\n    /// there exists a point in time where multiple slots for different\n    /// patterns may be written to before knowing which pattern has matched.\n    /// Therefore, the regex engines themselves, in order to support multiple\n    /// patterns correctly, must have all slots available. If `Captures`\n    /// doesn't have all slots available, then regex engines can't write\n    /// directly into the caller provided `Captures` and must instead write\n    /// into some other storage and then copy the slots involved in the match\n    /// at the end of the search.\n    ///\n    /// So overall, at least as of the time of writing, it seems like the path\n    /// of least resistance is to just require allocating all possible slots\n    /// instead of the conceptual minimum. Another way to justify this is that\n    /// the most common case is a single pattern, in which case, there is no\n    /// inefficiency here since the 'max' and 'sum' calculations above are\n    /// equivalent in that case.\n    ///\n    /// N.B. The mapping from group index to slot is maintained by `GroupInfo`\n    /// and is considered an API guarantee. See `GroupInfo` for more details on\n    /// that mapping.\n    ///\n    /// N.B. `Option<NonMaxUsize>` has the same size as a `usize`.\n    slots: Vec<Option<NonMaxUsize>>,\n}\n#[derive(Clone)]\npub struct NFA(Arc<Inner>);\n#[derive(Clone, Copy, Default, Eq, Hash, PartialEq, PartialOrd, Ord)]\n#[repr(transparent)]\npub struct StateID(SmallIndex);\n#[derive(Clone, Copy)]\nstruct Transition {\n    byte: u8,\n    next: StateID,\n}\n#[derive(Clone, Debug, Eq, PartialEq)]\npub struct MatchError(\n    #[cfg(feature = \"alloc\")]\n    alloc::boxed::Box<MatchErrorKind>,\n    #[cfg(not(feature = \"alloc\"))]\n    MatchErrorKind,\n);\n#[derive(Clone, Debug)]\npub(crate) struct Config {\n    match_kind: MatchKind,\n    quit: ByteSet,\n    dfa_size_limit: Option<usize>,\n    determinize_size_limit: Option<usize>,\n}\n#[derive(Clone, Debug, Default)]\npub struct Config {\n    utf8: Option<bool>,\n    reverse: Option<bool>,\n    nfa_size_limit: Option<Option<usize>>,\n    shrink: Option<bool>,\n    which_captures: Option<WhichCaptures>,\n    look_matcher: Option<LookMatcher>,\n    #[cfg(test)]\n    unanchored_prefix: Option<bool>,\n}\n#[derive(Clone)]\nstruct Transition {\n    /// The byte range.\n    range: Utf8Range,\n    /// The next state to transition to.\n    next_id: StateID,\n}\n#[derive(Clone, Debug)]\npub struct Config {\n    look_behind: Option<u8>,\n    anchored: Anchored,\n}\n#[derive(Clone, Copy)]\npub struct ByteClasses([u8; 256]);\n#[derive(Clone)]\npub struct Input<'h> {\n    haystack: &'h [u8],\n    span: Span,\n    anchored: Anchored,\n    earliest: bool,\n}\n#[derive(Clone, Debug, Default)]\npub struct Config {\n    match_kind: Option<MatchKind>,\n    pre: Option<Option<Prefilter>>,\n}\n#[derive(Clone, Debug, Default)]\npub struct Config {\n    match_kind: Option<MatchKind>,\n    pre: Option<Option<Prefilter>>,\n    starts_for_each_pattern: Option<bool>,\n    byte_classes: Option<bool>,\n    unicode_word_boundary: Option<bool>,\n    quitset: Option<ByteSet>,\n    specialize_start_states: Option<bool>,\n    cache_capacity: Option<usize>,\n    skip_cache_capacity_check: Option<bool>,\n    minimum_cache_clear_count: Option<Option<usize>>,\n    minimum_bytes_per_state: Option<Option<usize>>,\n}\n#[derive(Clone, Copy, Debug)]\npub struct Config {\n    case_insensitive: bool,\n    multi_line: bool,\n    dot_matches_new_line: bool,\n    crlf: bool,\n    line_terminator: u8,\n    swap_greed: bool,\n    ignore_whitespace: bool,\n    unicode: bool,\n    utf8: bool,\n    nest_limit: u32,\n    octal: bool,\n}\n#[derive(Clone, Copy, Eq, Hash, PartialEq)]\npub struct Transition {\n    /// The inclusive start of the byte range.\n    pub start: u8,\n    /// The inclusive end of the byte range.\n    pub end: u8,\n    /// The identifier of the state to transition to.\n    pub next: StateID,\n}\n#[derive(Clone, Copy, Eq, PartialEq)]\nstruct Transition(u64);\n#[derive(Clone, Debug, Default)]\npub struct Config {\n    match_kind: Option<MatchKind>,\n    utf8_empty: Option<bool>,\n    autopre: Option<bool>,\n    pre: Option<Option<Prefilter>>,\n    which_captures: Option<WhichCaptures>,\n    nfa_size_limit: Option<Option<usize>>,\n    onepass_size_limit: Option<Option<usize>>,\n    hybrid_cache_capacity: Option<usize>,\n    hybrid: Option<bool>,\n    dfa: Option<bool>,\n    dfa_size_limit: Option<Option<usize>>,\n    dfa_state_limit: Option<Option<usize>>,\n    onepass: Option<bool>,\n    backtrack: Option<bool>,\n    byte_classes: Option<bool>,\n    line_terminator: Option<u8>,\n}\n#[derive(Clone, Copy, Default, Eq, Hash, PartialEq, PartialOrd, Ord)]\n#[repr(transparent)]\npub struct PatternID(SmallIndex);\n#[derive(Clone, Copy, Eq, Hash, PartialEq, PartialOrd, Ord)]\n#[repr(transparent)]\npub struct NonMaxUsize(NonZeroUsize);\n#[cfg(feature = \"dfa-build\")]\n#[derive(Clone, Debug, Default)]\npub struct Config {\n    accelerate: Option<bool>,\n    pre: Option<Option<Prefilter>>,\n    minimize: Option<bool>,\n    match_kind: Option<MatchKind>,\n    start_kind: Option<StartKind>,\n    starts_for_each_pattern: Option<bool>,\n    byte_classes: Option<bool>,\n    unicode_word_boundary: Option<bool>,\n    quitset: Option<ByteSet>,\n    specialize_start_states: Option<bool>,\n    dfa_size_limit: Option<Option<usize>>,\n    determinize_size_limit: Option<Option<usize>>,\n}\n#[derive(Clone, Debug, Default)]\npub struct Config {\n    pre: Option<Option<Prefilter>>,\n    visited_capacity: Option<usize>,\n}\n#[derive(Clone, Debug, Default)]\npub struct Config {\n    match_kind: Option<MatchKind>,\n    starts_for_each_pattern: Option<bool>,\n    byte_classes: Option<bool>,\n    size_limit: Option<Option<usize>>,\n}\n#[derive(Clone, Debug)]\npub struct Cache {\n    /// Scratch space used to store slots during a search. Basically, we use\n    /// the caller provided slots to store slots known when a match occurs.\n    /// But after a match occurs, we might continue a search but ultimately\n    /// fail to extend the match. When continuing the search, we need some\n    /// place to store candidate capture offsets without overwriting the slot\n    /// offsets recorded for the most recently seen match.\n    explicit_slots: Vec<Option<NonMaxUsize>>,\n    /// The number of slots in the caller-provided 'Captures' value for the\n    /// current search. This is always at most 'explicit_slots.len()', but\n    /// might be less than it, if the caller provided fewer slots to fill.\n    explicit_slot_len: usize,\n}\nimpl DFA {\n    #[inline]\n    pub fn is_match<'h, I: Into<Input<'h>>>(&self, cache: &mut Cache, input: I) -> bool {}\n    #[inline]\n    pub fn find<'h, I: Into<Input<'h>>>(\n        &self,\n        cache: &mut Cache,\n        input: I,\n    ) -> Option<Match> {}\n    #[inline]\n    pub fn captures<'h, I: Into<Input<'h>>>(\n        &self,\n        cache: &mut Cache,\n        input: I,\n        caps: &mut Captures,\n    ) {}\n    #[inline]\n    pub fn try_search(\n        &self,\n        cache: &mut Cache,\n        input: &Input<'_>,\n        caps: &mut Captures,\n    ) -> Result<(), MatchError> {\n        let pid = self.try_search_slots(cache, input, caps.slots_mut())?;\n        caps.set_pattern(pid);\n        Ok(())\n    }\n    #[inline]\n    pub fn try_search_slots(\n        &self,\n        cache: &mut Cache,\n        input: &Input<'_>,\n        slots: &mut [Option<NonMaxUsize>],\n    ) -> Result<Option<PatternID>, MatchError> {\n        let utf8empty = self.get_nfa().has_empty() && self.get_nfa().is_utf8();\n        if !utf8empty {\n            return self.try_search_slots_imp(cache, input, slots);\n        }\n        let min = self.get_nfa().group_info().implicit_slot_len();\n        if slots.len() >= min {\n            return self.try_search_slots_imp(cache, input, slots);\n        }\n        if self.get_nfa().pattern_len() == 1 {\n            let mut enough = [None, None];\n            let got = self.try_search_slots_imp(cache, input, &mut enough)?;\n            slots.copy_from_slice(&enough[..slots.len()]);\n            return Ok(got);\n        }\n        let mut enough = vec![None; min];\n        let got = self.try_search_slots_imp(cache, input, &mut enough)?;\n        slots.copy_from_slice(&enough[..slots.len()]);\n        Ok(got)\n    }\n    #[inline(never)]\n    fn try_search_slots_imp(\n        &self,\n        cache: &mut Cache,\n        input: &Input<'_>,\n        slots: &mut [Option<NonMaxUsize>],\n    ) -> Result<Option<PatternID>, MatchError> {}\n}\nimpl Captures {\n    #[inline]\n    pub fn clear(&mut self) {}\n    #[inline]\n    pub fn set_pattern(&mut self, pid: Option<PatternID>) {\n        self.pid = pid;\n    }\n    #[inline]\n    pub fn slots(&self) -> &[Option<NonMaxUsize>] {}\n    #[inline]\n    pub fn slots_mut(&mut self) -> &mut [Option<NonMaxUsize>] {\n        &mut self.slots\n    }\n}\n\nThe function to be tested is presented with each line formatted as 'line number + code':\n/// Executes an anchored leftmost forward search and writes the spans\n/// of capturing groups that participated in a match into the provided\n/// [`Captures`] value. If no match was found, then [`Captures::is_match`]\n/// is guaranteed to return `false`.\n///\n/// The differences with [`DFA::captures`] are:\n///\n/// 1. This returns an error instead of panicking if the search fails.\n/// 2. Accepts an `&Input` instead of a `Into<Input>`. This permits reusing\n/// the same input for multiple searches, which _may_ be important for\n/// latency.\n/// 3. This does not automatically change the [`Anchored`] mode from `No`\n/// to `Yes`. Instead, if [`Input::anchored`] is `Anchored::No`, then an\n/// error is returned.\n///\n/// # Errors\n///\n/// This routine errors if the search could not complete. This can occur\n/// in the following circumstances:\n///\n/// * When the provided `Input` configuration is not supported. For\n/// example, by providing an unsupported anchor mode. Concretely,\n/// this occurs when using [`Anchored::Pattern`] without enabling\n/// [`Config::starts_for_each_pattern`].\n///\n/// When a search returns an error, callers cannot know whether a match\n/// exists or not.\n///\n/// # Example: specific pattern search\n///\n/// This example shows how to build a multi-regex that permits searching\n/// for specific patterns. Note that this is somewhat less useful than\n/// in other regex engines, since a one-pass DFA by definition has no\n/// ambiguity about which pattern can match at a position. That is, if it\n/// were possible for two different patterns to match at the same starting\n/// position, then the multi-regex would not be one-pass and construction\n/// would have failed.\n///\n/// Nevertheless, this can still be useful if you only care about matches\n/// for a specific pattern, and want the DFA to report \"no match\" even if\n/// some other pattern would have matched.\n///\n/// Note that in order to make use of this functionality,\n/// [`Config::starts_for_each_pattern`] must be enabled. It is disabled\n/// by default since it may result in higher memory usage.\n///\n/// ```\n/// use regex_automata::{\n///     dfa::onepass::DFA, Anchored, Input, Match, PatternID,\n/// };\n///\n/// let re = DFA::builder()\n///     .configure(DFA::config().starts_for_each_pattern(true))\n///     .build_many(&[\"[a-z]+\", \"[0-9]+\"])?;\n/// let (mut cache, mut caps) = (re.create_cache(), re.create_captures());\n/// let haystack = \"123abc\";\n/// let input = Input::new(haystack).anchored(Anchored::Yes);\n///\n/// // A normal multi-pattern search will show pattern 1 matches.\n/// re.try_search(&mut cache, &input, &mut caps)?;\n/// assert_eq!(Some(Match::must(1, 0..3)), caps.get_match());\n///\n/// // If we only want to report pattern 0 matches, then we'll get no\n/// // match here.\n/// let input = input.anchored(Anchored::Pattern(PatternID::must(0)));\n/// re.try_search(&mut cache, &input, &mut caps)?;\n/// assert_eq!(None, caps.get_match());\n///\n/// # Ok::<(), Box<dyn std::error::Error>>(())\n/// ```\n///\n/// # Example: specifying the bounds of a search\n///\n/// This example shows how providing the bounds of a search can produce\n/// different results than simply sub-slicing the haystack.\n///\n/// ```\n/// # if cfg!(miri) { return Ok(()); } // miri takes too long\n/// use regex_automata::{dfa::onepass::DFA, Anchored, Input, Match};\n///\n/// // one-pass DFAs fully support Unicode word boundaries!\n/// // A sad joke is that a Unicode aware regex like \\w+\\s is not one-pass.\n/// // :-(\n/// let re = DFA::new(r\"\\b[0-9]{3}\\b\")?;\n/// let (mut cache, mut caps) = (re.create_cache(), re.create_captures());\n/// let haystack = \"foo123bar\";\n///\n/// // Since we sub-slice the haystack, the search doesn't know about\n/// // the larger context and assumes that `123` is surrounded by word\n/// // boundaries. And of course, the match position is reported relative\n/// // to the sub-slice as well, which means we get `0..3` instead of\n/// // `3..6`.\n/// let expected = Some(Match::must(0, 0..3));\n/// let input = Input::new(&haystack[3..6]).anchored(Anchored::Yes);\n/// re.try_search(&mut cache, &input, &mut caps)?;\n/// assert_eq!(expected, caps.get_match());\n///\n/// // But if we provide the bounds of the search within the context of the\n/// // entire haystack, then the search can take the surrounding context\n/// // into account. (And if we did find a match, it would be reported\n/// // as a valid offset into `haystack` instead of its sub-slice.)\n/// let expected = None;\n/// let input = Input::new(haystack).range(3..6).anchored(Anchored::Yes);\n/// re.try_search(&mut cache, &input, &mut caps)?;\n/// assert_eq!(expected, caps.get_match());\n///\n/// # Ok::<(), Box<dyn std::error::Error>>(())\n/// ```\n1887 pub fn try_search(\n1888     &self,\n1889     cache: &mut Cache,\n1890     input: &Input<'_>,\n1891     caps: &mut Captures,\n1892 ) -> Result<(), MatchError> {\n1893     let pid = self.try_search_slots(cache, input, caps.slots_mut())?;\n1894     caps.set_pattern(pid);\n1895     Ok(())\n1896 }\n\nGenerate each test function in such a manner that it concurrently satisfies all the following preconditions:\n",
  "depend_pt": ""
}