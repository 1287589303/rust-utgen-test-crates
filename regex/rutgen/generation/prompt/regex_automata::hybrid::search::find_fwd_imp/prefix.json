{
  "system_pt": "As a software testing expert, please generate Rust test functions based on the following guidelines, focusing solely on constructing test inputs and calling the functions under test:\n1. Provide the code in plain text format, without explanations or Markdown.\n2. If the method under test belongs to a trait, construct appropriate structs within the test function, but avoid method overrides. If the method under test uses generics, instantiate them with suitable types based on the context.\n3. Generate test code with minimal scope: avoid creating external structures or implementations. Instead, define any necessary helper structures or implementations directly within the test function when required.\n4. Whenever possible, initialize the corresponding data structures using the initialization methods provided in the context.\n5. Ensure the generated function is fully implemented and can be compiled and executed directly without any missing parts.\n6. Create a minimal yet complete set of test functions, ensuring they adhere to all provided preconditions and cover boundary conditions, and reference the inferred test input conditions or ranges.\n7. Ensure the test inputs are designed to cover the inferred test input conditions or ranges as comprehensively as possible, with particular emphasis on boundary cases.\n8. Focus on crafting test inputs that effectively reveal potential bugs while meeting the specified requirements.\n9. Omit test oracles and assertions; concentrate on generating test inputs and function calls.\n10. Do not create a test module, but include intrinsic attributes like #[test] or #[should_panic] where necessary.\n",
  "static_pt": "The context for the focal function is as follows:\n// regex-automata/src/hybrid/search.rs\n// crate name is regex_automata\nuse crate::{\n    hybrid::{\n        dfa::{Cache, OverlappingState, DFA},\n        id::LazyStateID,\n    },\n    util::{prefilter::Prefilter, search::{HalfMatch, Input, MatchError, Span}},\n};\n#[derive(Clone)]\npub struct Input<'h> {\n    haystack: &'h [u8],\n    span: Span,\n    anchored: Anchored,\n    earliest: bool,\n}\n#[derive(Clone, Copy, Debug, Default, Eq, Hash, PartialEq, PartialOrd, Ord)]\npub struct LazyStateID(u32);\n#[derive(Clone, Debug)]\npub struct DFA {\n    config: Config,\n    nfa: thompson::NFA,\n    stride2: usize,\n    start_map: StartByteMap,\n    classes: ByteClasses,\n    quitset: ByteSet,\n    cache_capacity: usize,\n}\n#[derive(Clone, Debug)]\npub struct Cache {\n    /// The transition table.\n    ///\n    /// Given a `current` LazyStateID and an `input` byte, the next state can\n    /// be computed via `trans[untagged(current) + equiv_class(input)]`. Notice\n    /// that no multiplication is used. That's because state identifiers are\n    /// \"premultiplied.\"\n    ///\n    /// Note that the next state may be the \"unknown\" state. In this case, the\n    /// next state is not known and determinization for `current` on `input`\n    /// must be performed.\n    trans: Vec<LazyStateID>,\n    /// The starting states for this DFA.\n    ///\n    /// These are computed lazily. Initially, these are all set to \"unknown\"\n    /// lazy state IDs.\n    ///\n    /// When 'starts_for_each_pattern' is disabled (the default), then the size\n    /// of this is constrained to the possible starting configurations based\n    /// on the search parameters. (At time of writing, that's 4.) However,\n    /// when starting states for each pattern is enabled, then there are N\n    /// additional groups of starting states, where each group reflects the\n    /// different possible configurations and N is the number of patterns.\n    starts: Vec<LazyStateID>,\n    /// A sequence of NFA/DFA powerset states that have been computed for this\n    /// lazy DFA. This sequence is indexable by untagged LazyStateIDs. (Every\n    /// tagged LazyStateID can be used to index this sequence by converting it\n    /// to its untagged form.)\n    states: Vec<State>,\n    /// A map from states to their corresponding IDs. This map may be accessed\n    /// via the raw byte representation of a state, which means that a `State`\n    /// does not need to be allocated to determine whether it already exists\n    /// in this map. Indeed, the existence of such a state is what determines\n    /// whether we allocate a new `State` or not.\n    ///\n    /// The higher level idea here is that we do just enough determinization\n    /// for a state to check whether we've already computed it. If we have,\n    /// then we can save a little (albeit not much) work. The real savings is\n    /// in memory usage. If we never checked for trivially duplicate states,\n    /// then our memory usage would explode to unreasonable levels.\n    states_to_id: StateMap,\n    /// Sparse sets used to track which NFA states have been visited during\n    /// various traversals.\n    sparses: SparseSets,\n    /// Scratch space for traversing the NFA graph. (We use space on the heap\n    /// instead of the call stack.)\n    stack: Vec<NFAStateID>,\n    /// Scratch space for building a NFA/DFA powerset state. This is used to\n    /// help amortize allocation since not every powerset state generated is\n    /// added to the cache. In particular, if it already exists in the cache,\n    /// then there is no need to allocate a new `State` for it.\n    scratch_state_builder: StateBuilderEmpty,\n    /// A simple abstraction for handling the saving of at most a single state\n    /// across a cache clearing. This is required for correctness. Namely, if\n    /// adding a new state after clearing the cache fails, then the caller\n    /// must retain the ability to continue using the state ID given. The\n    /// state corresponding to the state ID is what we preserve across cache\n    /// clearings.\n    state_saver: StateSaver,\n    /// The memory usage, in bytes, used by 'states' and 'states_to_id'. We\n    /// track this as new states are added since states use a variable amount\n    /// of heap. Tracking this as we add states makes it possible to compute\n    /// the total amount of memory used by the determinizer in constant time.\n    memory_usage_state: usize,\n    /// The number of times the cache has been cleared. When a minimum cache\n    /// clear count is set, then the cache will return an error instead of\n    /// clearing the cache if the count has been exceeded.\n    clear_count: usize,\n    /// The total number of bytes searched since the last time this cache was\n    /// cleared, not including the current search.\n    ///\n    /// This can be added to the length of the current search to get the true\n    /// total number of bytes searched.\n    ///\n    /// This is generally only non-zero when the\n    /// `Cache::search_{start,update,finish}` APIs are used to track search\n    /// progress.\n    bytes_searched: usize,\n    /// The progress of the current search.\n    ///\n    /// This is only non-`None` when callers utlize the `Cache::search_start`,\n    /// `Cache::search_update` and `Cache::search_finish` APIs.\n    ///\n    /// The purpose of recording search progress is to be able to make a\n    /// determination about the efficiency of the cache. Namely, by keeping\n    /// track of the\n    progress: Option<SearchProgress>,\n}\n#[derive(Clone, Debug, Eq, PartialEq)]\npub struct MatchError(\n    #[cfg(feature = \"alloc\")]\n    alloc::boxed::Box<MatchErrorKind>,\n    #[cfg(not(feature = \"alloc\"))]\n    MatchErrorKind,\n);\n#[derive(Clone, Copy, Default, Eq, PartialEq)]\npub struct LookSet {\n    /// The underlying representation this set is exposed to make it possible\n    /// to store it somewhere efficiently. The representation is that\n    /// of a bitset, where each assertion occupies bit `i` where\n    /// `i = Look::as_repr()`.\n    ///\n    /// Note that users of this internal representation must permit the full\n    /// range of `u16` values to be represented. For example, even if the\n    /// current implementation only makes use of the 10 least significant bits,\n    /// it may use more bits in a future semver compatible release.\n    pub bits: u32,\n}\n#[derive(Clone)]\npub struct NFA(Arc<Inner>);\n#[derive(Clone, Debug)]\npub struct Prefilter {\n    #[cfg(not(feature = \"alloc\"))]\n    _unused: (),\n    #[cfg(feature = \"alloc\")]\n    pre: Arc<dyn PrefilterI>,\n    #[cfg(feature = \"alloc\")]\n    is_fast: bool,\n    #[cfg(feature = \"alloc\")]\n    max_needle_len: usize,\n}\n#[derive(Clone, Copy, Debug, Eq, Hash, PartialEq)]\npub struct HalfMatch {\n    /// The pattern ID.\n    pattern: PatternID,\n    /// The offset of the match.\n    ///\n    /// For forward searches, the offset is exclusive. For reverse searches,\n    /// the offset is inclusive.\n    offset: usize,\n}\n#[derive(Clone, Copy, Eq, Hash, PartialEq)]\npub struct Span {\n    /// The start offset of the span, inclusive.\n    pub start: usize,\n    /// The end offset of the span, exclusive.\n    pub end: usize,\n}\n#[derive(Clone, Copy, Default, Eq, Hash, PartialEq, PartialOrd, Ord)]\n#[repr(transparent)]\npub struct PatternID(SmallIndex);\n#[derive(Clone, Debug)]\npub struct CacheError(());\nimpl<'h> Input<'h> {\n    #[inline]\n    pub fn new<H: ?Sized + AsRef<[u8]>>(haystack: &'h H) -> Input<'h> {}\n    #[inline]\n    pub fn span<S: Into<Span>>(mut self, span: S) -> Input<'h> {}\n    #[inline]\n    pub fn range<R: RangeBounds<usize>>(mut self, range: R) -> Input<'h> {}\n    #[inline]\n    pub fn anchored(mut self, mode: Anchored) -> Input<'h> {}\n    #[inline]\n    pub fn earliest(mut self, yes: bool) -> Input<'h> {}\n    #[inline]\n    pub fn set_span<S: Into<Span>>(&mut self, span: S) {}\n    #[inline]\n    pub fn set_range<R: RangeBounds<usize>>(&mut self, range: R) {}\n    #[inline]\n    pub fn set_start(&mut self, start: usize) {}\n    #[inline]\n    pub fn set_end(&mut self, end: usize) {}\n    #[inline]\n    pub fn set_anchored(&mut self, mode: Anchored) {}\n    #[inline]\n    pub fn set_earliest(&mut self, yes: bool) {}\n    #[inline]\n    pub fn haystack(&self) -> &[u8] {\n        self.haystack\n    }\n    #[inline]\n    pub fn start(&self) -> usize {\n        self.get_span().start\n    }\n    #[inline]\n    pub fn end(&self) -> usize {\n        self.get_span().end\n    }\n    #[inline]\n    pub fn get_span(&self) -> Span {}\n    #[inline]\n    pub fn get_range(&self) -> Range<usize> {}\n    #[inline]\n    pub fn get_anchored(&self) -> Anchored {}\n    #[inline]\n    pub fn get_earliest(&self) -> bool {}\n    #[inline]\n    pub fn is_done(&self) -> bool {}\n    #[inline]\n    pub fn is_char_boundary(&self, offset: usize) -> bool {}\n}\nimpl LazyStateID {\n    #[cfg(any(target_pointer_width = \"32\", target_pointer_width = \"64\"))]\n    const MAX_BIT: usize = 31;\n    #[cfg(target_pointer_width = \"16\")]\n    const MAX_BIT: usize = 15;\n    const MASK_UNKNOWN: usize = 1 << (LazyStateID::MAX_BIT);\n    const MASK_DEAD: usize = 1 << (LazyStateID::MAX_BIT - 1);\n    const MASK_QUIT: usize = 1 << (LazyStateID::MAX_BIT - 2);\n    const MASK_START: usize = 1 << (LazyStateID::MAX_BIT - 3);\n    const MASK_MATCH: usize = 1 << (LazyStateID::MAX_BIT - 4);\n    const MAX: usize = LazyStateID::MASK_MATCH - 1;\n    #[inline]\n    pub(crate) fn new(id: usize) -> Result<LazyStateID, LazyStateIDError> {}\n    #[inline]\n    const fn new_unchecked(id: usize) -> LazyStateID {}\n    #[inline]\n    pub(crate) fn as_usize_untagged(&self) -> usize {}\n    #[inline]\n    pub(crate) const fn as_usize_unchecked(&self) -> usize {}\n    #[inline]\n    pub(crate) const fn to_unknown(&self) -> LazyStateID {}\n    #[inline]\n    pub(crate) const fn to_dead(&self) -> LazyStateID {}\n    #[inline]\n    pub(crate) const fn to_quit(&self) -> LazyStateID {}\n    #[inline]\n    pub(crate) const fn to_start(&self) -> LazyStateID {}\n    #[inline]\n    pub(crate) const fn to_match(&self) -> LazyStateID {}\n    #[inline]\n    pub const fn is_tagged(&self) -> bool {\n        self.as_usize_unchecked() > LazyStateID::MAX\n    }\n    #[inline]\n    pub const fn is_unknown(&self) -> bool {\n        self.as_usize_unchecked() & LazyStateID::MASK_UNKNOWN > 0\n    }\n    #[inline]\n    pub const fn is_dead(&self) -> bool {\n        self.as_usize_unchecked() & LazyStateID::MASK_DEAD > 0\n    }\n    #[inline]\n    pub const fn is_quit(&self) -> bool {\n        self.as_usize_unchecked() & LazyStateID::MASK_QUIT > 0\n    }\n    #[inline]\n    pub const fn is_start(&self) -> bool {\n        self.as_usize_unchecked() & LazyStateID::MASK_START > 0\n    }\n    #[inline]\n    pub const fn is_match(&self) -> bool {\n        self.as_usize_unchecked() & LazyStateID::MASK_MATCH > 0\n    }\n}\nimpl DFA {\n    #[cfg(feature = \"syntax\")]\n    pub fn new(pattern: &str) -> Result<DFA, BuildError> {}\n    #[cfg(feature = \"syntax\")]\n    pub fn new_many<P: AsRef<str>>(patterns: &[P]) -> Result<DFA, BuildError> {}\n    pub fn always_match() -> Result<DFA, BuildError> {}\n    pub fn never_match() -> Result<DFA, BuildError> {}\n    pub fn config() -> Config {}\n    pub fn builder() -> Builder {}\n    pub fn create_cache(&self) -> Cache {}\n    pub fn reset_cache(&self, cache: &mut Cache) {}\n    pub fn pattern_len(&self) -> usize {}\n    pub fn byte_classes(&self) -> &ByteClasses {}\n    pub fn get_config(&self) -> &Config {}\n    pub fn get_nfa(&self) -> &thompson::NFA {\n        &self.nfa\n    }\n    fn stride2(&self) -> usize {}\n    fn stride(&self) -> usize {}\n    pub fn memory_usage(&self) -> usize {}\n}\nimpl Cache {\n    pub fn new(dfa: &DFA) -> Cache {}\n    pub fn reset(&mut self, dfa: &DFA) {}\n    #[inline]\n    pub fn search_start(&mut self, at: usize) {\n        if let Some(p) = self.progress.take() {\n            self.bytes_searched += p.len();\n        }\n        self.progress = Some(SearchProgress { start: at, at });\n    }\n    #[inline]\n    pub fn search_update(&mut self, at: usize) {\n        let p = self.progress.as_mut().expect(\"no in-progress search to update\");\n        p.at = at;\n    }\n    #[inline]\n    pub fn search_finish(&mut self, at: usize) {\n        let mut p = self.progress.take().expect(\"no in-progress search to finish\");\n        p.at = at;\n        self.bytes_searched += p.len();\n    }\n    pub fn search_total_len(&self) -> usize {}\n    pub fn clear_count(&self) -> usize {}\n    pub fn memory_usage(&self) -> usize {}\n}\nimpl MatchError {\n    pub fn new(kind: MatchErrorKind) -> MatchError {}\n    pub fn kind(&self) -> &MatchErrorKind {}\n    pub fn quit(byte: u8, offset: usize) -> MatchError {\n        MatchError::new(MatchErrorKind::Quit {\n            byte,\n            offset,\n        })\n    }\n    pub fn gave_up(offset: usize) -> MatchError {}\n    pub fn haystack_too_long(len: usize) -> MatchError {}\n    pub fn unsupported_anchored(mode: Anchored) -> MatchError {}\n}\nimpl LookSet {\n    #[inline]\n    pub fn empty() -> LookSet {}\n    #[inline]\n    pub fn full() -> LookSet {}\n    #[inline]\n    pub fn singleton(look: Look) -> LookSet {}\n    #[inline]\n    pub fn len(self) -> usize {}\n    #[inline]\n    pub fn is_empty(self) -> bool {\n        self.len() == 0\n    }\n    #[inline]\n    pub fn contains(self, look: Look) -> bool {}\n    #[inline]\n    pub fn contains_anchor(&self) -> bool {}\n    #[inline]\n    pub fn contains_anchor_haystack(&self) -> bool {}\n    #[inline]\n    pub fn contains_anchor_line(&self) -> bool {}\n    #[inline]\n    pub fn contains_anchor_lf(&self) -> bool {}\n    #[inline]\n    pub fn contains_anchor_crlf(&self) -> bool {}\n    #[inline]\n    pub fn contains_word(self) -> bool {}\n    #[inline]\n    pub fn contains_word_unicode(self) -> bool {}\n    #[inline]\n    pub fn contains_word_ascii(self) -> bool {}\n    #[inline]\n    pub fn iter(self) -> LookSetIter {}\n    #[inline]\n    pub fn insert(self, look: Look) -> LookSet {}\n    #[inline]\n    pub fn set_insert(&mut self, look: Look) {}\n    #[inline]\n    pub fn remove(self, look: Look) -> LookSet {}\n    #[inline]\n    pub fn set_remove(&mut self, look: Look) {}\n    #[inline]\n    pub fn subtract(self, other: LookSet) -> LookSet {}\n    #[inline]\n    pub fn set_subtract(&mut self, other: LookSet) {}\n    #[inline]\n    pub fn union(self, other: LookSet) -> LookSet {}\n    #[inline]\n    pub fn set_union(&mut self, other: LookSet) {}\n    #[inline]\n    pub fn intersect(self, other: LookSet) -> LookSet {}\n    #[inline]\n    pub fn set_intersect(&mut self, other: LookSet) {}\n    #[inline]\n    pub fn read_repr(slice: &[u8]) -> LookSet {}\n    #[inline]\n    pub fn write_repr(self, slice: &mut [u8]) {}\n    pub fn available(self) -> Result<(), UnicodeWordBoundaryError> {}\n}\nimpl NFA {\n    #[cfg(feature = \"syntax\")]\n    pub fn new(pattern: &str) -> Result<NFA, BuildError> {}\n    #[cfg(feature = \"syntax\")]\n    pub fn new_many<P: AsRef<str>>(patterns: &[P]) -> Result<NFA, BuildError> {}\n    pub fn always_match() -> NFA {}\n    pub fn never_match() -> NFA {}\n    #[cfg(feature = \"syntax\")]\n    pub fn config() -> Config {}\n    #[cfg(feature = \"syntax\")]\n    pub fn compiler() -> Compiler {}\n    pub fn patterns(&self) -> PatternIter<'_> {}\n    #[inline]\n    pub fn pattern_len(&self) -> usize {}\n    #[inline]\n    pub fn start_anchored(&self) -> StateID {}\n    #[inline]\n    pub fn start_unanchored(&self) -> StateID {}\n    #[inline]\n    pub fn start_pattern(&self, pid: PatternID) -> Option<StateID> {}\n    #[inline]\n    pub(crate) fn byte_class_set(&self) -> &ByteClassSet {}\n    #[inline]\n    pub fn byte_classes(&self) -> &ByteClasses {}\n    #[inline]\n    pub fn state(&self, id: StateID) -> &State {}\n    #[inline]\n    pub fn states(&self) -> &[State] {}\n    #[inline]\n    pub fn group_info(&self) -> &GroupInfo {}\n    #[inline]\n    pub fn has_capture(&self) -> bool {}\n    #[inline]\n    pub fn has_empty(&self) -> bool {}\n    #[inline]\n    pub fn is_utf8(&self) -> bool {}\n    #[inline]\n    pub fn is_reverse(&self) -> bool {}\n    #[inline]\n    pub fn is_always_start_anchored(&self) -> bool {}\n    #[inline]\n    pub fn look_matcher(&self) -> &LookMatcher {}\n    #[inline]\n    pub fn look_set_any(&self) -> LookSet {}\n    #[inline]\n    pub fn look_set_prefix_any(&self) -> LookSet {\n        self.0.look_set_prefix_any\n    }\n    #[inline]\n    pub fn memory_usage(&self) -> usize {}\n}\nimpl Prefilter {\n    pub fn new<B: AsRef<[u8]>>(kind: MatchKind, needles: &[B]) -> Option<Prefilter> {}\n    fn from_choice(choice: Choice, max_needle_len: usize) -> Option<Prefilter> {}\n    #[cfg(feature = \"syntax\")]\n    pub fn from_hir_prefix(kind: MatchKind, hir: &Hir) -> Option<Prefilter> {}\n    #[cfg(feature = \"syntax\")]\n    pub fn from_hirs_prefix<H: Borrow<Hir>>(\n        kind: MatchKind,\n        hirs: &[H],\n    ) -> Option<Prefilter> {}\n    #[inline]\n    pub fn find(&self, haystack: &[u8], span: Span) -> Option<Span> {\n        #[cfg(not(feature = \"alloc\"))] { unreachable!() }\n        #[cfg(feature = \"alloc\")] { self.pre.find(haystack, span) }\n    }\n    #[inline]\n    pub fn prefix(&self, haystack: &[u8], span: Span) -> Option<Span> {}\n    #[inline]\n    pub fn memory_usage(&self) -> usize {}\n    #[inline]\n    pub fn max_needle_len(&self) -> usize {}\n    #[inline]\n    pub fn is_fast(&self) -> bool {}\n}\nimpl HalfMatch {\n    #[inline]\n    pub fn new(pattern: PatternID, offset: usize) -> HalfMatch {\n        HalfMatch { pattern, offset }\n    }\n    #[inline]\n    pub fn must(pattern: usize, offset: usize) -> HalfMatch {}\n    #[inline]\n    pub fn pattern(&self) -> PatternID {}\n    #[inline]\n    pub fn offset(&self) -> usize {}\n}\n#[cfg_attr(feature = \"perf-inline\", inline(always))]\nfn find_fwd_imp(\n    dfa: &DFA,\n    cache: &mut Cache,\n    input: &Input<'_>,\n    pre: Option<&'_ Prefilter>,\n    earliest: bool,\n) -> Result<Option<HalfMatch>, MatchError> {\n    let universal_start = dfa.get_nfa().look_set_prefix_any().is_empty();\n    let mut mat = None;\n    let mut sid = init_fwd(dfa, cache, input)?;\n    let mut at = input.start();\n    macro_rules! next_unchecked {\n        ($sid:expr, $at:expr) => {\n            { let byte = * input.haystack().get_unchecked($at); dfa\n            .next_state_untagged_unchecked(cache, $sid, byte) }\n        };\n    }\n    if let Some(ref pre) = pre {\n        let span = Span::from(at..input.end());\n        match pre.find(input.haystack(), span) {\n            None => return Ok(mat),\n            Some(ref span) => {\n                at = span.start;\n                if !universal_start {\n                    sid = prefilter_restart(dfa, cache, &input, at)?;\n                }\n            }\n        }\n    }\n    cache.search_start(at);\n    while at < input.end() {\n        if sid.is_tagged() {\n            cache.search_update(at);\n            sid = dfa\n                .next_state(cache, sid, input.haystack()[at])\n                .map_err(|_| gave_up(at))?;\n        } else {\n            let mut prev_sid = sid;\n            while at < input.end() {\n                prev_sid = unsafe { next_unchecked!(sid, at) };\n                if prev_sid.is_tagged() || at + 3 >= input.end() {\n                    core::mem::swap(&mut prev_sid, &mut sid);\n                    break;\n                }\n                at += 1;\n                sid = unsafe { next_unchecked!(prev_sid, at) };\n                if sid.is_tagged() {\n                    break;\n                }\n                at += 1;\n                prev_sid = unsafe { next_unchecked!(sid, at) };\n                if prev_sid.is_tagged() {\n                    core::mem::swap(&mut prev_sid, &mut sid);\n                    break;\n                }\n                at += 1;\n                sid = unsafe { next_unchecked!(prev_sid, at) };\n                if sid.is_tagged() {\n                    break;\n                }\n                at += 1;\n            }\n            if sid.is_unknown() {\n                cache.search_update(at);\n                sid = dfa\n                    .next_state(cache, prev_sid, input.haystack()[at])\n                    .map_err(|_| gave_up(at))?;\n            }\n        }\n        if sid.is_tagged() {\n            if sid.is_start() {\n                if let Some(ref pre) = pre {\n                    let span = Span::from(at..input.end());\n                    match pre.find(input.haystack(), span) {\n                        None => {\n                            cache.search_finish(span.end);\n                            return Ok(mat);\n                        }\n                        Some(ref span) => {\n                            if span.start > at {\n                                at = span.start;\n                                if !universal_start {\n                                    sid = prefilter_restart(dfa, cache, &input, at)?;\n                                }\n                                continue;\n                            }\n                        }\n                    }\n                }\n            } else if sid.is_match() {\n                let pattern = dfa.match_pattern(cache, sid, 0);\n                mat = Some(HalfMatch::new(pattern, at));\n                if earliest {\n                    cache.search_finish(at);\n                    return Ok(mat);\n                }\n            } else if sid.is_dead() {\n                cache.search_finish(at);\n                return Ok(mat);\n            } else if sid.is_quit() {\n                cache.search_finish(at);\n                return Err(MatchError::quit(input.haystack()[at], at));\n            } else {\n                debug_assert!(sid.is_unknown());\n                unreachable!(\"sid being unknown is a bug\");\n            }\n        }\n        at += 1;\n    }\n    eoi_fwd(dfa, cache, input, &mut sid, &mut mat)?;\n    cache.search_finish(input.end());\n    Ok(mat)\n}\n#[cfg_attr(feature = \"perf-inline\", inline(always))]\nfn init_fwd(\n    dfa: &DFA,\n    cache: &mut Cache,\n    input: &Input<'_>,\n) -> Result<LazyStateID, MatchError> {\n    let sid = dfa.start_state_forward(cache, input)?;\n    debug_assert!(! sid.is_match());\n    Ok(sid)\n}\n#[cfg_attr(feature = \"perf-inline\", inline(always))]\nfn prefilter_restart(\n    dfa: &DFA,\n    cache: &mut Cache,\n    input: &Input<'_>,\n    at: usize,\n) -> Result<LazyStateID, MatchError> {\n    let mut input = input.clone();\n    input.set_start(at);\n    init_fwd(dfa, cache, &input)\n}\n#[cfg_attr(feature = \"perf-inline\", inline(always))]\nfn eoi_fwd(\n    dfa: &DFA,\n    cache: &mut Cache,\n    input: &Input<'_>,\n    sid: &mut LazyStateID,\n    mat: &mut Option<HalfMatch>,\n) -> Result<(), MatchError> {\n    let sp = input.get_span();\n    match input.haystack().get(sp.end) {\n        Some(&b) => {\n            *sid = dfa.next_state(cache, *sid, b).map_err(|_| gave_up(sp.end))?;\n            if sid.is_match() {\n                let pattern = dfa.match_pattern(cache, *sid, 0);\n                *mat = Some(HalfMatch::new(pattern, sp.end));\n            } else if sid.is_quit() {\n                return Err(MatchError::quit(b, sp.end));\n            }\n        }\n        None => {\n            *sid = dfa\n                .next_eoi_state(cache, *sid)\n                .map_err(|_| gave_up(input.haystack().len()))?;\n            if sid.is_match() {\n                let pattern = dfa.match_pattern(cache, *sid, 0);\n                *mat = Some(HalfMatch::new(pattern, input.haystack().len()));\n            }\n            debug_assert!(! sid.is_quit());\n        }\n    }\n    Ok(())\n}\n\nThe function to be tested is presented with each line formatted as 'line number + code':\n 50 fn find_fwd_imp(\n 51     dfa: &DFA,\n 52     cache: &mut Cache,\n 53     input: &Input<'_>,\n 54     pre: Option<&'_ Prefilter>,\n 55     earliest: bool,\n 56 ) -> Result<Option<HalfMatch>, MatchError> {\n 57     // See 'prefilter_restart' docs for explanation.\n 58     let universal_start = dfa.get_nfa().look_set_prefix_any().is_empty();\n 59     let mut mat = None;\n 60     let mut sid = init_fwd(dfa, cache, input)?;\n 61     let mut at = input.start();\n 62     // This could just be a closure, but then I think it would be unsound\n 63     // because it would need to be safe to invoke. This way, the lack of safety\n 64     // is clearer in the code below.\n 65     macro_rules! next_unchecked {\n 66         ($sid:expr, $at:expr) => {{\n 67             let byte = *input.haystack().get_unchecked($at);\n 68             dfa.next_state_untagged_unchecked(cache, $sid, byte)\n 69         }};\n 70     }\n 71 \n 72     if let Some(ref pre) = pre {\n 73         let span = Span::from(at..input.end());\n 74         match pre.find(input.haystack(), span) {\n 75             None => return Ok(mat),\n 76             Some(ref span) => {\n 77                 at = span.start;\n 78                 if !universal_start {\n 79                     sid = prefilter_restart(dfa, cache, &input, at)?;\n 80                 }\n 81             }\n 82         }\n 83     }\n 84     cache.search_start(at);\n 85     while at < input.end() {\n 86         if sid.is_tagged() {\n 87             cache.search_update(at);\n 88             sid = dfa\n 89                 .next_state(cache, sid, input.haystack()[at])\n 90                 .map_err(|_| gave_up(at))?;\n 91         } else {\n 92             // SAFETY: There are two safety invariants we need to uphold\n 93             // here in the loops below: that 'sid' and 'prev_sid' are valid\n 94             // state IDs for this DFA, and that 'at' is a valid index into\n 95             // 'haystack'. For the former, we rely on the invariant that\n 96             // next_state* and start_state_forward always returns a valid state\n 97             // ID (given a valid state ID in the former case), and that we are\n 98             // only at this place in the code if 'sid' is untagged. Moreover,\n 99             // every call to next_state_untagged_unchecked below is guarded by\n100             // a check that sid is untagged. For the latter safety invariant,\n101             // we always guard unchecked access with a check that 'at' is less\n102             // than 'end', where 'end <= haystack.len()'. In the unrolled loop\n103             // below, we ensure that 'at' is always in bounds.\n104             //\n105             // PERF: For justification of omitting bounds checks, it gives us a\n106             // ~10% bump in search time. This was used for a benchmark:\n107             //\n108             //     regex-cli find half hybrid -p '(?m)^.+$' -UBb bigfile\n109             //\n110             // PERF: For justification for the loop unrolling, we use a few\n111             // different tests:\n112             //\n113             //     regex-cli find half hybrid -p '\\w{50}' -UBb bigfile\n114             //     regex-cli find half hybrid -p '(?m)^.+$' -UBb bigfile\n115             //     regex-cli find half hybrid -p 'ZQZQZQZQ' -UBb bigfile\n116             //\n117             // And there are three different configurations:\n118             //\n119             //     nounroll: this entire 'else' block vanishes and we just\n120             //               always use 'dfa.next_state(..)'.\n121             //      unroll1: just the outer loop below\n122             //      unroll2: just the inner loop below\n123             //      unroll3: both the outer and inner loops below\n124             //\n125             // This results in a matrix of timings for each of the above\n126             // regexes with each of the above unrolling configurations:\n127             //\n128             //              '\\w{50}'   '(?m)^.+$'   'ZQZQZQZQ'\n129             //   nounroll   1.51s      2.34s        1.51s\n130             //    unroll1   1.53s      2.32s        1.56s\n131             //    unroll2   2.22s      1.50s        0.61s\n132             //    unroll3   1.67s      1.45s        0.61s\n133             //\n134             // Ideally we'd be able to find a configuration that yields the\n135             // best time for all regexes, but alas we settle for unroll3 that\n136             // gives us *almost* the best for '\\w{50}' and the best for the\n137             // other two regexes.\n138             //\n139             // So what exactly is going on here? The first unrolling (grouping\n140             // together runs of untagged transitions) specifically targets\n141             // our choice of representation. The second unrolling (grouping\n142             // together runs of self-transitions) specifically targets a common\n143             // DFA topology. Let's dig in a little bit by looking at our\n144             // regexes:\n145             //\n146             // '\\w{50}': This regex spends a lot of time outside of the DFA's\n147             // start state matching some part of the '\\w' repetition. This\n148             // means that it's a bit of a worst case for loop unrolling that\n149             // targets self-transitions since the self-transitions in '\\w{50}'\n150             // are not particularly active for this haystack. However, the\n151             // first unrolling (grouping together untagged transitions)\n152             // does apply quite well here since very few transitions hit\n153             // match/dead/quit/unknown states. It is however worth mentioning\n154             // that if start states are configured to be tagged (which you\n155             // typically want to do if you have a prefilter), then this regex\n156             // actually slows way down because it is constantly ping-ponging\n157             // out of the unrolled loop and into the handling of a tagged start\n158             // state below. But when start states aren't tagged, the unrolled\n159             // loop stays hot. (This is why it's imperative that start state\n160             // tagging be disabled when there isn't a prefilter!)\n161             //\n162             // '(?m)^.+$': There are two important aspects of this regex: 1)\n163             // on this haystack, its match count is very high, much higher\n164             // than the other two regex and 2) it spends the vast majority\n165             // of its time matching '.+'. Since Unicode mode is disabled,\n166             // this corresponds to repeatedly following self transitions for\n167             // the vast majority of the input. This does benefit from the\n168             // untagged unrolling since most of the transitions will be to\n169             // untagged states, but the untagged unrolling does more work than\n170             // what is actually required. Namely, it has to keep track of the\n171             // previous and next state IDs, which I guess requires a bit more\n172             // shuffling. This is supported by the fact that nounroll+unroll1\n173             // are both slower than unroll2+unroll3, where the latter has a\n174             // loop unrolling that specifically targets self-transitions.\n175             //\n176             // 'ZQZQZQZQ': This one is very similar to '(?m)^.+$' because it\n177             // spends the vast majority of its time in self-transitions for\n178             // the (implicit) unanchored prefix. The main difference with\n179             // '(?m)^.+$' is that it has a much lower match count. So there\n180             // isn't much time spent in the overhead of reporting matches. This\n181             // is the primary explainer in the perf difference here. We include\n182             // this regex and the former to make sure we have comparison points\n183             // with high and low match counts.\n184             //\n185             // NOTE: I used 'OpenSubtitles2018.raw.sample.en' for 'bigfile'.\n186             //\n187             // NOTE: In a follow-up, it turns out that the \"inner\" loop\n188             // mentioned above was a pretty big pessimization in some other\n189             // cases. Namely, it resulted in too much ping-ponging into and out\n190             // of the loop, which resulted in nearly ~2x regressions in search\n191             // time when compared to the originally lazy DFA in the regex crate.\n192             // So I've removed the second loop unrolling that targets the\n193             // self-transition case.\n194             let mut prev_sid = sid;\n195             while at < input.end() {\n196                 prev_sid = unsafe { next_unchecked!(sid, at) };\n197                 if prev_sid.is_tagged() || at + 3 >= input.end() {\n198                     core::mem::swap(&mut prev_sid, &mut sid);\n199                     break;\n200                 }\n201                 at += 1;\n202 \n203                 sid = unsafe { next_unchecked!(prev_sid, at) };\n204                 if sid.is_tagged() {\n205                     break;\n206                 }\n207                 at += 1;\n208 \n209                 prev_sid = unsafe { next_unchecked!(sid, at) };\n210                 if prev_sid.is_tagged() {\n211                     core::mem::swap(&mut prev_sid, &mut sid);\n212                     break;\n213                 }\n214                 at += 1;\n215 \n216                 sid = unsafe { next_unchecked!(prev_sid, at) };\n217                 if sid.is_tagged() {\n218                     break;\n219                 }\n220                 at += 1;\n221             }\n222             // If we quit out of the code above with an unknown state ID at\n223             // any point, then we need to re-compute that transition using\n224             // 'next_state', which will do NFA powerset construction for us.\n225             if sid.is_unknown() {\n226                 cache.search_update(at);\n227                 sid = dfa\n228                     .next_state(cache, prev_sid, input.haystack()[at])\n229                     .map_err(|_| gave_up(at))?;\n230             }\n231         }\n232         if sid.is_tagged() {\n233             if sid.is_start() {\n234                 if let Some(ref pre) = pre {\n235                     let span = Span::from(at..input.end());\n236                     match pre.find(input.haystack(), span) {\n237                         None => {\n238                             cache.search_finish(span.end);\n239                             return Ok(mat);\n240                         }\n241                         Some(ref span) => {\n242                             // We want to skip any update to 'at' below\n243                             // at the end of this iteration and just\n244                             // jump immediately back to the next state\n245                             // transition at the leading position of the\n246                             // candidate match.\n247                             //\n248                             // ... but only if we actually made progress\n249                             // with our prefilter, otherwise if the start\n250                             // state has a self-loop, we can get stuck.\n251                             if span.start > at {\n252                                 at = span.start;\n253                                 if !universal_start {\n254                                     sid = prefilter_restart(\n255                                         dfa, cache, &input, at,\n256                                     )?;\n257                                 }\n258                                 continue;\n259                             }\n260                         }\n261                     }\n262                 }\n263             } else if sid.is_match() {\n264                 let pattern = dfa.match_pattern(cache, sid, 0);\n265                 // Since slice ranges are inclusive at the beginning and\n266                 // exclusive at the end, and since forward searches report\n267                 // the end, we can return 'at' as-is. This only works because\n268                 // matches are delayed by 1 byte. So by the time we observe a\n269                 // match, 'at' has already been set to 1 byte past the actual\n270                 // match location, which is precisely the exclusive ending\n271                 // bound of the match.\n272                 mat = Some(HalfMatch::new(pattern, at));\n273                 if earliest {\n274                     cache.search_finish(at);\n275                     return Ok(mat);\n276                 }\n277             } else if sid.is_dead() {\n278                 cache.search_finish(at);\n279                 return Ok(mat);\n280             } else if sid.is_quit() {\n281                 cache.search_finish(at);\n282                 return Err(MatchError::quit(input.haystack()[at], at));\n283             } else {\n284                 debug_assert!(sid.is_unknown());\n285                 unreachable!(\"sid being unknown is a bug\");\n286             }\n287         }\n288         at += 1;\n289     }\n290     eoi_fwd(dfa, cache, input, &mut sid, &mut mat)?;\n291     cache.search_finish(input.end());\n292     Ok(mat)\n293 }\n\nGenerate each test function in such a manner that it concurrently satisfies all the following preconditions:\n",
  "depend_pt": ""
}