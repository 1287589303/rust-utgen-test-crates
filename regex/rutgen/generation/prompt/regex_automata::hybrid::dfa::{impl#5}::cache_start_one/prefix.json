{
  "system_pt": "As a software testing expert, please generate Rust test functions based on the following guidelines, focusing solely on constructing test inputs and calling the functions under test:\n1. Provide the code in plain text format, without explanations or Markdown.\n2. If the method under test belongs to a trait, construct appropriate structs within the test function, but avoid method overrides. If the method under test uses generics, instantiate them with suitable types based on the context.\n3. Generate test code with minimal scope: avoid creating external structures or implementations. Instead, define any necessary helper structures or implementations directly within the test function when required.\n4. Whenever possible, initialize the corresponding data structures using the initialization methods provided in the context.\n5. Ensure the generated function is fully implemented and can be compiled and executed directly without any missing parts.\n6. Create a minimal yet complete set of test functions, ensuring they adhere to all provided preconditions and cover boundary conditions, and reference the inferred test input conditions or ranges.\n7. Ensure the test inputs are designed to cover the inferred test input conditions or ranges as comprehensively as possible, with particular emphasis on boundary cases.\n8. Focus on crafting test inputs that effectively reveal potential bugs while meeting the specified requirements.\n9. Omit test oracles and assertions; concentrate on generating test inputs and function calls.\n10. Do not create a test module, but include intrinsic attributes like #[test] or #[should_panic] where necessary.\n",
  "static_pt": "The context for the focal function is as follows:\n// regex-automata/src/hybrid/dfa.rs\n// crate name is regex_automata\n#[cfg(feature = \"std\")]\ntype StateMap = std::collections::HashMap<State, LazyStateID>;\n#[cfg(not(feature = \"std\"))]\ntype StateMap = alloc::collections::BTreeMap<State, LazyStateID>;\nuse core::{iter, mem::size_of};\nuse alloc::vec::Vec;\nuse crate::{\n    hybrid::{\n        error::{BuildError, CacheError, StartError},\n        id::{LazyStateID, LazyStateIDError},\n        search,\n    },\n    nfa::thompson,\n    util::{\n        alphabet::{self, ByteClasses, ByteSet},\n        determinize::{self, State, StateBuilderEmpty, StateBuilderNFA},\n        empty, prefilter::Prefilter, primitives::{PatternID, StateID as NFAStateID},\n        search::{Anchored, HalfMatch, Input, MatchError, MatchKind, PatternSet},\n        sparse_set::SparseSets, start::{self, Start, StartByteMap},\n    },\n};\nconst MIN_STATES: usize = SENTINEL_STATES + 2;\nconst SENTINEL_STATES: usize = 3;\n#[derive(Debug)]\nstruct Lazy<'i, 'c> {\n    dfa: &'i DFA,\n    cache: &'c mut Cache,\n}\n#[derive(Clone, Debug)]\npub struct DFA {\n    config: Config,\n    nfa: thompson::NFA,\n    stride2: usize,\n    start_map: StartByteMap,\n    classes: ByteClasses,\n    quitset: ByteSet,\n    cache_capacity: usize,\n}\n#[derive(Clone, Debug, Default)]\npub struct Config {\n    match_kind: Option<MatchKind>,\n    pre: Option<Option<Prefilter>>,\n    starts_for_each_pattern: Option<bool>,\n    byte_classes: Option<bool>,\n    unicode_word_boundary: Option<bool>,\n    quitset: Option<ByteSet>,\n    specialize_start_states: Option<bool>,\n    cache_capacity: Option<usize>,\n    skip_cache_capacity_check: Option<bool>,\n    minimum_cache_clear_count: Option<Option<usize>>,\n    minimum_bytes_per_state: Option<Option<usize>>,\n}\n#[derive(Clone)]\npub(crate) struct StateBuilderMatches(Vec<u8>);\n#[derive(Clone, Debug)]\npub(crate) struct StateBuilderEmpty(Vec<u8>);\n#[derive(Clone)]\npub(crate) struct SparseSet {\n    /// The number of elements currently in this set.\n    len: usize,\n    /// Dense contains the ids in the order in which they were inserted.\n    dense: Vec<StateID>,\n    /// Sparse maps ids to their location in dense.\n    ///\n    /// A state ID is in the set if and only if\n    /// sparse[id] < len && id == dense[sparse[id]].\n    ///\n    /// Note that these are indices into 'dense'. It's a little weird to use\n    /// StateID here, but we know our length can never exceed the bounds of\n    /// StateID (enforced by 'resize') and StateID will be at most 4 bytes\n    /// where as a usize is likely double that in most cases.\n    sparse: Vec<StateID>,\n}\n#[derive(Clone)]\npub struct DFA {\n    /// The configuration provided by the caller.\n    config: Config,\n    /// The NFA used to build this DFA.\n    ///\n    /// NOTE: We probably don't need to store the NFA here, but we use enough\n    /// bits from it that it's convenient to do so. And there really isn't much\n    /// cost to doing so either, since an NFA is reference counted internally.\n    nfa: NFA,\n    /// The transition table. Given a state ID 's' and a byte of haystack 'b',\n    /// the next state is `table[sid + classes[byte]]`.\n    ///\n    /// The stride of this table (i.e., the number of columns) is always\n    /// a power of 2, even if the alphabet length is smaller. This makes\n    /// converting between state IDs and state indices very cheap.\n    ///\n    /// Note that the stride always includes room for one extra \"transition\"\n    /// that isn't actually a transition. It is a 'PatternEpsilons' that is\n    /// used for match states only. Because of this, the maximum number of\n    /// active columns in the transition table is 257, which means the maximum\n    /// stride is 512 (the next power of 2 greater than or equal to 257).\n    table: Vec<Transition>,\n    /// The DFA state IDs of the starting states.\n    ///\n    /// `starts[0]` is always present and corresponds to the starting state\n    /// when searching for matches of any pattern in the DFA.\n    ///\n    /// `starts[i]` where i>0 corresponds to the starting state for the pattern\n    /// ID 'i-1'. These starting states are optional.\n    starts: Vec<StateID>,\n    /// Every state ID >= this value corresponds to a match state.\n    ///\n    /// This is what a search uses to detect whether a state is a match state\n    /// or not. It requires only a simple comparison instead of bit-unpacking\n    /// the PatternEpsilons from every state.\n    min_match_id: StateID,\n    /// The alphabet of this DFA, split into equivalence classes. Bytes in the\n    /// same equivalence class can never discriminate between a match and a\n    /// non-match.\n    classes: ByteClasses,\n    /// The number of elements in each state in the transition table. This may\n    /// be less than the stride, since the stride is always a power of 2 and\n    /// the alphabet length can be anything up to and including 256.\n    alphabet_len: usize,\n    /// The number of columns in the transition table, expressed as a power of\n    /// 2.\n    stride2: usize,\n    /// The offset at which the PatternEpsilons for a match state is stored in\n    /// the transition table.\n    ///\n    /// PERF: One wonders whether it would be better to put this in a separate\n    /// allocation, since only match states have a non-empty PatternEpsilons\n    /// and the number of match states tends be dwarfed by the number of\n    /// non-match states. So this would save '8*len(non_match_states)' for each\n    /// DFA. The question is whether moving this to a different allocation will\n    /// lead to a perf hit during searches. You might think dealing with match\n    /// states is rare, but some regexes spend a lot of time in match states\n    /// gobbling up input. But... match state handling is already somewhat\n    /// expensive, so maybe this wouldn't do much? Either way, it's worth\n    /// experimenting.\n    pateps_offset: usize,\n    /// The first explicit slot index. This refers to the first slot appearing\n    /// immediately after the last implicit slot. It is always 'patterns.len()\n    /// * 2'.\n    ///\n    /// We record this because we only store the explicit slots in our DFA\n    /// transition table that need to be saved. Implicit slots are handled\n    /// automatically as part of the search.\n    explicit_slot_start: usize,\n}\n#[derive(Debug, Clone)]\npub struct Cache {\n    pub(crate) capmatches: Captures,\n    pub(crate) pikevm: wrappers::PikeVMCache,\n    pub(crate) backtrack: wrappers::BoundedBacktrackerCache,\n    pub(crate) onepass: wrappers::OnePassCache,\n    pub(crate) hybrid: wrappers::HybridCache,\n    pub(crate) revhybrid: wrappers::ReverseHybridCache,\n}\n#[derive(Clone)]\npub struct DFA<T> {\n    /// The transition table for this DFA. This includes the transitions\n    /// themselves, along with the stride, number of states and the equivalence\n    /// class mapping.\n    tt: TransitionTable<T>,\n    /// The set of starting state identifiers for this DFA. The starting state\n    /// IDs act as pointers into the transition table. The specific starting\n    /// state chosen for each search is dependent on the context at which the\n    /// search begins.\n    st: StartTable<T>,\n    /// The set of match states and the patterns that match for each\n    /// corresponding match state.\n    ///\n    /// This structure is technically only needed because of support for\n    /// multi-regexes. Namely, multi-regexes require answering not just whether\n    /// a match exists, but _which_ patterns match. So we need to store the\n    /// matching pattern IDs for each match state. We do this even when there\n    /// is only one pattern for the sake of simplicity. In practice, this uses\n    /// up very little space for the case of one pattern.\n    ms: MatchStates<T>,\n    /// Information about which states are \"special.\" Special states are states\n    /// that are dead, quit, matching, starting or accelerated. For more info,\n    /// see the docs for `Special`.\n    special: Special,\n    /// The accelerators for this DFA.\n    ///\n    /// If a state is accelerated, then there exist only a small number of\n    /// bytes that can cause the DFA to leave the state. This permits searching\n    /// to use optimized routines to find those specific bytes instead of using\n    /// the transition table.\n    ///\n    /// All accelerated states exist in a contiguous range in the DFA's\n    /// transition table. See dfa/special.rs for more details on how states are\n    /// arranged.\n    accels: Accels<T>,\n    /// Any prefilter attached to this DFA.\n    ///\n    /// Note that currently prefilters are not serialized. When deserializing\n    /// a DFA from bytes, this is always set to `None`.\n    pre: Option<Prefilter>,\n    /// The set of \"quit\" bytes for this DFA.\n    ///\n    /// This is only used when computing the start state for a particular\n    /// position in a haystack. Namely, in the case where there is a quit\n    /// byte immediately before the start of the search, this set needs to be\n    /// explicitly consulted. In all other cases, quit bytes are detected by\n    /// the DFA itself, by transitioning all quit bytes to a special \"quit\n    /// state.\"\n    quitset: ByteSet,\n    /// Various flags describing the behavior of this DFA.\n    flags: Flags,\n}\n#[derive(Clone)]\npub struct DFA<T> {\n    tt: Transitions<T>,\n    st: StartTable<T>,\n    special: Special,\n    pre: Option<Prefilter>,\n    quitset: ByteSet,\n    flags: Flags,\n}\n#[derive(Debug)]\npub(crate) struct DFA(Option<DFAEngine>);\n#[derive(Clone)]\npub(crate) struct StateBuilderNFA {\n    repr: Vec<u8>,\n    prev_nfa_state_id: StateID,\n}\n#[derive(Clone, Debug)]\npub struct Cache {\n    /// Scratch space used to store slots during a search. Basically, we use\n    /// the caller provided slots to store slots known when a match occurs.\n    /// But after a match occurs, we might continue a search but ultimately\n    /// fail to extend the match. When continuing the search, we need some\n    /// place to store candidate capture offsets without overwriting the slot\n    /// offsets recorded for the most recently seen match.\n    explicit_slots: Vec<Option<NonMaxUsize>>,\n    /// The number of slots in the caller-provided 'Captures' value for the\n    /// current search. This is always at most 'explicit_slots.len()', but\n    /// might be less than it, if the caller provided fewer slots to fill.\n    explicit_slot_len: usize,\n}\n#[derive(Clone, Copy, Default, Eq, Hash, PartialEq, PartialOrd, Ord)]\n#[repr(transparent)]\npub struct StateID(SmallIndex);\n#[derive(Debug, Clone)]\npub struct Cache {\n    forward: dfa::Cache,\n    reverse: dfa::Cache,\n}\n#[derive(Clone, Debug)]\npub struct Cache {\n    /// Stack used on the heap for doing backtracking instead of the\n    /// traditional recursive approach. We don't want recursion because then\n    /// we're likely to hit a stack overflow for bigger regexes.\n    stack: Vec<Frame>,\n    /// The set of (StateID, HaystackOffset) pairs that have been visited\n    /// by the backtracker within a single search. If such a pair has been\n    /// visited, then we avoid doing the work for that pair again. This is\n    /// what \"bounds\" the backtracking and prevents it from having worst case\n    /// exponential time.\n    visited: Visited,\n}\n#[derive(Clone, Copy, Debug, Default, Eq, Hash, PartialEq, PartialOrd, Ord)]\npub struct LazyStateID(u32);\n#[derive(Clone, Copy, Default, Eq, PartialEq)]\npub struct LookSet {\n    /// The underlying representation this set is exposed to make it possible\n    /// to store it somewhere efficiently. The representation is that\n    /// of a bitset, where each assertion occupies bit `i` where\n    /// `i = Look::as_repr()`.\n    ///\n    /// Note that users of this internal representation must permit the full\n    /// range of `u16` values to be represented. For example, even if the\n    /// current implementation only makes use of the 10 least significant bits,\n    /// it may use more bits in a future semver compatible release.\n    pub bits: u32,\n}\n#[derive(Clone, Debug)]\npub struct CacheError(());\n#[derive(Clone, Debug)]\npub struct Cache {\n    /// The transition table.\n    ///\n    /// Given a `current` LazyStateID and an `input` byte, the next state can\n    /// be computed via `trans[untagged(current) + equiv_class(input)]`. Notice\n    /// that no multiplication is used. That's because state identifiers are\n    /// \"premultiplied.\"\n    ///\n    /// Note that the next state may be the \"unknown\" state. In this case, the\n    /// next state is not known and determinization for `current` on `input`\n    /// must be performed.\n    trans: Vec<LazyStateID>,\n    /// The starting states for this DFA.\n    ///\n    /// These are computed lazily. Initially, these are all set to \"unknown\"\n    /// lazy state IDs.\n    ///\n    /// When 'starts_for_each_pattern' is disabled (the default), then the size\n    /// of this is constrained to the possible starting configurations based\n    /// on the search parameters. (At time of writing, that's 4.) However,\n    /// when starting states for each pattern is enabled, then there are N\n    /// additional groups of starting states, where each group reflects the\n    /// different possible configurations and N is the number of patterns.\n    starts: Vec<LazyStateID>,\n    /// A sequence of NFA/DFA powerset states that have been computed for this\n    /// lazy DFA. This sequence is indexable by untagged LazyStateIDs. (Every\n    /// tagged LazyStateID can be used to index this sequence by converting it\n    /// to its untagged form.)\n    states: Vec<State>,\n    /// A map from states to their corresponding IDs. This map may be accessed\n    /// via the raw byte representation of a state, which means that a `State`\n    /// does not need to be allocated to determine whether it already exists\n    /// in this map. Indeed, the existence of such a state is what determines\n    /// whether we allocate a new `State` or not.\n    ///\n    /// The higher level idea here is that we do just enough determinization\n    /// for a state to check whether we've already computed it. If we have,\n    /// then we can save a little (albeit not much) work. The real savings is\n    /// in memory usage. If we never checked for trivially duplicate states,\n    /// then our memory usage would explode to unreasonable levels.\n    states_to_id: StateMap,\n    /// Sparse sets used to track which NFA states have been visited during\n    /// various traversals.\n    sparses: SparseSets,\n    /// Scratch space for traversing the NFA graph. (We use space on the heap\n    /// instead of the call stack.)\n    stack: Vec<NFAStateID>,\n    /// Scratch space for building a NFA/DFA powerset state. This is used to\n    /// help amortize allocation since not every powerset state generated is\n    /// added to the cache. In particular, if it already exists in the cache,\n    /// then there is no need to allocate a new `State` for it.\n    scratch_state_builder: StateBuilderEmpty,\n    /// A simple abstraction for handling the saving of at most a single state\n    /// across a cache clearing. This is required for correctness. Namely, if\n    /// adding a new state after clearing the cache fails, then the caller\n    /// must retain the ability to continue using the state ID given. The\n    /// state corresponding to the state ID is what we preserve across cache\n    /// clearings.\n    state_saver: StateSaver,\n    /// The memory usage, in bytes, used by 'states' and 'states_to_id'. We\n    /// track this as new states are added since states use a variable amount\n    /// of heap. Tracking this as we add states makes it possible to compute\n    /// the total amount of memory used by the determinizer in constant time.\n    memory_usage_state: usize,\n    /// The number of times the cache has been cleared. When a minimum cache\n    /// clear count is set, then the cache will return an error instead of\n    /// clearing the cache if the count has been exceeded.\n    clear_count: usize,\n    /// The total number of bytes searched since the last time this cache was\n    /// cleared, not including the current search.\n    ///\n    /// This can be added to the length of the current search to get the true\n    /// total number of bytes searched.\n    ///\n    /// This is generally only non-zero when the\n    /// `Cache::search_{start,update,finish}` APIs are used to track search\n    /// progress.\n    bytes_searched: usize,\n    /// The progress of the current search.\n    ///\n    /// This is only non-`None` when callers utlize the `Cache::search_start`,\n    /// `Cache::search_update` and `Cache::search_finish` APIs.\n    ///\n    /// The purpose of recording search progress is to be able to make a\n    /// determination about the efficiency of the cache. Namely, by keeping\n    /// track of the\n    progress: Option<SearchProgress>,\n}\n#[derive(Clone)]\npub struct NFA(Arc<Inner>);\n#[derive(Clone, Debug)]\npub struct Cache {\n    /// Stack used while computing epsilon closure. This effectively lets us\n    /// move what is more naturally expressed through recursion to a stack\n    /// on the heap.\n    stack: Vec<FollowEpsilon>,\n    /// The current active states being explored for the current byte in the\n    /// haystack.\n    curr: ActiveStates,\n    /// The next set of states we're building that will be explored for the\n    /// next byte in the haystack.\n    next: ActiveStates,\n}\n#[derive(Clone, Copy, Debug, Eq, PartialEq)]\npub(crate) enum Start {\n    /// This occurs when the starting position is not any of the ones below.\n    NonWordByte = 0,\n    /// This occurs when the byte immediately preceding the start of the search\n    /// is an ASCII word byte.\n    WordByte = 1,\n    /// This occurs when the starting position of the search corresponds to the\n    /// beginning of the haystack.\n    Text = 2,\n    /// This occurs when the byte immediately preceding the start of the search\n    /// is a line terminator. Specifically, `\\n`.\n    LineLF = 3,\n    /// This occurs when the byte immediately preceding the start of the search\n    /// is a line terminator. Specifically, `\\r`.\n    LineCR = 4,\n    /// This occurs when a custom line terminator has been set via a\n    /// `LookMatcher`, and when that line terminator is neither a `\\r` or a\n    /// `\\n`.\n    ///\n    /// If the custom line terminator is a word byte, then this start\n    /// configuration is still selected. DFAs that implement word boundary\n    /// assertions will likely need to check whether the custom line terminator\n    /// is a word byte, in which case, it should behave as if the byte\n    /// satisfies `\\b` in addition to multi-line anchors.\n    CustomLineTerminator = 5,\n}\nimpl<'i, 'c> Lazy<'i, 'c> {\n    fn new(dfa: &'i DFA, cache: &'c mut Cache) -> Lazy<'i, 'c> {}\n    fn as_ref<'a>(&'a self) -> LazyRef<'i, 'a> {}\n    #[cold]\n    #[inline(never)]\n    fn cache_next_state(\n        &mut self,\n        mut current: LazyStateID,\n        unit: alphabet::Unit,\n    ) -> Result<LazyStateID, CacheError> {}\n    #[cold]\n    #[inline(never)]\n    fn cache_start_group(\n        &mut self,\n        anchored: Anchored,\n        start: Start,\n    ) -> Result<LazyStateID, StartError> {}\n    fn cache_start_one(\n        &mut self,\n        nfa_start_id: NFAStateID,\n        start: Start,\n    ) -> Result<LazyStateID, CacheError> {\n        let mut builder_matches = self.get_state_builder().into_matches();\n        determinize::set_lookbehind_from_start(\n            self.dfa.get_nfa(),\n            &start,\n            &mut builder_matches,\n        );\n        self.cache.sparses.set1.clear();\n        determinize::epsilon_closure(\n            self.dfa.get_nfa(),\n            nfa_start_id,\n            builder_matches.look_have(),\n            &mut self.cache.stack,\n            &mut self.cache.sparses.set1,\n        );\n        let mut builder = builder_matches.into_nfa();\n        determinize::add_nfa_states(\n            &self.dfa.get_nfa(),\n            &self.cache.sparses.set1,\n            &mut builder,\n        );\n        let tag_starts = self.dfa.get_config().get_specialize_start_states();\n        self.add_builder_state(\n            builder,\n            |id| { if tag_starts { id.to_start() } else { id } },\n        )\n    }\n    fn add_builder_state(\n        &mut self,\n        builder: StateBuilderNFA,\n        idmap: impl Fn(LazyStateID) -> LazyStateID,\n    ) -> Result<LazyStateID, CacheError> {}\n    fn add_state(\n        &mut self,\n        state: State,\n        idmap: impl Fn(LazyStateID) -> LazyStateID,\n    ) -> Result<LazyStateID, CacheError> {}\n    fn next_state_id(&mut self) -> Result<LazyStateID, CacheError> {}\n    fn try_clear_cache(&mut self) -> Result<(), CacheError> {}\n    fn reset_cache(&mut self) {}\n    fn clear_cache(&mut self) {}\n    fn init_cache(&mut self) {}\n    fn save_state(&mut self, id: LazyStateID) {}\n    fn saved_state_id(&mut self) -> LazyStateID {}\n    fn set_all_transitions(&mut self, from: LazyStateID, to: LazyStateID) {}\n    fn set_transition(\n        &mut self,\n        from: LazyStateID,\n        unit: alphabet::Unit,\n        to: LazyStateID,\n    ) {}\n    fn set_start_state(&mut self, anchored: Anchored, start: Start, id: LazyStateID) {}\n    fn get_state_builder(&mut self) -> StateBuilderEmpty {\n        core::mem::replace(\n            &mut self.cache.scratch_state_builder,\n            StateBuilderEmpty::new(),\n        )\n    }\n    fn put_state_builder(&mut self, builder: StateBuilderNFA) {}\n}\nimpl DFA {\n    #[cfg(feature = \"syntax\")]\n    pub fn new(pattern: &str) -> Result<DFA, BuildError> {}\n    #[cfg(feature = \"syntax\")]\n    pub fn new_many<P: AsRef<str>>(patterns: &[P]) -> Result<DFA, BuildError> {}\n    pub fn always_match() -> Result<DFA, BuildError> {}\n    pub fn never_match() -> Result<DFA, BuildError> {}\n    pub fn config() -> Config {}\n    pub fn builder() -> Builder {}\n    pub fn create_cache(&self) -> Cache {}\n    pub fn reset_cache(&self, cache: &mut Cache) {}\n    pub fn pattern_len(&self) -> usize {}\n    pub fn byte_classes(&self) -> &ByteClasses {}\n    pub fn get_config(&self) -> &Config {\n        &self.config\n    }\n    pub fn get_nfa(&self) -> &thompson::NFA {\n        &self.nfa\n    }\n    fn stride2(&self) -> usize {}\n    fn stride(&self) -> usize {}\n    pub fn memory_usage(&self) -> usize {}\n}\nimpl Config {\n    pub fn new() -> Config {}\n    pub fn match_kind(mut self, kind: MatchKind) -> Config {}\n    pub fn prefilter(mut self, pre: Option<Prefilter>) -> Config {}\n    pub fn starts_for_each_pattern(mut self, yes: bool) -> Config {}\n    pub fn byte_classes(mut self, yes: bool) -> Config {}\n    pub fn unicode_word_boundary(mut self, yes: bool) -> Config {}\n    pub fn quit(mut self, byte: u8, yes: bool) -> Config {}\n    pub fn specialize_start_states(mut self, yes: bool) -> Config {}\n    pub fn cache_capacity(mut self, bytes: usize) -> Config {}\n    pub fn skip_cache_capacity_check(mut self, yes: bool) -> Config {}\n    pub fn minimum_cache_clear_count(mut self, min: Option<usize>) -> Config {}\n    pub fn minimum_bytes_per_state(mut self, min: Option<usize>) -> Config {}\n    pub fn get_match_kind(&self) -> MatchKind {}\n    pub fn get_prefilter(&self) -> Option<&Prefilter> {}\n    pub fn get_starts_for_each_pattern(&self) -> bool {}\n    pub fn get_byte_classes(&self) -> bool {}\n    pub fn get_unicode_word_boundary(&self) -> bool {}\n    pub fn get_quit(&self, byte: u8) -> bool {}\n    pub fn get_specialize_start_states(&self) -> bool {\n        self.specialize_start_states.unwrap_or(false)\n    }\n    pub fn get_cache_capacity(&self) -> usize {}\n    pub fn get_skip_cache_capacity_check(&self) -> bool {}\n    pub fn get_minimum_cache_clear_count(&self) -> Option<usize> {}\n    pub fn get_minimum_bytes_per_state(&self) -> Option<usize> {}\n    pub fn get_minimum_cache_capacity(\n        &self,\n        nfa: &thompson::NFA,\n    ) -> Result<usize, BuildError> {}\n    fn byte_classes_from_nfa(&self, nfa: &thompson::NFA, quit: &ByteSet) -> ByteClasses {}\n    fn quit_set_from_nfa(&self, nfa: &thompson::NFA) -> Result<ByteSet, BuildError> {}\n    fn overwrite(&self, o: Config) -> Config {}\n}\nimpl StateBuilderMatches {\n    pub(crate) fn into_nfa(mut self) -> StateBuilderNFA {\n        self.repr_vec().close_match_pattern_ids();\n        StateBuilderNFA {\n            repr: self.0,\n            prev_nfa_state_id: StateID::ZERO,\n        }\n    }\n    pub(crate) fn set_is_from_word(&mut self) {}\n    pub(crate) fn set_is_half_crlf(&mut self) {}\n    pub(crate) fn look_have(&self) -> LookSet {\n        LookSet::read_repr(&self.0[1..])\n    }\n    pub(crate) fn set_look_have(&mut self, set: impl FnMut(LookSet) -> LookSet) {}\n    pub(crate) fn add_match_pattern_id(&mut self, pid: PatternID) {}\n    fn repr(&self) -> Repr<'_> {}\n    fn repr_vec(&mut self) -> ReprVec<'_> {}\n}\nimpl StateBuilderEmpty {\n    pub(crate) fn new() -> StateBuilderEmpty {}\n    pub(crate) fn into_matches(mut self) -> StateBuilderMatches {\n        self.0.extend_from_slice(&[0, 0, 0, 0, 0, 0, 0, 0, 0]);\n        StateBuilderMatches(self.0)\n    }\n    fn clear(&mut self) {}\n    pub(crate) fn capacity(&self) -> usize {}\n}\nimpl SparseSet {\n    #[inline]\n    pub(crate) fn new(capacity: usize) -> SparseSet {}\n    #[inline]\n    pub(crate) fn resize(&mut self, new_capacity: usize) {}\n    #[inline]\n    pub(crate) fn capacity(&self) -> usize {}\n    #[inline]\n    pub(crate) fn len(&self) -> usize {}\n    #[inline]\n    pub(crate) fn is_empty(&self) -> bool {}\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    pub(crate) fn insert(&mut self, id: StateID) -> bool {}\n    #[inline]\n    pub(crate) fn contains(&self, id: StateID) -> bool {}\n    #[inline]\n    pub(crate) fn clear(&mut self) {\n        self.len = 0;\n    }\n    #[inline]\n    pub(crate) fn iter(&self) -> SparseSetIter<'_> {}\n    #[inline]\n    pub(crate) fn memory_usage(&self) -> usize {}\n}\npub(crate) fn set_lookbehind_from_start(\n    nfa: &thompson::NFA,\n    start: &Start,\n    builder: &mut StateBuilderMatches,\n) {\n    let rev = nfa.is_reverse();\n    let lineterm = nfa.look_matcher().get_line_terminator();\n    let lookset = nfa.look_set_any();\n    match *start {\n        Start::NonWordByte => {\n            if lookset.contains_word() {\n                builder\n                    .set_look_have(|have| {\n                        have.insert(Look::WordStartHalfAscii)\n                            .insert(Look::WordStartHalfUnicode)\n                    });\n            }\n        }\n        Start::WordByte => {\n            if lookset.contains_word() {\n                builder.set_is_from_word();\n            }\n        }\n        Start::Text => {\n            if lookset.contains_anchor_haystack() {\n                builder.set_look_have(|have| have.insert(Look::Start));\n            }\n            if lookset.contains_anchor_line() {\n                builder\n                    .set_look_have(|have| {\n                        have.insert(Look::StartLF).insert(Look::StartCRLF)\n                    });\n            }\n            if lookset.contains_word() {\n                builder\n                    .set_look_have(|have| {\n                        have.insert(Look::WordStartHalfAscii)\n                            .insert(Look::WordStartHalfUnicode)\n                    });\n            }\n        }\n        Start::LineLF => {\n            if rev {\n                if lookset.contains_anchor_crlf() {\n                    builder.set_is_half_crlf();\n                }\n                if lookset.contains_anchor_line() {\n                    builder.set_look_have(|have| have.insert(Look::StartLF));\n                }\n            } else {\n                if lookset.contains_anchor_line() {\n                    builder.set_look_have(|have| have.insert(Look::StartCRLF));\n                }\n            }\n            if lookset.contains_anchor_line() && lineterm == b'\\n' {\n                builder.set_look_have(|have| have.insert(Look::StartLF));\n            }\n            if lookset.contains_word() {\n                builder\n                    .set_look_have(|have| {\n                        have.insert(Look::WordStartHalfAscii)\n                            .insert(Look::WordStartHalfUnicode)\n                    });\n            }\n        }\n        Start::LineCR => {\n            if lookset.contains_anchor_crlf() {\n                if rev {\n                    builder.set_look_have(|have| have.insert(Look::StartCRLF));\n                } else {\n                    builder.set_is_half_crlf();\n                }\n            }\n            if lookset.contains_anchor_line() && lineterm == b'\\r' {\n                builder.set_look_have(|have| have.insert(Look::StartLF));\n            }\n            if lookset.contains_word() {\n                builder\n                    .set_look_have(|have| {\n                        have.insert(Look::WordStartHalfAscii)\n                            .insert(Look::WordStartHalfUnicode)\n                    });\n            }\n        }\n        Start::CustomLineTerminator => {\n            if lookset.contains_anchor_line() {\n                builder.set_look_have(|have| have.insert(Look::StartLF));\n            }\n            if lookset.contains_word() {\n                if utf8::is_word_byte(lineterm) {\n                    builder.set_is_from_word();\n                } else {\n                    builder\n                        .set_look_have(|have| {\n                            have.insert(Look::WordStartHalfAscii)\n                                .insert(Look::WordStartHalfUnicode)\n                        });\n                }\n            }\n        }\n    }\n}\npub(crate) fn epsilon_closure(\n    nfa: &thompson::NFA,\n    start_nfa_id: StateID,\n    look_have: LookSet,\n    stack: &mut Vec<StateID>,\n    set: &mut SparseSet,\n) {\n    assert!(stack.is_empty());\n    if !nfa.state(start_nfa_id).is_epsilon() {\n        set.insert(start_nfa_id);\n        return;\n    }\n    stack.push(start_nfa_id);\n    while let Some(mut id) = stack.pop() {\n        loop {\n            if !set.insert(id) {\n                break;\n            }\n            match *nfa.state(id) {\n                thompson::State::ByteRange { .. }\n                | thompson::State::Sparse { .. }\n                | thompson::State::Dense { .. }\n                | thompson::State::Fail\n                | thompson::State::Match { .. } => break,\n                thompson::State::Look { look, next } => {\n                    if !look_have.contains(look) {\n                        break;\n                    }\n                    id = next;\n                }\n                thompson::State::Union { ref alternates } => {\n                    id = match alternates.get(0) {\n                        None => break,\n                        Some(&id) => id,\n                    };\n                    stack.extend(alternates[1..].iter().rev());\n                }\n                thompson::State::BinaryUnion { alt1, alt2 } => {\n                    id = alt1;\n                    stack.push(alt2);\n                }\n                thompson::State::Capture { next, .. } => {\n                    id = next;\n                }\n            }\n        }\n    }\n}\npub(crate) fn add_nfa_states(\n    nfa: &thompson::NFA,\n    set: &SparseSet,\n    builder: &mut StateBuilderNFA,\n) {\n    for nfa_id in set.iter() {\n        match *nfa.state(nfa_id) {\n            thompson::State::ByteRange { .. } => {\n                builder.add_nfa_state_id(nfa_id);\n            }\n            thompson::State::Sparse { .. } => {\n                builder.add_nfa_state_id(nfa_id);\n            }\n            thompson::State::Dense { .. } => {\n                builder.add_nfa_state_id(nfa_id);\n            }\n            thompson::State::Look { look, .. } => {\n                builder.add_nfa_state_id(nfa_id);\n                builder.set_look_need(|need| need.insert(look));\n            }\n            thompson::State::Union { .. } | thompson::State::BinaryUnion { .. } => {\n                builder.add_nfa_state_id(nfa_id);\n            }\n            thompson::State::Capture { .. } => {}\n            thompson::State::Fail => {\n                builder.add_nfa_state_id(nfa_id);\n            }\n            thompson::State::Match { .. } => {\n                builder.add_nfa_state_id(nfa_id);\n            }\n        }\n    }\n    if builder.look_need().is_empty() {\n        builder.set_look_have(|_| LookSet::empty());\n    }\n}\n\nThe function to be tested is presented with each line formatted as 'line number + code':\n/// Compute and cache the starting state for the given NFA state ID and the\n/// starting configuration. The NFA state ID might be one of the following:\n///\n/// 1) An unanchored start state to match any pattern.\n/// 2) An anchored start state to match any pattern.\n/// 3) An anchored start state for a particular pattern.\n///\n/// This will never return an unknown lazy state ID.\n///\n/// If caching this state would otherwise result in a cache that has been\n/// cleared too many times, then an error is returned.\n2199 fn cache_start_one(\n2200     &mut self,\n2201     nfa_start_id: NFAStateID,\n2202     start: Start,\n2203 ) -> Result<LazyStateID, CacheError> {\n2204     let mut builder_matches = self.get_state_builder().into_matches();\n2205     determinize::set_lookbehind_from_start(\n2206         self.dfa.get_nfa(),\n2207         &start,\n2208         &mut builder_matches,\n2209     );\n2210     self.cache.sparses.set1.clear();\n2211     determinize::epsilon_closure(\n2212         self.dfa.get_nfa(),\n2213         nfa_start_id,\n2214         builder_matches.look_have(),\n2215         &mut self.cache.stack,\n2216         &mut self.cache.sparses.set1,\n2217     );\n2218     let mut builder = builder_matches.into_nfa();\n2219     determinize::add_nfa_states(\n2220         &self.dfa.get_nfa(),\n2221         &self.cache.sparses.set1,\n2222         &mut builder,\n2223     );\n2224     let tag_starts = self.dfa.get_config().get_specialize_start_states();\n2225     self.add_builder_state(builder, |id| {\n2226         if tag_starts {\n2227             id.to_start()\n2228         } else {\n2229             id\n2230         }\n2231     })\n2232 }\n\nGenerate each test function in such a manner that it concurrently satisfies all the following preconditions:\n",
  "depend_pt": ""
}