{
  "system_pt": "As a software testing expert, please generate accurate test oracles code based on the provided information. Follow these guidelines:\n1. Generate executable test oracle codes in plain text format, one per line. Do not output complete test functions, avoid additional explanations, and do not use Markdown.\n2. Combine the given function under test, context, relevant documentation, preconditions, expected return values or types, test input conditions or ranges, and existing test function prefixes to infer and generate corresponding test oracles code.\n3. Only generate necessary test oracles to ensure comprehensive validation.\n",
  "static_pt": "The context for the focal function is as follows:\n// regex-automata/src/meta/wrappers.rs\n// crate name is regex_automata\nuse alloc::vec::Vec;\nuse crate::{\n    meta::{\n        error::{BuildError, RetryError, RetryFailError},\n        regex::RegexInfo,\n    },\n    nfa::thompson::{pikevm, NFA},\n    util::{prefilter::Prefilter, primitives::NonMaxUsize},\n    HalfMatch, Input, Match, MatchKind, PatternID, PatternSet,\n};\n#[cfg(feature = \"dfa-build\")]\nuse crate::dfa;\n#[cfg(feature = \"dfa-onepass\")]\nuse crate::dfa::onepass;\n#[cfg(feature = \"hybrid\")]\nuse crate::hybrid;\n#[cfg(feature = \"nfa-backtrack\")]\nuse crate::nfa::thompson::backtrack;\n#[derive(Debug)]\npub(crate) struct HybridEngine(\n    #[cfg(feature = \"hybrid\")]\n    hybrid::regex::Regex,\n    #[cfg(not(feature = \"hybrid\"))]\n    (),\n);\n#[derive(Debug, Clone)]\npub struct Cache {\n    forward: dfa::Cache,\n    reverse: dfa::Cache,\n}\n#[derive(Debug)]\npub struct Regex {\n    /// The forward lazy DFA. This can only find the end of a match.\n    forward: DFA,\n    /// The reverse lazy DFA. This can only find the start of a match.\n    ///\n    /// This is built with 'all' match semantics (instead of leftmost-first)\n    /// so that it always finds the longest possible match (which corresponds\n    /// to the leftmost starting position). It is also compiled as an anchored\n    /// matcher and has 'starts_for_each_pattern' enabled. Including starting\n    /// states for each pattern is necessary to ensure that we only look for\n    /// matches of a pattern that matched in the forward direction. Otherwise,\n    /// we might wind up finding the \"leftmost\" starting position of a totally\n    /// different pattern!\n    reverse: DFA,\n}\n#[derive(Clone, Debug)]\npub struct DFA {\n    config: Config,\n    nfa: thompson::NFA,\n    stride2: usize,\n    start_map: StartByteMap,\n    classes: ByteClasses,\n    quitset: ByteSet,\n    cache_capacity: usize,\n}\n#[derive(Clone, Debug, Eq, PartialEq)]\npub struct MatchError(\n    #[cfg(feature = \"alloc\")]\n    alloc::boxed::Box<MatchErrorKind>,\n    #[cfg(not(feature = \"alloc\"))]\n    MatchErrorKind,\n);\n#[derive(Clone, Copy, Debug, Eq, Hash, PartialEq)]\npub struct HalfMatch {\n    /// The pattern ID.\n    pattern: PatternID,\n    /// The offset of the match.\n    ///\n    /// For forward searches, the offset is exclusive. For reverse searches,\n    /// the offset is inclusive.\n    offset: usize,\n}\n#[derive(Clone, Debug)]\npub(crate) struct HybridCache(\n    #[cfg(feature = \"hybrid\")]\n    Option<hybrid::regex::Cache>,\n    #[cfg(not(feature = \"hybrid\"))]\n    (),\n);\n#[derive(Debug)]\npub(crate) struct RetryFailError {\n    offset: usize,\n}\n#[derive(Clone, Debug)]\npub struct Cache {\n    /// The transition table.\n    ///\n    /// Given a `current` LazyStateID and an `input` byte, the next state can\n    /// be computed via `trans[untagged(current) + equiv_class(input)]`. Notice\n    /// that no multiplication is used. That's because state identifiers are\n    /// \"premultiplied.\"\n    ///\n    /// Note that the next state may be the \"unknown\" state. In this case, the\n    /// next state is not known and determinization for `current` on `input`\n    /// must be performed.\n    trans: Vec<LazyStateID>,\n    /// The starting states for this DFA.\n    ///\n    /// These are computed lazily. Initially, these are all set to \"unknown\"\n    /// lazy state IDs.\n    ///\n    /// When 'starts_for_each_pattern' is disabled (the default), then the size\n    /// of this is constrained to the possible starting configurations based\n    /// on the search parameters. (At time of writing, that's 4.) However,\n    /// when starting states for each pattern is enabled, then there are N\n    /// additional groups of starting states, where each group reflects the\n    /// different possible configurations and N is the number of patterns.\n    starts: Vec<LazyStateID>,\n    /// A sequence of NFA/DFA powerset states that have been computed for this\n    /// lazy DFA. This sequence is indexable by untagged LazyStateIDs. (Every\n    /// tagged LazyStateID can be used to index this sequence by converting it\n    /// to its untagged form.)\n    states: Vec<State>,\n    /// A map from states to their corresponding IDs. This map may be accessed\n    /// via the raw byte representation of a state, which means that a `State`\n    /// does not need to be allocated to determine whether it already exists\n    /// in this map. Indeed, the existence of such a state is what determines\n    /// whether we allocate a new `State` or not.\n    ///\n    /// The higher level idea here is that we do just enough determinization\n    /// for a state to check whether we've already computed it. If we have,\n    /// then we can save a little (albeit not much) work. The real savings is\n    /// in memory usage. If we never checked for trivially duplicate states,\n    /// then our memory usage would explode to unreasonable levels.\n    states_to_id: StateMap,\n    /// Sparse sets used to track which NFA states have been visited during\n    /// various traversals.\n    sparses: SparseSets,\n    /// Scratch space for traversing the NFA graph. (We use space on the heap\n    /// instead of the call stack.)\n    stack: Vec<NFAStateID>,\n    /// Scratch space for building a NFA/DFA powerset state. This is used to\n    /// help amortize allocation since not every powerset state generated is\n    /// added to the cache. In particular, if it already exists in the cache,\n    /// then there is no need to allocate a new `State` for it.\n    scratch_state_builder: StateBuilderEmpty,\n    /// A simple abstraction for handling the saving of at most a single state\n    /// across a cache clearing. This is required for correctness. Namely, if\n    /// adding a new state after clearing the cache fails, then the caller\n    /// must retain the ability to continue using the state ID given. The\n    /// state corresponding to the state ID is what we preserve across cache\n    /// clearings.\n    state_saver: StateSaver,\n    /// The memory usage, in bytes, used by 'states' and 'states_to_id'. We\n    /// track this as new states are added since states use a variable amount\n    /// of heap. Tracking this as we add states makes it possible to compute\n    /// the total amount of memory used by the determinizer in constant time.\n    memory_usage_state: usize,\n    /// The number of times the cache has been cleared. When a minimum cache\n    /// clear count is set, then the cache will return an error instead of\n    /// clearing the cache if the count has been exceeded.\n    clear_count: usize,\n    /// The total number of bytes searched since the last time this cache was\n    /// cleared, not including the current search.\n    ///\n    /// This can be added to the length of the current search to get the true\n    /// total number of bytes searched.\n    ///\n    /// This is generally only non-zero when the\n    /// `Cache::search_{start,update,finish}` APIs are used to track search\n    /// progress.\n    bytes_searched: usize,\n    /// The progress of the current search.\n    ///\n    /// This is only non-`None` when callers utlize the `Cache::search_start`,\n    /// `Cache::search_update` and `Cache::search_finish` APIs.\n    ///\n    /// The purpose of recording search progress is to be able to make a\n    /// determination about the efficiency of the cache. Namely, by keeping\n    /// track of the\n    progress: Option<SearchProgress>,\n}\n#[derive(Clone)]\npub struct Input<'h> {\n    haystack: &'h [u8],\n    span: Span,\n    anchored: Anchored,\n    earliest: bool,\n}\n#[derive(Debug)]\npub struct Regex {\n    /// The actual regex implementation.\n    imp: Arc<RegexI>,\n    /// A thread safe pool of caches.\n    ///\n    /// For the higher level search APIs, a `Cache` is automatically plucked\n    /// from this pool before running a search. The lower level `with` methods\n    /// permit the caller to provide their own cache, thereby bypassing\n    /// accesses to this pool.\n    ///\n    /// Note that we put this outside the `Arc` so that cloning a `Regex`\n    /// results in creating a fresh `CachePool`. This in turn permits callers\n    /// to clone regexes into separate threads where each such regex gets\n    /// the pool's \"thread owner\" optimization. Otherwise, if one shares the\n    /// `Regex` directly, then the pool will go through a slower mutex path for\n    /// all threads except for the \"owner.\"\n    pool: CachePool,\n}\nimpl HybridEngine {\n    pub(crate) fn new(\n        info: &RegexInfo,\n        pre: Option<Prefilter>,\n        nfa: &NFA,\n        nfarev: &NFA,\n    ) -> Option<HybridEngine> {}\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    pub(crate) fn try_search(\n        &self,\n        cache: &mut HybridCache,\n        input: &Input<'_>,\n    ) -> Result<Option<Match>, RetryFailError> {}\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    pub(crate) fn try_search_half_fwd(\n        &self,\n        cache: &mut HybridCache,\n        input: &Input<'_>,\n    ) -> Result<Option<HalfMatch>, RetryFailError> {}\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    pub(crate) fn try_search_half_fwd_stopat(\n        &self,\n        cache: &mut HybridCache,\n        input: &Input<'_>,\n    ) -> Result<Result<HalfMatch, usize>, RetryFailError> {}\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    pub(crate) fn try_search_half_rev(\n        &self,\n        cache: &mut HybridCache,\n        input: &Input<'_>,\n    ) -> Result<Option<HalfMatch>, RetryFailError> {\n        #[cfg(feature = \"hybrid\")]\n        {\n            let rev = self.0.reverse();\n            let mut revcache = cache.0.as_mut().unwrap().as_parts_mut().1;\n            rev.try_search_rev(&mut revcache, input).map_err(|e| e.into())\n        }\n        #[cfg(not(feature = \"hybrid\"))] { unreachable!() }\n    }\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    pub(crate) fn try_search_half_rev_limited(\n        &self,\n        cache: &mut HybridCache,\n        input: &Input<'_>,\n        min_start: usize,\n    ) -> Result<Option<HalfMatch>, RetryError> {}\n    #[inline]\n    pub(crate) fn try_which_overlapping_matches(\n        &self,\n        cache: &mut HybridCache,\n        input: &Input<'_>,\n        patset: &mut PatternSet,\n    ) -> Result<(), RetryFailError> {}\n}\nimpl Cache {\n    pub fn new(re: &Regex) -> Cache {}\n    pub fn reset(&mut self, re: &Regex) {}\n    pub fn forward(&mut self) -> &dfa::Cache {}\n    pub fn reverse(&mut self) -> &dfa::Cache {}\n    pub fn forward_mut(&mut self) -> &mut dfa::Cache {}\n    pub fn reverse_mut(&mut self) -> &mut dfa::Cache {}\n    pub fn as_parts(&self) -> (&dfa::Cache, &dfa::Cache) {}\n    pub fn as_parts_mut(&mut self) -> (&mut dfa::Cache, &mut dfa::Cache) {\n        (&mut self.forward, &mut self.reverse)\n    }\n    pub fn memory_usage(&self) -> usize {}\n}\nimpl Regex {\n    pub fn forward(&self) -> &DFA {}\n    pub fn reverse(&self) -> &DFA {\n        &self.reverse\n    }\n    pub fn pattern_len(&self) -> usize {}\n}\nimpl DFA {\n    #[inline]\n    pub fn try_search_fwd(\n        &self,\n        cache: &mut Cache,\n        input: &Input<'_>,\n    ) -> Result<Option<HalfMatch>, MatchError> {}\n    #[inline]\n    pub fn try_search_rev(\n        &self,\n        cache: &mut Cache,\n        input: &Input<'_>,\n    ) -> Result<Option<HalfMatch>, MatchError> {\n        let utf8empty = self.get_nfa().has_empty() && self.get_nfa().is_utf8();\n        let hm = match search::find_rev(self, cache, input)? {\n            None => return Ok(None),\n            Some(hm) if !utf8empty => return Ok(Some(hm)),\n            Some(hm) => hm,\n        };\n        empty::skip_splits_rev(\n            input,\n            hm,\n            hm.offset(),\n            |input| {\n                let got = search::find_rev(self, cache, input)?;\n                Ok(got.map(|hm| (hm, hm.offset())))\n            },\n        )\n    }\n    #[inline]\n    pub fn try_search_overlapping_fwd(\n        &self,\n        cache: &mut Cache,\n        input: &Input<'_>,\n        state: &mut OverlappingState,\n    ) -> Result<(), MatchError> {}\n    #[inline]\n    pub fn try_search_overlapping_rev(\n        &self,\n        cache: &mut Cache,\n        input: &Input<'_>,\n        state: &mut OverlappingState,\n    ) -> Result<(), MatchError> {}\n    #[inline]\n    pub fn try_which_overlapping_matches(\n        &self,\n        cache: &mut Cache,\n        input: &Input<'_>,\n        patset: &mut PatternSet,\n    ) -> Result<(), MatchError> {}\n}\n\nThe function to be tested is presented with each line formatted as 'line number + code':\n702 pub(crate) fn try_search_half_rev(\n703     &self,\n704     cache: &mut HybridCache,\n705     input: &Input<'_>,\n706 ) -> Result<Option<HalfMatch>, RetryFailError> {\n707     #[cfg(feature = \"hybrid\")]\n708     {\n709         let rev = self.0.reverse();\n710         let mut revcache = cache.0.as_mut().unwrap().as_parts_mut().1;\n711         rev.try_search_rev(&mut revcache, input).map_err(|e| e.into())\n712     }\n713     #[cfg(not(feature = \"hybrid\"))]\n714     {\n715         // Impossible to reach because this engine is never constructed\n716         // if the requisite features aren't enabled.\n717         unreachable!()\n718     }\n719 }\n\nThe path conditions that the generated test functions should satisfy are as follows:\n"
}