{
  "system_pt": "As a software testing expert, please generate Rust test functions based on the following guidelines, focusing solely on constructing test inputs and calling the functions under test:\n1. Provide the code in plain text format, without explanations or Markdown.\n2. If the method under test belongs to a trait, construct appropriate structs within the test function, but avoid method overrides. If the method under test uses generics, instantiate them with suitable types based on the context.\n3. Generate test code with minimal scope: avoid creating external structures or implementations. Instead, define any necessary helper structures or implementations directly within the test function when required.\n4. Whenever possible, initialize the corresponding data structures using the initialization methods provided in the context.\n5. Ensure the generated function is fully implemented and can be compiled and executed directly without any missing parts.\n6. Create a minimal yet complete set of test functions, ensuring they adhere to all provided preconditions and cover boundary conditions, and reference the inferred test input conditions or ranges.\n7. Ensure the test inputs are designed to cover the inferred test input conditions or ranges as comprehensively as possible, with particular emphasis on boundary cases.\n8. Focus on crafting test inputs that effectively reveal potential bugs while meeting the specified requirements.\n9. Omit test oracles and assertions; concentrate on generating test inputs and function calls.\n10. Do not create a test module, but include intrinsic attributes like #[test] or #[should_panic] where necessary.\n",
  "static_pt": "The context for the focal function is as follows:\n// regex-automata/src/meta/wrappers.rs\n// crate name is regex_automata\nuse alloc::vec::Vec;\nuse crate::{\n    meta::{\n        error::{BuildError, RetryError, RetryFailError},\n        regex::RegexInfo,\n    },\n    nfa::thompson::{pikevm, NFA},\n    util::{prefilter::Prefilter, primitives::NonMaxUsize},\n    HalfMatch, Input, Match, MatchKind, PatternID, PatternSet,\n};\n#[cfg(feature = \"dfa-build\")]\nuse crate::dfa;\n#[cfg(feature = \"dfa-onepass\")]\nuse crate::dfa::onepass;\n#[cfg(feature = \"hybrid\")]\nuse crate::hybrid;\n#[cfg(feature = \"nfa-backtrack\")]\nuse crate::nfa::thompson::backtrack;\n#[derive(Debug)]\npub(crate) struct DFAEngine(\n    #[cfg(feature = \"dfa-build\")]\n    dfa::regex::Regex,\n    #[cfg(not(feature = \"dfa-build\"))]\n    (),\n);\n#[derive(Clone, Debug, Default)]\npub struct Config {\n    match_kind: Option<MatchKind>,\n    utf8_empty: Option<bool>,\n    autopre: Option<bool>,\n    pre: Option<Option<Prefilter>>,\n    which_captures: Option<WhichCaptures>,\n    nfa_size_limit: Option<Option<usize>>,\n    onepass_size_limit: Option<Option<usize>>,\n    hybrid_cache_capacity: Option<usize>,\n    hybrid: Option<bool>,\n    dfa: Option<bool>,\n    dfa_size_limit: Option<Option<usize>>,\n    dfa_state_limit: Option<Option<usize>>,\n    onepass: Option<bool>,\n    backtrack: Option<bool>,\n    byte_classes: Option<bool>,\n    line_terminator: Option<u8>,\n}\n#[cfg(feature = \"dfa-build\")]\n#[derive(Clone, Debug, Default)]\npub struct Config {\n    accelerate: Option<bool>,\n    pre: Option<Option<Prefilter>>,\n    minimize: Option<bool>,\n    match_kind: Option<MatchKind>,\n    start_kind: Option<StartKind>,\n    starts_for_each_pattern: Option<bool>,\n    byte_classes: Option<bool>,\n    unicode_word_boundary: Option<bool>,\n    quitset: Option<ByteSet>,\n    specialize_start_states: Option<bool>,\n    dfa_size_limit: Option<Option<usize>>,\n    determinize_size_limit: Option<Option<usize>>,\n}\n#[cfg(feature = \"dfa-build\")]\n#[derive(Clone, Debug)]\npub struct Builder {\n    config: Config,\n    #[cfg(feature = \"syntax\")]\n    thompson: thompson::Compiler,\n}\n#[derive(Clone)]\npub struct NFA(Arc<Inner>);\n#[derive(Clone, Debug)]\npub struct Builder {\n    #[cfg(feature = \"dfa-build\")]\n    dfa: dense::Builder,\n}\n#[derive(Clone, Debug)]\npub(crate) struct RegexInfo(Arc<RegexInfoI>);\n#[derive(Clone, Debug)]\npub struct Prefilter {\n    #[cfg(not(feature = \"alloc\"))]\n    _unused: (),\n    #[cfg(feature = \"alloc\")]\n    pre: Arc<dyn PrefilterI>,\n    #[cfg(feature = \"alloc\")]\n    is_fast: bool,\n    #[cfg(feature = \"alloc\")]\n    max_needle_len: usize,\n}\n#[cfg(feature = \"dfa-build\")]\n#[derive(Clone, Debug)]\npub struct BuildError {\n    kind: BuildErrorKind,\n}\n#[derive(Debug)]\npub struct Regex {\n    /// The actual regex implementation.\n    imp: Arc<RegexI>,\n    /// A thread safe pool of caches.\n    ///\n    /// For the higher level search APIs, a `Cache` is automatically plucked\n    /// from this pool before running a search. The lower level `with` methods\n    /// permit the caller to provide their own cache, thereby bypassing\n    /// accesses to this pool.\n    ///\n    /// Note that we put this outside the `Arc` so that cloning a `Regex`\n    /// results in creating a fresh `CachePool`. This in turn permits callers\n    /// to clone regexes into separate threads where each such regex gets\n    /// the pool's \"thread owner\" optimization. Otherwise, if one shares the\n    /// `Regex` directly, then the pool will go through a slower mutex path for\n    /// all threads except for the \"owner.\"\n    pool: CachePool,\n}\n#[derive(Debug)]\npub struct Regex {\n    /// The forward lazy DFA. This can only find the end of a match.\n    forward: DFA,\n    /// The reverse lazy DFA. This can only find the start of a match.\n    ///\n    /// This is built with 'all' match semantics (instead of leftmost-first)\n    /// so that it always finds the longest possible match (which corresponds\n    /// to the leftmost starting position). It is also compiled as an anchored\n    /// matcher and has 'starts_for_each_pattern' enabled. Including starting\n    /// states for each pattern is necessary to ensure that we only look for\n    /// matches of a pattern that matched in the forward direction. Otherwise,\n    /// we might wind up finding the \"leftmost\" starting position of a totally\n    /// different pattern!\n    reverse: DFA,\n}\n#[derive(Clone, Copy, Debug, Eq, PartialEq)]\npub enum StartKind {\n    /// Support both anchored and unanchored searches.\n    Both,\n    /// Support only unanchored searches. Requesting an anchored search will\n    /// panic.\n    ///\n    /// Note that even if an unanchored search is requested, the pattern itself\n    /// may still be anchored. For example, `^abc` will only match `abc` at the\n    /// start of a haystack. This will remain true, even if the regex engine\n    /// only supported unanchored searches.\n    Unanchored,\n    /// Support only anchored searches. Requesting an unanchored search will\n    /// panic.\n    Anchored,\n}\n#[non_exhaustive]\n#[derive(Clone, Copy, Debug, Eq, PartialEq)]\npub enum MatchKind {\n    /// Report all possible matches.\n    All,\n    /// Report only the leftmost matches. When multiple leftmost matches exist,\n    /// report the match corresponding to the part of the regex that appears\n    /// first in the syntax.\n    LeftmostFirst,\n}\n#[derive(Clone, Eq, PartialEq)]\npub enum State {\n    /// A state with a single transition that can only be taken if the current\n    /// input symbol is in a particular range of bytes.\n    ByteRange {\n        /// The transition from this state to the next.\n        trans: Transition,\n    },\n    /// A state with possibly many transitions represented in a sparse fashion.\n    /// Transitions are non-overlapping and ordered lexicographically by input\n    /// range.\n    ///\n    /// In practice, this is used for encoding UTF-8 automata. Its presence is\n    /// primarily an optimization that avoids many additional unconditional\n    /// epsilon transitions (via [`Union`](State::Union) states), and thus\n    /// decreases the overhead of traversing the NFA. This can improve both\n    /// matching time and DFA construction time.\n    Sparse(SparseTransitions),\n    /// A dense representation of a state with multiple transitions.\n    Dense(DenseTransitions),\n    /// A conditional epsilon transition satisfied via some sort of\n    /// look-around. Look-around is limited to anchor and word boundary\n    /// assertions.\n    ///\n    /// Look-around states are meant to be evaluated while performing epsilon\n    /// closure (computing the set of states reachable from a particular state\n    /// via only epsilon transitions). If the current position in the haystack\n    /// satisfies the look-around assertion, then you're permitted to follow\n    /// that epsilon transition.\n    Look {\n        /// The look-around assertion that must be satisfied before moving\n        /// to `next`.\n        look: Look,\n        /// The state to transition to if the look-around assertion is\n        /// satisfied.\n        next: StateID,\n    },\n    /// An alternation such that there exists an epsilon transition to all\n    /// states in `alternates`, where matches found via earlier transitions\n    /// are preferred over later transitions.\n    Union {\n        /// An ordered sequence of unconditional epsilon transitions to other\n        /// states. Transitions earlier in the sequence are preferred over\n        /// transitions later in the sequence.\n        alternates: Box<[StateID]>,\n    },\n    /// An alternation such that there exists precisely two unconditional\n    /// epsilon transitions, where matches found via `alt1` are preferred over\n    /// matches found via `alt2`.\n    ///\n    /// This state exists as a common special case of Union where there are\n    /// only two alternates. In this case, we don't need any allocations to\n    /// represent the state. This saves a bit of memory and also saves an\n    /// additional memory access when traversing the NFA.\n    BinaryUnion {\n        /// An unconditional epsilon transition to another NFA state. This\n        /// is preferred over `alt2`.\n        alt1: StateID,\n        /// An unconditional epsilon transition to another NFA state. Matches\n        /// reported via this transition should only be reported if no matches\n        /// were found by following `alt1`.\n        alt2: StateID,\n    },\n    /// An empty state that records a capture location.\n    ///\n    /// From the perspective of finite automata, this is precisely equivalent\n    /// to an unconditional epsilon transition, but serves the purpose of\n    /// instructing NFA simulations to record additional state when the finite\n    /// state machine passes through this epsilon transition.\n    ///\n    /// `slot` in this context refers to the specific capture group slot\n    /// offset that is being recorded. Each capturing group has two slots\n    /// corresponding to the start and end of the matching portion of that\n    /// group.\n    ///\n    /// The pattern ID and capture group index are also included in this state\n    /// in case they are useful. But mostly, all you'll need is `next` and\n    /// `slot`.\n    Capture {\n        /// The state to transition to, unconditionally.\n        next: StateID,\n        /// The pattern ID that this capture belongs to.\n        pattern_id: PatternID,\n        /// The capture group index that this capture belongs to. Capture group\n        /// indices are local to each pattern. For example, when capturing\n        /// groups are enabled, every pattern has a capture group at index\n        /// `0`.\n        group_index: SmallIndex,\n        /// The slot index for this capture. Every capturing group has two\n        /// slots: one for the start haystack offset and one for the end\n        /// haystack offset. Unlike capture group indices, slot indices are\n        /// global across all patterns in this NFA. That is, each slot belongs\n        /// to a single pattern, but there is only one slot at index `i`.\n        slot: SmallIndex,\n    },\n    /// A state that cannot be transitioned out of. This is useful for cases\n    /// where you want to prevent matching from occurring. For example, if your\n    /// regex parser permits empty character classes, then one could choose\n    /// a `Fail` state to represent them. (An empty character class can be\n    /// thought of as an empty set. Since nothing is in an empty set, they can\n    /// never match anything.)\n    Fail,\n    /// A match state. There is at least one such occurrence of this state for\n    /// each regex that can match that is in this NFA.\n    Match {\n        /// The matching pattern ID.\n        pattern_id: PatternID,\n    },\n}\nimpl DFAEngine {\n    pub(crate) fn new(\n        info: &RegexInfo,\n        pre: Option<Prefilter>,\n        nfa: &NFA,\n        nfarev: &NFA,\n    ) -> Option<DFAEngine> {\n        #[cfg(feature = \"dfa-build\")]\n        {\n            if !info.config().get_dfa() {\n                return None;\n            }\n            if let Some(state_limit) = info.config().get_dfa_state_limit() {\n                if nfa.states().len() > state_limit {\n                    debug!(\n                        \"skipping full DFA because NFA has {} states, \\\n                         which exceeds the heuristic limit of {}\",\n                        nfa.states().len(), state_limit,\n                    );\n                    return None;\n                }\n            }\n            let size_limit = info.config().get_dfa_size_limit().map(|n| n / 4);\n            let dfa_config = dfa::dense::Config::new()\n                .match_kind(info.config().get_match_kind())\n                .prefilter(pre.clone())\n                .starts_for_each_pattern(true)\n                .byte_classes(info.config().get_byte_classes())\n                .unicode_word_boundary(true)\n                .specialize_start_states(pre.is_some())\n                .determinize_size_limit(size_limit)\n                .dfa_size_limit(size_limit);\n            let result = dfa::dense::Builder::new()\n                .configure(dfa_config.clone())\n                .build_from_nfa(&nfa);\n            let fwd = match result {\n                Ok(fwd) => fwd,\n                Err(_err) => {\n                    debug!(\"forward full DFA failed to build: {}\", _err);\n                    return None;\n                }\n            };\n            let result = dfa::dense::Builder::new()\n                .configure(\n                    dfa_config\n                        .clone()\n                        .start_kind(dfa::StartKind::Anchored)\n                        .match_kind(MatchKind::All)\n                        .prefilter(None)\n                        .specialize_start_states(false),\n                )\n                .build_from_nfa(&nfarev);\n            let rev = match result {\n                Ok(rev) => rev,\n                Err(_err) => {\n                    debug!(\"reverse full DFA failed to build: {}\", _err);\n                    return None;\n                }\n            };\n            let engine = dfa::regex::Builder::new().build_from_dfas(fwd, rev);\n            debug!(\n                \"fully compiled forward and reverse DFAs built, {} bytes\", engine\n                .forward().memory_usage() + engine.reverse().memory_usage(),\n            );\n            Some(DFAEngine(engine))\n        }\n        #[cfg(not(feature = \"dfa-build\"))] { None }\n    }\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    pub(crate) fn try_search(\n        &self,\n        input: &Input<'_>,\n    ) -> Result<Option<Match>, RetryFailError> {}\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    pub(crate) fn try_search_half_fwd(\n        &self,\n        input: &Input<'_>,\n    ) -> Result<Option<HalfMatch>, RetryFailError> {}\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    pub(crate) fn try_search_half_fwd_stopat(\n        &self,\n        input: &Input<'_>,\n    ) -> Result<Result<HalfMatch, usize>, RetryFailError> {}\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    pub(crate) fn try_search_half_rev(\n        &self,\n        input: &Input<'_>,\n    ) -> Result<Option<HalfMatch>, RetryFailError> {}\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    pub(crate) fn try_search_half_rev_limited(\n        &self,\n        input: &Input<'_>,\n        min_start: usize,\n    ) -> Result<Option<HalfMatch>, RetryError> {}\n    #[inline]\n    pub(crate) fn try_which_overlapping_matches(\n        &self,\n        input: &Input<'_>,\n        patset: &mut PatternSet,\n    ) -> Result<(), RetryFailError> {}\n    pub(crate) fn memory_usage(&self) -> usize {}\n}\nimpl Config {\n    pub fn new() -> Config {}\n    pub fn match_kind(self, kind: MatchKind) -> Config {}\n    pub fn utf8_empty(self, yes: bool) -> Config {}\n    pub fn auto_prefilter(self, yes: bool) -> Config {}\n    pub fn prefilter(self, pre: Option<Prefilter>) -> Config {}\n    pub fn which_captures(mut self, which_captures: WhichCaptures) -> Config {}\n    pub fn nfa_size_limit(self, limit: Option<usize>) -> Config {}\n    pub fn onepass_size_limit(self, limit: Option<usize>) -> Config {}\n    pub fn hybrid_cache_capacity(self, limit: usize) -> Config {}\n    pub fn dfa_size_limit(self, limit: Option<usize>) -> Config {}\n    pub fn dfa_state_limit(self, limit: Option<usize>) -> Config {}\n    pub fn byte_classes(self, yes: bool) -> Config {}\n    pub fn line_terminator(self, byte: u8) -> Config {}\n    pub fn hybrid(self, yes: bool) -> Config {}\n    pub fn dfa(self, yes: bool) -> Config {}\n    pub fn onepass(self, yes: bool) -> Config {}\n    pub fn backtrack(self, yes: bool) -> Config {}\n    pub fn get_match_kind(&self) -> MatchKind {\n        self.match_kind.unwrap_or(MatchKind::LeftmostFirst)\n    }\n    pub fn get_utf8_empty(&self) -> bool {}\n    pub fn get_auto_prefilter(&self) -> bool {}\n    pub fn get_prefilter(&self) -> Option<&Prefilter> {}\n    pub fn get_which_captures(&self) -> WhichCaptures {}\n    pub fn get_nfa_size_limit(&self) -> Option<usize> {}\n    pub fn get_onepass_size_limit(&self) -> Option<usize> {}\n    pub fn get_hybrid_cache_capacity(&self) -> usize {}\n    pub fn get_dfa_size_limit(&self) -> Option<usize> {\n        self.dfa_size_limit.unwrap_or(Some(40 * (1 << 10)))\n    }\n    pub fn get_dfa_state_limit(&self) -> Option<usize> {\n        self.dfa_state_limit.unwrap_or(Some(30))\n    }\n    pub fn get_byte_classes(&self) -> bool {\n        self.byte_classes.unwrap_or(true)\n    }\n    pub fn get_line_terminator(&self) -> u8 {}\n    pub fn get_hybrid(&self) -> bool {}\n    pub fn get_dfa(&self) -> bool {\n        #[cfg(feature = \"dfa-build\")] { self.dfa.unwrap_or(true) }\n        #[cfg(not(feature = \"dfa-build\"))] { false }\n    }\n    pub fn get_onepass(&self) -> bool {}\n    pub fn get_backtrack(&self) -> bool {}\n    pub(crate) fn overwrite(&self, o: Config) -> Config {}\n}\n#[cfg(feature = \"dfa-build\")]\nimpl Config {\n    pub fn new() -> Config {\n        Config::default()\n    }\n    pub fn accelerate(mut self, yes: bool) -> Config {}\n    pub fn prefilter(mut self, pre: Option<Prefilter>) -> Config {\n        self.pre = Some(pre);\n        if self.specialize_start_states.is_none() {\n            self.specialize_start_states = Some(self.get_prefilter().is_some());\n        }\n        self\n    }\n    pub fn minimize(mut self, yes: bool) -> Config {}\n    pub fn match_kind(mut self, kind: MatchKind) -> Config {\n        self.match_kind = Some(kind);\n        self\n    }\n    pub fn start_kind(mut self, kind: StartKind) -> Config {\n        self.start_kind = Some(kind);\n        self\n    }\n    pub fn starts_for_each_pattern(mut self, yes: bool) -> Config {\n        self.starts_for_each_pattern = Some(yes);\n        self\n    }\n    pub fn byte_classes(mut self, yes: bool) -> Config {\n        self.byte_classes = Some(yes);\n        self\n    }\n    pub fn unicode_word_boundary(mut self, yes: bool) -> Config {\n        self.unicode_word_boundary = Some(yes);\n        self\n    }\n    pub fn quit(mut self, byte: u8, yes: bool) -> Config {}\n    pub fn specialize_start_states(mut self, yes: bool) -> Config {\n        self.specialize_start_states = Some(yes);\n        self\n    }\n    pub fn dfa_size_limit(mut self, bytes: Option<usize>) -> Config {\n        self.dfa_size_limit = Some(bytes);\n        self\n    }\n    pub fn determinize_size_limit(mut self, bytes: Option<usize>) -> Config {\n        self.determinize_size_limit = Some(bytes);\n        self\n    }\n    pub fn get_accelerate(&self) -> bool {}\n    pub fn get_prefilter(&self) -> Option<&Prefilter> {}\n    pub fn get_minimize(&self) -> bool {}\n    pub fn get_match_kind(&self) -> MatchKind {}\n    pub fn get_starts(&self) -> StartKind {}\n    pub fn get_starts_for_each_pattern(&self) -> bool {}\n    pub fn get_byte_classes(&self) -> bool {}\n    pub fn get_unicode_word_boundary(&self) -> bool {}\n    pub fn get_quit(&self, byte: u8) -> bool {}\n    pub fn get_specialize_start_states(&self) -> bool {}\n    pub fn get_dfa_size_limit(&self) -> Option<usize> {}\n    pub fn get_determinize_size_limit(&self) -> Option<usize> {}\n    pub(crate) fn overwrite(&self, o: Config) -> Config {}\n}\n#[cfg(feature = \"dfa-build\")]\nimpl Builder {\n    pub fn new() -> Builder {\n        Builder {\n            config: Config::default(),\n            #[cfg(feature = \"syntax\")]\n            thompson: thompson::Compiler::new(),\n        }\n    }\n    #[cfg(feature = \"syntax\")]\n    pub fn build(&self, pattern: &str) -> Result<OwnedDFA, BuildError> {}\n    #[cfg(feature = \"syntax\")]\n    pub fn build_many<P: AsRef<str>>(\n        &self,\n        patterns: &[P],\n    ) -> Result<OwnedDFA, BuildError> {}\n    pub fn build_from_nfa(&self, nfa: &thompson::NFA) -> Result<OwnedDFA, BuildError> {\n        let mut quitset = self.config.quitset.unwrap_or(ByteSet::empty());\n        if self.config.get_unicode_word_boundary()\n            && nfa.look_set_any().contains_word_unicode()\n        {\n            for b in 0x80..=0xFF {\n                quitset.add(b);\n            }\n        }\n        let classes = if !self.config.get_byte_classes() {\n            ByteClasses::singletons()\n        } else {\n            let mut set = nfa.byte_class_set().clone();\n            if !quitset.is_empty() {\n                set.add_set(&quitset);\n            }\n            set.byte_classes()\n        };\n        let mut dfa = DFA::initial(\n            classes,\n            nfa.pattern_len(),\n            self.config.get_starts(),\n            nfa.look_matcher(),\n            self.config.get_starts_for_each_pattern(),\n            self.config.get_prefilter().map(|p| p.clone()),\n            quitset,\n            Flags::from_nfa(&nfa),\n        )?;\n        determinize::Config::new()\n            .match_kind(self.config.get_match_kind())\n            .quit(quitset)\n            .dfa_size_limit(self.config.get_dfa_size_limit())\n            .determinize_size_limit(self.config.get_determinize_size_limit())\n            .run(nfa, &mut dfa)?;\n        if self.config.get_minimize() {\n            dfa.minimize();\n        }\n        if self.config.get_accelerate() {\n            dfa.accelerate();\n        }\n        if !self.config.get_specialize_start_states() {\n            dfa.special.set_no_special_start_states();\n        }\n        dfa.set_universal_starts();\n        Ok(dfa)\n    }\n    pub fn configure(&mut self, config: Config) -> &mut Builder {\n        self.config = self.config.overwrite(config);\n        self\n    }\n    #[cfg(feature = \"syntax\")]\n    pub fn syntax(&mut self, config: crate::util::syntax::Config) -> &mut Builder {}\n    #[cfg(feature = \"syntax\")]\n    pub fn thompson(&mut self, config: thompson::Config) -> &mut Builder {}\n}\nimpl NFA {\n    #[cfg(feature = \"syntax\")]\n    pub fn new(pattern: &str) -> Result<NFA, BuildError> {}\n    #[cfg(feature = \"syntax\")]\n    pub fn new_many<P: AsRef<str>>(patterns: &[P]) -> Result<NFA, BuildError> {}\n    pub fn always_match() -> NFA {}\n    pub fn never_match() -> NFA {}\n    #[cfg(feature = \"syntax\")]\n    pub fn config() -> Config {}\n    #[cfg(feature = \"syntax\")]\n    pub fn compiler() -> Compiler {}\n    pub fn patterns(&self) -> PatternIter<'_> {}\n    #[inline]\n    pub fn pattern_len(&self) -> usize {}\n    #[inline]\n    pub fn start_anchored(&self) -> StateID {}\n    #[inline]\n    pub fn start_unanchored(&self) -> StateID {}\n    #[inline]\n    pub fn start_pattern(&self, pid: PatternID) -> Option<StateID> {}\n    #[inline]\n    pub(crate) fn byte_class_set(&self) -> &ByteClassSet {}\n    #[inline]\n    pub fn byte_classes(&self) -> &ByteClasses {}\n    #[inline]\n    pub fn state(&self, id: StateID) -> &State {}\n    #[inline]\n    pub fn states(&self) -> &[State] {\n        &self.0.states\n    }\n    #[inline]\n    pub fn group_info(&self) -> &GroupInfo {}\n    #[inline]\n    pub fn has_capture(&self) -> bool {}\n    #[inline]\n    pub fn has_empty(&self) -> bool {}\n    #[inline]\n    pub fn is_utf8(&self) -> bool {}\n    #[inline]\n    pub fn is_reverse(&self) -> bool {}\n    #[inline]\n    pub fn is_always_start_anchored(&self) -> bool {}\n    #[inline]\n    pub fn look_matcher(&self) -> &LookMatcher {}\n    #[inline]\n    pub fn look_set_any(&self) -> LookSet {}\n    #[inline]\n    pub fn look_set_prefix_any(&self) -> LookSet {}\n    #[inline]\n    pub fn memory_usage(&self) -> usize {}\n}\nimpl Builder {\n    pub fn new() -> Builder {\n        Builder {\n            #[cfg(feature = \"dfa-build\")]\n            dfa: dense::Builder::new(),\n        }\n    }\n    #[cfg(all(feature = \"syntax\", feature = \"dfa-build\"))]\n    pub fn build(&self, pattern: &str) -> Result<Regex, BuildError> {}\n    #[cfg(all(feature = \"syntax\", feature = \"dfa-build\"))]\n    pub fn build_sparse(\n        &self,\n        pattern: &str,\n    ) -> Result<Regex<sparse::DFA<Vec<u8>>>, BuildError> {}\n    #[cfg(all(feature = \"syntax\", feature = \"dfa-build\"))]\n    pub fn build_many<P: AsRef<str>>(\n        &self,\n        patterns: &[P],\n    ) -> Result<Regex, BuildError> {}\n    #[cfg(all(feature = \"syntax\", feature = \"dfa-build\"))]\n    pub fn build_many_sparse<P: AsRef<str>>(\n        &self,\n        patterns: &[P],\n    ) -> Result<Regex<sparse::DFA<Vec<u8>>>, BuildError> {}\n    pub fn build_from_dfas<A: Automaton>(&self, forward: A, reverse: A) -> Regex<A> {}\n    #[cfg(all(feature = \"syntax\", feature = \"dfa-build\"))]\n    pub fn syntax(&mut self, config: crate::util::syntax::Config) -> &mut Builder {}\n    #[cfg(all(feature = \"syntax\", feature = \"dfa-build\"))]\n    pub fn thompson(&mut self, config: crate::nfa::thompson::Config) -> &mut Builder {}\n    #[cfg(feature = \"dfa-build\")]\n    pub fn dense(&mut self, config: dense::Config) -> &mut Builder {}\n}\nimpl RegexInfo {\n    fn new(config: Config, hirs: &[&Hir]) -> RegexInfo {}\n    pub(crate) fn config(&self) -> &Config {\n        &self.0.config\n    }\n    pub(crate) fn props(&self) -> &[hir::Properties] {}\n    pub(crate) fn props_union(&self) -> &hir::Properties {}\n    pub(crate) fn pattern_len(&self) -> usize {}\n    pub(crate) fn memory_usage(&self) -> usize {}\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    pub(crate) fn is_anchored_start(&self, input: &Input<'_>) -> bool {}\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    pub(crate) fn is_always_anchored_start(&self) -> bool {}\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    pub(crate) fn is_always_anchored_end(&self) -> bool {}\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    fn is_impossible(&self, input: &Input<'_>) -> bool {}\n}\n\nThe function to be tested is presented with each line formatted as 'line number + code':\n854 pub(crate) fn new(\n855     info: &RegexInfo,\n856     pre: Option<Prefilter>,\n857     nfa: &NFA,\n858     nfarev: &NFA,\n859 ) -> Option<DFAEngine> {\n860     #[cfg(feature = \"dfa-build\")]\n861     {\n862         if !info.config().get_dfa() {\n863             return None;\n864         }\n865         // If our NFA is anything but small, don't even bother with a DFA.\n866         if let Some(state_limit) = info.config().get_dfa_state_limit() {\n867             if nfa.states().len() > state_limit {\n868                 debug!(\n869                     \"skipping full DFA because NFA has {} states, \\\n870                      which exceeds the heuristic limit of {}\",\n871                     nfa.states().len(),\n872                     state_limit,\n873                 );\n874                 return None;\n875             }\n876         }\n877         // We cut the size limit in four because the total heap used by\n878         // DFA construction is determinization aux memory and the DFA\n879         // itself, and those things are configured independently in the\n880         // lower level DFA builder API. And then split that in two because\n881         // of forward and reverse DFAs.\n882         let size_limit = info.config().get_dfa_size_limit().map(|n| n / 4);\n883         let dfa_config = dfa::dense::Config::new()\n884             .match_kind(info.config().get_match_kind())\n885             .prefilter(pre.clone())\n886             // Enabling this is necessary for ensuring we can service any\n887             // kind of 'Input' search without error. For the full DFA, this\n888             // can be quite costly. But since we have such a small bound\n889             // on the size of the DFA, in practice, any multl-regexes are\n890             // probably going to blow the limit anyway.\n891             .starts_for_each_pattern(true)\n892             .byte_classes(info.config().get_byte_classes())\n893             .unicode_word_boundary(true)\n894             .specialize_start_states(pre.is_some())\n895             .determinize_size_limit(size_limit)\n896             .dfa_size_limit(size_limit);\n897         let result = dfa::dense::Builder::new()\n898             .configure(dfa_config.clone())\n899             .build_from_nfa(&nfa);\n900         let fwd = match result {\n901             Ok(fwd) => fwd,\n902             Err(_err) => {\n903                 debug!(\"forward full DFA failed to build: {}\", _err);\n904                 return None;\n905             }\n906         };\n907         let result = dfa::dense::Builder::new()\n908             .configure(\n909                 dfa_config\n910                     .clone()\n911                     // We never need unanchored reverse searches, so\n912                     // there's no point in building it into the DFA, which\n913                     // WILL take more space. (This isn't done for the lazy\n914                     // DFA because the DFA is, well, lazy. It doesn't pay\n915                     // the cost for supporting unanchored searches unless\n916                     // you actually do an unanchored search, which we\n917                     // don't.)\n918                     .start_kind(dfa::StartKind::Anchored)\n919                     .match_kind(MatchKind::All)\n920                     .prefilter(None)\n921                     .specialize_start_states(false),\n922             )\n923             .build_from_nfa(&nfarev);\n924         let rev = match result {\n925             Ok(rev) => rev,\n926             Err(_err) => {\n927                 debug!(\"reverse full DFA failed to build: {}\", _err);\n928                 return None;\n929             }\n930         };\n931         let engine = dfa::regex::Builder::new().build_from_dfas(fwd, rev);\n932         debug!(\n933             \"fully compiled forward and reverse DFAs built, {} bytes\",\n934             engine.forward().memory_usage()\n935                 + engine.reverse().memory_usage(),\n936         );\n937         Some(DFAEngine(engine))\n938     }\n939     #[cfg(not(feature = \"dfa-build\"))]\n940     {\n941         None\n942     }\n943 }\n\nGenerate each test function in such a manner that it concurrently satisfies all the following preconditions:\n",
  "depend_pt": ""
}