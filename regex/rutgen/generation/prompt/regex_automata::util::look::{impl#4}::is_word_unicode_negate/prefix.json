{
  "system_pt": "As a software testing expert, please generate Rust test functions based on the following guidelines, focusing solely on constructing test inputs and calling the functions under test:\n1. Provide the code in plain text format, without explanations or Markdown.\n2. If the method under test belongs to a trait, construct appropriate structs within the test function, but avoid method overrides. If the method under test uses generics, instantiate them with suitable types based on the context.\n3. Generate test code with minimal scope: avoid creating external structures or implementations. Instead, define any necessary helper structures or implementations directly within the test function when required.\n4. Whenever possible, initialize the corresponding data structures using the initialization methods provided in the context.\n5. Ensure the generated function is fully implemented and can be compiled and executed directly without any missing parts.\n6. Create a minimal yet complete set of test functions, ensuring they adhere to all provided preconditions and cover boundary conditions, and reference the inferred test input conditions or ranges.\n7. Ensure the test inputs are designed to cover the inferred test input conditions or ranges as comprehensively as possible, with particular emphasis on boundary cases.\n8. Focus on crafting test inputs that effectively reveal potential bugs while meeting the specified requirements.\n9. Omit test oracles and assertions; concentrate on generating test inputs and function calls.\n10. Do not create a test module, but include intrinsic attributes like #[test] or #[should_panic] where necessary.\n",
  "static_pt": "The context for the focal function is as follows:\n// regex-automata/src/util/look.rs\n// crate name is regex_automata\nuse crate::util::{escape::DebugByte, utf8};\n#[derive(Clone, Debug)]\npub struct LookMatcher {\n    lineterm: DebugByte,\n}\n#[derive(Clone, Copy)]\npub struct DebugByte(pub u8);\n#[derive(Clone, Debug)]\npub struct UnicodeWordBoundaryError(());\nimpl LookMatcher {\n    pub fn new() -> LookMatcher {}\n    pub fn set_line_terminator(&mut self, byte: u8) -> &mut LookMatcher {}\n    pub fn get_line_terminator(&self) -> u8 {}\n    #[inline]\n    pub fn matches(&self, look: Look, haystack: &[u8], at: usize) -> bool {}\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    pub(crate) fn matches_inline(&self, look: Look, haystack: &[u8], at: usize) -> bool {}\n    #[inline]\n    pub fn matches_set(&self, set: LookSet, haystack: &[u8], at: usize) -> bool {}\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    pub(crate) fn matches_set_inline(\n        &self,\n        set: LookSet,\n        haystack: &[u8],\n        at: usize,\n    ) -> bool {}\n    #[cfg(feature = \"alloc\")]\n    pub(crate) fn add_to_byteset(\n        &self,\n        look: Look,\n        set: &mut crate::util::alphabet::ByteClassSet,\n    ) {}\n    #[inline]\n    pub fn is_start(&self, _haystack: &[u8], at: usize) -> bool {}\n    #[inline]\n    pub fn is_end(&self, haystack: &[u8], at: usize) -> bool {}\n    #[inline]\n    pub fn is_start_lf(&self, haystack: &[u8], at: usize) -> bool {}\n    #[inline]\n    pub fn is_end_lf(&self, haystack: &[u8], at: usize) -> bool {}\n    #[inline]\n    pub fn is_start_crlf(&self, haystack: &[u8], at: usize) -> bool {}\n    #[inline]\n    pub fn is_end_crlf(&self, haystack: &[u8], at: usize) -> bool {}\n    #[inline]\n    pub fn is_word_ascii(&self, haystack: &[u8], at: usize) -> bool {}\n    #[inline]\n    pub fn is_word_ascii_negate(&self, haystack: &[u8], at: usize) -> bool {}\n    #[inline]\n    pub fn is_word_unicode(\n        &self,\n        haystack: &[u8],\n        at: usize,\n    ) -> Result<bool, UnicodeWordBoundaryError> {}\n    #[inline]\n    pub fn is_word_unicode_negate(\n        &self,\n        haystack: &[u8],\n        at: usize,\n    ) -> Result<bool, UnicodeWordBoundaryError> {\n        let word_before = at > 0\n            && match utf8::decode_last(&haystack[..at]) {\n                None | Some(Err(_)) => return Ok(false),\n                Some(Ok(_)) => is_word_char::rev(haystack, at)?,\n            };\n        let word_after = at < haystack.len()\n            && match utf8::decode(&haystack[at..]) {\n                None | Some(Err(_)) => return Ok(false),\n                Some(Ok(_)) => is_word_char::fwd(haystack, at)?,\n            };\n        Ok(word_before == word_after)\n    }\n    #[inline]\n    pub fn is_word_start_ascii(&self, haystack: &[u8], at: usize) -> bool {}\n    #[inline]\n    pub fn is_word_end_ascii(&self, haystack: &[u8], at: usize) -> bool {}\n    #[inline]\n    pub fn is_word_start_unicode(\n        &self,\n        haystack: &[u8],\n        at: usize,\n    ) -> Result<bool, UnicodeWordBoundaryError> {}\n    #[inline]\n    pub fn is_word_end_unicode(\n        &self,\n        haystack: &[u8],\n        at: usize,\n    ) -> Result<bool, UnicodeWordBoundaryError> {}\n    #[inline]\n    pub fn is_word_start_half_ascii(&self, haystack: &[u8], at: usize) -> bool {}\n    #[inline]\n    pub fn is_word_end_half_ascii(&self, haystack: &[u8], at: usize) -> bool {}\n    #[inline]\n    pub fn is_word_start_half_unicode(\n        &self,\n        haystack: &[u8],\n        at: usize,\n    ) -> Result<bool, UnicodeWordBoundaryError> {}\n    #[inline]\n    pub fn is_word_end_half_unicode(\n        &self,\n        haystack: &[u8],\n        at: usize,\n    ) -> Result<bool, UnicodeWordBoundaryError> {}\n}\n#[cfg_attr(feature = \"perf-inline\", inline(always))]\npub(super) fn rev(\n    _bytes: &[u8],\n    _at: usize,\n) -> Result<bool, super::UnicodeWordBoundaryError> {\n    Err(super::UnicodeWordBoundaryError::new())\n}\n#[cfg_attr(feature = \"perf-inline\", inline(always))]\npub(crate) fn decode(bytes: &[u8]) -> Option<Result<char, u8>> {\n    if bytes.is_empty() {\n        return None;\n    }\n    let len = match len(bytes[0]) {\n        None => return Some(Err(bytes[0])),\n        Some(len) if len > bytes.len() => return Some(Err(bytes[0])),\n        Some(1) => return Some(Ok(char::from(bytes[0]))),\n        Some(len) => len,\n    };\n    match core::str::from_utf8(&bytes[..len]) {\n        Ok(s) => Some(Ok(s.chars().next().unwrap())),\n        Err(_) => Some(Err(bytes[0])),\n    }\n}\n#[cfg_attr(feature = \"perf-inline\", inline(always))]\npub(crate) fn decode_last(bytes: &[u8]) -> Option<Result<char, u8>> {\n    if bytes.is_empty() {\n        return None;\n    }\n    let mut start = bytes.len() - 1;\n    let limit = bytes.len().saturating_sub(4);\n    while start > limit && !is_leading_or_invalid_byte(bytes[start]) {\n        start -= 1;\n    }\n    match decode(&bytes[start..]) {\n        None => None,\n        Some(Ok(ch)) => Some(Ok(ch)),\n        Some(Err(_)) => Some(Err(bytes[bytes.len() - 1])),\n    }\n}\n#[cfg_attr(feature = \"perf-inline\", inline(always))]\npub(super) fn fwd(\n    _bytes: &[u8],\n    _at: usize,\n) -> Result<bool, super::UnicodeWordBoundaryError> {\n    Err(super::UnicodeWordBoundaryError::new())\n}\n\nThe function to be tested is presented with each line formatted as 'line number + code':\n/// Returns true when [`Look::WordUnicodeNegate`] is satisfied `at` the\n/// given position in `haystack`.\n///\n/// # Panics\n///\n/// This may panic when `at > haystack.len()`. Note that `at ==\n/// haystack.len()` is legal and guaranteed not to panic.\n///\n/// # Errors\n///\n/// This returns an error when Unicode word boundary tables\n/// are not available. Specifically, this only occurs when the\n/// `unicode-word-boundary` feature is not enabled.\n1042 pub fn is_word_unicode_negate(\n1043     &self,\n1044     haystack: &[u8],\n1045     at: usize,\n1046 ) -> Result<bool, UnicodeWordBoundaryError> {\n1047     // This is pretty subtle. Why do we need to do UTF-8 decoding here?\n1048     // Well... at time of writing, the is_word_char_{fwd,rev} routines will\n1049     // only return true if there is a valid UTF-8 encoding of a \"word\"\n1050     // codepoint, and false in every other case (including invalid UTF-8).\n1051     // This means that in regions of invalid UTF-8 (which might be a\n1052     // subset of valid UTF-8!), it would result in \\B matching. While this\n1053     // would be questionable in the context of truly invalid UTF-8, it is\n1054     // *certainly* wrong to report match boundaries that split the encoding\n1055     // of a codepoint. So to work around this, we ensure that we can decode\n1056     // a codepoint on either side of `at`. If either direction fails, then\n1057     // we don't permit \\B to match at all.\n1058     //\n1059     // Now, this isn't exactly optimal from a perf perspective. We could\n1060     // try and detect this in is_word_char::{fwd,rev}, but it's not clear\n1061     // if it's worth it. \\B is, after all, rarely used. Even worse,\n1062     // is_word_char::{fwd,rev} could do its own UTF-8 decoding, and so this\n1063     // will wind up doing UTF-8 decoding twice. Owch. We could fix this\n1064     // with more code complexity, but it just doesn't feel worth it for \\B.\n1065     //\n1066     // And in particular, we do *not* have to do this with \\b, because \\b\n1067     // *requires* that at least one side of `at` be a \"word\" codepoint,\n1068     // which in turn implies one side of `at` must be valid UTF-8. This in\n1069     // turn implies that \\b can never split a valid UTF-8 encoding of a\n1070     // codepoint. In the case where one side of `at` is truly invalid UTF-8\n1071     // and the other side IS a word codepoint, then we want \\b to match\n1072     // since it represents a valid UTF-8 boundary. It also makes sense. For\n1073     // example, you'd want \\b\\w+\\b to match 'abc' in '\\xFFabc\\xFF'.\n1074     //\n1075     // Note also that this is not just '!is_word_unicode(..)' like it is\n1076     // for the ASCII case. For example, neither \\b nor \\B is satisfied\n1077     // within invalid UTF-8 sequences.\n1078     let word_before = at > 0\n1079         && match utf8::decode_last(&haystack[..at]) {\n1080             None | Some(Err(_)) => return Ok(false),\n1081             Some(Ok(_)) => is_word_char::rev(haystack, at)?,\n1082         };\n1083     let word_after = at < haystack.len()\n1084         && match utf8::decode(&haystack[at..]) {\n1085             None | Some(Err(_)) => return Ok(false),\n1086             Some(Ok(_)) => is_word_char::fwd(haystack, at)?,\n1087         };\n1088     Ok(word_before == word_after)\n1089 }\n\nGenerate each test function in such a manner that it concurrently satisfies all the following preconditions:\n",
  "depend_pt": ""
}