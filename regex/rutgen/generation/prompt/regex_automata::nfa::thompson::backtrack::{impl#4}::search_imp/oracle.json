{
  "system_pt": "As a software testing expert, please generate accurate test oracles code based on the provided information. Follow these guidelines:\n1. Generate executable test oracle codes in plain text format, one per line. Do not output complete test functions, avoid additional explanations, and do not use Markdown.\n2. Combine the given function under test, context, relevant documentation, preconditions, expected return values or types, test input conditions or ranges, and existing test function prefixes to infer and generate corresponding test oracles code.\n3. Only generate necessary test oracles to ensure comprehensive validation.\n",
  "static_pt": "The context for the focal function is as follows:\n// regex-automata/src/nfa/thompson/backtrack.rs\n// crate name is regex_automata\nuse alloc::{vec, vec::Vec};\nuse crate::{\n    nfa::thompson::{self, BuildError, State, NFA},\n    util::{\n        captures::Captures, empty, iter, prefilter::Prefilter,\n        primitives::{NonMaxUsize, PatternID, SmallIndex, StateID},\n        search::{Anchored, HalfMatch, Input, Match, MatchError, Span},\n    },\n};\n#[derive(Clone, Debug)]\npub struct BoundedBacktracker {\n    config: Config,\n    nfa: NFA,\n}\n#[derive(Clone)]\npub struct NFA(Arc<Inner>);\n#[derive(Clone)]\npub struct Input<'h> {\n    haystack: &'h [u8],\n    span: Span,\n    anchored: Anchored,\n    earliest: bool,\n}\n#[derive(Clone, Debug)]\npub struct Cache {\n    /// Stack used on the heap for doing backtracking instead of the\n    /// traditional recursive approach. We don't want recursion because then\n    /// we're likely to hit a stack overflow for bigger regexes.\n    stack: Vec<Frame>,\n    /// The set of (StateID, HaystackOffset) pairs that have been visited\n    /// by the backtracker within a single search. If such a pair has been\n    /// visited, then we avoid doing the work for that pair again. This is\n    /// what \"bounds\" the backtracking and prevents it from having worst case\n    /// exponential time.\n    visited: Visited,\n}\n#[derive(Clone, Debug)]\npub struct Prefilter {\n    #[cfg(not(feature = \"alloc\"))]\n    _unused: (),\n    #[cfg(feature = \"alloc\")]\n    pre: Arc<dyn PrefilterI>,\n    #[cfg(feature = \"alloc\")]\n    is_fast: bool,\n    #[cfg(feature = \"alloc\")]\n    max_needle_len: usize,\n}\n#[derive(Clone, Debug, Default)]\npub struct Config {\n    pre: Option<Option<Prefilter>>,\n    visited_capacity: Option<usize>,\n}\n#[derive(Clone, Copy, Eq, Hash, PartialEq)]\npub struct Span {\n    /// The start offset of the span, inclusive.\n    pub start: usize,\n    /// The end offset of the span, exclusive.\n    pub end: usize,\n}\n#[derive(Clone, Copy, Debug)]\npub struct Config {\n    case_insensitive: bool,\n    multi_line: bool,\n    dot_matches_new_line: bool,\n    crlf: bool,\n    line_terminator: u8,\n    swap_greed: bool,\n    ignore_whitespace: bool,\n    unicode: bool,\n    utf8: bool,\n    nest_limit: u32,\n    octal: bool,\n}\n#[derive(Clone, Debug)]\npub struct Config {\n    look_behind: Option<u8>,\n    anchored: Anchored,\n}\n#[derive(Clone, Copy, Default, Eq, Hash, PartialEq, PartialOrd, Ord)]\n#[repr(transparent)]\npub struct PatternID(SmallIndex);\n#[derive(Clone, Debug, Default)]\npub struct Config {\n    match_kind: Option<MatchKind>,\n    pre: Option<Option<Prefilter>>,\n    starts_for_each_pattern: Option<bool>,\n    byte_classes: Option<bool>,\n    unicode_word_boundary: Option<bool>,\n    quitset: Option<ByteSet>,\n    specialize_start_states: Option<bool>,\n    cache_capacity: Option<usize>,\n    skip_cache_capacity_check: Option<bool>,\n    minimum_cache_clear_count: Option<Option<usize>>,\n    minimum_bytes_per_state: Option<Option<usize>>,\n}\n#[derive(Clone, Debug, Eq, PartialEq)]\npub struct MatchError(\n    #[cfg(feature = \"alloc\")]\n    alloc::boxed::Box<MatchErrorKind>,\n    #[cfg(not(feature = \"alloc\"))]\n    MatchErrorKind,\n);\n#[derive(Clone, Debug, Default)]\npub struct Config {\n    match_kind: Option<MatchKind>,\n    pre: Option<Option<Prefilter>>,\n}\n#[derive(Clone, Debug, Default)]\npub struct Config {\n    match_kind: Option<MatchKind>,\n    starts_for_each_pattern: Option<bool>,\n    byte_classes: Option<bool>,\n    size_limit: Option<Option<usize>>,\n}\n#[derive(Clone, Copy, Debug, Eq, Hash, PartialEq)]\npub struct HalfMatch {\n    /// The pattern ID.\n    pattern: PatternID,\n    /// The offset of the match.\n    ///\n    /// For forward searches, the offset is exclusive. For reverse searches,\n    /// the offset is inclusive.\n    offset: usize,\n}\n#[derive(Clone, Debug)]\npub(crate) struct Config {\n    match_kind: MatchKind,\n    quit: ByteSet,\n    dfa_size_limit: Option<usize>,\n    determinize_size_limit: Option<usize>,\n}\n#[derive(Clone, Copy, Eq, Hash, PartialEq, PartialOrd, Ord)]\n#[repr(transparent)]\npub struct NonMaxUsize(NonZeroUsize);\n#[cfg(feature = \"dfa-build\")]\n#[derive(Clone, Debug, Default)]\npub struct Config {\n    accelerate: Option<bool>,\n    pre: Option<Option<Prefilter>>,\n    minimize: Option<bool>,\n    match_kind: Option<MatchKind>,\n    start_kind: Option<StartKind>,\n    starts_for_each_pattern: Option<bool>,\n    byte_classes: Option<bool>,\n    unicode_word_boundary: Option<bool>,\n    quitset: Option<ByteSet>,\n    specialize_start_states: Option<bool>,\n    dfa_size_limit: Option<Option<usize>>,\n    determinize_size_limit: Option<Option<usize>>,\n}\n#[derive(Clone, Debug, Default)]\npub struct Config {\n    utf8: Option<bool>,\n    reverse: Option<bool>,\n    nfa_size_limit: Option<Option<usize>>,\n    shrink: Option<bool>,\n    which_captures: Option<WhichCaptures>,\n    look_matcher: Option<LookMatcher>,\n    #[cfg(test)]\n    unanchored_prefix: Option<bool>,\n}\n#[derive(Clone, Debug, Default)]\npub struct Config {\n    match_kind: Option<MatchKind>,\n    utf8_empty: Option<bool>,\n    autopre: Option<bool>,\n    pre: Option<Option<Prefilter>>,\n    which_captures: Option<WhichCaptures>,\n    nfa_size_limit: Option<Option<usize>>,\n    onepass_size_limit: Option<Option<usize>>,\n    hybrid_cache_capacity: Option<usize>,\n    hybrid: Option<bool>,\n    dfa: Option<bool>,\n    dfa_size_limit: Option<Option<usize>>,\n    dfa_state_limit: Option<Option<usize>>,\n    onepass: Option<bool>,\n    backtrack: Option<bool>,\n    byte_classes: Option<bool>,\n    line_terminator: Option<u8>,\n}\n#[derive(Clone, Copy, Default, Eq, Hash, PartialEq, PartialOrd, Ord)]\n#[repr(transparent)]\npub struct StateID(SmallIndex);\n#[derive(Clone, Copy, Debug, Eq, PartialEq)]\npub enum Anchored {\n    /// Run an unanchored search. This means a match may occur anywhere at or\n    /// after the start position of the search.\n    ///\n    /// This search can return a match for any pattern in the regex.\n    No,\n    /// Run an anchored search. This means that a match must begin at the\n    /// start position of the search.\n    ///\n    /// This search can return a match for any pattern in the regex.\n    Yes,\n    /// Run an anchored search for a specific pattern. This means that a match\n    /// must be for the given pattern and must begin at the start position of\n    /// the search.\n    Pattern(PatternID),\n}\nimpl BoundedBacktracker {\n    #[inline]\n    pub fn try_search(\n        &self,\n        cache: &mut Cache,\n        input: &Input<'_>,\n        caps: &mut Captures,\n    ) -> Result<(), MatchError> {}\n    #[inline]\n    pub fn try_search_slots(\n        &self,\n        cache: &mut Cache,\n        input: &Input<'_>,\n        slots: &mut [Option<NonMaxUsize>],\n    ) -> Result<Option<PatternID>, MatchError> {}\n    #[inline(never)]\n    fn try_search_slots_imp(\n        &self,\n        cache: &mut Cache,\n        input: &Input<'_>,\n        slots: &mut [Option<NonMaxUsize>],\n    ) -> Result<Option<HalfMatch>, MatchError> {}\n    fn search_imp(\n        &self,\n        cache: &mut Cache,\n        input: &Input<'_>,\n        slots: &mut [Option<NonMaxUsize>],\n    ) -> Result<Option<HalfMatch>, MatchError> {\n        for slot in slots.iter_mut() {\n            *slot = None;\n        }\n        cache.setup_search(&self, input)?;\n        if input.is_done() {\n            return Ok(None);\n        }\n        let (anchored, start_id) = match input.get_anchored() {\n            Anchored::No => {\n                (self.nfa.is_always_start_anchored(), self.nfa.start_anchored())\n            }\n            Anchored::Yes => (true, self.nfa.start_anchored()),\n            Anchored::Pattern(pid) => {\n                match self.nfa.start_pattern(pid) {\n                    None => return Ok(None),\n                    Some(sid) => (true, sid),\n                }\n            }\n        };\n        if anchored {\n            let at = input.start();\n            return Ok(self.backtrack(cache, input, at, start_id, slots));\n        }\n        let pre = self.get_config().get_prefilter();\n        let mut at = input.start();\n        while at <= input.end() {\n            if let Some(ref pre) = pre {\n                let span = Span::from(at..input.end());\n                match pre.find(input.haystack(), span) {\n                    None => break,\n                    Some(ref span) => at = span.start,\n                }\n            }\n            if let Some(hm) = self.backtrack(cache, input, at, start_id, slots) {\n                return Ok(Some(hm));\n            }\n            at += 1;\n        }\n        Ok(None)\n    }\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    fn backtrack(\n        &self,\n        cache: &mut Cache,\n        input: &Input<'_>,\n        at: usize,\n        start_id: StateID,\n        slots: &mut [Option<NonMaxUsize>],\n    ) -> Option<HalfMatch> {\n        cache.stack.push(Frame::Step { sid: start_id, at });\n        while let Some(frame) = cache.stack.pop() {\n            match frame {\n                Frame::Step { sid, at } => {\n                    if let Some(hm) = self.step(cache, input, sid, at, slots) {\n                        return Some(hm);\n                    }\n                }\n                Frame::RestoreCapture { slot, offset } => {\n                    slots[slot] = offset;\n                }\n            }\n        }\n        None\n    }\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    fn step(\n        &self,\n        cache: &mut Cache,\n        input: &Input<'_>,\n        mut sid: StateID,\n        mut at: usize,\n        slots: &mut [Option<NonMaxUsize>],\n    ) -> Option<HalfMatch> {}\n}\nimpl NFA {\n    #[cfg(feature = \"syntax\")]\n    pub fn new(pattern: &str) -> Result<NFA, BuildError> {}\n    #[cfg(feature = \"syntax\")]\n    pub fn new_many<P: AsRef<str>>(patterns: &[P]) -> Result<NFA, BuildError> {}\n    pub fn always_match() -> NFA {}\n    pub fn never_match() -> NFA {}\n    #[cfg(feature = \"syntax\")]\n    pub fn config() -> Config {}\n    #[cfg(feature = \"syntax\")]\n    pub fn compiler() -> Compiler {}\n    pub fn patterns(&self) -> PatternIter<'_> {}\n    #[inline]\n    pub fn pattern_len(&self) -> usize {}\n    #[inline]\n    pub fn start_anchored(&self) -> StateID {\n        self.0.start_anchored\n    }\n    #[inline]\n    pub fn start_unanchored(&self) -> StateID {}\n    #[inline]\n    pub fn start_pattern(&self, pid: PatternID) -> Option<StateID> {\n        self.0.start_pattern.get(pid.as_usize()).copied()\n    }\n    #[inline]\n    pub(crate) fn byte_class_set(&self) -> &ByteClassSet {}\n    #[inline]\n    pub fn byte_classes(&self) -> &ByteClasses {}\n    #[inline]\n    pub fn state(&self, id: StateID) -> &State {}\n    #[inline]\n    pub fn states(&self) -> &[State] {}\n    #[inline]\n    pub fn group_info(&self) -> &GroupInfo {}\n    #[inline]\n    pub fn has_capture(&self) -> bool {}\n    #[inline]\n    pub fn has_empty(&self) -> bool {}\n    #[inline]\n    pub fn is_utf8(&self) -> bool {}\n    #[inline]\n    pub fn is_reverse(&self) -> bool {}\n    #[inline]\n    pub fn is_always_start_anchored(&self) -> bool {\n        self.start_anchored() == self.start_unanchored()\n    }\n    #[inline]\n    pub fn look_matcher(&self) -> &LookMatcher {}\n    #[inline]\n    pub fn look_set_any(&self) -> LookSet {}\n    #[inline]\n    pub fn look_set_prefix_any(&self) -> LookSet {}\n    #[inline]\n    pub fn memory_usage(&self) -> usize {}\n}\nimpl<'h> Input<'h> {\n    #[inline]\n    pub fn new<H: ?Sized + AsRef<[u8]>>(haystack: &'h H) -> Input<'h> {}\n    #[inline]\n    pub fn span<S: Into<Span>>(mut self, span: S) -> Input<'h> {}\n    #[inline]\n    pub fn range<R: RangeBounds<usize>>(mut self, range: R) -> Input<'h> {}\n    #[inline]\n    pub fn anchored(mut self, mode: Anchored) -> Input<'h> {}\n    #[inline]\n    pub fn earliest(mut self, yes: bool) -> Input<'h> {}\n    #[inline]\n    pub fn set_span<S: Into<Span>>(&mut self, span: S) {}\n    #[inline]\n    pub fn set_range<R: RangeBounds<usize>>(&mut self, range: R) {}\n    #[inline]\n    pub fn set_start(&mut self, start: usize) {}\n    #[inline]\n    pub fn set_end(&mut self, end: usize) {}\n    #[inline]\n    pub fn set_anchored(&mut self, mode: Anchored) {}\n    #[inline]\n    pub fn set_earliest(&mut self, yes: bool) {}\n    #[inline]\n    pub fn haystack(&self) -> &[u8] {\n        self.haystack\n    }\n    #[inline]\n    pub fn start(&self) -> usize {\n        self.get_span().start\n    }\n    #[inline]\n    pub fn end(&self) -> usize {\n        self.get_span().end\n    }\n    #[inline]\n    pub fn get_span(&self) -> Span {}\n    #[inline]\n    pub fn get_range(&self) -> Range<usize> {}\n    #[inline]\n    pub fn get_anchored(&self) -> Anchored {\n        self.anchored\n    }\n    #[inline]\n    pub fn get_earliest(&self) -> bool {}\n    #[inline]\n    pub fn is_done(&self) -> bool {\n        self.get_span().start > self.get_span().end\n    }\n    #[inline]\n    pub fn is_char_boundary(&self, offset: usize) -> bool {}\n}\nimpl Cache {\n    pub fn new(re: &BoundedBacktracker) -> Cache {}\n    pub fn reset(&mut self, re: &BoundedBacktracker) {}\n    pub fn memory_usage(&self) -> usize {}\n    fn setup_search(\n        &mut self,\n        re: &BoundedBacktracker,\n        input: &Input<'_>,\n    ) -> Result<(), MatchError> {\n        self.stack.clear();\n        self.visited.setup_search(re, input)?;\n        Ok(())\n    }\n}\nimpl Prefilter {\n    pub fn new<B: AsRef<[u8]>>(kind: MatchKind, needles: &[B]) -> Option<Prefilter> {}\n    fn from_choice(choice: Choice, max_needle_len: usize) -> Option<Prefilter> {}\n    #[cfg(feature = \"syntax\")]\n    pub fn from_hir_prefix(kind: MatchKind, hir: &Hir) -> Option<Prefilter> {}\n    #[cfg(feature = \"syntax\")]\n    pub fn from_hirs_prefix<H: Borrow<Hir>>(\n        kind: MatchKind,\n        hirs: &[H],\n    ) -> Option<Prefilter> {}\n    #[inline]\n    pub fn find(&self, haystack: &[u8], span: Span) -> Option<Span> {\n        #[cfg(not(feature = \"alloc\"))] { unreachable!() }\n        #[cfg(feature = \"alloc\")] { self.pre.find(haystack, span) }\n    }\n    #[inline]\n    pub fn prefix(&self, haystack: &[u8], span: Span) -> Option<Span> {}\n    #[inline]\n    pub fn memory_usage(&self) -> usize {}\n    #[inline]\n    pub fn max_needle_len(&self) -> usize {}\n    #[inline]\n    pub fn is_fast(&self) -> bool {}\n}\nimpl Config {\n    pub fn new() -> Config {}\n    pub fn prefilter(mut self, pre: Option<Prefilter>) -> Config {}\n    pub fn visited_capacity(mut self, capacity: usize) -> Config {}\n    pub fn get_prefilter(&self) -> Option<&Prefilter> {\n        self.pre.as_ref().unwrap_or(&None).as_ref()\n    }\n    pub fn get_visited_capacity(&self) -> usize {}\n    pub(crate) fn overwrite(&self, o: Config) -> Config {}\n}\n\nThe function to be tested is presented with each line formatted as 'line number + code':\n/// The implementation of standard leftmost backtracking search.\n///\n/// Capturing group spans are written to 'caps', but only if requested.\n/// 'caps' can be one of three things: 1) totally empty, in which case, we\n/// only report the pattern that matched or 2) only has slots for recording\n/// the overall match offsets for any pattern or 3) has all slots available\n/// for recording the spans of any groups participating in a match.\n1357 fn search_imp(\n1358     &self,\n1359     cache: &mut Cache,\n1360     input: &Input<'_>,\n1361     slots: &mut [Option<NonMaxUsize>],\n1362 ) -> Result<Option<HalfMatch>, MatchError> {\n1363     // Unlike in the PikeVM, we write our capturing group spans directly\n1364     // into the caller's captures groups. So we have to make sure we're\n1365     // starting with a blank slate first. In the PikeVM, we avoid this\n1366     // by construction: the spans that are copied to every slot in the\n1367     // 'Captures' value already account for presence/absence. In this\n1368     // backtracker, we write directly into the caller provided slots, where\n1369     // as in the PikeVM, we write into scratch space first and only copy\n1370     // them to the caller provided slots when a match is found.\n1371     for slot in slots.iter_mut() {\n1372         *slot = None;\n1373     }\n1374     cache.setup_search(&self, input)?;\n1375     if input.is_done() {\n1376         return Ok(None);\n1377     }\n1378     let (anchored, start_id) = match input.get_anchored() {\n1379         // Only way we're unanchored is if both the caller asked for an\n1380         // unanchored search *and* the pattern is itself not anchored.\n1381         Anchored::No => (\n1382             self.nfa.is_always_start_anchored(),\n1383             // We always use the anchored starting state here, even if\n1384             // doing an unanchored search. The \"unanchored\" part of it is\n1385             // implemented in the loop below, by simply trying the next\n1386             // byte offset if the previous backtracking exploration failed.\n1387             self.nfa.start_anchored(),\n1388         ),\n1389         Anchored::Yes => (true, self.nfa.start_anchored()),\n1390         Anchored::Pattern(pid) => match self.nfa.start_pattern(pid) {\n1391             None => return Ok(None),\n1392             Some(sid) => (true, sid),\n1393         },\n1394     };\n1395     if anchored {\n1396         let at = input.start();\n1397         return Ok(self.backtrack(cache, input, at, start_id, slots));\n1398     }\n1399     let pre = self.get_config().get_prefilter();\n1400     let mut at = input.start();\n1401     while at <= input.end() {\n1402         if let Some(ref pre) = pre {\n1403             let span = Span::from(at..input.end());\n1404             match pre.find(input.haystack(), span) {\n1405                 None => break,\n1406                 Some(ref span) => at = span.start,\n1407             }\n1408         }\n1409         if let Some(hm) = self.backtrack(cache, input, at, start_id, slots)\n1410         {\n1411             return Ok(Some(hm));\n1412         }\n1413         at += 1;\n1414     }\n1415     Ok(None)\n1416 }\n\nThe path conditions that the generated test functions should satisfy are as follows:\n"
}