{
  "system_pt": "As a software testing expert, infer the test input conditions or ranges based on the provided information. Follow these guidelines:\n1. Provide test input conditions or ranges in one line in plain text only, without additional explanations or Markdown formatting\n2. Analyze the function under test, context, preconditions, and expected return values or types to determine appropriate test input conditions or ranges\n3. The inferred test input conditions or ranges should comprehensively satisfy all provided preconditions simultaneously.\n4. Ensure the test input conditions or ranges cover boundary cases and edge scenarios\n",
  "static_pt": "The context for the focal function is as follows:\n// regex-automata/src/nfa/thompson/pikevm.rs\n// crate name is regex_automata\n#[cfg(feature = \"internal-instrument-pikevm\")]\nuse core::cell::RefCell;\nuse alloc::{vec, vec::Vec};\nuse crate::{\n    nfa::thompson::{self, BuildError, State, NFA},\n    util::{\n        captures::Captures, empty, iter, prefilter::Prefilter,\n        primitives::{NonMaxUsize, PatternID, SmallIndex, StateID},\n        search::{Anchored, HalfMatch, Input, Match, MatchKind, PatternSet, Span},\n        sparse_set::SparseSet,\n    },\n};\n#[derive(Clone, Debug)]\npub struct PikeVM {\n    config: Config,\n    nfa: NFA,\n}\n#[derive(Clone)]\npub(crate) struct SparseSet {\n    /// The number of elements currently in this set.\n    len: usize,\n    /// Dense contains the ids in the order in which they were inserted.\n    dense: Vec<StateID>,\n    /// Sparse maps ids to their location in dense.\n    ///\n    /// A state ID is in the set if and only if\n    /// sparse[id] < len && id == dense[sparse[id]].\n    ///\n    /// Note that these are indices into 'dense'. It's a little weird to use\n    /// StateID here, but we know our length can never exceed the bounds of\n    /// StateID (enforced by 'resize') and StateID will be at most 4 bytes\n    /// where as a usize is likely double that in most cases.\n    sparse: Vec<StateID>,\n}\n#[derive(Clone)]\npub struct Input<'h> {\n    haystack: &'h [u8],\n    span: Span,\n    anchored: Anchored,\n    earliest: bool,\n}\n#[derive(Clone, Debug, Default)]\npub struct Config {\n    match_kind: Option<MatchKind>,\n    pre: Option<Option<Prefilter>>,\n}\n#[derive(Clone, Debug)]\npub struct Prefilter {\n    #[cfg(not(feature = \"alloc\"))]\n    _unused: (),\n    #[cfg(feature = \"alloc\")]\n    pre: Arc<dyn PrefilterI>,\n    #[cfg(feature = \"alloc\")]\n    is_fast: bool,\n    #[cfg(feature = \"alloc\")]\n    max_needle_len: usize,\n}\n#[derive(Clone, Debug)]\nstruct SlotTable {\n    /// The actual table of offsets.\n    table: Vec<Option<NonMaxUsize>>,\n    /// The number of slots per state, i.e., the table's stride or the length\n    /// of each row.\n    slots_per_state: usize,\n    /// The number of slots in the caller-provided 'Captures' value for the\n    /// current search. Setting this to 'slots_per_state' is always correct,\n    /// but may be wasteful.\n    slots_for_captures: usize,\n}\n#[derive(Clone, Debug)]\npub struct Cache {\n    /// Stack used while computing epsilon closure. This effectively lets us\n    /// move what is more naturally expressed through recursion to a stack\n    /// on the heap.\n    stack: Vec<FollowEpsilon>,\n    /// The current active states being explored for the current byte in the\n    /// haystack.\n    curr: ActiveStates,\n    /// The next set of states we're building that will be explored for the\n    /// next byte in the haystack.\n    next: ActiveStates,\n}\n#[derive(Clone, Copy, Debug, Eq, Hash, PartialEq)]\npub struct HalfMatch {\n    /// The pattern ID.\n    pattern: PatternID,\n    /// The offset of the match.\n    ///\n    /// For forward searches, the offset is exclusive. For reverse searches,\n    /// the offset is inclusive.\n    offset: usize,\n}\n#[derive(Clone, Debug, Default)]\npub struct Config {\n    match_kind: Option<MatchKind>,\n    utf8_empty: Option<bool>,\n    autopre: Option<bool>,\n    pre: Option<Option<Prefilter>>,\n    which_captures: Option<WhichCaptures>,\n    nfa_size_limit: Option<Option<usize>>,\n    onepass_size_limit: Option<Option<usize>>,\n    hybrid_cache_capacity: Option<usize>,\n    hybrid: Option<bool>,\n    dfa: Option<bool>,\n    dfa_size_limit: Option<Option<usize>>,\n    dfa_state_limit: Option<Option<usize>>,\n    onepass: Option<bool>,\n    backtrack: Option<bool>,\n    byte_classes: Option<bool>,\n    line_terminator: Option<u8>,\n}\n#[derive(Clone, Debug)]\npub struct Config {\n    look_behind: Option<u8>,\n    anchored: Anchored,\n}\n#[cfg(feature = \"dfa-build\")]\n#[derive(Clone, Debug, Default)]\npub struct Config {\n    accelerate: Option<bool>,\n    pre: Option<Option<Prefilter>>,\n    minimize: Option<bool>,\n    match_kind: Option<MatchKind>,\n    start_kind: Option<StartKind>,\n    starts_for_each_pattern: Option<bool>,\n    byte_classes: Option<bool>,\n    unicode_word_boundary: Option<bool>,\n    quitset: Option<ByteSet>,\n    specialize_start_states: Option<bool>,\n    dfa_size_limit: Option<Option<usize>>,\n    determinize_size_limit: Option<Option<usize>>,\n}\n#[derive(Clone, Copy, Default, Eq, Hash, PartialEq, PartialOrd, Ord)]\n#[repr(transparent)]\npub struct PatternID(SmallIndex);\n#[derive(Clone, Copy, Eq, Hash, PartialEq, PartialOrd, Ord)]\n#[repr(transparent)]\npub struct NonMaxUsize(NonZeroUsize);\n#[derive(Clone)]\npub struct NFA(Arc<Inner>);\n#[derive(Clone, Copy, Debug)]\npub struct Config {\n    case_insensitive: bool,\n    multi_line: bool,\n    dot_matches_new_line: bool,\n    crlf: bool,\n    line_terminator: u8,\n    swap_greed: bool,\n    ignore_whitespace: bool,\n    unicode: bool,\n    utf8: bool,\n    nest_limit: u32,\n    octal: bool,\n}\n#[derive(Clone, Debug)]\npub(crate) struct Config {\n    match_kind: MatchKind,\n    quit: ByteSet,\n    dfa_size_limit: Option<usize>,\n    determinize_size_limit: Option<usize>,\n}\n#[derive(Clone, Debug, Default)]\npub struct Config {\n    utf8: Option<bool>,\n    reverse: Option<bool>,\n    nfa_size_limit: Option<Option<usize>>,\n    shrink: Option<bool>,\n    which_captures: Option<WhichCaptures>,\n    look_matcher: Option<LookMatcher>,\n    #[cfg(test)]\n    unanchored_prefix: Option<bool>,\n}\n#[derive(Clone, Copy, Eq, Hash, PartialEq)]\npub struct Span {\n    /// The start offset of the span, inclusive.\n    pub start: usize,\n    /// The end offset of the span, exclusive.\n    pub end: usize,\n}\n#[derive(Clone, Debug)]\nstruct ActiveStates {\n    /// The set of active NFA states. This set preserves insertion order, which\n    /// is critical for simulating the match semantics of backtracking regex\n    /// engines.\n    set: SparseSet,\n    /// The slots for every NFA state, where each slot stores a (possibly\n    /// absent) offset. Every capturing group has two slots. One for a start\n    /// offset and one for an end offset.\n    slot_table: SlotTable,\n}\n#[derive(Clone, Debug, Default)]\npub struct Config {\n    match_kind: Option<MatchKind>,\n    starts_for_each_pattern: Option<bool>,\n    byte_classes: Option<bool>,\n    size_limit: Option<Option<usize>>,\n}\n#[derive(Clone, Copy, Default, Eq, Hash, PartialEq, PartialOrd, Ord)]\n#[repr(transparent)]\npub struct StateID(SmallIndex);\n#[derive(Clone, Debug, Default)]\npub struct Config {\n    match_kind: Option<MatchKind>,\n    pre: Option<Option<Prefilter>>,\n    starts_for_each_pattern: Option<bool>,\n    byte_classes: Option<bool>,\n    unicode_word_boundary: Option<bool>,\n    quitset: Option<ByteSet>,\n    specialize_start_states: Option<bool>,\n    cache_capacity: Option<usize>,\n    skip_cache_capacity_check: Option<bool>,\n    minimum_cache_clear_count: Option<Option<usize>>,\n    minimum_bytes_per_state: Option<Option<usize>>,\n}\n#[derive(Clone, Debug, Default)]\npub struct Config {\n    pre: Option<Option<Prefilter>>,\n    visited_capacity: Option<usize>,\n}\n#[non_exhaustive]\n#[derive(Clone, Copy, Debug, Eq, PartialEq)]\npub enum MatchKind {\n    /// Report all possible matches.\n    All,\n    /// Report only the leftmost matches. When multiple leftmost matches exist,\n    /// report the match corresponding to the part of the regex that appears\n    /// first in the syntax.\n    LeftmostFirst,\n}\n#[derive(Clone, Debug)]\nenum FollowEpsilon {\n    /// Explore the epsilon transitions from a state ID.\n    Explore(StateID),\n    /// Reset the given `slot` to the given `offset` (which might be `None`).\n    RestoreCapture { slot: SmallIndex, offset: Option<NonMaxUsize> },\n}\nimpl PikeVM {\n    fn search_imp(\n        &self,\n        cache: &mut Cache,\n        input: &Input<'_>,\n        slots: &mut [Option<NonMaxUsize>],\n    ) -> Option<HalfMatch> {\n        cache.setup_search(slots.len());\n        if input.is_done() {\n            return None;\n        }\n        assert!(\n            input.haystack().len() < core::usize::MAX,\n            \"byte slice lengths must be less than usize MAX\",\n        );\n        instrument!(| c | c.reset(& self.nfa));\n        let allmatches = self.config.get_match_kind().continue_past_first_match();\n        let (anchored, start_id) = match self.start_config(input) {\n            None => return None,\n            Some(config) => config,\n        };\n        let pre = if anchored { None } else { self.get_config().get_prefilter() };\n        let Cache { ref mut stack, ref mut curr, ref mut next } = cache;\n        let mut hm = None;\n        let mut at = input.start();\n        while at <= input.end() {\n            if curr.set.is_empty() {\n                if hm.is_some() && !allmatches {\n                    break;\n                }\n                if anchored && at > input.start() {\n                    break;\n                }\n                if let Some(ref pre) = pre {\n                    let span = Span::from(at..input.end());\n                    match pre.find(input.haystack(), span) {\n                        None => break,\n                        Some(ref span) => at = span.start,\n                    }\n                }\n            }\n            if (!hm.is_some() || allmatches) && (!anchored || at == input.start()) {\n                let slots = next.slot_table.all_absent();\n                self.epsilon_closure(stack, slots, curr, input, at, start_id);\n            }\n            if let Some(pid) = self.nexts(stack, curr, next, input, at, slots) {\n                hm = Some(HalfMatch::new(pid, at));\n            }\n            if input.get_earliest() && hm.is_some() {\n                break;\n            }\n            core::mem::swap(curr, next);\n            next.set.clear();\n            at += 1;\n        }\n        instrument!(| c | c.eprint(& self.nfa));\n        hm\n    }\n    fn which_overlapping_imp(\n        &self,\n        cache: &mut Cache,\n        input: &Input<'_>,\n        patset: &mut PatternSet,\n    ) {}\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    fn nexts(\n        &self,\n        stack: &mut Vec<FollowEpsilon>,\n        curr: &mut ActiveStates,\n        next: &mut ActiveStates,\n        input: &Input<'_>,\n        at: usize,\n        slots: &mut [Option<NonMaxUsize>],\n    ) -> Option<PatternID> {\n        instrument!(| c | c.record_state_set(& curr.set));\n        let mut pid = None;\n        let ActiveStates { ref set, ref mut slot_table } = *curr;\n        for sid in set.iter() {\n            pid = match self.next(stack, slot_table, next, input, at, sid) {\n                None => continue,\n                Some(pid) => Some(pid),\n            };\n            slots.copy_from_slice(slot_table.for_state(sid));\n            if !self.config.get_match_kind().continue_past_first_match() {\n                break;\n            }\n        }\n        pid\n    }\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    fn nexts_overlapping(\n        &self,\n        stack: &mut Vec<FollowEpsilon>,\n        curr: &mut ActiveStates,\n        next: &mut ActiveStates,\n        input: &Input<'_>,\n        at: usize,\n        patset: &mut PatternSet,\n    ) {}\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    fn next(\n        &self,\n        stack: &mut Vec<FollowEpsilon>,\n        curr_slot_table: &mut SlotTable,\n        next: &mut ActiveStates,\n        input: &Input<'_>,\n        at: usize,\n        sid: StateID,\n    ) -> Option<PatternID> {}\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    fn epsilon_closure(\n        &self,\n        stack: &mut Vec<FollowEpsilon>,\n        curr_slots: &mut [Option<NonMaxUsize>],\n        next: &mut ActiveStates,\n        input: &Input<'_>,\n        at: usize,\n        sid: StateID,\n    ) {\n        instrument!(| c | { c.record_closure(sid); c.record_stack_push(sid); });\n        stack.push(FollowEpsilon::Explore(sid));\n        while let Some(frame) = stack.pop() {\n            match frame {\n                FollowEpsilon::RestoreCapture { slot, offset: pos } => {\n                    curr_slots[slot] = pos;\n                }\n                FollowEpsilon::Explore(sid) => {\n                    self.epsilon_closure_explore(\n                        stack,\n                        curr_slots,\n                        next,\n                        input,\n                        at,\n                        sid,\n                    );\n                }\n            }\n        }\n    }\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    fn epsilon_closure_explore(\n        &self,\n        stack: &mut Vec<FollowEpsilon>,\n        curr_slots: &mut [Option<NonMaxUsize>],\n        next: &mut ActiveStates,\n        input: &Input<'_>,\n        at: usize,\n        mut sid: StateID,\n    ) {}\n    fn start_config(&self, input: &Input<'_>) -> Option<(bool, StateID)> {\n        match input.get_anchored() {\n            Anchored::No => {\n                Some((self.nfa.is_always_start_anchored(), self.nfa.start_anchored()))\n            }\n            Anchored::Yes => Some((true, self.nfa.start_anchored())),\n            Anchored::Pattern(pid) => Some((true, self.nfa.start_pattern(pid)?)),\n        }\n    }\n}\nimpl SparseSet {\n    #[inline]\n    pub(crate) fn new(capacity: usize) -> SparseSet {}\n    #[inline]\n    pub(crate) fn resize(&mut self, new_capacity: usize) {}\n    #[inline]\n    pub(crate) fn capacity(&self) -> usize {}\n    #[inline]\n    pub(crate) fn len(&self) -> usize {}\n    #[inline]\n    pub(crate) fn is_empty(&self) -> bool {\n        self.len() == 0\n    }\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    pub(crate) fn insert(&mut self, id: StateID) -> bool {}\n    #[inline]\n    pub(crate) fn contains(&self, id: StateID) -> bool {}\n    #[inline]\n    pub(crate) fn clear(&mut self) {\n        self.len = 0;\n    }\n    #[inline]\n    pub(crate) fn iter(&self) -> SparseSetIter<'_> {}\n    #[inline]\n    pub(crate) fn memory_usage(&self) -> usize {}\n}\nimpl<'h> Input<'h> {\n    #[inline]\n    pub fn new<H: ?Sized + AsRef<[u8]>>(haystack: &'h H) -> Input<'h> {}\n    #[inline]\n    pub fn span<S: Into<Span>>(mut self, span: S) -> Input<'h> {}\n    #[inline]\n    pub fn range<R: RangeBounds<usize>>(mut self, range: R) -> Input<'h> {}\n    #[inline]\n    pub fn anchored(mut self, mode: Anchored) -> Input<'h> {}\n    #[inline]\n    pub fn earliest(mut self, yes: bool) -> Input<'h> {}\n    #[inline]\n    pub fn set_span<S: Into<Span>>(&mut self, span: S) {}\n    #[inline]\n    pub fn set_range<R: RangeBounds<usize>>(&mut self, range: R) {}\n    #[inline]\n    pub fn set_start(&mut self, start: usize) {}\n    #[inline]\n    pub fn set_end(&mut self, end: usize) {}\n    #[inline]\n    pub fn set_anchored(&mut self, mode: Anchored) {}\n    #[inline]\n    pub fn set_earliest(&mut self, yes: bool) {}\n    #[inline]\n    pub fn haystack(&self) -> &[u8] {\n        self.haystack\n    }\n    #[inline]\n    pub fn start(&self) -> usize {\n        self.get_span().start\n    }\n    #[inline]\n    pub fn end(&self) -> usize {\n        self.get_span().end\n    }\n    #[inline]\n    pub fn get_span(&self) -> Span {}\n    #[inline]\n    pub fn get_range(&self) -> Range<usize> {}\n    #[inline]\n    pub fn get_anchored(&self) -> Anchored {}\n    #[inline]\n    pub fn get_earliest(&self) -> bool {\n        self.earliest\n    }\n    #[inline]\n    pub fn is_done(&self) -> bool {\n        self.get_span().start > self.get_span().end\n    }\n    #[inline]\n    pub fn is_char_boundary(&self, offset: usize) -> bool {}\n}\nimpl Config {\n    pub fn new() -> Config {}\n    pub fn match_kind(mut self, kind: MatchKind) -> Config {}\n    pub fn prefilter(mut self, pre: Option<Prefilter>) -> Config {}\n    pub fn get_match_kind(&self) -> MatchKind {\n        self.match_kind.unwrap_or(MatchKind::LeftmostFirst)\n    }\n    pub fn get_prefilter(&self) -> Option<&Prefilter> {\n        self.pre.as_ref().unwrap_or(&None).as_ref()\n    }\n    pub(crate) fn overwrite(&self, o: Config) -> Config {}\n}\nimpl Prefilter {\n    pub fn new<B: AsRef<[u8]>>(kind: MatchKind, needles: &[B]) -> Option<Prefilter> {}\n    fn from_choice(choice: Choice, max_needle_len: usize) -> Option<Prefilter> {}\n    #[cfg(feature = \"syntax\")]\n    pub fn from_hir_prefix(kind: MatchKind, hir: &Hir) -> Option<Prefilter> {}\n    #[cfg(feature = \"syntax\")]\n    pub fn from_hirs_prefix<H: Borrow<Hir>>(\n        kind: MatchKind,\n        hirs: &[H],\n    ) -> Option<Prefilter> {}\n    #[inline]\n    pub fn find(&self, haystack: &[u8], span: Span) -> Option<Span> {\n        #[cfg(not(feature = \"alloc\"))] { unreachable!() }\n        #[cfg(feature = \"alloc\")] { self.pre.find(haystack, span) }\n    }\n    #[inline]\n    pub fn prefix(&self, haystack: &[u8], span: Span) -> Option<Span> {}\n    #[inline]\n    pub fn memory_usage(&self) -> usize {}\n    #[inline]\n    pub fn max_needle_len(&self) -> usize {}\n    #[inline]\n    pub fn is_fast(&self) -> bool {}\n}\nimpl SlotTable {\n    fn new() -> SlotTable {}\n    fn reset(&mut self, re: &PikeVM) {}\n    fn memory_usage(&self) -> usize {}\n    fn setup_search(&mut self, captures_slot_len: usize) {}\n    fn for_state(&mut self, sid: StateID) -> &mut [Option<NonMaxUsize>] {}\n    fn all_absent(&mut self) -> &mut [Option<NonMaxUsize>] {\n        let i = self.table.len() - self.slots_for_captures;\n        &mut self.table[i..i + self.slots_for_captures]\n    }\n}\nimpl Cache {\n    pub fn new(re: &PikeVM) -> Cache {}\n    pub fn reset(&mut self, re: &PikeVM) {}\n    pub fn memory_usage(&self) -> usize {}\n    fn setup_search(&mut self, captures_slot_len: usize) {\n        self.stack.clear();\n        self.curr.setup_search(captures_slot_len);\n        self.next.setup_search(captures_slot_len);\n    }\n}\nimpl MatchKind {\n    #[cfg(feature = \"alloc\")]\n    pub(crate) fn continue_past_first_match(&self) -> bool {\n        *self == MatchKind::All\n    }\n}\nimpl HalfMatch {\n    #[inline]\n    pub fn new(pattern: PatternID, offset: usize) -> HalfMatch {\n        HalfMatch { pattern, offset }\n    }\n    #[inline]\n    pub fn must(pattern: usize, offset: usize) -> HalfMatch {}\n    #[inline]\n    pub fn pattern(&self) -> PatternID {}\n    #[inline]\n    pub fn offset(&self) -> usize {}\n}\n\nThe function to be tested is presented with each line formatted as 'line number + code':\n/// The implementation of standard leftmost search.\n///\n/// Capturing group spans are written to `slots`, but only if requested.\n/// `slots` can be any length. Any slot in the NFA that is activated but\n/// which is out of bounds for the given `slots` is ignored.\n1224 fn search_imp(\n1225     &self,\n1226     cache: &mut Cache,\n1227     input: &Input<'_>,\n1228     slots: &mut [Option<NonMaxUsize>],\n1229 ) -> Option<HalfMatch> {\n1230     cache.setup_search(slots.len());\n1231     if input.is_done() {\n1232         return None;\n1233     }\n1234     // Why do we even care about this? Well, in our 'Captures'\n1235     // representation, we use usize::MAX as a sentinel to indicate \"no\n1236     // match.\" This isn't problematic so long as our haystack doesn't have\n1237     // a maximal length. Byte slices are guaranteed by Rust to have a\n1238     // length that fits into isize, and so this assert should always pass.\n1239     // But we put it here to make our assumption explicit.\n1240     assert!(\n1241         input.haystack().len() < core::usize::MAX,\n1242         \"byte slice lengths must be less than usize MAX\",\n1243     );\n1244     instrument!(|c| c.reset(&self.nfa));\n1245 \n1246     // Whether we want to visit all match states instead of emulating the\n1247     // 'leftmost' semantics of typical backtracking regex engines.\n1248     let allmatches =\n1249         self.config.get_match_kind().continue_past_first_match();\n1250     let (anchored, start_id) = match self.start_config(input) {\n1251         None => return None,\n1252         Some(config) => config,\n1253     };\n1254 \n1255     let pre =\n1256         if anchored { None } else { self.get_config().get_prefilter() };\n1257     let Cache { ref mut stack, ref mut curr, ref mut next } = cache;\n1258     let mut hm = None;\n1259     // Yes, our search doesn't end at input.end(), but includes it. This\n1260     // is necessary because matches are delayed by one byte, just like\n1261     // how the DFA engines work. The delay is used to handle look-behind\n1262     // assertions. In the case of the PikeVM, the delay is implemented\n1263     // by not considering a match to exist until it is visited in\n1264     // 'steps'. Technically, we know a match exists in the previous\n1265     // iteration via 'epsilon_closure'. (It's the same thing in NFA-to-DFA\n1266     // determinization. We don't mark a DFA state as a match state if it\n1267     // contains an NFA match state, but rather, whether the DFA state was\n1268     // generated by a transition from a DFA state that contains an NFA\n1269     // match state.)\n1270     let mut at = input.start();\n1271     while at <= input.end() {\n1272         // If we have no states left to visit, then there are some cases\n1273         // where we know we can quit early or even skip ahead.\n1274         if curr.set.is_empty() {\n1275             // We have a match and we haven't been instructed to continue\n1276             // on even after finding a match, so we can quit.\n1277             if hm.is_some() && !allmatches {\n1278                 break;\n1279             }\n1280             // If we're running an anchored search and we've advanced\n1281             // beyond the start position with no other states to try, then\n1282             // we will never observe a match and thus can stop.\n1283             if anchored && at > input.start() {\n1284                 break;\n1285             }\n1286             // If there no states left to explore at this position and we\n1287             // know we can't terminate early, then we are effectively at\n1288             // the starting state of the NFA. If we fell through here,\n1289             // we'd end up adding our '(?s-u:.)*?' prefix and it would be\n1290             // the only thing in 'curr'. So we might as well just skip\n1291             // ahead until we find something that we know might advance us\n1292             // forward.\n1293             if let Some(ref pre) = pre {\n1294                 let span = Span::from(at..input.end());\n1295                 match pre.find(input.haystack(), span) {\n1296                     None => break,\n1297                     Some(ref span) => at = span.start,\n1298                 }\n1299             }\n1300         }\n1301         // Instead of using the NFA's unanchored start state, we actually\n1302         // always use its anchored starting state. As a result, when doing\n1303         // an unanchored search, we need to simulate our own '(?s-u:.)*?'\n1304         // prefix, to permit a match to appear anywhere.\n1305         //\n1306         // Now, we don't *have* to do things this way. We could use the\n1307         // NFA's unanchored starting state and do one 'epsilon_closure'\n1308         // call from that starting state before the main loop here. And\n1309         // that is just as correct. However, it turns out to be slower\n1310         // than our approach here because it slightly increases the cost\n1311         // of processing each byte by requiring us to visit more NFA\n1312         // states to deal with the additional NFA states in the unanchored\n1313         // prefix. By simulating it explicitly here, we lower those costs\n1314         // substantially. The cost is itself small, but it adds up for\n1315         // large haystacks.\n1316         //\n1317         // In order to simulate the '(?s-u:.)*?' prefix---which is not\n1318         // greedy---we are careful not to perform an epsilon closure on\n1319         // the start state if we already have a match. Namely, if we\n1320         // did otherwise, we would never reach a terminating condition\n1321         // because there would always be additional states to process.\n1322         // In effect, the exclusion of running 'epsilon_closure' when\n1323         // we have a match corresponds to the \"dead\" states we have in\n1324         // our DFA regex engines. Namely, in a DFA, match states merely\n1325         // instruct the search execution to record the current offset as\n1326         // the most recently seen match. It is the dead state that actually\n1327         // indicates when to stop the search (other than EOF or quit\n1328         // states).\n1329         //\n1330         // However, when 'allmatches' is true, the caller has asked us to\n1331         // leave in every possible match state. This tends not to make a\n1332         // whole lot of sense in unanchored searches, because it means the\n1333         // search really cannot terminate until EOF. And often, in that\n1334         // case, you wind up skipping over a bunch of matches and are left\n1335         // with the \"last\" match. Arguably, it just doesn't make a lot of\n1336         // sense to run a 'leftmost' search (which is what this routine is)\n1337         // with 'allmatches' set to true. But the DFAs support it and this\n1338         // matches their behavior. (Generally, 'allmatches' is useful for\n1339         // overlapping searches or leftmost anchored searches to find the\n1340         // longest possible match by ignoring match priority.)\n1341         //\n1342         // Additionally, when we're running an anchored search, this\n1343         // epsilon closure should only be computed at the beginning of the\n1344         // search. If we re-computed it at every position, we would be\n1345         // simulating an unanchored search when we were tasked to perform\n1346         // an anchored search.\n1347         if (!hm.is_some() || allmatches)\n1348             && (!anchored || at == input.start())\n1349         {\n1350             // Since we are adding to the 'curr' active states and since\n1351             // this is for the start ID, we use a slots slice that is\n1352             // guaranteed to have the right length but where every element\n1353             // is absent. This is exactly what we want, because this\n1354             // epsilon closure is responsible for simulating an unanchored\n1355             // '(?s:.)*?' prefix. It is specifically outside of any\n1356             // capturing groups, and thus, using slots that are always\n1357             // absent is correct.\n1358             //\n1359             // Note though that we can't just use '&mut []' here, since\n1360             // this epsilon closure may traverse through 'Captures' epsilon\n1361             // transitions, and thus must be able to write offsets to the\n1362             // slots given which are later copied to slot values in 'curr'.\n1363             let slots = next.slot_table.all_absent();\n1364             self.epsilon_closure(stack, slots, curr, input, at, start_id);\n1365         }\n1366         if let Some(pid) = self.nexts(stack, curr, next, input, at, slots)\n1367         {\n1368             hm = Some(HalfMatch::new(pid, at));\n1369         }\n1370         // Unless the caller asked us to return early, we need to mush on\n1371         // to see if we can extend our match. (But note that 'nexts' will\n1372         // quit right after seeing a match when match_kind==LeftmostFirst,\n1373         // as is consistent with leftmost-first match priority.)\n1374         if input.get_earliest() && hm.is_some() {\n1375             break;\n1376         }\n1377         core::mem::swap(curr, next);\n1378         next.set.clear();\n1379         at += 1;\n1380     }\n1381     instrument!(|c| c.eprint(&self.nfa));\n1382     hm\n1383 }\n\nWhen inferring test input conditions or ranges, consider the following preconditions and expected return values or types:\n"
}