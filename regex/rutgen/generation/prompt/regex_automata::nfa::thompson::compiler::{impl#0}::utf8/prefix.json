{
  "system_pt": "As a software testing expert, please generate Rust test functions based on the following guidelines, focusing solely on constructing test inputs and calling the functions under test:\n1. Provide the code in plain text format, without explanations or Markdown.\n2. If the method under test belongs to a trait, construct appropriate structs within the test function, but avoid method overrides. If the method under test uses generics, instantiate them with suitable types based on the context.\n3. Generate test code with minimal scope: avoid creating external structures or implementations. Instead, define any necessary helper structures or implementations directly within the test function when required.\n4. Whenever possible, initialize the corresponding data structures using the initialization methods provided in the context.\n5. Ensure the generated function is fully implemented and can be compiled and executed directly without any missing parts.\n6. Create a minimal yet complete set of test functions, ensuring they adhere to all provided preconditions and cover boundary conditions, and reference the inferred test input conditions or ranges.\n7. Ensure the test inputs are designed to cover the inferred test input conditions or ranges as comprehensively as possible, with particular emphasis on boundary cases.\n8. Focus on crafting test inputs that effectively reveal potential bugs while meeting the specified requirements.\n9. Omit test oracles and assertions; concentrate on generating test inputs and function calls.\n10. Do not create a test module, but include intrinsic attributes like #[test] or #[should_panic] where necessary.\n",
  "static_pt": "The context for the focal function is as follows:\n// regex-automata/src/nfa/thompson/compiler.rs\n// crate name is regex_automata\nuse core::{borrow::Borrow, cell::RefCell};\nuse alloc::{sync::Arc, vec, vec::Vec};\nuse regex_syntax::{\n    hir::{self, Hir},\n    utf8::{Utf8Range, Utf8Sequences},\n    ParserBuilder,\n};\nuse crate::{\n    nfa::thompson::{\n        builder::Builder, error::BuildError, literal_trie::LiteralTrie,\n        map::{Utf8BoundedMap, Utf8SuffixKey, Utf8SuffixMap},\n        nfa::{Transition, NFA},\n        range_trie::RangeTrie,\n    },\n    util::{\n        look::{Look, LookMatcher},\n        primitives::{PatternID, StateID},\n    },\n};\n#[derive(Clone, Debug, Default)]\npub struct Config {\n    utf8: Option<bool>,\n    reverse: Option<bool>,\n    nfa_size_limit: Option<Option<usize>>,\n    shrink: Option<bool>,\n    which_captures: Option<WhichCaptures>,\n    look_matcher: Option<LookMatcher>,\n    #[cfg(test)]\n    unanchored_prefix: Option<bool>,\n}\n#[derive(Clone, Debug)]\npub struct LookMatcher {\n    lineterm: DebugByte,\n}\n#[derive(Clone, Copy, Debug)]\npub enum WhichCaptures {\n    /// All capture states, including those corresponding to both implicit and\n    /// explicit capture groups, are included in the Thompson NFA.\n    All,\n    /// Only capture states corresponding to implicit capture groups are\n    /// included. Implicit capture groups appear in every pattern implicitly\n    /// and correspond to the overall match of a pattern.\n    ///\n    /// This is useful when one only cares about the overall match of a\n    /// pattern. By excluding capture states from explicit capture groups,\n    /// one might be able to reduce the memory usage of a multi-pattern regex\n    /// substantially if it was otherwise written to have many explicit capture\n    /// groups.\n    Implicit,\n    /// No capture states are compiled into the Thompson NFA.\n    ///\n    /// This is useful when capture states are either not needed (for example,\n    /// if one is only trying to build a DFA) or if they aren't supported (for\n    /// example, a reverse NFA).\n    None,\n}\nimpl Config {\n    pub fn new() -> Config {}\n    pub fn utf8(mut self, yes: bool) -> Config {\n        self.utf8 = Some(yes);\n        self\n    }\n    pub fn reverse(mut self, yes: bool) -> Config {}\n    pub fn nfa_size_limit(mut self, bytes: Option<usize>) -> Config {}\n    pub fn shrink(mut self, yes: bool) -> Config {}\n    #[deprecated(since = \"0.3.5\", note = \"use which_captures instead\")]\n    pub fn captures(self, yes: bool) -> Config {}\n    pub fn which_captures(mut self, which_captures: WhichCaptures) -> Config {}\n    pub fn look_matcher(mut self, m: LookMatcher) -> Config {}\n    #[cfg(test)]\n    fn unanchored_prefix(mut self, yes: bool) -> Config {}\n    pub fn get_utf8(&self) -> bool {}\n    pub fn get_reverse(&self) -> bool {}\n    pub fn get_nfa_size_limit(&self) -> Option<usize> {}\n    pub fn get_shrink(&self) -> bool {}\n    #[deprecated(since = \"0.3.5\", note = \"use get_which_captures instead\")]\n    pub fn get_captures(&self) -> bool {}\n    pub fn get_which_captures(&self) -> WhichCaptures {}\n    pub fn get_look_matcher(&self) -> LookMatcher {}\n    fn get_unanchored_prefix(&self) -> bool {}\n    pub(crate) fn overwrite(&self, o: Config) -> Config {}\n}\n\nThe function to be tested is presented with each line formatted as 'line number + code':\n/// Whether to enable UTF-8 mode during search or not.\n///\n/// A regex engine is said to be in UTF-8 mode when it guarantees that\n/// all matches returned by it have spans consisting of only valid UTF-8.\n/// That is, it is impossible for a match span to be returned that\n/// contains any invalid UTF-8.\n///\n/// UTF-8 mode generally consists of two things:\n///\n/// 1. Whether the NFA's states are constructed such that all paths to a\n/// match state that consume at least one byte always correspond to valid\n/// UTF-8.\n/// 2. Whether all paths to a match state that do _not_ consume any bytes\n/// should always correspond to valid UTF-8 boundaries.\n///\n/// (1) is a guarantee made by whoever constructs the NFA.\n/// If you're parsing a regex from its concrete syntax, then\n/// [`syntax::Config::utf8`](crate::util::syntax::Config::utf8) can make\n/// this guarantee for you. It does it by returning an error if the regex\n/// pattern could every report a non-empty match span that contains invalid\n/// UTF-8. So long as `syntax::Config::utf8` mode is enabled and your regex\n/// successfully parses, then you're guaranteed that the corresponding NFA\n/// will only ever report non-empty match spans containing valid UTF-8.\n///\n/// (2) is a trickier guarantee because it cannot be enforced by the NFA\n/// state graph itself. Consider, for example, the regex `a*`. It matches\n/// the empty strings in `☃` at positions `0`, `1`, `2` and `3`, where\n/// positions `1` and `2` occur within the UTF-8 encoding of a codepoint,\n/// and thus correspond to invalid UTF-8 boundaries. Therefore, this\n/// guarantee must be made at a higher level than the NFA state graph\n/// itself. This crate deals with this case in each regex engine. Namely,\n/// when a zero-width match that splits a codepoint is found and UTF-8\n/// mode enabled, then it is ignored and the engine moves on looking for\n/// the next match.\n///\n/// Thus, UTF-8 mode is both a promise that the NFA built only reports\n/// non-empty matches that are valid UTF-8, and an *instruction* to regex\n/// engines that empty matches that split codepoints should be banned.\n///\n/// Because UTF-8 mode is fundamentally about avoiding invalid UTF-8 spans,\n/// it only makes sense to enable this option when you *know* your haystack\n/// is valid UTF-8. (For example, a `&str`.) Enabling UTF-8 mode and\n/// searching a haystack that contains invalid UTF-8 leads to **unspecified\n/// behavior**.\n///\n/// Therefore, it may make sense to enable `syntax::Config::utf8` while\n/// simultaneously *disabling* this option. That would ensure all non-empty\n/// match spans are valid UTF-8, but that empty match spans may still split\n/// a codepoint or match at other places that aren't valid UTF-8.\n///\n/// In general, this mode is only relevant if your regex can match the\n/// empty string. Most regexes don't.\n///\n/// This is enabled by default.\n///\n/// # Example\n///\n/// This example shows how UTF-8 mode can impact the match spans that may\n/// be reported in certain cases.\n///\n/// ```\n/// use regex_automata::{\n///     nfa::thompson::{self, pikevm::PikeVM},\n///     Match, Input,\n/// };\n///\n/// let re = PikeVM::new(\"\")?;\n/// let (mut cache, mut caps) = (re.create_cache(), re.create_captures());\n///\n/// // UTF-8 mode is enabled by default.\n/// let mut input = Input::new(\"☃\");\n/// re.search(&mut cache, &input, &mut caps);\n/// assert_eq!(Some(Match::must(0, 0..0)), caps.get_match());\n///\n/// // Even though an empty regex matches at 1..1, our next match is\n/// // 3..3 because 1..1 and 2..2 split the snowman codepoint (which is\n/// // three bytes long).\n/// input.set_start(1);\n/// re.search(&mut cache, &input, &mut caps);\n/// assert_eq!(Some(Match::must(0, 3..3)), caps.get_match());\n///\n/// // But if we disable UTF-8, then we'll get matches at 1..1 and 2..2:\n/// let re = PikeVM::builder()\n///     .thompson(thompson::Config::new().utf8(false))\n///     .build(\"\")?;\n/// re.search(&mut cache, &input, &mut caps);\n/// assert_eq!(Some(Match::must(0, 1..1)), caps.get_match());\n///\n/// input.set_start(2);\n/// re.search(&mut cache, &input, &mut caps);\n/// assert_eq!(Some(Match::must(0, 2..2)), caps.get_match());\n///\n/// input.set_start(3);\n/// re.search(&mut cache, &input, &mut caps);\n/// assert_eq!(Some(Match::must(0, 3..3)), caps.get_match());\n///\n/// input.set_start(4);\n/// re.search(&mut cache, &input, &mut caps);\n/// assert_eq!(None, caps.get_match());\n///\n/// # Ok::<(), Box<dyn std::error::Error>>(())\n/// ```\n147 pub fn utf8(mut self, yes: bool) -> Config {\n148     self.utf8 = Some(yes);\n149     self\n150 }\n\nGenerate each test function in such a manner that it concurrently satisfies all the following preconditions:\n",
  "depend_pt": ""
}