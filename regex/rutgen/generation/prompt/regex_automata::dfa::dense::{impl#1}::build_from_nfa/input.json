{
  "system_pt": "As a software testing expert, infer the test input conditions or ranges based on the provided information. Follow these guidelines:\n1. Provide test input conditions or ranges in one line in plain text only, without additional explanations or Markdown formatting\n2. Analyze the function under test, context, preconditions, and expected return values or types to determine appropriate test input conditions or ranges\n3. The inferred test input conditions or ranges should comprehensively satisfy all provided preconditions simultaneously.\n4. Ensure the test input conditions or ranges cover boundary cases and edge scenarios\n",
  "static_pt": "The context for the focal function is as follows:\n// regex-automata/src/dfa/dense.rs\n// crate name is regex_automata\n#[cfg(feature = \"alloc\")]\npub(crate) type OwnedDFA = DFA<alloc::vec::Vec<u32>>;\n#[cfg(feature = \"dfa-build\")]\nuse core::cmp;\nuse core::{fmt, iter, mem::size_of, slice};\n#[cfg(feature = \"dfa-build\")]\nuse alloc::{\n    collections::{BTreeMap, BTreeSet},\n    vec, vec::Vec,\n};\n#[cfg(feature = \"dfa-build\")]\nuse crate::{\n    dfa::{accel::Accel, determinize, minimize::Minimizer, remapper::Remapper, sparse},\n    nfa::thompson, util::{look::LookMatcher, search::MatchKind},\n};\nuse crate::{\n    dfa::{\n        accel::Accels, automaton::{fmt_state_indicator, Automaton, StartError},\n        special::Special, start::StartKind, DEAD,\n    },\n    util::{\n        alphabet::{self, ByteClasses, ByteSet},\n        int::{Pointer, Usize},\n        prefilter::Prefilter, primitives::{PatternID, StateID},\n        search::Anchored, start::{self, Start, StartByteMap},\n        wire::{self, DeserializeError, Endian, SerializeError},\n    },\n};\nconst LABEL: &str = \"rust-regex-automata-dfa-dense\";\nconst VERSION: u32 = 2;\n#[cfg(feature = \"dfa-build\")]\n#[derive(Clone, Debug)]\npub struct Builder {\n    config: Config,\n    #[cfg(feature = \"syntax\")]\n    thompson: thompson::Compiler,\n}\n#[derive(Clone)]\npub struct NFA(Arc<Inner>);\n#[cfg(feature = \"dfa-build\")]\n#[derive(Clone, Debug, Default)]\npub struct Config {\n    accelerate: Option<bool>,\n    pre: Option<Option<Prefilter>>,\n    minimize: Option<bool>,\n    match_kind: Option<MatchKind>,\n    start_kind: Option<StartKind>,\n    starts_for_each_pattern: Option<bool>,\n    byte_classes: Option<bool>,\n    unicode_word_boundary: Option<bool>,\n    quitset: Option<ByteSet>,\n    specialize_start_states: Option<bool>,\n    dfa_size_limit: Option<Option<usize>>,\n    determinize_size_limit: Option<Option<usize>>,\n}\n#[derive(Clone, Debug)]\npub(crate) struct Config {\n    match_kind: MatchKind,\n    quit: ByteSet,\n    dfa_size_limit: Option<usize>,\n    determinize_size_limit: Option<usize>,\n}\n#[derive(Clone, Copy, Debug)]\npub(crate) struct Special {\n    /// The identifier of the last special state in a DFA. A state is special\n    /// if and only if its identifier is less than or equal to `max`.\n    pub(crate) max: StateID,\n    /// The identifier of the quit state in a DFA. (There is no analogous field\n    /// for the dead state since the dead state's ID is always zero, regardless\n    /// of state ID size.)\n    pub(crate) quit_id: StateID,\n    /// The identifier of the first match state.\n    pub(crate) min_match: StateID,\n    /// The identifier of the last match state.\n    pub(crate) max_match: StateID,\n    /// The identifier of the first accelerated state.\n    pub(crate) min_accel: StateID,\n    /// The identifier of the last accelerated state.\n    pub(crate) max_accel: StateID,\n    /// The identifier of the first start state.\n    pub(crate) min_start: StateID,\n    /// The identifier of the last start state.\n    pub(crate) max_start: StateID,\n}\n#[cfg(feature = \"alloc\")]\n#[derive(Clone, Debug)]\npub(crate) struct ByteClassSet(ByteSet);\n#[derive(Clone, Copy)]\npub struct ByteClasses([u8; 256]);\n#[derive(Clone, Copy, Debug)]\npub(crate) struct Flags {\n    /// Whether the DFA can match the empty string. When this is false, all\n    /// matches returned by this DFA are guaranteed to have non-zero length.\n    pub(crate) has_empty: bool,\n    /// Whether the DFA should only produce matches with spans that correspond\n    /// to valid UTF-8. This also includes omitting any zero-width matches that\n    /// split the UTF-8 encoding of a codepoint.\n    pub(crate) is_utf8: bool,\n    /// Whether the DFA is always anchored or not, regardless of `Input`\n    /// configuration. This is useful for avoiding a reverse scan even when\n    /// executing unanchored searches.\n    pub(crate) is_always_start_anchored: bool,\n}\n#[derive(Clone, Copy, Debug, Default, Eq, PartialEq)]\npub(crate) struct ByteSet {\n    bits: BitSet,\n}\n#[derive(Clone, Copy, Default, Eq, PartialEq)]\npub struct LookSet {\n    /// The underlying representation this set is exposed to make it possible\n    /// to store it somewhere efficiently. The representation is that\n    /// of a bitset, where each assertion occupies bit `i` where\n    /// `i = Look::as_repr()`.\n    ///\n    /// Note that users of this internal representation must permit the full\n    /// range of `u16` values to be represented. For example, even if the\n    /// current implementation only makes use of the 10 least significant bits,\n    /// it may use more bits in a future semver compatible release.\n    pub bits: u32,\n}\n#[derive(Clone, Debug, Default)]\npub struct Config {\n    match_kind: Option<MatchKind>,\n    starts_for_each_pattern: Option<bool>,\n    byte_classes: Option<bool>,\n    size_limit: Option<Option<usize>>,\n}\n#[derive(Clone, Copy, Debug)]\npub struct Config {\n    case_insensitive: bool,\n    multi_line: bool,\n    dot_matches_new_line: bool,\n    crlf: bool,\n    line_terminator: u8,\n    swap_greed: bool,\n    ignore_whitespace: bool,\n    unicode: bool,\n    utf8: bool,\n    nest_limit: u32,\n    octal: bool,\n}\n#[derive(Clone, Debug, Default)]\npub struct Config {\n    pre: Option<Option<Prefilter>>,\n    visited_capacity: Option<usize>,\n}\n#[derive(Clone, Debug)]\npub struct Compiler {\n    /// A regex parser, used when compiling an NFA directly from a pattern\n    /// string.\n    parser: ParserBuilder,\n    /// The compiler configuration.\n    config: Config,\n    /// The builder for actually constructing an NFA. This provides a\n    /// convenient abstraction for writing a compiler.\n    builder: RefCell<Builder>,\n    /// State used for compiling character classes to UTF-8 byte automata.\n    /// State is not retained between character class compilations. This just\n    /// serves to amortize allocation to the extent possible.\n    utf8_state: RefCell<Utf8State>,\n    /// State used for arranging character classes in reverse into a trie.\n    trie_state: RefCell<RangeTrie>,\n    /// State used for caching common suffixes when compiling reverse UTF-8\n    /// automata (for Unicode character classes).\n    utf8_suffix: RefCell<Utf8SuffixMap>,\n}\n#[derive(Clone, Debug)]\npub struct LookMatcher {\n    lineterm: DebugByte,\n}\n#[derive(Clone, Debug, Default)]\npub struct Config {\n    match_kind: Option<MatchKind>,\n    pre: Option<Option<Prefilter>>,\n    starts_for_each_pattern: Option<bool>,\n    byte_classes: Option<bool>,\n    unicode_word_boundary: Option<bool>,\n    quitset: Option<ByteSet>,\n    specialize_start_states: Option<bool>,\n    cache_capacity: Option<usize>,\n    skip_cache_capacity_check: Option<bool>,\n    minimum_cache_clear_count: Option<Option<usize>>,\n    minimum_bytes_per_state: Option<Option<usize>>,\n}\n#[derive(Clone, Debug, Default)]\npub struct Config {\n    utf8: Option<bool>,\n    reverse: Option<bool>,\n    nfa_size_limit: Option<Option<usize>>,\n    shrink: Option<bool>,\n    which_captures: Option<WhichCaptures>,\n    look_matcher: Option<LookMatcher>,\n    #[cfg(test)]\n    unanchored_prefix: Option<bool>,\n}\n#[derive(Clone, Debug)]\npub struct Prefilter {\n    #[cfg(not(feature = \"alloc\"))]\n    _unused: (),\n    #[cfg(feature = \"alloc\")]\n    pre: Arc<dyn PrefilterI>,\n    #[cfg(feature = \"alloc\")]\n    is_fast: bool,\n    #[cfg(feature = \"alloc\")]\n    max_needle_len: usize,\n}\n#[derive(Clone, Debug)]\npub struct Config {\n    look_behind: Option<u8>,\n    anchored: Anchored,\n}\n#[cfg(feature = \"dfa-build\")]\n#[derive(Clone, Debug)]\npub struct BuildError {\n    kind: BuildErrorKind,\n}\n#[derive(Clone, Debug, Default)]\npub struct Config {\n    match_kind: Option<MatchKind>,\n    utf8_empty: Option<bool>,\n    autopre: Option<bool>,\n    pre: Option<Option<Prefilter>>,\n    which_captures: Option<WhichCaptures>,\n    nfa_size_limit: Option<Option<usize>>,\n    onepass_size_limit: Option<Option<usize>>,\n    hybrid_cache_capacity: Option<usize>,\n    hybrid: Option<bool>,\n    dfa: Option<bool>,\n    dfa_size_limit: Option<Option<usize>>,\n    dfa_state_limit: Option<Option<usize>>,\n    onepass: Option<bool>,\n    backtrack: Option<bool>,\n    byte_classes: Option<bool>,\n    line_terminator: Option<u8>,\n}\n#[derive(Clone, Debug, Default)]\npub struct Config {\n    match_kind: Option<MatchKind>,\n    pre: Option<Option<Prefilter>>,\n}\n#[non_exhaustive]\n#[derive(Clone, Copy, Debug, Eq, PartialEq)]\npub enum MatchKind {\n    /// Report all possible matches.\n    All,\n    /// Report only the leftmost matches. When multiple leftmost matches exist,\n    /// report the match corresponding to the part of the regex that appears\n    /// first in the syntax.\n    LeftmostFirst,\n}\n#[derive(Clone, Copy, Debug, Eq, PartialEq)]\npub enum StartKind {\n    /// Support both anchored and unanchored searches.\n    Both,\n    /// Support only unanchored searches. Requesting an anchored search will\n    /// panic.\n    ///\n    /// Note that even if an unanchored search is requested, the pattern itself\n    /// may still be anchored. For example, `^abc` will only match `abc` at the\n    /// start of a haystack. This will remain true, even if the regex engine\n    /// only supported unanchored searches.\n    Unanchored,\n    /// Support only anchored searches. Requesting an unanchored search will\n    /// panic.\n    Anchored,\n}\n#[cfg(feature = \"dfa-build\")]\nimpl Builder {\n    pub fn new() -> Builder {}\n    #[cfg(feature = \"syntax\")]\n    pub fn build(&self, pattern: &str) -> Result<OwnedDFA, BuildError> {}\n    #[cfg(feature = \"syntax\")]\n    pub fn build_many<P: AsRef<str>>(\n        &self,\n        patterns: &[P],\n    ) -> Result<OwnedDFA, BuildError> {}\n    pub fn build_from_nfa(&self, nfa: &thompson::NFA) -> Result<OwnedDFA, BuildError> {\n        let mut quitset = self.config.quitset.unwrap_or(ByteSet::empty());\n        if self.config.get_unicode_word_boundary()\n            && nfa.look_set_any().contains_word_unicode()\n        {\n            for b in 0x80..=0xFF {\n                quitset.add(b);\n            }\n        }\n        let classes = if !self.config.get_byte_classes() {\n            ByteClasses::singletons()\n        } else {\n            let mut set = nfa.byte_class_set().clone();\n            if !quitset.is_empty() {\n                set.add_set(&quitset);\n            }\n            set.byte_classes()\n        };\n        let mut dfa = DFA::initial(\n            classes,\n            nfa.pattern_len(),\n            self.config.get_starts(),\n            nfa.look_matcher(),\n            self.config.get_starts_for_each_pattern(),\n            self.config.get_prefilter().map(|p| p.clone()),\n            quitset,\n            Flags::from_nfa(&nfa),\n        )?;\n        determinize::Config::new()\n            .match_kind(self.config.get_match_kind())\n            .quit(quitset)\n            .dfa_size_limit(self.config.get_dfa_size_limit())\n            .determinize_size_limit(self.config.get_determinize_size_limit())\n            .run(nfa, &mut dfa)?;\n        if self.config.get_minimize() {\n            dfa.minimize();\n        }\n        if self.config.get_accelerate() {\n            dfa.accelerate();\n        }\n        if !self.config.get_specialize_start_states() {\n            dfa.special.set_no_special_start_states();\n        }\n        dfa.set_universal_starts();\n        Ok(dfa)\n    }\n    pub fn configure(&mut self, config: Config) -> &mut Builder {}\n    #[cfg(feature = \"syntax\")]\n    pub fn syntax(&mut self, config: crate::util::syntax::Config) -> &mut Builder {}\n    #[cfg(feature = \"syntax\")]\n    pub fn thompson(&mut self, config: thompson::Config) -> &mut Builder {}\n}\nimpl NFA {\n    #[cfg(feature = \"syntax\")]\n    pub fn new(pattern: &str) -> Result<NFA, BuildError> {}\n    #[cfg(feature = \"syntax\")]\n    pub fn new_many<P: AsRef<str>>(patterns: &[P]) -> Result<NFA, BuildError> {}\n    pub fn always_match() -> NFA {}\n    pub fn never_match() -> NFA {}\n    #[cfg(feature = \"syntax\")]\n    pub fn config() -> Config {}\n    #[cfg(feature = \"syntax\")]\n    pub fn compiler() -> Compiler {}\n    pub fn patterns(&self) -> PatternIter<'_> {}\n    #[inline]\n    pub fn pattern_len(&self) -> usize {\n        self.0.start_pattern.len()\n    }\n    #[inline]\n    pub fn start_anchored(&self) -> StateID {}\n    #[inline]\n    pub fn start_unanchored(&self) -> StateID {}\n    #[inline]\n    pub fn start_pattern(&self, pid: PatternID) -> Option<StateID> {}\n    #[inline]\n    pub(crate) fn byte_class_set(&self) -> &ByteClassSet {\n        &self.0.byte_class_set\n    }\n    #[inline]\n    pub fn byte_classes(&self) -> &ByteClasses {}\n    #[inline]\n    pub fn state(&self, id: StateID) -> &State {}\n    #[inline]\n    pub fn states(&self) -> &[State] {}\n    #[inline]\n    pub fn group_info(&self) -> &GroupInfo {}\n    #[inline]\n    pub fn has_capture(&self) -> bool {}\n    #[inline]\n    pub fn has_empty(&self) -> bool {}\n    #[inline]\n    pub fn is_utf8(&self) -> bool {}\n    #[inline]\n    pub fn is_reverse(&self) -> bool {}\n    #[inline]\n    pub fn is_always_start_anchored(&self) -> bool {}\n    #[inline]\n    pub fn look_matcher(&self) -> &LookMatcher {\n        &self.0.look_matcher\n    }\n    #[inline]\n    pub fn look_set_any(&self) -> LookSet {\n        self.0.look_set_any\n    }\n    #[inline]\n    pub fn look_set_prefix_any(&self) -> LookSet {}\n    #[inline]\n    pub fn memory_usage(&self) -> usize {}\n}\n#[cfg(feature = \"dfa-build\")]\nimpl Config {\n    pub fn new() -> Config {}\n    pub fn accelerate(mut self, yes: bool) -> Config {}\n    pub fn prefilter(mut self, pre: Option<Prefilter>) -> Config {}\n    pub fn minimize(mut self, yes: bool) -> Config {}\n    pub fn match_kind(mut self, kind: MatchKind) -> Config {}\n    pub fn start_kind(mut self, kind: StartKind) -> Config {}\n    pub fn starts_for_each_pattern(mut self, yes: bool) -> Config {}\n    pub fn byte_classes(mut self, yes: bool) -> Config {}\n    pub fn unicode_word_boundary(mut self, yes: bool) -> Config {}\n    pub fn quit(mut self, byte: u8, yes: bool) -> Config {}\n    pub fn specialize_start_states(mut self, yes: bool) -> Config {}\n    pub fn dfa_size_limit(mut self, bytes: Option<usize>) -> Config {}\n    pub fn determinize_size_limit(mut self, bytes: Option<usize>) -> Config {}\n    pub fn get_accelerate(&self) -> bool {\n        self.accelerate.unwrap_or(true)\n    }\n    pub fn get_prefilter(&self) -> Option<&Prefilter> {\n        self.pre.as_ref().unwrap_or(&None).as_ref()\n    }\n    pub fn get_minimize(&self) -> bool {\n        self.minimize.unwrap_or(false)\n    }\n    pub fn get_match_kind(&self) -> MatchKind {\n        self.match_kind.unwrap_or(MatchKind::LeftmostFirst)\n    }\n    pub fn get_starts(&self) -> StartKind {\n        self.start_kind.unwrap_or(StartKind::Both)\n    }\n    pub fn get_starts_for_each_pattern(&self) -> bool {\n        self.starts_for_each_pattern.unwrap_or(false)\n    }\n    pub fn get_byte_classes(&self) -> bool {\n        self.byte_classes.unwrap_or(true)\n    }\n    pub fn get_unicode_word_boundary(&self) -> bool {\n        self.unicode_word_boundary.unwrap_or(false)\n    }\n    pub fn get_quit(&self, byte: u8) -> bool {}\n    pub fn get_specialize_start_states(&self) -> bool {\n        self.specialize_start_states.unwrap_or(false)\n    }\n    pub fn get_dfa_size_limit(&self) -> Option<usize> {\n        self.dfa_size_limit.unwrap_or(None)\n    }\n    pub fn get_determinize_size_limit(&self) -> Option<usize> {\n        self.determinize_size_limit.unwrap_or(None)\n    }\n    pub(crate) fn overwrite(&self, o: Config) -> Config {}\n}\nimpl Config {\n    pub fn new() -> Config {\n        Config {\n            match_kind: MatchKind::LeftmostFirst,\n            quit: ByteSet::empty(),\n            dfa_size_limit: None,\n            determinize_size_limit: None,\n        }\n    }\n    pub fn run(\n        &self,\n        nfa: &thompson::NFA,\n        dfa: &mut dense::OwnedDFA,\n    ) -> Result<(), BuildError> {\n        let dead = State::dead();\n        let quit = State::dead();\n        let mut cache = StateMap::default();\n        cache.insert(dead.clone(), DEAD);\n        let runner = Runner {\n            config: self.clone(),\n            nfa,\n            dfa,\n            builder_states: alloc::vec![dead, quit],\n            cache,\n            memory_usage_state: 0,\n            sparses: SparseSets::new(nfa.states().len()),\n            stack: alloc::vec![],\n            scratch_state_builder: StateBuilderEmpty::new(),\n        };\n        runner.run()\n    }\n    pub fn match_kind(&mut self, kind: MatchKind) -> &mut Config {\n        self.match_kind = kind;\n        self\n    }\n    pub fn quit(&mut self, set: ByteSet) -> &mut Config {\n        self.quit = set;\n        self\n    }\n    pub fn dfa_size_limit(&mut self, bytes: Option<usize>) -> &mut Config {\n        self.dfa_size_limit = bytes;\n        self\n    }\n    pub fn determinize_size_limit(&mut self, bytes: Option<usize>) -> &mut Config {\n        self.determinize_size_limit = bytes;\n        self\n    }\n}\nimpl Special {\n    #[cfg(feature = \"dfa-build\")]\n    pub(crate) fn new() -> Special {}\n    #[cfg(feature = \"dfa-build\")]\n    pub(crate) fn remap(&self, map: impl Fn(StateID) -> StateID) -> Special {}\n    pub(crate) fn from_bytes(\n        mut slice: &[u8],\n    ) -> Result<(Special, usize), DeserializeError> {}\n    pub(crate) fn validate(&self) -> Result<(), DeserializeError> {}\n    pub(crate) fn validate_state_len(\n        &self,\n        len: usize,\n        stride2: usize,\n    ) -> Result<(), DeserializeError> {}\n    pub(crate) fn write_to<E: Endian>(\n        &self,\n        dst: &mut [u8],\n    ) -> Result<usize, SerializeError> {}\n    pub(crate) fn write_to_len(&self) -> usize {}\n    #[cfg(feature = \"dfa-build\")]\n    pub(crate) fn set_max(&mut self) {}\n    #[cfg(feature = \"dfa-build\")]\n    pub(crate) fn set_no_special_start_states(&mut self) {\n        use core::cmp::max;\n        self.max = max(self.quit_id, max(self.max_match, self.max_accel));\n        self.min_start = DEAD;\n        self.max_start = DEAD;\n    }\n    #[inline]\n    pub(crate) fn is_special_state(&self, id: StateID) -> bool {}\n    #[inline]\n    pub(crate) fn is_dead_state(&self, id: StateID) -> bool {}\n    #[inline]\n    pub(crate) fn is_quit_state(&self, id: StateID) -> bool {}\n    #[inline]\n    pub(crate) fn is_match_state(&self, id: StateID) -> bool {}\n    #[inline]\n    pub(crate) fn is_accel_state(&self, id: StateID) -> bool {}\n    #[inline]\n    pub(crate) fn is_start_state(&self, id: StateID) -> bool {}\n    #[inline]\n    pub(crate) fn match_len(&self, stride: usize) -> usize {}\n    #[inline]\n    pub(crate) fn matches(&self) -> bool {}\n    #[cfg(feature = \"dfa-build\")]\n    pub(crate) fn accel_len(&self, stride: usize) -> usize {}\n    #[inline]\n    pub(crate) fn accels(&self) -> bool {}\n    #[inline]\n    pub(crate) fn starts(&self) -> bool {}\n}\n#[cfg(feature = \"alloc\")]\nimpl ByteClassSet {\n    pub(crate) fn empty() -> Self {\n        ByteClassSet(ByteSet::empty())\n    }\n    pub(crate) fn set_range(&mut self, start: u8, end: u8) {}\n    pub(crate) fn add_set(&mut self, set: &ByteSet) {\n        for (start, end) in set.iter_ranges() {\n            self.set_range(start, end);\n        }\n    }\n    pub(crate) fn byte_classes(&self) -> ByteClasses {\n        let mut classes = ByteClasses::empty();\n        let mut class = 0u8;\n        let mut b = 0u8;\n        loop {\n            classes.set(b, class);\n            if b == 255 {\n                break;\n            }\n            if self.0.contains(b) {\n                class = class.checked_add(1).unwrap();\n            }\n            b = b.checked_add(1).unwrap();\n        }\n        classes\n    }\n}\nimpl ByteClasses {\n    #[inline]\n    pub fn empty() -> ByteClasses {}\n    #[inline]\n    pub fn singletons() -> ByteClasses {\n        let mut classes = ByteClasses::empty();\n        for b in 0..=255 {\n            classes.set(b, b);\n        }\n        classes\n    }\n    pub(crate) fn from_bytes(\n        slice: &[u8],\n    ) -> Result<(ByteClasses, usize), DeserializeError> {}\n    pub(crate) fn write_to(&self, mut dst: &mut [u8]) -> Result<usize, SerializeError> {}\n    pub(crate) fn write_to_len(&self) -> usize {}\n    #[inline]\n    pub fn set(&mut self, byte: u8, class: u8) {}\n    #[inline]\n    pub fn get(&self, byte: u8) -> u8 {}\n    #[inline]\n    pub fn get_by_unit(&self, unit: Unit) -> usize {}\n    #[inline]\n    pub fn eoi(&self) -> Unit {}\n    #[inline]\n    pub fn alphabet_len(&self) -> usize {}\n    #[inline]\n    pub fn stride2(&self) -> usize {}\n    #[inline]\n    pub fn is_singleton(&self) -> bool {}\n    #[inline]\n    pub fn iter(&self) -> ByteClassIter<'_> {}\n    pub fn representatives<R: core::ops::RangeBounds<u8>>(\n        &self,\n        range: R,\n    ) -> ByteClassRepresentatives<'_> {}\n    #[inline]\n    pub fn elements(&self, class: Unit) -> ByteClassElements {}\n    fn element_ranges(&self, class: Unit) -> ByteClassElementRanges {}\n}\nimpl Flags {\n    #[cfg(feature = \"dfa-build\")]\n    fn from_nfa(nfa: &thompson::NFA) -> Flags {\n        Flags {\n            has_empty: nfa.has_empty(),\n            is_utf8: nfa.is_utf8(),\n            is_always_start_anchored: nfa.is_always_start_anchored(),\n        }\n    }\n    pub(crate) fn from_bytes(slice: &[u8]) -> Result<(Flags, usize), DeserializeError> {}\n    pub(crate) fn write_to<E: Endian>(\n        &self,\n        dst: &mut [u8],\n    ) -> Result<usize, SerializeError> {}\n    pub(crate) fn write_to_len(&self) -> usize {}\n}\nimpl ByteSet {\n    pub(crate) fn empty() -> ByteSet {\n        ByteSet { bits: BitSet([0; 2]) }\n    }\n    pub(crate) fn add(&mut self, byte: u8) {\n        let bucket = byte / 128;\n        let bit = byte % 128;\n        self.bits.0[usize::from(bucket)] |= 1 << bit;\n    }\n    pub(crate) fn remove(&mut self, byte: u8) {}\n    pub(crate) fn contains(&self, byte: u8) -> bool {}\n    pub(crate) fn contains_range(&self, start: u8, end: u8) -> bool {}\n    pub(crate) fn iter(&self) -> ByteSetIter {}\n    pub(crate) fn iter_ranges(&self) -> ByteSetRangeIter {}\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    pub(crate) fn is_empty(&self) -> bool {\n        self.bits.0 == [0, 0]\n    }\n    pub(crate) fn from_bytes(\n        slice: &[u8],\n    ) -> Result<(ByteSet, usize), DeserializeError> {}\n    pub(crate) fn write_to<E: crate::util::wire::Endian>(\n        &self,\n        dst: &mut [u8],\n    ) -> Result<usize, SerializeError> {}\n    pub(crate) fn write_to_len(&self) -> usize {}\n}\nimpl LookSet {\n    #[inline]\n    pub fn empty() -> LookSet {}\n    #[inline]\n    pub fn full() -> LookSet {}\n    #[inline]\n    pub fn singleton(look: Look) -> LookSet {}\n    #[inline]\n    pub fn len(self) -> usize {}\n    #[inline]\n    pub fn is_empty(self) -> bool {}\n    #[inline]\n    pub fn contains(self, look: Look) -> bool {}\n    #[inline]\n    pub fn contains_anchor(&self) -> bool {}\n    #[inline]\n    pub fn contains_anchor_haystack(&self) -> bool {}\n    #[inline]\n    pub fn contains_anchor_line(&self) -> bool {}\n    #[inline]\n    pub fn contains_anchor_lf(&self) -> bool {}\n    #[inline]\n    pub fn contains_anchor_crlf(&self) -> bool {}\n    #[inline]\n    pub fn contains_word(self) -> bool {}\n    #[inline]\n    pub fn contains_word_unicode(self) -> bool {\n        self.contains(Look::WordUnicode) || self.contains(Look::WordUnicodeNegate)\n            || self.contains(Look::WordStartUnicode)\n            || self.contains(Look::WordEndUnicode)\n            || self.contains(Look::WordStartHalfUnicode)\n            || self.contains(Look::WordEndHalfUnicode)\n    }\n    #[inline]\n    pub fn contains_word_ascii(self) -> bool {}\n    #[inline]\n    pub fn iter(self) -> LookSetIter {}\n    #[inline]\n    pub fn insert(self, look: Look) -> LookSet {}\n    #[inline]\n    pub fn set_insert(&mut self, look: Look) {}\n    #[inline]\n    pub fn remove(self, look: Look) -> LookSet {}\n    #[inline]\n    pub fn set_remove(&mut self, look: Look) {}\n    #[inline]\n    pub fn subtract(self, other: LookSet) -> LookSet {}\n    #[inline]\n    pub fn set_subtract(&mut self, other: LookSet) {}\n    #[inline]\n    pub fn union(self, other: LookSet) -> LookSet {}\n    #[inline]\n    pub fn set_union(&mut self, other: LookSet) {}\n    #[inline]\n    pub fn intersect(self, other: LookSet) -> LookSet {}\n    #[inline]\n    pub fn set_intersect(&mut self, other: LookSet) {}\n    #[inline]\n    pub fn read_repr(slice: &[u8]) -> LookSet {}\n    #[inline]\n    pub fn write_repr(self, slice: &mut [u8]) {}\n    pub fn available(self) -> Result<(), UnicodeWordBoundaryError> {}\n}\n\nThe function to be tested is presented with each line formatted as 'line number + code':\n/// Build a DFA from the given NFA.\n///\n/// # Example\n///\n/// This example shows how to build a DFA if you already have an NFA in\n/// hand.\n///\n/// ```\n/// use regex_automata::{\n///     dfa::{Automaton, dense},\n///     nfa::thompson::NFA,\n///     HalfMatch, Input,\n/// };\n///\n/// let haystack = \"foo123bar\".as_bytes();\n///\n/// // This shows how to set non-default options for building an NFA.\n/// let nfa = NFA::compiler()\n///     .configure(NFA::config().shrink(true))\n///     .build(r\"[0-9]+\")?;\n/// let dfa = dense::Builder::new().build_from_nfa(&nfa)?;\n/// let expected = Some(HalfMatch::must(0, 6));\n/// let got = dfa.try_search_fwd(&Input::new(haystack))?;\n/// assert_eq!(expected, got);\n///\n/// # Ok::<(), Box<dyn std::error::Error>>(())\n/// ```\n1209 pub fn build_from_nfa(\n1210     &self,\n1211     nfa: &thompson::NFA,\n1212 ) -> Result<OwnedDFA, BuildError> {\n1213     let mut quitset = self.config.quitset.unwrap_or(ByteSet::empty());\n1214     if self.config.get_unicode_word_boundary()\n1215         && nfa.look_set_any().contains_word_unicode()\n1216     {\n1217         for b in 0x80..=0xFF {\n1218             quitset.add(b);\n1219         }\n1220     }\n1221     let classes = if !self.config.get_byte_classes() {\n1222         // DFAs will always use the equivalence class map, but enabling\n1223         // this option is useful for debugging. Namely, this will cause all\n1224         // transitions to be defined over their actual bytes instead of an\n1225         // opaque equivalence class identifier. The former is much easier\n1226         // to grok as a human.\n1227         ByteClasses::singletons()\n1228     } else {\n1229         let mut set = nfa.byte_class_set().clone();\n1230         // It is important to distinguish any \"quit\" bytes from all other\n1231         // bytes. Otherwise, a non-quit byte may end up in the same\n1232         // class as a quit byte, and thus cause the DFA to stop when it\n1233         // shouldn't.\n1234         //\n1235         // Test case:\n1236         //\n1237         //   regex-cli find match dense --unicode-word-boundary \\\n1238         //     -p '^#' -p '\\b10\\.55\\.182\\.100\\b' -y @conn.json.1000x.log\n1239         if !quitset.is_empty() {\n1240             set.add_set(&quitset);\n1241         }\n1242         set.byte_classes()\n1243     };\n1244 \n1245     let mut dfa = DFA::initial(\n1246         classes,\n1247         nfa.pattern_len(),\n1248         self.config.get_starts(),\n1249         nfa.look_matcher(),\n1250         self.config.get_starts_for_each_pattern(),\n1251         self.config.get_prefilter().map(|p| p.clone()),\n1252         quitset,\n1253         Flags::from_nfa(&nfa),\n1254     )?;\n1255     determinize::Config::new()\n1256         .match_kind(self.config.get_match_kind())\n1257         .quit(quitset)\n1258         .dfa_size_limit(self.config.get_dfa_size_limit())\n1259         .determinize_size_limit(self.config.get_determinize_size_limit())\n1260         .run(nfa, &mut dfa)?;\n1261     if self.config.get_minimize() {\n1262         dfa.minimize();\n1263     }\n1264     if self.config.get_accelerate() {\n1265         dfa.accelerate();\n1266     }\n1267     // The state shuffling done before this point always assumes that start\n1268     // states should be marked as \"special,\" even though it isn't the\n1269     // default configuration. State shuffling is complex enough as it is,\n1270     // so it's simpler to just \"fix\" our special state ID ranges to not\n1271     // include starting states after-the-fact.\n1272     if !self.config.get_specialize_start_states() {\n1273         dfa.special.set_no_special_start_states();\n1274     }\n1275     // Look for and set the universal starting states.\n1276     dfa.set_universal_starts();\n1277     Ok(dfa)\n1278 }\n\nWhen inferring test input conditions or ranges, consider the following preconditions and expected return values or types:\n"
}