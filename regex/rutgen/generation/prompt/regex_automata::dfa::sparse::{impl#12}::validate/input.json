{
  "system_pt": "As a software testing expert, infer the test input conditions or ranges based on the provided information. Follow these guidelines:\n1. Provide test input conditions or ranges in one line in plain text only, without additional explanations or Markdown formatting\n2. Analyze the function under test, context, preconditions, and expected return values or types to determine appropriate test input conditions or ranges\n3. The inferred test input conditions or ranges should comprehensively satisfy all provided preconditions simultaneously.\n4. Ensure the test input conditions or ranges cover boundary cases and edge scenarios\n",
  "static_pt": "The context for the focal function is as follows:\n// regex-automata/src/dfa/sparse.rs\n// crate name is regex_automata\n#[cfg(feature = \"dfa-build\")]\nuse core::iter;\nuse core::{fmt, mem::size_of};\n#[cfg(feature = \"dfa-build\")]\nuse alloc::{vec, vec::Vec};\n#[cfg(feature = \"dfa-build\")]\nuse crate::dfa::dense::{self, BuildError};\nuse crate::{\n    dfa::{\n        automaton::{fmt_state_indicator, Automaton, StartError},\n        dense::Flags, special::Special, StartKind, DEAD,\n    },\n    util::{\n        alphabet::{ByteClasses, ByteSet},\n        escape::DebugByte, int::{Pointer, Usize, U16, U32},\n        prefilter::Prefilter, primitives::{PatternID, StateID},\n        search::Anchored, start::{self, Start, StartByteMap},\n        wire::{self, DeserializeError, Endian, SerializeError},\n    },\n};\nconst LABEL: &str = \"rust-regex-automata-dfa-sparse\";\nconst VERSION: u32 = 2;\n#[derive(Clone)]\nstruct StartTable<T> {\n    /// The initial start state IDs as a contiguous table of native endian\n    /// encoded integers, represented by `S`.\n    ///\n    /// In practice, T is either Vec<u8> or &[u8] and has no alignment\n    /// requirements.\n    ///\n    /// The first `2 * stride` (currently always 8) entries always correspond\n    /// to the starts states for the entire DFA, with the first 4 entries being\n    /// for unanchored searches and the second 4 entries being for anchored\n    /// searches. To keep things simple, we always use 8 entries even if the\n    /// `StartKind` is not both.\n    ///\n    /// After that, there are `stride * patterns` state IDs, where `patterns`\n    /// may be zero in the case of a DFA with no patterns or in the case where\n    /// the DFA was built without enabling starting states for each pattern.\n    table: T,\n    /// The starting state configuration supported. When 'both', both\n    /// unanchored and anchored searches work. When 'unanchored', anchored\n    /// searches panic. When 'anchored', unanchored searches panic.\n    kind: StartKind,\n    /// The start state configuration for every possible byte.\n    start_map: StartByteMap,\n    /// The number of starting state IDs per pattern.\n    stride: usize,\n    /// The total number of patterns for which starting states are encoded.\n    /// This is `None` for DFAs that were built without start states for each\n    /// pattern. Thus, one cannot use this field to say how many patterns\n    /// are in the DFA in all cases. It is specific to how many patterns are\n    /// represented in this start table.\n    pattern_len: Option<usize>,\n    /// The universal starting state for unanchored searches. This is only\n    /// present when the DFA supports unanchored searches and when all starting\n    /// state IDs for an unanchored search are equivalent.\n    universal_start_unanchored: Option<StateID>,\n    /// The universal starting state for anchored searches. This is only\n    /// present when the DFA supports anchored searches and when all starting\n    /// state IDs for an anchored search are equivalent.\n    universal_start_anchored: Option<StateID>,\n}\n#[derive(Clone, Copy, Debug)]\npub(crate) struct Special {\n    /// The identifier of the last special state in a DFA. A state is special\n    /// if and only if its identifier is less than or equal to `max`.\n    pub(crate) max: StateID,\n    /// The identifier of the quit state in a DFA. (There is no analogous field\n    /// for the dead state since the dead state's ID is always zero, regardless\n    /// of state ID size.)\n    pub(crate) quit_id: StateID,\n    /// The identifier of the first match state.\n    pub(crate) min_match: StateID,\n    /// The identifier of the last match state.\n    pub(crate) max_match: StateID,\n    /// The identifier of the first accelerated state.\n    pub(crate) min_accel: StateID,\n    /// The identifier of the last accelerated state.\n    pub(crate) max_accel: StateID,\n    /// The identifier of the first start state.\n    pub(crate) min_start: StateID,\n    /// The identifier of the last start state.\n    pub(crate) max_start: StateID,\n}\n#[derive(Debug)]\npub struct DeserializeError(DeserializeErrorKind);\n#[derive(Debug)]\nstruct Seen {\n    #[cfg(feature = \"alloc\")]\n    set: alloc::collections::BTreeSet<StateID>,\n    #[cfg(not(feature = \"alloc\"))]\n    set: core::marker::PhantomData<StateID>,\n}\n#[derive(Clone, Copy, Default, Eq, Hash, PartialEq, PartialOrd, Ord)]\n#[repr(transparent)]\npub struct StateID(SmallIndex);\n#[derive(Clone)]\npub(crate) struct StartByteMap {\n    map: [Start; 256],\n}\nstruct StartStateIter<'a, T> {\n    st: &'a StartTable<T>,\n    i: usize,\n}\n#[derive(Clone, Copy, Debug, Eq, PartialEq)]\npub enum StartKind {\n    /// Support both anchored and unanchored searches.\n    Both,\n    /// Support only unanchored searches. Requesting an anchored search will\n    /// panic.\n    ///\n    /// Note that even if an unanchored search is requested, the pattern itself\n    /// may still be anchored. For example, `^abc` will only match `abc` at the\n    /// start of a haystack. This will remain true, even if the regex engine\n    /// only supported unanchored searches.\n    Unanchored,\n    /// Support only anchored searches. Requesting an unanchored search will\n    /// panic.\n    Anchored,\n}\n#[derive(Clone, Copy, Debug, Eq, PartialEq)]\npub(crate) enum Start {\n    /// This occurs when the starting position is not any of the ones below.\n    NonWordByte = 0,\n    /// This occurs when the byte immediately preceding the start of the search\n    /// is an ASCII word byte.\n    WordByte = 1,\n    /// This occurs when the starting position of the search corresponds to the\n    /// beginning of the haystack.\n    Text = 2,\n    /// This occurs when the byte immediately preceding the start of the search\n    /// is a line terminator. Specifically, `\\n`.\n    LineLF = 3,\n    /// This occurs when the byte immediately preceding the start of the search\n    /// is a line terminator. Specifically, `\\r`.\n    LineCR = 4,\n    /// This occurs when a custom line terminator has been set via a\n    /// `LookMatcher`, and when that line terminator is neither a `\\r` or a\n    /// `\\n`.\n    ///\n    /// If the custom line terminator is a word byte, then this start\n    /// configuration is still selected. DFAs that implement word boundary\n    /// assertions will likely need to check whether the custom line terminator\n    /// is a word byte, in which case, it should behave as if the byte\n    /// satisfies `\\b` in addition to multi-line anchors.\n    CustomLineTerminator = 5,\n}\n#[derive(Clone, Copy, Debug, Eq, PartialEq)]\npub enum Anchored {\n    /// Run an unanchored search. This means a match may occur anywhere at or\n    /// after the start position of the search.\n    ///\n    /// This search can return a match for any pattern in the regex.\n    No,\n    /// Run an anchored search. This means that a match must begin at the\n    /// start position of the search.\n    ///\n    /// This search can return a match for any pattern in the regex.\n    Yes,\n    /// Run an anchored search for a specific pattern. This means that a match\n    /// must be for the given pattern and must begin at the start position of\n    /// the search.\n    Pattern(PatternID),\n}\nimpl<T: AsRef<[u8]>> StartTable<T> {\n    fn write_to<E: Endian>(&self, mut dst: &mut [u8]) -> Result<usize, SerializeError> {}\n    fn write_to_len(&self) -> usize {}\n    fn validate(&self, sp: &Special, seen: &Seen) -> Result<(), DeserializeError> {\n        for (id, _, _) in self.iter() {\n            if !seen.contains(&id) {\n                return Err(DeserializeError::generic(\"found invalid start state ID\"));\n            }\n            if sp.is_match_state(id) {\n                return Err(\n                    DeserializeError::generic(\"start states cannot be match states\"),\n                );\n            }\n        }\n        Ok(())\n    }\n    fn as_ref(&self) -> StartTable<&'_ [u8]> {}\n    #[cfg(feature = \"alloc\")]\n    fn to_owned(&self) -> StartTable<alloc::vec::Vec<u8>> {}\n    fn start(&self, anchored: Anchored, start: Start) -> Result<StateID, StartError> {}\n    fn iter(&self) -> StartStateIter<'_, T> {\n        StartStateIter { st: self, i: 0 }\n    }\n    fn len(&self) -> usize {}\n    fn table(&self) -> &[u8] {}\n    fn memory_usage(&self) -> usize {}\n}\nimpl Special {\n    #[cfg(feature = \"dfa-build\")]\n    pub(crate) fn new() -> Special {}\n    #[cfg(feature = \"dfa-build\")]\n    pub(crate) fn remap(&self, map: impl Fn(StateID) -> StateID) -> Special {}\n    pub(crate) fn from_bytes(\n        mut slice: &[u8],\n    ) -> Result<(Special, usize), DeserializeError> {}\n    pub(crate) fn validate(&self) -> Result<(), DeserializeError> {}\n    pub(crate) fn validate_state_len(\n        &self,\n        len: usize,\n        stride2: usize,\n    ) -> Result<(), DeserializeError> {}\n    pub(crate) fn write_to<E: Endian>(\n        &self,\n        dst: &mut [u8],\n    ) -> Result<usize, SerializeError> {}\n    pub(crate) fn write_to_len(&self) -> usize {}\n    #[cfg(feature = \"dfa-build\")]\n    pub(crate) fn set_max(&mut self) {}\n    #[cfg(feature = \"dfa-build\")]\n    pub(crate) fn set_no_special_start_states(&mut self) {}\n    #[inline]\n    pub(crate) fn is_special_state(&self, id: StateID) -> bool {}\n    #[inline]\n    pub(crate) fn is_dead_state(&self, id: StateID) -> bool {}\n    #[inline]\n    pub(crate) fn is_quit_state(&self, id: StateID) -> bool {}\n    #[inline]\n    pub(crate) fn is_match_state(&self, id: StateID) -> bool {\n        !self.is_dead_state(id) && self.min_match <= id && id <= self.max_match\n    }\n    #[inline]\n    pub(crate) fn is_accel_state(&self, id: StateID) -> bool {}\n    #[inline]\n    pub(crate) fn is_start_state(&self, id: StateID) -> bool {}\n    #[inline]\n    pub(crate) fn match_len(&self, stride: usize) -> usize {}\n    #[inline]\n    pub(crate) fn matches(&self) -> bool {}\n    #[cfg(feature = \"dfa-build\")]\n    pub(crate) fn accel_len(&self, stride: usize) -> usize {}\n    #[inline]\n    pub(crate) fn accels(&self) -> bool {}\n    #[inline]\n    pub(crate) fn starts(&self) -> bool {}\n}\nimpl DeserializeError {\n    pub(crate) fn generic(msg: &'static str) -> DeserializeError {\n        DeserializeError(DeserializeErrorKind::Generic {\n            msg,\n        })\n    }\n    pub(crate) fn buffer_too_small(what: &'static str) -> DeserializeError {}\n    fn invalid_usize(what: &'static str) -> DeserializeError {}\n    fn version_mismatch(expected: u32, found: u32) -> DeserializeError {}\n    fn endian_mismatch(expected: u32, found: u32) -> DeserializeError {}\n    fn alignment_mismatch(alignment: usize, address: usize) -> DeserializeError {}\n    fn label_mismatch(expected: &'static str) -> DeserializeError {}\n    fn arithmetic_overflow(what: &'static str) -> DeserializeError {}\n    fn pattern_id_error(err: PatternIDError, what: &'static str) -> DeserializeError {}\n    pub(crate) fn state_id_error(\n        err: StateIDError,\n        what: &'static str,\n    ) -> DeserializeError {}\n}\n#[cfg(not(feature = \"alloc\"))]\nimpl Seen {\n    fn new() -> Seen {}\n    fn insert(&mut self, _id: StateID) {}\n    fn contains(&self, _id: &StateID) -> bool {\n        true\n    }\n}\n\nThe function to be tested is presented with each line formatted as 'line number + code':\n/// Validates that every starting state ID in this table is valid.\n///\n/// That is, every starting state ID can be used to correctly decode a\n/// state in the DFA's sparse transitions.\n2017 fn validate(\n2018     &self,\n2019     sp: &Special,\n2020     seen: &Seen,\n2021 ) -> Result<(), DeserializeError> {\n2022     for (id, _, _) in self.iter() {\n2023         if !seen.contains(&id) {\n2024             return Err(DeserializeError::generic(\n2025                 \"found invalid start state ID\",\n2026             ));\n2027         }\n2028         if sp.is_match_state(id) {\n2029             return Err(DeserializeError::generic(\n2030                 \"start states cannot be match states\",\n2031             ));\n2032         }\n2033     }\n2034     Ok(())\n2035 }\n\nWhen inferring test input conditions or ranges, consider the following preconditions and expected return values or types:\n"
}