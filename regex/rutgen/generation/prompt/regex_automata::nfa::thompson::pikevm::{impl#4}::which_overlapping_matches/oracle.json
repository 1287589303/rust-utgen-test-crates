{
  "system_pt": "As a software testing expert, please generate accurate test oracles code based on the provided information. Follow these guidelines:\n1. Generate executable test oracle codes in plain text format, one per line. Do not output complete test functions, avoid additional explanations, and do not use Markdown.\n2. Combine the given function under test, context, relevant documentation, preconditions, expected return values or types, test input conditions or ranges, and existing test function prefixes to infer and generate corresponding test oracles code.\n3. Only generate necessary test oracles to ensure comprehensive validation.\n",
  "static_pt": "The context for the focal function is as follows:\n// regex-automata/src/nfa/thompson/pikevm.rs\n// crate name is regex_automata\n#[cfg(feature = \"internal-instrument-pikevm\")]\nuse core::cell::RefCell;\nuse alloc::{vec, vec::Vec};\nuse crate::{\n    nfa::thompson::{self, BuildError, State, NFA},\n    util::{\n        captures::Captures, empty, iter, prefilter::Prefilter,\n        primitives::{NonMaxUsize, PatternID, SmallIndex, StateID},\n        search::{Anchored, HalfMatch, Input, Match, MatchKind, PatternSet, Span},\n        sparse_set::SparseSet,\n    },\n};\n#[derive(Clone, Debug)]\npub struct PikeVM {\n    config: Config,\n    nfa: NFA,\n}\n#[derive(Clone, Debug)]\npub(crate) struct Config {\n    match_kind: MatchKind,\n    quit: ByteSet,\n    dfa_size_limit: Option<usize>,\n    determinize_size_limit: Option<usize>,\n}\n#[derive(Clone, Debug, Default)]\npub struct Config {\n    match_kind: Option<MatchKind>,\n    utf8_empty: Option<bool>,\n    autopre: Option<bool>,\n    pre: Option<Option<Prefilter>>,\n    which_captures: Option<WhichCaptures>,\n    nfa_size_limit: Option<Option<usize>>,\n    onepass_size_limit: Option<Option<usize>>,\n    hybrid_cache_capacity: Option<usize>,\n    hybrid: Option<bool>,\n    dfa: Option<bool>,\n    dfa_size_limit: Option<Option<usize>>,\n    dfa_state_limit: Option<Option<usize>>,\n    onepass: Option<bool>,\n    backtrack: Option<bool>,\n    byte_classes: Option<bool>,\n    line_terminator: Option<u8>,\n}\n#[derive(Clone, Debug)]\npub struct Cache {\n    /// Stack used while computing epsilon closure. This effectively lets us\n    /// move what is more naturally expressed through recursion to a stack\n    /// on the heap.\n    stack: Vec<FollowEpsilon>,\n    /// The current active states being explored for the current byte in the\n    /// haystack.\n    curr: ActiveStates,\n    /// The next set of states we're building that will be explored for the\n    /// next byte in the haystack.\n    next: ActiveStates,\n}\n#[cfg(feature = \"alloc\")]\n#[derive(Clone, Debug, Eq, PartialEq)]\npub struct PatternSet {\n    /// The number of patterns set to 'true' in this set.\n    len: usize,\n    /// A map from PatternID to boolean of whether a pattern matches or not.\n    ///\n    /// This should probably be a bitset, but it's probably unlikely to matter\n    /// much in practice.\n    ///\n    /// The main downside of this representation (and similarly for a bitset)\n    /// is that iteration scales with the capacity of the set instead of\n    /// the length of the set. This doesn't seem likely to be a problem in\n    /// practice.\n    ///\n    /// Another alternative is to just use a 'SparseSet' for this. It does use\n    /// more memory (quite a bit more), but that seems fine I think compared\n    /// to the memory being used by the regex engine. The real hiccup with\n    /// it is that it yields pattern IDs in the order they were inserted.\n    /// Which is actually kind of nice, but at the time of writing, pattern\n    /// IDs are yielded in ascending order in the regex crate RegexSet API.\n    /// If we did change to 'SparseSet', we could provide an additional\n    /// 'iter_match_order' iterator, but keep the ascending order one for\n    /// compatibility.\n    which: alloc::boxed::Box<[bool]>,\n}\n#[derive(Clone)]\npub struct Input<'h> {\n    haystack: &'h [u8],\n    span: Span,\n    anchored: Anchored,\n    earliest: bool,\n}\n#[cfg(feature = \"dfa-build\")]\n#[derive(Clone, Debug, Default)]\npub struct Config {\n    accelerate: Option<bool>,\n    pre: Option<Option<Prefilter>>,\n    minimize: Option<bool>,\n    match_kind: Option<MatchKind>,\n    start_kind: Option<StartKind>,\n    starts_for_each_pattern: Option<bool>,\n    byte_classes: Option<bool>,\n    unicode_word_boundary: Option<bool>,\n    quitset: Option<ByteSet>,\n    specialize_start_states: Option<bool>,\n    dfa_size_limit: Option<Option<usize>>,\n    determinize_size_limit: Option<Option<usize>>,\n}\n#[derive(Clone, Debug, Default)]\npub struct Config {\n    utf8: Option<bool>,\n    reverse: Option<bool>,\n    nfa_size_limit: Option<Option<usize>>,\n    shrink: Option<bool>,\n    which_captures: Option<WhichCaptures>,\n    look_matcher: Option<LookMatcher>,\n    #[cfg(test)]\n    unanchored_prefix: Option<bool>,\n}\n#[derive(Clone)]\npub struct NFA(Arc<Inner>);\n#[derive(Clone, Copy, Debug)]\npub struct Config {\n    case_insensitive: bool,\n    multi_line: bool,\n    dot_matches_new_line: bool,\n    crlf: bool,\n    line_terminator: u8,\n    swap_greed: bool,\n    ignore_whitespace: bool,\n    unicode: bool,\n    utf8: bool,\n    nest_limit: u32,\n    octal: bool,\n}\n#[derive(Clone, Debug, Default)]\npub struct Config {\n    match_kind: Option<MatchKind>,\n    pre: Option<Option<Prefilter>>,\n}\n#[derive(Clone, Debug, Default)]\npub struct Config {\n    pre: Option<Option<Prefilter>>,\n    visited_capacity: Option<usize>,\n}\n#[derive(Clone, Debug, Default)]\npub struct Config {\n    match_kind: Option<MatchKind>,\n    starts_for_each_pattern: Option<bool>,\n    byte_classes: Option<bool>,\n    size_limit: Option<Option<usize>>,\n}\n#[derive(Clone, Debug, Default)]\npub struct Config {\n    match_kind: Option<MatchKind>,\n    pre: Option<Option<Prefilter>>,\n    starts_for_each_pattern: Option<bool>,\n    byte_classes: Option<bool>,\n    unicode_word_boundary: Option<bool>,\n    quitset: Option<ByteSet>,\n    specialize_start_states: Option<bool>,\n    cache_capacity: Option<usize>,\n    skip_cache_capacity_check: Option<bool>,\n    minimum_cache_clear_count: Option<Option<usize>>,\n    minimum_bytes_per_state: Option<Option<usize>>,\n}\n#[derive(Clone, Debug)]\npub struct Config {\n    look_behind: Option<u8>,\n    anchored: Anchored,\n}\nimpl PikeVM {\n    #[inline]\n    pub fn search(&self, cache: &mut Cache, input: &Input<'_>, caps: &mut Captures) {}\n    #[inline]\n    pub fn search_slots(\n        &self,\n        cache: &mut Cache,\n        input: &Input<'_>,\n        slots: &mut [Option<NonMaxUsize>],\n    ) -> Option<PatternID> {}\n    #[inline(never)]\n    fn search_slots_imp(\n        &self,\n        cache: &mut Cache,\n        input: &Input<'_>,\n        slots: &mut [Option<NonMaxUsize>],\n    ) -> Option<HalfMatch> {}\n    #[inline]\n    pub fn which_overlapping_matches(\n        &self,\n        cache: &mut Cache,\n        input: &Input<'_>,\n        patset: &mut PatternSet,\n    ) {\n        self.which_overlapping_imp(cache, input, patset)\n    }\n}\n\nThe function to be tested is presented with each line formatted as 'line number + code':\n/// Writes the set of patterns that match anywhere in the given search\n/// configuration to `patset`. If multiple patterns match at the same\n/// position and this `PikeVM` was configured with [`MatchKind::All`]\n/// semantics, then all matching patterns are written to the given set.\n///\n/// Unless all of the patterns in this `PikeVM` are anchored, then\n/// generally speaking, this will visit every byte in the haystack.\n///\n/// This search routine *does not* clear the pattern set. This gives some\n/// flexibility to the caller (e.g., running multiple searches with the\n/// same pattern set), but does make the API bug-prone if you're reusing\n/// the same pattern set for multiple searches but intended them to be\n/// independent.\n///\n/// If a pattern ID matched but the given `PatternSet` does not have\n/// sufficient capacity to store it, then it is not inserted and silently\n/// dropped.\n///\n/// # Example\n///\n/// This example shows how to find all matching patterns in a haystack,\n/// even when some patterns match at the same position as other patterns.\n///\n/// ```\n/// # if cfg!(miri) { return Ok(()); } // miri takes too long\n/// use regex_automata::{\n///     nfa::thompson::pikevm::PikeVM,\n///     Input, MatchKind, PatternSet,\n/// };\n///\n/// let patterns = &[\n///     r\"\\w+\", r\"\\d+\", r\"\\pL+\", r\"foo\", r\"bar\", r\"barfoo\", r\"foobar\",\n/// ];\n/// let re = PikeVM::builder()\n///     .configure(PikeVM::config().match_kind(MatchKind::All))\n///     .build_many(patterns)?;\n/// let mut cache = re.create_cache();\n///\n/// let input = Input::new(\"foobar\");\n/// let mut patset = PatternSet::new(re.pattern_len());\n/// re.which_overlapping_matches(&mut cache, &input, &mut patset);\n/// let expected = vec![0, 2, 3, 4, 6];\n/// let got: Vec<usize> = patset.iter().map(|p| p.as_usize()).collect();\n/// assert_eq!(expected, got);\n///\n/// # Ok::<(), Box<dyn std::error::Error>>(())\n/// ```\n1208 pub fn which_overlapping_matches(\n1209     &self,\n1210     cache: &mut Cache,\n1211     input: &Input<'_>,\n1212     patset: &mut PatternSet,\n1213 ) {\n1214     self.which_overlapping_imp(cache, input, patset)\n1215 }\n\nThe path conditions that the generated test functions should satisfy are as follows:\n"
}