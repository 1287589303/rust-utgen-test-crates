{
  "system_pt": "As a software testing expert, please generate Rust test functions based on the following guidelines, focusing solely on constructing test inputs and calling the functions under test:\n1. Provide the code in plain text format, without explanations or Markdown.\n2. If the method under test belongs to a trait, construct appropriate structs within the test function, but avoid method overrides. If the method under test uses generics, instantiate them with suitable types based on the context.\n3. Generate test code with minimal scope: avoid creating external structures or implementations. Instead, define any necessary helper structures or implementations directly within the test function when required.\n4. Whenever possible, initialize the corresponding data structures using the initialization methods provided in the context.\n5. Ensure the generated function is fully implemented and can be compiled and executed directly without any missing parts.\n6. Create a minimal yet complete set of test functions, ensuring they adhere to all provided preconditions and cover boundary conditions, and reference the inferred test input conditions or ranges.\n7. Ensure the test inputs are designed to cover the inferred test input conditions or ranges as comprehensively as possible, with particular emphasis on boundary cases.\n8. Focus on crafting test inputs that effectively reveal potential bugs while meeting the specified requirements.\n9. Omit test oracles and assertions; concentrate on generating test inputs and function calls.\n10. Do not create a test module, but include intrinsic attributes like #[test] or #[should_panic] where necessary.\n",
  "static_pt": "The context for the focal function is as follows:\n// regex-automata/src/hybrid/dfa.rs\n// crate name is regex_automata\n#[cfg(feature = \"std\")]\ntype StateMap = std::collections::HashMap<State, LazyStateID>;\n#[cfg(not(feature = \"std\"))]\ntype StateMap = alloc::collections::BTreeMap<State, LazyStateID>;\nuse core::{iter, mem::size_of};\nuse alloc::vec::Vec;\nuse crate::{\n    hybrid::{\n        error::{BuildError, CacheError, StartError},\n        id::{LazyStateID, LazyStateIDError},\n        search,\n    },\n    nfa::thompson,\n    util::{\n        alphabet::{self, ByteClasses, ByteSet},\n        determinize::{self, State, StateBuilderEmpty, StateBuilderNFA},\n        empty, prefilter::Prefilter, primitives::{PatternID, StateID as NFAStateID},\n        search::{Anchored, HalfMatch, Input, MatchError, MatchKind, PatternSet},\n        sparse_set::SparseSets, start::{self, Start, StartByteMap},\n    },\n};\nconst MIN_STATES: usize = SENTINEL_STATES + 2;\nconst SENTINEL_STATES: usize = 3;\n#[derive(Clone)]\npub struct NFA(Arc<Inner>);\n#[derive(Clone, Eq, Hash, PartialEq, PartialOrd, Ord)]\npub(crate) struct State(Arc<[u8]>);\n#[derive(Clone, Copy)]\npub struct ByteClasses([u8; 256]);\n#[derive(Clone, Copy, Debug, Eq, PartialEq)]\npub(crate) enum Start {\n    /// This occurs when the starting position is not any of the ones below.\n    NonWordByte = 0,\n    /// This occurs when the byte immediately preceding the start of the search\n    /// is an ASCII word byte.\n    WordByte = 1,\n    /// This occurs when the starting position of the search corresponds to the\n    /// beginning of the haystack.\n    Text = 2,\n    /// This occurs when the byte immediately preceding the start of the search\n    /// is a line terminator. Specifically, `\\n`.\n    LineLF = 3,\n    /// This occurs when the byte immediately preceding the start of the search\n    /// is a line terminator. Specifically, `\\r`.\n    LineCR = 4,\n    /// This occurs when a custom line terminator has been set via a\n    /// `LookMatcher`, and when that line terminator is neither a `\\r` or a\n    /// `\\n`.\n    ///\n    /// If the custom line terminator is a word byte, then this start\n    /// configuration is still selected. DFAs that implement word boundary\n    /// assertions will likely need to check whether the custom line terminator\n    /// is a word byte, in which case, it should behave as if the byte\n    /// satisfies `\\b` in addition to multi-line anchors.\n    CustomLineTerminator = 5,\n}\n#[derive(Clone, Eq, PartialEq)]\npub enum State {\n    /// A state with a single transition that can only be taken if the current\n    /// input symbol is in a particular range of bytes.\n    ByteRange {\n        /// The transition from this state to the next.\n        trans: Transition,\n    },\n    /// A state with possibly many transitions represented in a sparse fashion.\n    /// Transitions are non-overlapping and ordered lexicographically by input\n    /// range.\n    ///\n    /// In practice, this is used for encoding UTF-8 automata. Its presence is\n    /// primarily an optimization that avoids many additional unconditional\n    /// epsilon transitions (via [`Union`](State::Union) states), and thus\n    /// decreases the overhead of traversing the NFA. This can improve both\n    /// matching time and DFA construction time.\n    Sparse(SparseTransitions),\n    /// A dense representation of a state with multiple transitions.\n    Dense(DenseTransitions),\n    /// A conditional epsilon transition satisfied via some sort of\n    /// look-around. Look-around is limited to anchor and word boundary\n    /// assertions.\n    ///\n    /// Look-around states are meant to be evaluated while performing epsilon\n    /// closure (computing the set of states reachable from a particular state\n    /// via only epsilon transitions). If the current position in the haystack\n    /// satisfies the look-around assertion, then you're permitted to follow\n    /// that epsilon transition.\n    Look {\n        /// The look-around assertion that must be satisfied before moving\n        /// to `next`.\n        look: Look,\n        /// The state to transition to if the look-around assertion is\n        /// satisfied.\n        next: StateID,\n    },\n    /// An alternation such that there exists an epsilon transition to all\n    /// states in `alternates`, where matches found via earlier transitions\n    /// are preferred over later transitions.\n    Union {\n        /// An ordered sequence of unconditional epsilon transitions to other\n        /// states. Transitions earlier in the sequence are preferred over\n        /// transitions later in the sequence.\n        alternates: Box<[StateID]>,\n    },\n    /// An alternation such that there exists precisely two unconditional\n    /// epsilon transitions, where matches found via `alt1` are preferred over\n    /// matches found via `alt2`.\n    ///\n    /// This state exists as a common special case of Union where there are\n    /// only two alternates. In this case, we don't need any allocations to\n    /// represent the state. This saves a bit of memory and also saves an\n    /// additional memory access when traversing the NFA.\n    BinaryUnion {\n        /// An unconditional epsilon transition to another NFA state. This\n        /// is preferred over `alt2`.\n        alt1: StateID,\n        /// An unconditional epsilon transition to another NFA state. Matches\n        /// reported via this transition should only be reported if no matches\n        /// were found by following `alt1`.\n        alt2: StateID,\n    },\n    /// An empty state that records a capture location.\n    ///\n    /// From the perspective of finite automata, this is precisely equivalent\n    /// to an unconditional epsilon transition, but serves the purpose of\n    /// instructing NFA simulations to record additional state when the finite\n    /// state machine passes through this epsilon transition.\n    ///\n    /// `slot` in this context refers to the specific capture group slot\n    /// offset that is being recorded. Each capturing group has two slots\n    /// corresponding to the start and end of the matching portion of that\n    /// group.\n    ///\n    /// The pattern ID and capture group index are also included in this state\n    /// in case they are useful. But mostly, all you'll need is `next` and\n    /// `slot`.\n    Capture {\n        /// The state to transition to, unconditionally.\n        next: StateID,\n        /// The pattern ID that this capture belongs to.\n        pattern_id: PatternID,\n        /// The capture group index that this capture belongs to. Capture group\n        /// indices are local to each pattern. For example, when capturing\n        /// groups are enabled, every pattern has a capture group at index\n        /// `0`.\n        group_index: SmallIndex,\n        /// The slot index for this capture. Every capturing group has two\n        /// slots: one for the start haystack offset and one for the end\n        /// haystack offset. Unlike capture group indices, slot indices are\n        /// global across all patterns in this NFA. That is, each slot belongs\n        /// to a single pattern, but there is only one slot at index `i`.\n        slot: SmallIndex,\n    },\n    /// A state that cannot be transitioned out of. This is useful for cases\n    /// where you want to prevent matching from occurring. For example, if your\n    /// regex parser permits empty character classes, then one could choose\n    /// a `Fail` state to represent them. (An empty character class can be\n    /// thought of as an empty set. Since nothing is in an empty set, they can\n    /// never match anything.)\n    Fail,\n    /// A match state. There is at least one such occurrence of this state for\n    /// each regex that can match that is in this NFA.\n    Match {\n        /// The matching pattern ID.\n        pattern_id: PatternID,\n    },\n}\nimpl Start {\n    pub(crate) fn from_usize(n: usize) -> Option<Start> {}\n    pub(crate) fn len() -> usize {\n        6\n    }\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    pub(crate) fn as_u8(&self) -> u8 {}\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    pub(crate) fn as_usize(&self) -> usize {}\n}\nimpl NFA {\n    #[cfg(feature = \"syntax\")]\n    pub fn new(pattern: &str) -> Result<NFA, BuildError> {}\n    #[cfg(feature = \"syntax\")]\n    pub fn new_many<P: AsRef<str>>(patterns: &[P]) -> Result<NFA, BuildError> {}\n    pub fn always_match() -> NFA {}\n    pub fn never_match() -> NFA {}\n    #[cfg(feature = \"syntax\")]\n    pub fn config() -> Config {}\n    #[cfg(feature = \"syntax\")]\n    pub fn compiler() -> Compiler {}\n    pub fn patterns(&self) -> PatternIter<'_> {}\n    #[inline]\n    pub fn pattern_len(&self) -> usize {\n        self.0.start_pattern.len()\n    }\n    #[inline]\n    pub fn start_anchored(&self) -> StateID {}\n    #[inline]\n    pub fn start_unanchored(&self) -> StateID {}\n    #[inline]\n    pub fn start_pattern(&self, pid: PatternID) -> Option<StateID> {}\n    #[inline]\n    pub(crate) fn byte_class_set(&self) -> &ByteClassSet {}\n    #[inline]\n    pub fn byte_classes(&self) -> &ByteClasses {}\n    #[inline]\n    pub fn state(&self, id: StateID) -> &State {}\n    #[inline]\n    pub fn states(&self) -> &[State] {\n        &self.0.states\n    }\n    #[inline]\n    pub fn group_info(&self) -> &GroupInfo {}\n    #[inline]\n    pub fn has_capture(&self) -> bool {}\n    #[inline]\n    pub fn has_empty(&self) -> bool {}\n    #[inline]\n    pub fn is_utf8(&self) -> bool {}\n    #[inline]\n    pub fn is_reverse(&self) -> bool {}\n    #[inline]\n    pub fn is_always_start_anchored(&self) -> bool {}\n    #[inline]\n    pub fn look_matcher(&self) -> &LookMatcher {}\n    #[inline]\n    pub fn look_set_any(&self) -> LookSet {}\n    #[inline]\n    pub fn look_set_prefix_any(&self) -> LookSet {}\n    #[inline]\n    pub fn memory_usage(&self) -> usize {}\n}\nimpl State {\n    pub(crate) fn dead() -> State {\n        StateBuilderEmpty::new().into_matches().into_nfa().to_state()\n    }\n    pub(crate) fn is_match(&self) -> bool {}\n    pub(crate) fn is_from_word(&self) -> bool {}\n    pub(crate) fn is_half_crlf(&self) -> bool {}\n    pub(crate) fn look_have(&self) -> LookSet {}\n    pub(crate) fn look_need(&self) -> LookSet {}\n    pub(crate) fn match_len(&self) -> usize {}\n    pub(crate) fn match_pattern(&self, index: usize) -> PatternID {}\n    pub(crate) fn match_pattern_ids(&self) -> Option<Vec<PatternID>> {}\n    #[cfg(all(test, not(miri)))]\n    pub(crate) fn iter_match_pattern_ids<F: FnMut(PatternID)>(&self, f: F) {}\n    pub(crate) fn iter_nfa_state_ids<F: FnMut(StateID)>(&self, f: F) {}\n    pub(crate) fn memory_usage(&self) -> usize {\n        self.0.len()\n    }\n    fn repr(&self) -> Repr<'_> {}\n}\nimpl ByteClasses {\n    #[inline]\n    pub fn empty() -> ByteClasses {}\n    #[inline]\n    pub fn singletons() -> ByteClasses {}\n    pub(crate) fn from_bytes(\n        slice: &[u8],\n    ) -> Result<(ByteClasses, usize), DeserializeError> {}\n    pub(crate) fn write_to(&self, mut dst: &mut [u8]) -> Result<usize, SerializeError> {}\n    pub(crate) fn write_to_len(&self) -> usize {}\n    #[inline]\n    pub fn set(&mut self, byte: u8, class: u8) {}\n    #[inline]\n    pub fn get(&self, byte: u8) -> u8 {}\n    #[inline]\n    pub fn get_by_unit(&self, unit: Unit) -> usize {}\n    #[inline]\n    pub fn eoi(&self) -> Unit {}\n    #[inline]\n    pub fn alphabet_len(&self) -> usize {}\n    #[inline]\n    pub fn stride2(&self) -> usize {\n        let zeros = self.alphabet_len().next_power_of_two().trailing_zeros();\n        usize::try_from(zeros).unwrap()\n    }\n    #[inline]\n    pub fn is_singleton(&self) -> bool {}\n    #[inline]\n    pub fn iter(&self) -> ByteClassIter<'_> {}\n    pub fn representatives<R: core::ops::RangeBounds<u8>>(\n        &self,\n        range: R,\n    ) -> ByteClassRepresentatives<'_> {}\n    #[inline]\n    pub fn elements(&self, class: Unit) -> ByteClassElements {}\n    fn element_ranges(&self, class: Unit) -> ByteClassElementRanges {}\n}\nfn minimum_cache_capacity(\n    nfa: &thompson::NFA,\n    classes: &ByteClasses,\n    starts_for_each_pattern: bool,\n) -> usize {\n    const ID_SIZE: usize = size_of::<LazyStateID>();\n    const STATE_SIZE: usize = size_of::<State>();\n    let stride = 1 << classes.stride2();\n    let states_len = nfa.states().len();\n    let sparses = 2 * states_len * NFAStateID::SIZE;\n    let trans = MIN_STATES * stride * ID_SIZE;\n    let mut starts = Start::len() * ID_SIZE;\n    if starts_for_each_pattern {\n        starts += (Start::len() * nfa.pattern_len()) * ID_SIZE;\n    }\n    assert!(MIN_STATES >= 5, \"minimum number of states has to be at least 5\");\n    let non_sentinel = MIN_STATES.checked_sub(SENTINEL_STATES).unwrap();\n    let dead_state_size = State::dead().memory_usage();\n    let max_state_size = 5 + 4 + (nfa.pattern_len() * 4) + (states_len * 5);\n    let states = (SENTINEL_STATES * (STATE_SIZE + dead_state_size))\n        + (non_sentinel * (STATE_SIZE + max_state_size));\n    let states_to_sid = (MIN_STATES * STATE_SIZE) + (MIN_STATES * ID_SIZE);\n    let stack = states_len * NFAStateID::SIZE;\n    let scratch_state_builder = max_state_size;\n    trans + starts + states + states_to_sid + sparses + stack + scratch_state_builder\n}\n\nThe function to be tested is presented with each line formatted as 'line number + code':\n/// Based on the minimum number of states required for a useful lazy DFA cache,\n/// this returns a heuristic minimum number of bytes of heap space required.\n///\n/// This is a \"heuristic\" because the minimum it returns is likely bigger than\n/// the true minimum. Namely, it assumes that each powerset NFA/DFA state uses\n/// the maximum number of NFA states (all of them). This is likely bigger\n/// than what is required in practice. Computing the true minimum effectively\n/// requires determinization, which is probably too much work to do for a\n/// simple check like this.\n///\n/// One of the issues with this approach IMO is that it requires that this\n/// be in sync with the calculation above for computing how much heap memory\n/// the DFA cache uses. If we get it wrong, it's possible for example for the\n/// minimum to be smaller than the computed heap memory, and thus, it may be\n/// the case that we can't add the required minimum number of states. That in\n/// turn will make lazy DFA panic because we assume that we can add at least a\n/// minimum number of states.\n///\n/// Another approach would be to always allow the minimum number of states to\n/// be added to the lazy DFA cache, even if it exceeds the configured cache\n/// limit. This does mean that the limit isn't really a limit in all cases,\n/// which is unfortunate. But it does at least guarantee that the lazy DFA can\n/// always make progress, even if it is slow. (This approach is very similar to\n/// enabling the 'skip_cache_capacity_check' config knob, except it wouldn't\n/// rely on cache size calculation. Instead, it would just always permit a\n/// minimum number of states to be added.)\n4319 fn minimum_cache_capacity(\n4320     nfa: &thompson::NFA,\n4321     classes: &ByteClasses,\n4322     starts_for_each_pattern: bool,\n4323 ) -> usize {\n4324     const ID_SIZE: usize = size_of::<LazyStateID>();\n4325     const STATE_SIZE: usize = size_of::<State>();\n4326 \n4327     let stride = 1 << classes.stride2();\n4328     let states_len = nfa.states().len();\n4329     let sparses = 2 * states_len * NFAStateID::SIZE;\n4330     let trans = MIN_STATES * stride * ID_SIZE;\n4331 \n4332     let mut starts = Start::len() * ID_SIZE;\n4333     if starts_for_each_pattern {\n4334         starts += (Start::len() * nfa.pattern_len()) * ID_SIZE;\n4335     }\n4336 \n4337     // The min number of states HAS to be at least 4: we have 3 sentinel states\n4338     // and then we need space for one more when we save a state after clearing\n4339     // the cache. We also need space for one more, otherwise we get stuck in a\n4340     // loop where we try to add a 5th state, which gets rejected, which clears\n4341     // the cache, which adds back a saved state (4th total state) which then\n4342     // tries to add the 5th state again.\n4343     assert!(MIN_STATES >= 5, \"minimum number of states has to be at least 5\");\n4344     // The minimum number of non-sentinel states. We consider this separately\n4345     // because sentinel states are much smaller in that they contain no NFA\n4346     // states. Given our aggressive calculation here, it's worth being more\n4347     // precise with the number of states we need.\n4348     let non_sentinel = MIN_STATES.checked_sub(SENTINEL_STATES).unwrap();\n4349 \n4350     // Every `State` has 5 bytes for flags, 4 bytes (max) for the number of\n4351     // patterns, followed by 32-bit encodings of patterns and then delta\n4352     // varint encodings of NFA state IDs. We use the worst case (which isn't\n4353     // technically possible) of 5 bytes for each NFA state ID.\n4354     //\n4355     // HOWEVER, three of the states needed by a lazy DFA are just the sentinel\n4356     // unknown, dead and quit states. Those states have a known size and it is\n4357     // small.\n4358     let dead_state_size = State::dead().memory_usage();\n4359     let max_state_size = 5 + 4 + (nfa.pattern_len() * 4) + (states_len * 5);\n4360     let states = (SENTINEL_STATES * (STATE_SIZE + dead_state_size))\n4361         + (non_sentinel * (STATE_SIZE + max_state_size));\n4362     // NOTE: We don't double count heap memory used by State for this map since\n4363     // we use reference counting to avoid doubling memory usage. (This tends to\n4364     // be where most memory is allocated in the cache.)\n4365     let states_to_sid = (MIN_STATES * STATE_SIZE) + (MIN_STATES * ID_SIZE);\n4366     let stack = states_len * NFAStateID::SIZE;\n4367     let scratch_state_builder = max_state_size;\n4368 \n4369     trans\n4370         + starts\n4371         + states\n4372         + states_to_sid\n4373         + sparses\n4374         + stack\n4375         + scratch_state_builder\n4376 }\n\nGenerate each test function in such a manner that it concurrently satisfies all the following preconditions:\n",
  "depend_pt": ""
}