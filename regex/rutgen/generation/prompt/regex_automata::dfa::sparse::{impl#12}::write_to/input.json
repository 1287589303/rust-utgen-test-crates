{
  "system_pt": "As a software testing expert, infer the test input conditions or ranges based on the provided information. Follow these guidelines:\n1. Provide test input conditions or ranges in one line in plain text only, without additional explanations or Markdown formatting\n2. Analyze the function under test, context, preconditions, and expected return values or types to determine appropriate test input conditions or ranges\n3. The inferred test input conditions or ranges should comprehensively satisfy all provided preconditions simultaneously.\n4. Ensure the test input conditions or ranges cover boundary cases and edge scenarios\n",
  "static_pt": "The context for the focal function is as follows:\n// regex-automata/src/dfa/sparse.rs\n// crate name is regex_automata\n#[cfg(feature = \"dfa-build\")]\nuse core::iter;\nuse core::{fmt, mem::size_of};\n#[cfg(feature = \"dfa-build\")]\nuse alloc::{vec, vec::Vec};\n#[cfg(feature = \"dfa-build\")]\nuse crate::dfa::dense::{self, BuildError};\nuse crate::{\n    dfa::{\n        automaton::{fmt_state_indicator, Automaton, StartError},\n        dense::Flags, special::Special, StartKind, DEAD,\n    },\n    util::{\n        alphabet::{ByteClasses, ByteSet},\n        escape::DebugByte, int::{Pointer, Usize, U16, U32},\n        prefilter::Prefilter, primitives::{PatternID, StateID},\n        search::Anchored, start::{self, Start, StartByteMap},\n        wire::{self, DeserializeError, Endian, SerializeError},\n    },\n};\nconst LABEL: &str = \"rust-regex-automata-dfa-sparse\";\nconst VERSION: u32 = 2;\n#[derive(Clone)]\nstruct StartTable<T> {\n    /// The initial start state IDs as a contiguous table of native endian\n    /// encoded integers, represented by `S`.\n    ///\n    /// In practice, T is either Vec<u8> or &[u8] and has no alignment\n    /// requirements.\n    ///\n    /// The first `2 * stride` (currently always 8) entries always correspond\n    /// to the starts states for the entire DFA, with the first 4 entries being\n    /// for unanchored searches and the second 4 entries being for anchored\n    /// searches. To keep things simple, we always use 8 entries even if the\n    /// `StartKind` is not both.\n    ///\n    /// After that, there are `stride * patterns` state IDs, where `patterns`\n    /// may be zero in the case of a DFA with no patterns or in the case where\n    /// the DFA was built without enabling starting states for each pattern.\n    table: T,\n    /// The starting state configuration supported. When 'both', both\n    /// unanchored and anchored searches work. When 'unanchored', anchored\n    /// searches panic. When 'anchored', unanchored searches panic.\n    kind: StartKind,\n    /// The start state configuration for every possible byte.\n    start_map: StartByteMap,\n    /// The number of starting state IDs per pattern.\n    stride: usize,\n    /// The total number of patterns for which starting states are encoded.\n    /// This is `None` for DFAs that were built without start states for each\n    /// pattern. Thus, one cannot use this field to say how many patterns\n    /// are in the DFA in all cases. It is specific to how many patterns are\n    /// represented in this start table.\n    pattern_len: Option<usize>,\n    /// The universal starting state for unanchored searches. This is only\n    /// present when the DFA supports unanchored searches and when all starting\n    /// state IDs for an unanchored search are equivalent.\n    universal_start_unanchored: Option<StateID>,\n    /// The universal starting state for anchored searches. This is only\n    /// present when the DFA supports anchored searches and when all starting\n    /// state IDs for an anchored search are equivalent.\n    universal_start_anchored: Option<StateID>,\n}\n#[derive(Debug)]\npub struct SerializeError {\n    /// The name of the thing that a buffer is too small for.\n    ///\n    /// Currently, the only kind of serialization error is one that is\n    /// committed by a caller: providing a destination buffer that is too\n    /// small to fit the serialized object. This makes sense conceptually,\n    /// since every valid inhabitant of a type should be serializable.\n    ///\n    /// This is somewhat exposed in the public API of this crate. For example,\n    /// the `to_bytes_{big,little}_endian` APIs return a `Vec<u8>` and are\n    /// guaranteed to never panic or error. This is only possible because the\n    /// implementation guarantees that it will allocate a `Vec<u8>` that is\n    /// big enough.\n    ///\n    /// In summary, if a new serialization error kind needs to be added, then\n    /// it will need careful consideration.\n    what: &'static str,\n}\n#[derive(Clone)]\npub(crate) struct StartByteMap {\n    map: [Start; 256],\n}\nstruct StartStateIter<'a, T> {\n    st: &'a StartTable<T>,\n    i: usize,\n}\n#[derive(Clone, Copy, Default, Eq, Hash, PartialEq, PartialOrd, Ord)]\n#[repr(transparent)]\npub struct StateID(SmallIndex);\n#[derive(Clone, Copy, Debug, Eq, PartialEq)]\npub enum StartKind {\n    /// Support both anchored and unanchored searches.\n    Both,\n    /// Support only unanchored searches. Requesting an anchored search will\n    /// panic.\n    ///\n    /// Note that even if an unanchored search is requested, the pattern itself\n    /// may still be anchored. For example, `^abc` will only match `abc` at the\n    /// start of a haystack. This will remain true, even if the regex engine\n    /// only supported unanchored searches.\n    Unanchored,\n    /// Support only anchored searches. Requesting an unanchored search will\n    /// panic.\n    Anchored,\n}\n#[derive(Clone, Copy, Debug, Eq, PartialEq)]\npub enum Anchored {\n    /// Run an unanchored search. This means a match may occur anywhere at or\n    /// after the start position of the search.\n    ///\n    /// This search can return a match for any pattern in the regex.\n    No,\n    /// Run an anchored search. This means that a match must begin at the\n    /// start position of the search.\n    ///\n    /// This search can return a match for any pattern in the regex.\n    Yes,\n    /// Run an anchored search for a specific pattern. This means that a match\n    /// must be for the given pattern and must begin at the start position of\n    /// the search.\n    Pattern(PatternID),\n}\n#[derive(Clone, Copy, Debug, Eq, PartialEq)]\npub(crate) enum Start {\n    /// This occurs when the starting position is not any of the ones below.\n    NonWordByte = 0,\n    /// This occurs when the byte immediately preceding the start of the search\n    /// is an ASCII word byte.\n    WordByte = 1,\n    /// This occurs when the starting position of the search corresponds to the\n    /// beginning of the haystack.\n    Text = 2,\n    /// This occurs when the byte immediately preceding the start of the search\n    /// is a line terminator. Specifically, `\\n`.\n    LineLF = 3,\n    /// This occurs when the byte immediately preceding the start of the search\n    /// is a line terminator. Specifically, `\\r`.\n    LineCR = 4,\n    /// This occurs when a custom line terminator has been set via a\n    /// `LookMatcher`, and when that line terminator is neither a `\\r` or a\n    /// `\\n`.\n    ///\n    /// If the custom line terminator is a word byte, then this start\n    /// configuration is still selected. DFAs that implement word boundary\n    /// assertions will likely need to check whether the custom line terminator\n    /// is a word byte, in which case, it should behave as if the byte\n    /// satisfies `\\b` in addition to multi-line anchors.\n    CustomLineTerminator = 5,\n}\nimpl<T: AsRef<[u8]>> StartTable<T> {\n    fn write_to<E: Endian>(&self, mut dst: &mut [u8]) -> Result<usize, SerializeError> {\n        let nwrite = self.write_to_len();\n        if dst.len() < nwrite {\n            return Err(SerializeError::buffer_too_small(\"sparse starting table ids\"));\n        }\n        dst = &mut dst[..nwrite];\n        let nw = self.kind.write_to::<E>(dst)?;\n        dst = &mut dst[nw..];\n        let nw = self.start_map.write_to(dst)?;\n        dst = &mut dst[nw..];\n        E::write_u32(u32::try_from(self.stride).unwrap(), dst);\n        dst = &mut dst[size_of::<u32>()..];\n        E::write_u32(\n            u32::try_from(self.pattern_len.unwrap_or(0xFFFF_FFFF)).unwrap(),\n            dst,\n        );\n        dst = &mut dst[size_of::<u32>()..];\n        E::write_u32(\n            self.universal_start_unanchored.map_or(u32::MAX, |sid| sid.as_u32()),\n            dst,\n        );\n        dst = &mut dst[size_of::<u32>()..];\n        E::write_u32(\n            self.universal_start_anchored.map_or(u32::MAX, |sid| sid.as_u32()),\n            dst,\n        );\n        dst = &mut dst[size_of::<u32>()..];\n        for (sid, _, _) in self.iter() {\n            E::write_u32(sid.as_u32(), dst);\n            dst = &mut dst[StateID::SIZE..];\n        }\n        Ok(nwrite)\n    }\n    fn write_to_len(&self) -> usize {\n        self.kind.write_to_len() + self.start_map.write_to_len() + size_of::<u32>()\n            + size_of::<u32>() + size_of::<u32>() + size_of::<u32>() + self.table().len()\n    }\n    fn validate(&self, sp: &Special, seen: &Seen) -> Result<(), DeserializeError> {}\n    fn as_ref(&self) -> StartTable<&'_ [u8]> {}\n    #[cfg(feature = \"alloc\")]\n    fn to_owned(&self) -> StartTable<alloc::vec::Vec<u8>> {}\n    fn start(&self, anchored: Anchored, start: Start) -> Result<StateID, StartError> {}\n    fn iter(&self) -> StartStateIter<'_, T> {\n        StartStateIter { st: self, i: 0 }\n    }\n    fn len(&self) -> usize {}\n    fn table(&self) -> &[u8] {}\n    fn memory_usage(&self) -> usize {}\n}\nimpl StartKind {\n    pub(crate) fn from_bytes(\n        slice: &[u8],\n    ) -> Result<(StartKind, usize), DeserializeError> {}\n    pub(crate) fn write_to<E: Endian>(\n        &self,\n        dst: &mut [u8],\n    ) -> Result<usize, SerializeError> {\n        let nwrite = self.write_to_len();\n        if dst.len() < nwrite {\n            return Err(SerializeError::buffer_too_small(\"start kind\"));\n        }\n        let n = match *self {\n            StartKind::Both => 0,\n            StartKind::Unanchored => 1,\n            StartKind::Anchored => 2,\n        };\n        E::write_u32(n, dst);\n        Ok(nwrite)\n    }\n    pub(crate) fn write_to_len(&self) -> usize {}\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    pub(crate) fn has_unanchored(&self) -> bool {}\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    pub(crate) fn has_anchored(&self) -> bool {}\n}\nimpl SerializeError {\n    pub(crate) fn buffer_too_small(what: &'static str) -> SerializeError {\n        SerializeError { what }\n    }\n}\nimpl StartByteMap {\n    pub(crate) fn new(lookm: &LookMatcher) -> StartByteMap {}\n    #[cfg_attr(feature = \"perf-inline\", inline(always))]\n    pub(crate) fn get(&self, byte: u8) -> Start {}\n    pub(crate) fn from_bytes(\n        slice: &[u8],\n    ) -> Result<(StartByteMap, usize), DeserializeError> {}\n    pub(crate) fn write_to(&self, dst: &mut [u8]) -> Result<usize, SerializeError> {\n        let nwrite = self.write_to_len();\n        if dst.len() < nwrite {\n            return Err(SerializeError::buffer_too_small(\"start byte map\"));\n        }\n        for (i, &start) in self.map.iter().enumerate() {\n            dst[i] = start.as_u8();\n        }\n        Ok(nwrite)\n    }\n    pub(crate) fn write_to_len(&self) -> usize {}\n}\n\nThe function to be tested is presented with each line formatted as 'line number + code':\n1953 fn write_to<E: Endian>(\n1954     &self,\n1955     mut dst: &mut [u8],\n1956 ) -> Result<usize, SerializeError> {\n1957     let nwrite = self.write_to_len();\n1958     if dst.len() < nwrite {\n1959         return Err(SerializeError::buffer_too_small(\n1960             \"sparse starting table ids\",\n1961         ));\n1962     }\n1963     dst = &mut dst[..nwrite];\n1964 \n1965     // write start kind\n1966     let nw = self.kind.write_to::<E>(dst)?;\n1967     dst = &mut dst[nw..];\n1968     // write start byte map\n1969     let nw = self.start_map.write_to(dst)?;\n1970     dst = &mut dst[nw..];\n1971     // write stride\n1972     E::write_u32(u32::try_from(self.stride).unwrap(), dst);\n1973     dst = &mut dst[size_of::<u32>()..];\n1974     // write pattern length\n1975     E::write_u32(\n1976         u32::try_from(self.pattern_len.unwrap_or(0xFFFF_FFFF)).unwrap(),\n1977         dst,\n1978     );\n1979     dst = &mut dst[size_of::<u32>()..];\n1980     // write universal start unanchored state id, u32::MAX if absent\n1981     E::write_u32(\n1982         self.universal_start_unanchored\n1983             .map_or(u32::MAX, |sid| sid.as_u32()),\n1984         dst,\n1985     );\n1986     dst = &mut dst[size_of::<u32>()..];\n1987     // write universal start anchored state id, u32::MAX if absent\n1988     E::write_u32(\n1989         self.universal_start_anchored.map_or(u32::MAX, |sid| sid.as_u32()),\n1990         dst,\n1991     );\n1992     dst = &mut dst[size_of::<u32>()..];\n1993     // write start IDs\n1994     for (sid, _, _) in self.iter() {\n1995         E::write_u32(sid.as_u32(), dst);\n1996         dst = &mut dst[StateID::SIZE..];\n1997     }\n1998     Ok(nwrite)\n1999 }\n\nWhen inferring test input conditions or ranges, consider the following preconditions and expected return values or types:\n"
}