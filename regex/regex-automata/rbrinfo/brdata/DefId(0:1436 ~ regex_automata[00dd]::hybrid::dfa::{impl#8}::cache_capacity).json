{
  "name": "regex_automata::hybrid::dfa::{impl#8}::cache_capacity",
  "mod_info": {
    "name": "hybrid::dfa",
    "loc": "regex-automata/src/hybrid/mod.rs:140:1:140:13"
  },
  "visible": true,
  "loc": "regex-automata/src/hybrid/dfa.rs:3506:5:3509:6",
  "doc": "/// Sets the maximum amount of heap memory, in bytes, to allocate to the\n/// cache for use during a lazy DFA search. If the lazy DFA would otherwise\n/// use more heap memory, then, depending on other configuration knobs,\n/// either stop the search and return an error or clear the cache and\n/// continue the search.\n///\n/// The default cache capacity is some \"reasonable\" number that will\n/// accommodate most regular expressions. You may find that if you need\n/// to build a large DFA then it may be necessary to increase the cache\n/// capacity.\n///\n/// Note that while building a lazy DFA will do a \"minimum\" check to ensure\n/// the capacity is big enough, this is more or less about correctness.\n/// If the cache is bigger than the minimum but still \"too small,\" then the\n/// lazy DFA could wind up spending a lot of time clearing the cache and\n/// recomputing transitions, thus negating the performance benefits of a\n/// lazy DFA. Thus, setting the cache capacity is mostly an experimental\n/// endeavor. For most common patterns, however, the default should be\n/// sufficient.\n///\n/// For more details on how the lazy DFA's cache is used, see the\n/// documentation for [`Cache`].\n///\n/// # Example\n///\n/// This example shows what happens if the configured cache capacity is\n/// too small. In such cases, one can override the cache capacity to make\n/// it bigger. Alternatively, one might want to use less memory by setting\n/// a smaller cache capacity.\n///\n/// ```\n/// # if cfg!(miri) { return Ok(()); } // miri takes too long\n/// use regex_automata::{hybrid::dfa::DFA, HalfMatch, Input};\n///\n/// let pattern = r\"\\p{L}{1000}\";\n///\n/// // The default cache capacity is likely too small to deal with regexes\n/// // that are very large. Large repetitions of large Unicode character\n/// // classes are a common way to make very large regexes.\n/// let _ = DFA::new(pattern).unwrap_err();\n/// // Bump up the capacity to something bigger.\n/// let dfa = DFA::builder()\n///     .configure(DFA::config().cache_capacity(100 * (1<<20))) // 100 MB\n///     .build(pattern)?;\n/// let mut cache = dfa.create_cache();\n///\n/// let haystack = \"ͰͲͶͿΆΈΉΊΌΎΏΑΒΓΔΕΖΗΘΙ\".repeat(50);\n/// let expected = Some(HalfMatch::must(0, 2000));\n/// let got = dfa.try_search_fwd(&mut cache, &Input::new(&haystack))?;\n/// assert_eq!(expected, got);\n///\n/// # Ok::<(), Box<dyn std::error::Error>>(())\n/// ```\n",
  "code": [
    "pub fn cache_capacity(mut self, bytes: usize) -> Config {",
    "    self.cache_capacity = Some(bytes);",
    "    self",
    "}"
  ],
  "size": {
    "chain": 1,
    "contra": 0,
    "min_set": 1
  },
  "cond_chains": [
    {
      "id": 1,
      "conds": [],
      "ret": "self",
      "path": [
        0,
        1
      ],
      "may_contra": false,
      "min_set": true
    }
  ]
}