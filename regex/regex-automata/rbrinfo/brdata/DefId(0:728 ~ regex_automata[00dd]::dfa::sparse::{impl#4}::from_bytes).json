{
  "name": "regex_automata::dfa::sparse::{impl#4}::from_bytes",
  "mod_info": {
    "name": "dfa::sparse",
    "loc": "regex-automata/src/dfa/mod.rs:343:1:343:16"
  },
  "visible": true,
  "loc": "regex-automata/src/dfa/sparse.rs:984:5:996:6",
  "doc": "/// Safely deserialize a sparse DFA with a specific state identifier\n/// representation. Upon success, this returns both the deserialized DFA\n/// and the number of bytes read from the given slice. Namely, the contents\n/// of the slice beyond the DFA are not read.\n///\n/// Deserializing a DFA using this routine will never allocate heap memory.\n/// For safety purposes, the DFA's transitions will be verified such that\n/// every transition points to a valid state. If this verification is too\n/// costly, then a [`DFA::from_bytes_unchecked`] API is provided, which\n/// will always execute in constant time.\n///\n/// The bytes given must be generated by one of the serialization APIs\n/// of a `DFA` using a semver compatible release of this crate. Those\n/// include:\n///\n/// * [`DFA::to_bytes_little_endian`]\n/// * [`DFA::to_bytes_big_endian`]\n/// * [`DFA::to_bytes_native_endian`]\n/// * [`DFA::write_to_little_endian`]\n/// * [`DFA::write_to_big_endian`]\n/// * [`DFA::write_to_native_endian`]\n///\n/// The `to_bytes` methods allocate and return a `Vec<u8>` for you. The\n/// `write_to` methods do not allocate and write to an existing slice\n/// (which may be on the stack). Since deserialization always uses the\n/// native endianness of the target platform, the serialization API you use\n/// should match the endianness of the target platform. (It's often a good\n/// idea to generate serialized DFAs for both forms of endianness and then\n/// load the correct one based on endianness.)\n///\n/// # Errors\n///\n/// Generally speaking, it's easier to state the conditions in which an\n/// error is _not_ returned. All of the following must be true:\n///\n/// * The bytes given must be produced by one of the serialization APIs\n///   on this DFA, as mentioned above.\n/// * The endianness of the target platform matches the endianness used to\n///   serialized the provided DFA.\n///\n/// If any of the above are not true, then an error will be returned.\n///\n/// Note that unlike deserializing a [`dense::DFA`], deserializing a sparse\n/// DFA has no alignment requirements. That is, an alignment of `1` is\n/// valid.\n///\n/// # Panics\n///\n/// This routine will never panic for any input.\n///\n/// # Example\n///\n/// This example shows how to serialize a DFA to raw bytes, deserialize it\n/// and then use it for searching.\n///\n/// ```\n/// use regex_automata::{dfa::{Automaton, sparse::DFA}, HalfMatch, Input};\n///\n/// let initial = DFA::new(\"foo[0-9]+\")?;\n/// let bytes = initial.to_bytes_native_endian();\n/// let dfa: DFA<&[u8]> = DFA::from_bytes(&bytes)?.0;\n///\n/// let expected = Some(HalfMatch::must(0, 8));\n/// assert_eq!(expected, dfa.try_search_fwd(&Input::new(\"foo12345\"))?);\n/// # Ok::<(), Box<dyn std::error::Error>>(())\n/// ```\n///\n/// # Example: loading a DFA from static memory\n///\n/// One use case this library supports is the ability to serialize a\n/// DFA to disk and then use `include_bytes!` to store it in a compiled\n/// Rust program. Those bytes can then be cheaply deserialized into a\n/// `DFA` structure at runtime and used for searching without having to\n/// re-compile the DFA (which can be quite costly).\n///\n/// We can show this in two parts. The first part is serializing the DFA to\n/// a file:\n///\n/// ```no_run\n/// use regex_automata::dfa::sparse::DFA;\n///\n/// let dfa = DFA::new(\"foo[0-9]+\")?;\n///\n/// // Write a big endian serialized version of this DFA to a file.\n/// let bytes = dfa.to_bytes_big_endian();\n/// std::fs::write(\"foo.bigendian.dfa\", &bytes)?;\n///\n/// // Do it again, but this time for little endian.\n/// let bytes = dfa.to_bytes_little_endian();\n/// std::fs::write(\"foo.littleendian.dfa\", &bytes)?;\n/// # Ok::<(), Box<dyn std::error::Error>>(())\n/// ```\n///\n/// And now the second part is embedding the DFA into the compiled program\n/// and deserializing it at runtime on first use. We use conditional\n/// compilation to choose the correct endianness. We do not need to employ\n/// any special tricks to ensure a proper alignment, since a sparse DFA has\n/// no alignment requirements.\n///\n/// ```no_run\n/// use regex_automata::{\n///     dfa::{Automaton, sparse::DFA},\n///     util::lazy::Lazy,\n///     HalfMatch, Input,\n/// };\n///\n/// // This crate provides its own \"lazy\" type, kind of like\n/// // lazy_static! or once_cell::sync::Lazy. But it works in no-alloc\n/// // no-std environments and let's us write this using completely\n/// // safe code.\n/// static RE: Lazy<DFA<&'static [u8]>> = Lazy::new(|| {\n///     # const _: &str = stringify! {\n///     #[cfg(target_endian = \"big\")]\n///     static BYTES: &[u8] = include_bytes!(\"foo.bigendian.dfa\");\n///     #[cfg(target_endian = \"little\")]\n///     static BYTES: &[u8] = include_bytes!(\"foo.littleendian.dfa\");\n///     # };\n///     # static BYTES: &[u8] = b\"\";\n///\n///     let (dfa, _) = DFA::from_bytes(BYTES)\n///         .expect(\"serialized DFA should be valid\");\n///     dfa\n/// });\n///\n/// let expected = Ok(Some(HalfMatch::must(0, 8)));\n/// assert_eq!(expected, RE.try_search_fwd(&Input::new(\"foo12345\")));\n/// ```\n///\n/// Alternatively, consider using\n/// [`lazy_static`](https://crates.io/crates/lazy_static)\n/// or\n/// [`once_cell`](https://crates.io/crates/once_cell),\n/// which will guarantee safety for you.\n",
  "code": [
    "pub fn from_bytes(",
    "    slice: &'a [u8],",
    ") -> Result<(DFA<&'a [u8]>, usize), DeserializeError> {",
    "    // SAFETY: This is safe because we validate both the sparse transitions",
    "    // (by trying to decode every state) and start state ID list below. If",
    "    // either validation fails, then we return an error.",
    "    let (dfa, nread) = unsafe { DFA::from_bytes_unchecked(slice)? };",
    "    let seen = dfa.tt.validate(&dfa.special)?;",
    "    dfa.st.validate(&dfa.special, &seen)?;",
    "    // N.B. dfa.special doesn't have a way to do unchecked deserialization,",
    "    // so it has already been validated.",
    "    Ok((dfa, nread))",
    "}"
  ],
  "size": {
    "chain": 4,
    "contra": 0,
    "min_set": 4
  },
  "cond_chains": [
    {
      "id": 1,
      "conds": [
        {
          "cond": "DFA::from_bytes_unchecked(slice)?",
          "norm": null,
          "value": "Err/None",
          "line": 990,
          "bound": null
        }
      ],
      "ret": null,
      "path": [
        0,
        1,
        2,
        4,
        6,
        7,
        34,
        35
      ],
      "may_contra": false,
      "min_set": true
    },
    {
      "id": 2,
      "conds": [
        {
          "cond": "DFA::from_bytes_unchecked(slice)?",
          "norm": null,
          "value": "Ok/Some",
          "line": 990,
          "bound": null
        },
        {
          "cond": "dfa.tt.validate(&dfa.special)?",
          "norm": null,
          "value": "Err/None",
          "line": 991,
          "bound": null
        }
      ],
      "ret": null,
      "path": [
        0,
        1,
        2,
        5,
        8,
        9,
        10,
        11,
        12,
        14,
        16,
        17,
        31,
        32,
        33,
        35
      ],
      "may_contra": false,
      "min_set": true
    },
    {
      "id": 3,
      "conds": [
        {
          "cond": "DFA::from_bytes_unchecked(slice)?",
          "norm": null,
          "value": "Ok/Some",
          "line": 990,
          "bound": null
        },
        {
          "cond": "dfa.tt.validate(&dfa.special)?",
          "norm": null,
          "value": "Ok/Some",
          "line": 991,
          "bound": null
        },
        {
          "cond": "dfa.st.validate(&dfa.special, &seen)?",
          "norm": null,
          "value": "Err/None",
          "line": 992,
          "bound": null
        }
      ],
      "ret": null,
      "path": [
        0,
        1,
        2,
        5,
        8,
        9,
        10,
        11,
        12,
        15,
        18,
        19,
        20,
        21,
        23,
        25,
        26,
        32,
        33,
        35
      ],
      "may_contra": false,
      "min_set": true
    },
    {
      "id": 4,
      "conds": [
        {
          "cond": "DFA::from_bytes_unchecked(slice)?",
          "norm": null,
          "value": "Ok/Some",
          "line": 990,
          "bound": null
        },
        {
          "cond": "dfa.tt.validate(&dfa.special)?",
          "norm": null,
          "value": "Ok/Some",
          "line": 991,
          "bound": null
        },
        {
          "cond": "dfa.st.validate(&dfa.special, &seen)?",
          "norm": null,
          "value": "Ok/Some",
          "line": 992,
          "bound": null
        }
      ],
      "ret": "Ok((dfa, nread))",
      "path": [
        0,
        1,
        2,
        5,
        8,
        9,
        10,
        11,
        12,
        15,
        18,
        19,
        20,
        21,
        24,
        27,
        28,
        29,
        30,
        35
      ],
      "may_contra": false,
      "min_set": true
    }
  ]
}