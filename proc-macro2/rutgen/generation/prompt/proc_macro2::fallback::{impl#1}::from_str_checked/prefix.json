{
  "system_pt": "As a software testing expert, please generate Rust test functions based on the following guidelines, focusing solely on constructing test inputs and calling the functions under test:\n1. Provide the code in plain text format, without explanations or Markdown.\n2. If the method under test belongs to a trait, construct appropriate structs within the test function, but avoid method overrides. If the method under test uses generics, instantiate them with suitable types based on the context.\n3. Generate test code with minimal scope: avoid creating external structures or implementations. Instead, define any necessary helper structures or implementations directly within the test function when required.\n4. Whenever possible, initialize the corresponding data structures using the initialization methods provided in the context.\n5. Ensure the generated function is fully implemented and can be compiled and executed directly without any missing parts.\n6. Create a minimal yet complete set of test functions, ensuring they adhere to all provided preconditions and cover boundary conditions, and reference the inferred test input conditions or ranges.\n7. Ensure the test inputs are designed to cover the inferred test input conditions or ranges as comprehensively as possible, with particular emphasis on boundary cases.\n8. Focus on crafting test inputs that effectively reveal potential bugs while meeting the specified requirements.\n9. Omit test oracles and assertions; concentrate on generating test inputs and function calls.\n10. Do not create a test module, but include intrinsic attributes like #[test] or #[should_panic] where necessary.\n",
  "static_pt": "The context for the focal function is as follows:\n// src/fallback.rs\n// crate name is proc_macro2\npub(crate) type TokenTreeIter = RcVecIntoIter<TokenTree>;\n#[cfg(wrap_proc_macro)]\nuse crate::imp;\n#[cfg(span_locations)]\nuse crate::location::LineColumn;\nuse crate::parse::{self, Cursor};\nuse crate::rcvec::{RcVec, RcVecBuilder, RcVecIntoIter, RcVecMut};\nuse crate::{Delimiter, Spacing, TokenTree};\n#[cfg(all(span_locations, not(fuzzing)))]\nuse alloc::collections::BTreeMap;\n#[cfg(all(span_locations, not(fuzzing)))]\nuse core::cell::RefCell;\n#[cfg(span_locations)]\nuse core::cmp;\nuse core::fmt::{self, Debug, Display, Write};\nuse core::mem::ManuallyDrop;\n#[cfg(span_locations)]\nuse core::ops::Range;\nuse core::ops::RangeBounds;\nuse core::ptr;\nuse core::str;\n#[cfg(feature = \"proc-macro\")]\nuse core::str::FromStr;\nuse std::ffi::CStr;\n#[cfg(wrap_proc_macro)]\nuse std::panic;\n#[cfg(procmacro2_semver_exempt)]\nuse std::path::PathBuf;\n#[derive(Clone)]\npub(crate) struct TokenStream {\n    inner: RcVec<TokenTree>,\n}\n#[derive(Copy, Clone, Eq, PartialEq)]\npub(crate) struct Cursor<'a> {\n    pub(crate) rest: &'a str,\n    #[cfg(span_locations)]\n    pub(crate) off: u32,\n}\npub(crate) struct RcVec<T> {\n    inner: Rc<Vec<T>>,\n}\n#[derive(Debug)]\npub(crate) struct LexError {\n    pub(crate) span: Span,\n}\n#[derive(Clone)]\npub enum TokenTree {\n    /// A token stream surrounded by bracket delimiters.\n    Group(Group),\n    /// An identifier.\n    Ident(Ident),\n    /// A single punctuation character (`+`, `,`, `$`, etc.).\n    Punct(Punct),\n    /// A literal character (`'a'`), string (`\"hello\"`), number (`2.3`), etc.\n    Literal(Literal),\n}\nimpl TokenStream {\n    pub(crate) fn new() -> Self {\n        TokenStream {\n            inner: RcVecBuilder::new().build(),\n        }\n    }\n    pub(crate) fn from_str_checked(src: &str) -> Result<Self, LexError> {\n        let mut cursor = get_cursor(src);\n        const BYTE_ORDER_MARK: &str = \"\\u{feff}\";\n        if cursor.starts_with(BYTE_ORDER_MARK) {\n            cursor = cursor.advance(BYTE_ORDER_MARK.len());\n        }\n        parse::token_stream(cursor)\n    }\n    #[cfg(feature = \"proc-macro\")]\n    pub(crate) fn from_str_unchecked(src: &str) -> Self {\n        Self::from_str_checked(src).unwrap()\n    }\n    pub(crate) fn is_empty(&self) -> bool {}\n    fn take_inner(self) -> RcVecBuilder<TokenTree> {}\n}\nimpl<'a> Cursor<'a> {\n    pub(crate) fn advance(&self, bytes: usize) -> Cursor<'a> {\n        let (_front, rest) = self.rest.split_at(bytes);\n        Cursor {\n            rest,\n            #[cfg(span_locations)]\n            off: self.off + _front.chars().count() as u32,\n        }\n    }\n    pub(crate) fn starts_with(&self, s: &str) -> bool {\n        self.rest.starts_with(s)\n    }\n    pub(crate) fn starts_with_char(&self, ch: char) -> bool {}\n    pub(crate) fn starts_with_fn<Pattern>(&self, f: Pattern) -> bool\n    where\n        Pattern: FnMut(char) -> bool,\n    {}\n    pub(crate) fn is_empty(&self) -> bool {}\n    fn len(&self) -> usize {}\n    fn as_bytes(&self) -> &'a [u8] {}\n    fn bytes(&self) -> Bytes<'a> {}\n    fn chars(&self) -> Chars<'a> {}\n    fn char_indices(&self) -> CharIndices<'a> {}\n    fn parse(&self, tag: &str) -> Result<Cursor<'a>, Reject> {}\n}\n#[cfg(not(span_locations))]\nfn get_cursor(src: &str) -> Cursor {\n    Cursor { rest: src }\n}\npub(crate) fn token_stream(mut input: Cursor) -> Result<TokenStream, LexError> {\n    let mut trees = TokenStreamBuilder::new();\n    let mut stack = Vec::new();\n    loop {\n        input = skip_whitespace(input);\n        if let Ok((rest, ())) = doc_comment(input, &mut trees) {\n            input = rest;\n            continue;\n        }\n        #[cfg(span_locations)]\n        let lo = input.off;\n        let first = match input.bytes().next() {\n            Some(first) => first,\n            None => {\n                match stack.last() {\n                    None => return Ok(trees.build()),\n                    #[cfg(span_locations)]\n                    Some((lo, _frame)) => {\n                        return Err(LexError {\n                            span: Span { lo: *lo, hi: *lo },\n                        });\n                    }\n                    #[cfg(not(span_locations))]\n                    Some(_frame) => return Err(LexError { span: Span {} }),\n                }\n            }\n        };\n        if let Some(open_delimiter) = match first {\n            b'(' if !input.starts_with(ERROR) => Some(Delimiter::Parenthesis),\n            b'[' => Some(Delimiter::Bracket),\n            b'{' => Some(Delimiter::Brace),\n            _ => None,\n        } {\n            input = input.advance(1);\n            let frame = (open_delimiter, trees);\n            #[cfg(span_locations)]\n            let frame = (lo, frame);\n            stack.push(frame);\n            trees = TokenStreamBuilder::new();\n        } else if let Some(close_delimiter) = match first {\n            b')' => Some(Delimiter::Parenthesis),\n            b']' => Some(Delimiter::Bracket),\n            b'}' => Some(Delimiter::Brace),\n            _ => None,\n        } {\n            let frame = match stack.pop() {\n                Some(frame) => frame,\n                None => return Err(lex_error(input)),\n            };\n            #[cfg(span_locations)]\n            let (lo, frame) = frame;\n            let (open_delimiter, outer) = frame;\n            if open_delimiter != close_delimiter {\n                return Err(lex_error(input));\n            }\n            input = input.advance(1);\n            let mut g = Group::new(open_delimiter, trees.build());\n            g.set_span(Span {\n                #[cfg(span_locations)]\n                lo,\n                #[cfg(span_locations)]\n                hi: input.off,\n            });\n            trees = outer;\n            trees\n                .push_token_from_parser(\n                    TokenTree::Group(crate::Group::_new_fallback(g)),\n                );\n        } else {\n            let (rest, mut tt) = match leaf_token(input) {\n                Ok((rest, tt)) => (rest, tt),\n                Err(Reject) => return Err(lex_error(input)),\n            };\n            tt.set_span(\n                crate::Span::_new_fallback(Span {\n                    #[cfg(span_locations)]\n                    lo,\n                    #[cfg(span_locations)]\n                    hi: rest.off,\n                }),\n            );\n            trees.push_token_from_parser(tt);\n            input = rest;\n        }\n    }\n}\n\nThe function to be tested is presented with each line formatted as 'line number + code':\n72 pub(crate) fn from_str_checked(src: &str) -> Result<Self, LexError> {\n73     // Create a dummy file & add it to the source map\n74     let mut cursor = get_cursor(src);\n75 \n76     // Strip a byte order mark if present\n77     const BYTE_ORDER_MARK: &str = \"\\u{feff}\";\n78     if cursor.starts_with(BYTE_ORDER_MARK) {\n79         cursor = cursor.advance(BYTE_ORDER_MARK.len());\n80     }\n81 \n82     parse::token_stream(cursor)\n83 }\n\nGenerate each test function in such a manner that it concurrently satisfies all the following preconditions:\n",
  "depend_pt": ""
}