{
  "system_pt": "As a software testing expert, please generate Rust test functions based on the following guidelines, focusing solely on constructing test inputs and calling the functions under test:\n1. Provide the code in plain text format, without explanations or Markdown.\n2. If the method under test belongs to a trait, construct appropriate structs within the test function, but avoid method overrides. If the method under test uses generics, instantiate them with suitable types based on the context.\n3. Generate test code with minimal scope: avoid creating external structures or implementations. Instead, define any necessary helper structures or implementations directly within the test function when required.\n4. Whenever possible, initialize the corresponding data structures using the initialization methods provided in the context.\n5. Ensure the generated function is fully implemented and can be compiled and executed directly without any missing parts.\n6. Create a minimal yet complete set of test functions, ensuring they adhere to all provided preconditions and cover boundary conditions, and reference the inferred test input conditions or ranges.\n7. Ensure the test inputs are designed to cover the inferred test input conditions or ranges as comprehensively as possible, with particular emphasis on boundary cases.\n8. Focus on crafting test inputs that effectively reveal potential bugs while meeting the specified requirements.\n9. Omit test oracles and assertions; concentrate on generating test inputs and function calls.\n10. Do not create a test module, but include intrinsic attributes like #[test] or #[should_panic] where necessary.\n",
  "static_pt": "The context for the focal function is as follows:\n// src/parse.rs\n// crate name is proc_macro2\ntype PResult<'a, O> = Result<(Cursor<'a>, O), Reject>;\nuse crate::fallback::{\n    self, is_ident_continue, is_ident_start, Group, Ident, LexError, Literal, Span,\n    TokenStream, TokenStreamBuilder,\n};\nuse crate::{Delimiter, Punct, Spacing, TokenTree};\nuse core::char;\nuse core::str::{Bytes, CharIndices, Chars};\nconst ERROR: &str = \"(/*ERROR*/)\";\npub(crate) struct TokenStreamBuilder {\n    inner: RcVecBuilder<TokenTree>,\n}\n#[derive(Copy, Clone, Eq, PartialEq)]\npub(crate) struct Cursor<'a> {\n    pub(crate) rest: &'a str,\n    #[cfg(span_locations)]\n    pub(crate) off: u32,\n}\n#[derive(Clone)]\npub struct Group {\n    inner: imp::Group,\n}\n#[derive(Clone)]\npub(crate) struct Group {\n    delimiter: Delimiter,\n    stream: TokenStream,\n    span: Span,\n}\n#[derive(Copy, Clone)]\npub struct Span {\n    inner: imp::Span,\n    _marker: ProcMacroAutoTraits,\n}\n#[derive(Debug)]\npub(crate) struct LexError {\n    pub(crate) span: Span,\n}\n#[derive(Clone, Copy, PartialEq, Eq)]\npub(crate) struct Span {\n    #[cfg(span_locations)]\n    pub(crate) lo: u32,\n    #[cfg(span_locations)]\n    pub(crate) hi: u32,\n}\n#[derive(Clone)]\npub(crate) struct TokenStream {\n    inner: RcVec<TokenTree>,\n}\npub(crate) struct Reject;\n#[derive(Clone)]\npub enum TokenTree {\n    /// A token stream surrounded by bracket delimiters.\n    Group(Group),\n    /// An identifier.\n    Ident(Ident),\n    /// A single punctuation character (`+`, `,`, `$`, etc.).\n    Punct(Punct),\n    /// A literal character (`'a'`), string (`\"hello\"`), number (`2.3`), etc.\n    Literal(Literal),\n}\n#[derive(Copy, Clone, Debug, Eq, PartialEq)]\npub enum Delimiter {\n    /// `( ... )`\n    Parenthesis,\n    /// `{ ... }`\n    Brace,\n    /// `[ ... ]`\n    Bracket,\n    /// `∅ ... ∅`\n    ///\n    /// An invisible delimiter, that may, for example, appear around tokens\n    /// coming from a \"macro variable\" `$var`. It is important to preserve\n    /// operator priorities in cases like `$var * 3` where `$var` is `1 + 2`.\n    /// Invisible delimiters may not survive roundtrip of a token stream through\n    /// a string.\n    ///\n    /// <div class=\"warning\">\n    ///\n    /// Note: rustc currently can ignore the grouping of tokens delimited by `None` in the output\n    /// of a proc_macro. Only `None`-delimited groups created by a macro_rules macro in the input\n    /// of a proc_macro macro are preserved, and only in very specific circumstances.\n    /// Any `None`-delimited groups (re)created by a proc_macro will therefore not preserve\n    /// operator priorities as indicated above. The other `Delimiter` variants should be used\n    /// instead in this context. This is a rustc bug. For details, see\n    /// [rust-lang/rust#67062](https://github.com/rust-lang/rust/issues/67062).\n    ///\n    /// </div>\n    None,\n}\n#[derive(Copy, Clone)]\npub(crate) enum Span {\n    Compiler(proc_macro::Span),\n    Fallback(fallback::Span),\n}\n#[derive(Clone)]\npub(crate) enum Group {\n    Compiler(proc_macro::Group),\n    Fallback(fallback::Group),\n}\nimpl TokenStreamBuilder {\n    pub(crate) fn new() -> Self {\n        TokenStreamBuilder {\n            inner: RcVecBuilder::new(),\n        }\n    }\n    pub(crate) fn with_capacity(cap: usize) -> Self {\n        TokenStreamBuilder {\n            inner: RcVecBuilder::with_capacity(cap),\n        }\n    }\n    pub(crate) fn push_token_from_parser(&mut self, tt: TokenTree) {\n        self.inner.push(tt);\n    }\n    pub(crate) fn build(self) -> TokenStream {\n        TokenStream {\n            inner: self.inner.build(),\n        }\n    }\n}\nimpl<'a> Cursor<'a> {\n    pub(crate) fn advance(&self, bytes: usize) -> Cursor<'a> {\n        let (_front, rest) = self.rest.split_at(bytes);\n        Cursor {\n            rest,\n            #[cfg(span_locations)]\n            off: self.off + _front.chars().count() as u32,\n        }\n    }\n    pub(crate) fn starts_with(&self, s: &str) -> bool {\n        self.rest.starts_with(s)\n    }\n    pub(crate) fn starts_with_char(&self, ch: char) -> bool {}\n    pub(crate) fn starts_with_fn<Pattern>(&self, f: Pattern) -> bool\n    where\n        Pattern: FnMut(char) -> bool,\n    {}\n    pub(crate) fn is_empty(&self) -> bool {}\n    fn len(&self) -> usize {}\n    fn as_bytes(&self) -> &'a [u8] {}\n    fn bytes(&self) -> Bytes<'a> {\n        self.rest.bytes()\n    }\n    fn chars(&self) -> Chars<'a> {}\n    fn char_indices(&self) -> CharIndices<'a> {}\n    fn parse(&self, tag: &str) -> Result<Cursor<'a>, Reject> {}\n}\nimpl Group {\n    fn _new(inner: imp::Group) -> Self {\n        Group { inner }\n    }\n    fn _new_fallback(inner: fallback::Group) -> Self {\n        Group {\n            inner: imp::Group::from(inner),\n        }\n    }\n    pub(crate) fn new(delimiter: Delimiter, stream: TokenStream) -> Self {\n        Group {\n            delimiter,\n            stream,\n            span: Span::call_site(),\n        }\n    }\n    pub fn delimiter(&self) -> Delimiter {}\n    pub fn stream(&self) -> TokenStream {}\n    pub fn span(&self) -> Span {}\n    pub fn span_open(&self) -> Span {}\n    pub fn span_close(&self) -> Span {}\n    pub fn delim_span(&self) -> DelimSpan {}\n    pub(crate) fn set_span(&mut self, span: Span) {\n        self.span = span;\n    }\n}\nimpl TokenTree {\n    pub fn span(&self) -> Span {}\n    pub fn set_span(&mut self, span: Span) {\n        match self {\n            TokenTree::Group(t) => t.set_span(span),\n            TokenTree::Ident(t) => t.set_span(span),\n            TokenTree::Punct(t) => t.set_span(span),\n            TokenTree::Literal(t) => t.set_span(span),\n        }\n    }\n}\nimpl Span {\n    fn _new(inner: imp::Span) -> Self {\n        Span { inner, _marker: MARKER }\n    }\n    fn _new_fallback(inner: fallback::Span) -> Self {\n        Span {\n            inner: imp::Span::from(inner),\n            _marker: MARKER,\n        }\n    }\n    pub fn call_site() -> Self {\n        Span::_new(imp::Span::call_site())\n    }\n    pub fn mixed_site() -> Self {\n        Span::_new(imp::Span::mixed_site())\n    }\n    #[cfg(procmacro2_semver_exempt)]\n    #[cfg_attr(docsrs, doc(cfg(procmacro2_semver_exempt)))]\n    pub fn def_site() -> Self {\n        Span::_new(imp::Span::def_site())\n    }\n    pub fn resolved_at(&self, other: Span) -> Span {}\n    pub fn located_at(&self, other: Span) -> Span {}\n    #[cfg(wrap_proc_macro)]\n    pub fn unwrap(self) -> proc_macro::Span {}\n    #[cfg(wrap_proc_macro)]\n    pub fn unstable(self) -> proc_macro::Span {}\n    #[cfg(all(procmacro2_semver_exempt, any(not(wrap_proc_macro), super_unstable)))]\n    #[cfg_attr(docsrs, doc(cfg(procmacro2_semver_exempt)))]\n    pub fn source_file(&self) -> SourceFile {}\n    #[cfg(span_locations)]\n    #[cfg_attr(docsrs, doc(cfg(feature = \"span-locations\")))]\n    pub fn byte_range(&self) -> Range<usize> {}\n    #[cfg(span_locations)]\n    #[cfg_attr(docsrs, doc(cfg(feature = \"span-locations\")))]\n    pub fn start(&self) -> LineColumn {}\n    #[cfg(span_locations)]\n    #[cfg_attr(docsrs, doc(cfg(feature = \"span-locations\")))]\n    pub fn end(&self) -> LineColumn {}\n    pub fn join(&self, other: Span) -> Option<Span> {}\n    #[cfg(procmacro2_semver_exempt)]\n    #[cfg_attr(docsrs, doc(cfg(procmacro2_semver_exempt)))]\n    pub fn eq(&self, other: &Span) -> bool {}\n    pub fn source_text(&self) -> Option<String> {}\n}\npub(crate) fn token_stream(mut input: Cursor) -> Result<TokenStream, LexError> {\n    let mut trees = TokenStreamBuilder::new();\n    let mut stack = Vec::new();\n    loop {\n        input = skip_whitespace(input);\n        if let Ok((rest, ())) = doc_comment(input, &mut trees) {\n            input = rest;\n            continue;\n        }\n        #[cfg(span_locations)]\n        let lo = input.off;\n        let first = match input.bytes().next() {\n            Some(first) => first,\n            None => {\n                match stack.last() {\n                    None => return Ok(trees.build()),\n                    #[cfg(span_locations)]\n                    Some((lo, _frame)) => {\n                        return Err(LexError {\n                            span: Span { lo: *lo, hi: *lo },\n                        });\n                    }\n                    #[cfg(not(span_locations))]\n                    Some(_frame) => return Err(LexError { span: Span {} }),\n                }\n            }\n        };\n        if let Some(open_delimiter) = match first {\n            b'(' if !input.starts_with(ERROR) => Some(Delimiter::Parenthesis),\n            b'[' => Some(Delimiter::Bracket),\n            b'{' => Some(Delimiter::Brace),\n            _ => None,\n        } {\n            input = input.advance(1);\n            let frame = (open_delimiter, trees);\n            #[cfg(span_locations)]\n            let frame = (lo, frame);\n            stack.push(frame);\n            trees = TokenStreamBuilder::new();\n        } else if let Some(close_delimiter) = match first {\n            b')' => Some(Delimiter::Parenthesis),\n            b']' => Some(Delimiter::Bracket),\n            b'}' => Some(Delimiter::Brace),\n            _ => None,\n        } {\n            let frame = match stack.pop() {\n                Some(frame) => frame,\n                None => return Err(lex_error(input)),\n            };\n            #[cfg(span_locations)]\n            let (lo, frame) = frame;\n            let (open_delimiter, outer) = frame;\n            if open_delimiter != close_delimiter {\n                return Err(lex_error(input));\n            }\n            input = input.advance(1);\n            let mut g = Group::new(open_delimiter, trees.build());\n            g.set_span(Span {\n                #[cfg(span_locations)]\n                lo,\n                #[cfg(span_locations)]\n                hi: input.off,\n            });\n            trees = outer;\n            trees\n                .push_token_from_parser(\n                    TokenTree::Group(crate::Group::_new_fallback(g)),\n                );\n        } else {\n            let (rest, mut tt) = match leaf_token(input) {\n                Ok((rest, tt)) => (rest, tt),\n                Err(Reject) => return Err(lex_error(input)),\n            };\n            tt.set_span(\n                crate::Span::_new_fallback(Span {\n                    #[cfg(span_locations)]\n                    lo,\n                    #[cfg(span_locations)]\n                    hi: rest.off,\n                }),\n            );\n            trees.push_token_from_parser(tt);\n            input = rest;\n        }\n    }\n}\nfn doc_comment<'a>(\n    input: Cursor<'a>,\n    trees: &mut TokenStreamBuilder,\n) -> PResult<'a, ()> {\n    #[cfg(span_locations)]\n    let lo = input.off;\n    let (rest, (comment, inner)) = doc_comment_contents(input)?;\n    let fallback_span = Span {\n        #[cfg(span_locations)]\n        lo,\n        #[cfg(span_locations)]\n        hi: rest.off,\n    };\n    let span = crate::Span::_new_fallback(fallback_span);\n    let mut scan_for_bare_cr = comment;\n    while let Some(cr) = scan_for_bare_cr.find('\\r') {\n        let rest = &scan_for_bare_cr[cr + 1..];\n        if !rest.starts_with('\\n') {\n            return Err(Reject);\n        }\n        scan_for_bare_cr = rest;\n    }\n    let mut pound = Punct::new('#', Spacing::Alone);\n    pound.set_span(span);\n    trees.push_token_from_parser(TokenTree::Punct(pound));\n    if inner {\n        let mut bang = Punct::new('!', Spacing::Alone);\n        bang.set_span(span);\n        trees.push_token_from_parser(TokenTree::Punct(bang));\n    }\n    let doc_ident = crate::Ident::_new_fallback(\n        Ident::new_unchecked(\"doc\", fallback_span),\n    );\n    let mut equal = Punct::new('=', Spacing::Alone);\n    equal.set_span(span);\n    let mut literal = crate::Literal::_new_fallback(Literal::string(comment));\n    literal.set_span(span);\n    let mut bracketed = TokenStreamBuilder::with_capacity(3);\n    bracketed.push_token_from_parser(TokenTree::Ident(doc_ident));\n    bracketed.push_token_from_parser(TokenTree::Punct(equal));\n    bracketed.push_token_from_parser(TokenTree::Literal(literal));\n    let group = Group::new(Delimiter::Bracket, bracketed.build());\n    let mut group = crate::Group::_new_fallback(group);\n    group.set_span(span);\n    trees.push_token_from_parser(TokenTree::Group(group));\n    Ok((rest, ()))\n}\nfn skip_whitespace(input: Cursor) -> Cursor {\n    let mut s = input;\n    while !s.is_empty() {\n        let byte = s.as_bytes()[0];\n        if byte == b'/' {\n            if s.starts_with(\"//\") && (!s.starts_with(\"///\") || s.starts_with(\"////\"))\n                && !s.starts_with(\"//!\")\n            {\n                let (cursor, _) = take_until_newline_or_eof(s);\n                s = cursor;\n                continue;\n            } else if s.starts_with(\"/**/\") {\n                s = s.advance(4);\n                continue;\n            } else if s.starts_with(\"/*\")\n                && (!s.starts_with(\"/**\") || s.starts_with(\"/***\"))\n                && !s.starts_with(\"/*!\")\n            {\n                match block_comment(s) {\n                    Ok((rest, _)) => {\n                        s = rest;\n                        continue;\n                    }\n                    Err(Reject) => return s,\n                }\n            }\n        }\n        match byte {\n            b' ' | 0x09..=0x0d => {\n                s = s.advance(1);\n                continue;\n            }\n            b if b.is_ascii() => {}\n            _ => {\n                let ch = s.chars().next().unwrap();\n                if is_whitespace(ch) {\n                    s = s.advance(ch.len_utf8());\n                    continue;\n                }\n            }\n        }\n        return s;\n    }\n    s\n}\nfn leaf_token(input: Cursor) -> PResult<TokenTree> {\n    if let Ok((input, l)) = literal(input) {\n        Ok((input, TokenTree::Literal(crate::Literal::_new_fallback(l))))\n    } else if let Ok((input, p)) = punct(input) {\n        Ok((input, TokenTree::Punct(p)))\n    } else if let Ok((input, i)) = ident(input) {\n        Ok((input, TokenTree::Ident(i)))\n    } else if input.starts_with(ERROR) {\n        let rest = input.advance(ERROR.len());\n        let repr = crate::Literal::_new_fallback(Literal::_new(ERROR.to_owned()));\n        Ok((rest, TokenTree::Literal(repr)))\n    } else {\n        Err(Reject)\n    }\n}\nfn lex_error(cursor: Cursor) -> LexError {\n    #[cfg(not(span_locations))]\n    let _ = cursor;\n    LexError {\n        span: Span {\n            #[cfg(span_locations)]\n            lo: cursor.off,\n            #[cfg(span_locations)]\n            hi: cursor.off,\n        },\n    }\n}\n\nThe function to be tested is presented with each line formatted as 'line number + code':\n168 pub(crate) fn token_stream(mut input: Cursor) -> Result<TokenStream, LexError> {\n169     let mut trees = TokenStreamBuilder::new();\n170     let mut stack = Vec::new();\n171 \n172     loop {\n173         input = skip_whitespace(input);\n174 \n175         if let Ok((rest, ())) = doc_comment(input, &mut trees) {\n176             input = rest;\n177             continue;\n178         }\n179 \n180         #[cfg(span_locations)]\n181         let lo = input.off;\n182 \n183         let first = match input.bytes().next() {\n184             Some(first) => first,\n185             None => match stack.last() {\n186                 None => return Ok(trees.build()),\n187                 #[cfg(span_locations)]\n188                 Some((lo, _frame)) => {\n189                     return Err(LexError {\n190                         span: Span { lo: *lo, hi: *lo },\n191                     })\n192                 }\n193                 #[cfg(not(span_locations))]\n194                 Some(_frame) => return Err(LexError { span: Span {} }),\n195             },\n196         };\n197 \n198         if let Some(open_delimiter) = match first {\n199             b'(' if !input.starts_with(ERROR) => Some(Delimiter::Parenthesis),\n200             b'[' => Some(Delimiter::Bracket),\n201             b'{' => Some(Delimiter::Brace),\n202             _ => None,\n203         } {\n204             input = input.advance(1);\n205             let frame = (open_delimiter, trees);\n206             #[cfg(span_locations)]\n207             let frame = (lo, frame);\n208             stack.push(frame);\n209             trees = TokenStreamBuilder::new();\n210         } else if let Some(close_delimiter) = match first {\n211             b')' => Some(Delimiter::Parenthesis),\n212             b']' => Some(Delimiter::Bracket),\n213             b'}' => Some(Delimiter::Brace),\n214             _ => None,\n215         } {\n216             let frame = match stack.pop() {\n217                 Some(frame) => frame,\n218                 None => return Err(lex_error(input)),\n219             };\n220             #[cfg(span_locations)]\n221             let (lo, frame) = frame;\n222             let (open_delimiter, outer) = frame;\n223             if open_delimiter != close_delimiter {\n224                 return Err(lex_error(input));\n225             }\n226             input = input.advance(1);\n227             let mut g = Group::new(open_delimiter, trees.build());\n228             g.set_span(Span {\n229                 #[cfg(span_locations)]\n230                 lo,\n231                 #[cfg(span_locations)]\n232                 hi: input.off,\n233             });\n234             trees = outer;\n235             trees.push_token_from_parser(TokenTree::Group(crate::Group::_new_fallback(g)));\n236         } else {\n237             let (rest, mut tt) = match leaf_token(input) {\n238                 Ok((rest, tt)) => (rest, tt),\n239                 Err(Reject) => return Err(lex_error(input)),\n240             };\n241             tt.set_span(crate::Span::_new_fallback(Span {\n242                 #[cfg(span_locations)]\n243                 lo,\n244                 #[cfg(span_locations)]\n245                 hi: rest.off,\n246             }));\n247             trees.push_token_from_parser(tt);\n248             input = rest;\n249         }\n250     }\n251 }\n\nGenerate each test function in such a manner that it concurrently satisfies all the following preconditions:\n",
  "depend_pt": ""
}