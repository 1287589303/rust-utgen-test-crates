{
  "system_pt": "As a software testing expert, please generate accurate test oracles code based on the provided information. Follow these guidelines:\n1. Generate executable test oracle codes in plain text format, one per line. Do not output complete test functions, avoid additional explanations, and do not use Markdown.\n2. Combine the given function under test, context, relevant documentation, preconditions, expected return values or types, test input conditions or ranges, and existing test function prefixes to infer and generate corresponding test oracles code.\n3. Only generate necessary test oracles to ensure comprehensive validation.\n",
  "static_pt": "The context for the focal function is as follows:\n// rand_core/src/block.rs\n// crate name is rand_core\nuse crate::impls::fill_via_chunks;\nuse crate::{CryptoRng, RngCore, SeedableRng, TryRngCore};\nuse core::fmt;\n#[cfg(feature = \"serde\")]\nuse serde::{Deserialize, Serialize};\npub trait RngCore {\n    fn next_u32(&mut self) -> u32;\n    fn next_u64(&mut self) -> u64;\n    fn fill_bytes(&mut self, dst: &mut [u8]);\n}\npub trait SeedableRng: Sized {\n    type Seed: Clone + Default + AsRef<[u8]> + AsMut<[u8]>;\n    fn from_seed(seed: Self::Seed) -> Self;\n    fn seed_from_u64(mut state: u64) -> Self {\n        fn pcg32(state: &mut u64) -> [u8; 4] {\n            const MUL: u64 = 6364136223846793005;\n            const INC: u64 = 11634580027462260723;\n            *state = state.wrapping_mul(MUL).wrapping_add(INC);\n            let state = *state;\n            let xorshifted = (((state >> 18) ^ state) >> 27) as u32;\n            let rot = (state >> 59) as u32;\n            let x = xorshifted.rotate_right(rot);\n            x.to_le_bytes()\n        }\n        let mut seed = Self::Seed::default();\n        let mut iter = seed.as_mut().chunks_exact_mut(4);\n        for chunk in &mut iter {\n            chunk.copy_from_slice(&pcg32(&mut state));\n        }\n        let rem = iter.into_remainder();\n        if !rem.is_empty() {\n            rem.copy_from_slice(&pcg32(&mut state)[..rem.len()]);\n        }\n        Self::from_seed(seed)\n    }\n    fn from_rng(rng: &mut impl RngCore) -> Self {\n        let mut seed = Self::Seed::default();\n        rng.fill_bytes(seed.as_mut());\n        Self::from_seed(seed)\n    }\n    fn try_from_rng<R: TryRngCore>(rng: &mut R) -> Result<Self, R::Error> {\n        let mut seed = Self::Seed::default();\n        rng.try_fill_bytes(seed.as_mut())?;\n        Ok(Self::from_seed(seed))\n    }\n    #[cfg(feature = \"os_rng\")]\n    fn from_os_rng() -> Self {\n        match Self::try_from_os_rng() {\n            Ok(res) => res,\n            Err(err) => panic!(\"from_os_rng failed: {}\", err),\n        }\n    }\n    #[cfg(feature = \"os_rng\")]\n    fn try_from_os_rng() -> Result<Self, getrandom::Error> {\n        let mut seed = Self::Seed::default();\n        getrandom::fill(seed.as_mut())?;\n        let res = Self::from_seed(seed);\n        Ok(res)\n    }\n}\npub trait BlockRngCore {\n    type Item;\n    type Results: AsRef<[Self::Item]> + AsMut<[Self::Item]> + Default;\n    fn generate(&mut self, results: &mut Self::Results);\n}\n#[derive(Clone)]\n#[cfg_attr(feature = \"serde\", derive(Serialize, Deserialize))]\n#[cfg_attr(\n    feature = \"serde\",\n    serde(\n        bound = \"for<'x> R: Serialize + Deserialize<'x>, for<'x> R::Results: Serialize + Deserialize<'x>\"\n    )\n)]\npub struct BlockRng<R: BlockRngCore> {\n    results: R::Results,\n    index: usize,\n    /// The *core* part of the RNG, implementing the `generate` function.\n    pub core: R,\n}\nimpl<R: BlockRngCore<Item = u32>> RngCore for BlockRng<R> {\n    #[inline]\n    fn next_u32(&mut self) -> u32 {}\n    #[inline]\n    fn next_u64(&mut self) -> u64 {}\n    #[inline]\n    fn fill_bytes(&mut self, dest: &mut [u8]) {\n        let mut read_len = 0;\n        while read_len < dest.len() {\n            if self.index >= self.results.as_ref().len() {\n                self.generate_and_set(0);\n            }\n            let (consumed_u32, filled_u8) = fill_via_chunks(\n                &self.results.as_mut()[self.index..],\n                &mut dest[read_len..],\n            );\n            self.index += consumed_u32;\n            read_len += filled_u8;\n        }\n    }\n}\nimpl<R: BlockRngCore> BlockRng<R> {\n    #[inline]\n    pub fn new(core: R) -> BlockRng<R> {}\n    #[inline(always)]\n    pub fn index(&self) -> usize {}\n    #[inline]\n    pub fn reset(&mut self) {}\n    #[inline]\n    pub fn generate_and_set(&mut self, index: usize) {\n        assert!(index < self.results.as_ref().len());\n        self.core.generate(&mut self.results);\n        self.index = index;\n    }\n}\npub(crate) fn fill_via_chunks<T: Observable>(\n    src: &[T],\n    dest: &mut [u8],\n) -> (usize, usize) {\n    let size = core::mem::size_of::<T>();\n    let mut dest = dest.chunks_exact_mut(size);\n    let mut src = src.iter();\n    let zipped = dest.by_ref().zip(src.by_ref());\n    let num_chunks = zipped.len();\n    zipped.for_each(|(dest, src)| dest.copy_from_slice(src.to_le_bytes().as_ref()));\n    let byte_len = num_chunks * size;\n    if let Some(src) = src.next() {\n        let dest = dest.into_remainder();\n        let n = dest.len();\n        if n > 0 {\n            dest.copy_from_slice(&src.to_le_bytes().as_ref()[..n]);\n            return (num_chunks + 1, byte_len + n);\n        }\n    }\n    (num_chunks, byte_len)\n}\n\nThe function to be tested is presented with each line formatted as 'line number + code':\n222 fn fill_bytes(&mut self, dest: &mut [u8]) {\n223     let mut read_len = 0;\n224     while read_len < dest.len() {\n225         if self.index >= self.results.as_ref().len() {\n226             self.generate_and_set(0);\n227         }\n228         let (consumed_u32, filled_u8) =\n229             fill_via_chunks(&self.results.as_mut()[self.index..], &mut dest[read_len..]);\n230 \n231         self.index += consumed_u32;\n232         read_len += filled_u8;\n233     }\n234 }\n\nThe path conditions that the generated test functions should satisfy are as follows:\n"
}