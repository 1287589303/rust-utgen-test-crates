{
  "system_pt": "As a software testing expert, please generate accurate test oracles code based on the provided information. Follow these guidelines:\n1. Generate executable test oracle codes in plain text format, one per line. Do not output complete test functions, avoid additional explanations, and do not use Markdown.\n2. Combine the given function under test, context, relevant documentation, preconditions, expected return values or types, test input conditions or ranges, and existing test function prefixes to infer and generate corresponding test oracles code.\n3. Only generate necessary test oracles to ensure comprehensive validation.\n",
  "static_pt": "The context for the focal function is as follows:\n// src/buf/buf_impl.rs\n// crate name is bytes\n#[cfg(feature = \"std\")]\nuse crate::buf::{reader, Reader};\nuse crate::buf::{take, Chain, Take};\n#[cfg(feature = \"std\")]\nuse crate::{min_u64_usize, saturating_sub_usize_u64};\nuse crate::{panic_advance, panic_does_not_fit, TryGetError};\n#[cfg(feature = \"std\")]\nuse std::io::IoSlice;\nuse alloc::boxed::Box;\npub trait Buf {\n    fn remaining(&self) -> usize;\n    #[cfg_attr(docsrs, doc(alias = \"bytes\"))]\n    fn chunk(&self) -> &[u8];\n    #[cfg(feature = \"std\")]\n    #[cfg_attr(docsrs, doc(cfg(feature = \"std\")))]\n    fn chunks_vectored<'a>(&'a self, dst: &mut [IoSlice<'a>]) -> usize;\n    fn advance(&mut self, cnt: usize);\n    fn has_remaining(&self) -> bool;\n    fn copy_to_slice(&mut self, dst: &mut [u8]);\n    fn get_u8(&mut self) -> u8;\n    fn get_i8(&mut self) -> i8;\n    fn get_u16(&mut self) -> u16;\n    fn get_u16_le(&mut self) -> u16;\n    fn get_u16_ne(&mut self) -> u16;\n    fn get_i16(&mut self) -> i16;\n    fn get_i16_le(&mut self) -> i16;\n    fn get_i16_ne(&mut self) -> i16;\n    fn get_u32(&mut self) -> u32;\n    fn get_u32_le(&mut self) -> u32;\n    fn get_u32_ne(&mut self) -> u32;\n    fn get_i32(&mut self) -> i32;\n    fn get_i32_le(&mut self) -> i32;\n    fn get_i32_ne(&mut self) -> i32;\n    fn get_u64(&mut self) -> u64;\n    fn get_u64_le(&mut self) -> u64;\n    fn get_u64_ne(&mut self) -> u64;\n    fn get_i64(&mut self) -> i64;\n    fn get_i64_le(&mut self) -> i64;\n    fn get_i64_ne(&mut self) -> i64;\n    fn get_u128(&mut self) -> u128;\n    fn get_u128_le(&mut self) -> u128;\n    fn get_u128_ne(&mut self) -> u128;\n    fn get_i128(&mut self) -> i128;\n    fn get_i128_le(&mut self) -> i128;\n    fn get_i128_ne(&mut self) -> i128;\n    fn get_uint(&mut self, nbytes: usize) -> u64;\n    fn get_uint_le(&mut self, nbytes: usize) -> u64;\n    fn get_uint_ne(&mut self, nbytes: usize) -> u64;\n    fn get_int(&mut self, nbytes: usize) -> i64;\n    fn get_int_le(&mut self, nbytes: usize) -> i64;\n    fn get_int_ne(&mut self, nbytes: usize) -> i64;\n    fn get_f32(&mut self) -> f32;\n    fn get_f32_le(&mut self) -> f32;\n    fn get_f32_ne(&mut self) -> f32;\n    fn get_f64(&mut self) -> f64;\n    fn get_f64_le(&mut self) -> f64;\n    fn get_f64_ne(&mut self) -> f64;\n    fn try_copy_to_slice(&mut self, mut dst: &mut [u8]) -> Result<(), TryGetError>;\n    fn try_get_u8(&mut self) -> Result<u8, TryGetError>;\n    fn try_get_i8(&mut self) -> Result<i8, TryGetError>;\n    fn try_get_u16(&mut self) -> Result<u16, TryGetError>;\n    fn try_get_u16_le(&mut self) -> Result<u16, TryGetError>;\n    fn try_get_u16_ne(&mut self) -> Result<u16, TryGetError>;\n    fn try_get_i16(&mut self) -> Result<i16, TryGetError>;\n    fn try_get_i16_le(&mut self) -> Result<i16, TryGetError>;\n    fn try_get_i16_ne(&mut self) -> Result<i16, TryGetError>;\n    fn try_get_u32(&mut self) -> Result<u32, TryGetError>;\n    fn try_get_u32_le(&mut self) -> Result<u32, TryGetError>;\n    fn try_get_u32_ne(&mut self) -> Result<u32, TryGetError>;\n    fn try_get_i32(&mut self) -> Result<i32, TryGetError>;\n    fn try_get_i32_le(&mut self) -> Result<i32, TryGetError>;\n    fn try_get_i32_ne(&mut self) -> Result<i32, TryGetError>;\n    fn try_get_u64(&mut self) -> Result<u64, TryGetError>;\n    fn try_get_u64_le(&mut self) -> Result<u64, TryGetError>;\n    fn try_get_u64_ne(&mut self) -> Result<u64, TryGetError>;\n    fn try_get_i64(&mut self) -> Result<i64, TryGetError>;\n    fn try_get_i64_le(&mut self) -> Result<i64, TryGetError>;\n    fn try_get_i64_ne(&mut self) -> Result<i64, TryGetError>;\n    fn try_get_u128(&mut self) -> Result<u128, TryGetError>;\n    fn try_get_u128_le(&mut self) -> Result<u128, TryGetError>;\n    fn try_get_u128_ne(&mut self) -> Result<u128, TryGetError>;\n    fn try_get_i128(&mut self) -> Result<i128, TryGetError>;\n    fn try_get_i128_le(&mut self) -> Result<i128, TryGetError>;\n    fn try_get_i128_ne(&mut self) -> Result<i128, TryGetError>;\n    fn try_get_uint(&mut self, nbytes: usize) -> Result<u64, TryGetError>;\n    fn try_get_uint_le(&mut self, nbytes: usize) -> Result<u64, TryGetError>;\n    fn try_get_uint_ne(&mut self, nbytes: usize) -> Result<u64, TryGetError>;\n    fn try_get_int(&mut self, nbytes: usize) -> Result<i64, TryGetError>;\n    fn try_get_int_le(&mut self, nbytes: usize) -> Result<i64, TryGetError>;\n    fn try_get_int_ne(&mut self, nbytes: usize) -> Result<i64, TryGetError>;\n    fn try_get_f32(&mut self) -> Result<f32, TryGetError>;\n    fn try_get_f32_le(&mut self) -> Result<f32, TryGetError>;\n    fn try_get_f32_ne(&mut self) -> Result<f32, TryGetError>;\n    fn try_get_f64(&mut self) -> Result<f64, TryGetError>;\n    fn try_get_f64_le(&mut self) -> Result<f64, TryGetError>;\n    fn try_get_f64_ne(&mut self) -> Result<f64, TryGetError>;\n    fn copy_to_bytes(&mut self, len: usize) -> crate::Bytes {\n        use super::BufMut;\n        if self.remaining() < len {\n            panic_advance(\n                &TryGetError {\n                    requested: len,\n                    available: self.remaining(),\n                },\n            );\n        }\n        let mut ret = crate::BytesMut::with_capacity(len);\n        ret.put(self.take(len));\n        ret.freeze()\n    }\n    fn take(self, limit: usize) -> Take<Self>\n    where\n        Self: Sized,\n    {\n        take::new(self, limit)\n    }\n    fn chain<U: Buf>(self, next: U) -> Chain<Self, U>\n    where\n        Self: Sized,\n    {\n        Chain::new(self, next)\n    }\n    #[cfg(feature = \"std\")]\n    #[cfg_attr(docsrs, doc(cfg(feature = \"std\")))]\n    fn reader(self) -> Reader<Self>\n    where\n        Self: Sized,\n    {\n        reader::new(self)\n    }\n}\npub struct BytesMut {\n    ptr: NonNull<u8>,\n    len: usize,\n    cap: usize,\n    data: *mut Shared,\n}\n#[derive(Debug, PartialEq, Eq)]\npub struct TryGetError {\n    /// The number of bytes necessary to get the value\n    pub requested: usize,\n    /// The number of bytes available in the buffer\n    pub available: usize,\n}\n#[derive(Debug)]\npub struct Take<T> {\n    inner: T,\n    limit: usize,\n}\npub struct Bytes {\n    ptr: *const u8,\n    len: usize,\n    data: AtomicPtr<()>,\n    vtable: &'static Vtable,\n}\nimpl BytesMut {\n    #[inline]\n    pub fn with_capacity(capacity: usize) -> BytesMut {\n        BytesMut::from_vec(Vec::with_capacity(capacity))\n    }\n    #[inline]\n    pub fn new() -> BytesMut {}\n    #[inline]\n    pub fn len(&self) -> usize {}\n    #[inline]\n    pub fn is_empty(&self) -> bool {}\n    #[inline]\n    pub fn capacity(&self) -> usize {}\n    #[inline]\n    pub fn freeze(self) -> Bytes {\n        let bytes = ManuallyDrop::new(self);\n        if bytes.kind() == KIND_VEC {\n            unsafe {\n                let off = bytes.get_vec_pos();\n                let vec = rebuild_vec(bytes.ptr.as_ptr(), bytes.len, bytes.cap, off);\n                let mut b: Bytes = vec.into();\n                b.advance(off);\n                b\n            }\n        } else {\n            debug_assert_eq!(bytes.kind(), KIND_ARC);\n            let ptr = bytes.ptr.as_ptr();\n            let len = bytes.len;\n            let data = AtomicPtr::new(bytes.data.cast());\n            unsafe { Bytes::with_vtable(ptr, len, data, &SHARED_VTABLE) }\n        }\n    }\n    pub fn zeroed(len: usize) -> BytesMut {}\n    #[must_use = \"consider BytesMut::truncate if you don't need the other half\"]\n    pub fn split_off(&mut self, at: usize) -> BytesMut {}\n    #[must_use = \"consider BytesMut::clear if you don't need the other half\"]\n    pub fn split(&mut self) -> BytesMut {}\n    #[must_use = \"consider BytesMut::advance if you don't need the other half\"]\n    pub fn split_to(&mut self, at: usize) -> BytesMut {}\n    pub fn truncate(&mut self, len: usize) {}\n    pub fn clear(&mut self) {}\n    pub fn resize(&mut self, new_len: usize, value: u8) {}\n    #[inline]\n    pub unsafe fn set_len(&mut self, len: usize) {}\n    #[inline]\n    pub fn reserve(&mut self, additional: usize) {}\n    fn reserve_inner(&mut self, additional: usize, allocate: bool) -> bool {}\n    #[inline]\n    #[must_use = \"consider BytesMut::reserve if you need an infallible reservation\"]\n    pub fn try_reclaim(&mut self, additional: usize) -> bool {}\n    #[inline]\n    pub fn extend_from_slice(&mut self, extend: &[u8]) {}\n    pub fn unsplit(&mut self, other: BytesMut) {}\n    #[inline]\n    pub(crate) fn from_vec(vec: Vec<u8>) -> BytesMut {}\n    #[inline]\n    fn as_slice(&self) -> &[u8] {}\n    #[inline]\n    fn as_slice_mut(&mut self) -> &mut [u8] {}\n    pub(crate) unsafe fn advance_unchecked(&mut self, count: usize) {}\n    fn try_unsplit(&mut self, other: BytesMut) -> Result<(), BytesMut> {}\n    #[inline]\n    fn kind(&self) -> usize {}\n    unsafe fn promote_to_shared(&mut self, ref_cnt: usize) {}\n    #[inline]\n    unsafe fn shallow_clone(&mut self) -> BytesMut {}\n    #[inline]\n    unsafe fn get_vec_pos(&self) -> usize {}\n    #[inline]\n    unsafe fn set_vec_pos(&mut self, pos: usize) {}\n    #[inline]\n    pub fn spare_capacity_mut(&mut self) -> &mut [MaybeUninit<u8>] {}\n}\n#[cold]\nfn panic_advance(error_info: &TryGetError) -> ! {\n    panic!(\n        \"advance out of bounds: the len is {} but advancing by {}\", error_info.available,\n        error_info.requested\n    );\n}\n\nThe function to be tested is presented with each line formatted as 'line number + code':\n/// Consumes `len` bytes inside self and returns new instance of `Bytes`\n/// with this data.\n///\n/// This function may be optimized by the underlying type to avoid actual\n/// copies. For example, `Bytes` implementation will do a shallow copy\n/// (ref-count increment).\n///\n/// # Examples\n///\n/// ```\n/// use bytes::Buf;\n///\n/// let bytes = (&b\"hello world\"[..]).copy_to_bytes(5);\n/// assert_eq!(&bytes[..], &b\"hello\"[..]);\n/// ```\n///\n/// # Panics\n///\n/// This function panics if `len > self.remaining()`.\n2358 fn copy_to_bytes(&mut self, len: usize) -> crate::Bytes {\n2359     use super::BufMut;\n2360 \n2361     if self.remaining() < len {\n2362         panic_advance(&TryGetError {\n2363             requested: len,\n2364             available: self.remaining(),\n2365         });\n2366     }\n2367 \n2368     let mut ret = crate::BytesMut::with_capacity(len);\n2369     ret.put(self.take(len));\n2370     ret.freeze()\n2371 }\n\nThe path conditions that the generated test functions should satisfy are as follows:\n"
}