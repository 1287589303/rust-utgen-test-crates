{
  "system_pt": "As a software testing expert, infer the test input conditions or ranges based on the provided information. Follow these guidelines:\n1. Provide test input conditions or ranges in one line in plain text only, without additional explanations or Markdown formatting\n2. Analyze the function under test, context, preconditions, and expected return values or types to determine appropriate test input conditions or ranges\n3. The inferred test input conditions or ranges should comprehensively satisfy all provided preconditions simultaneously.\n4. Ensure the test input conditions or ranges cover boundary cases and edge scenarios\n",
  "static_pt": "The context for the focal function is as follows:\n// src/bytes.rs\n// crate name is bytes\nuse core::iter::FromIterator;\nuse core::mem::{self, ManuallyDrop, MaybeUninit};\nuse core::ops::{Deref, DerefMut};\nuse core::ptr::{self, NonNull};\nuse core::{cmp, fmt, hash, isize, slice, usize};\nuse alloc::{\n    borrow::{Borrow, BorrowMut},\n    boxed::Box, string::String, vec, vec::Vec,\n};\nuse crate::buf::{IntoIter, UninitSlice};\nuse crate::bytes::Vtable;\n#[allow(unused)]\nuse crate::loom::sync::atomic::AtomicMut;\nuse crate::loom::sync::atomic::{AtomicPtr, AtomicUsize, Ordering};\nuse crate::{offset_from, Buf, BufMut, Bytes, TryGetError};\nstatic SHARED_VTABLE: Vtable = Vtable {\n    clone: shared_v_clone,\n    into_vec: shared_v_to_vec,\n    into_mut: shared_v_to_mut,\n    is_unique: shared_v_is_unique,\n    drop: shared_v_drop,\n};\nconst _: [(); 0 - mem::align_of::<Shared>() % 2] = [];\nconst KIND_ARC: usize = 0b0;\nconst KIND_VEC: usize = 0b1;\nconst KIND_MASK: usize = 0b1;\nconst MAX_ORIGINAL_CAPACITY_WIDTH: usize = 17;\nconst MIN_ORIGINAL_CAPACITY_WIDTH: usize = 10;\nconst ORIGINAL_CAPACITY_MASK: usize = 0b11100;\nconst ORIGINAL_CAPACITY_OFFSET: usize = 2;\nconst VEC_POS_OFFSET: usize = 5;\nconst MAX_VEC_POS: usize = usize::MAX >> VEC_POS_OFFSET;\nconst NOT_VEC_POS_MASK: usize = 0b11111;\n#[cfg(target_pointer_width = \"64\")]\nconst PTR_WIDTH: usize = 64;\n#[cfg(target_pointer_width = \"32\")]\nconst PTR_WIDTH: usize = 32;\npub trait Buf {\n    fn remaining(&self) -> usize;\n    #[cfg_attr(docsrs, doc(alias = \"bytes\"))]\n    fn chunk(&self) -> &[u8];\n    #[cfg(feature = \"std\")]\n    #[cfg_attr(docsrs, doc(cfg(feature = \"std\")))]\n    fn chunks_vectored<'a>(&'a self, dst: &mut [IoSlice<'a>]) -> usize;\n    fn advance(&mut self, cnt: usize);\n    fn has_remaining(&self) -> bool;\n    fn copy_to_slice(&mut self, dst: &mut [u8]);\n    fn get_u8(&mut self) -> u8;\n    fn get_i8(&mut self) -> i8;\n    fn get_u16(&mut self) -> u16;\n    fn get_u16_le(&mut self) -> u16;\n    fn get_u16_ne(&mut self) -> u16;\n    fn get_i16(&mut self) -> i16;\n    fn get_i16_le(&mut self) -> i16;\n    fn get_i16_ne(&mut self) -> i16;\n    fn get_u32(&mut self) -> u32;\n    fn get_u32_le(&mut self) -> u32;\n    fn get_u32_ne(&mut self) -> u32;\n    fn get_i32(&mut self) -> i32;\n    fn get_i32_le(&mut self) -> i32;\n    fn get_i32_ne(&mut self) -> i32;\n    fn get_u64(&mut self) -> u64;\n    fn get_u64_le(&mut self) -> u64;\n    fn get_u64_ne(&mut self) -> u64;\n    fn get_i64(&mut self) -> i64;\n    fn get_i64_le(&mut self) -> i64;\n    fn get_i64_ne(&mut self) -> i64;\n    fn get_u128(&mut self) -> u128;\n    fn get_u128_le(&mut self) -> u128;\n    fn get_u128_ne(&mut self) -> u128;\n    fn get_i128(&mut self) -> i128;\n    fn get_i128_le(&mut self) -> i128;\n    fn get_i128_ne(&mut self) -> i128;\n    fn get_uint(&mut self, nbytes: usize) -> u64;\n    fn get_uint_le(&mut self, nbytes: usize) -> u64;\n    fn get_uint_ne(&mut self, nbytes: usize) -> u64;\n    fn get_int(&mut self, nbytes: usize) -> i64;\n    fn get_int_le(&mut self, nbytes: usize) -> i64;\n    fn get_int_ne(&mut self, nbytes: usize) -> i64;\n    fn get_f32(&mut self) -> f32;\n    fn get_f32_le(&mut self) -> f32;\n    fn get_f32_ne(&mut self) -> f32;\n    fn get_f64(&mut self) -> f64;\n    fn get_f64_le(&mut self) -> f64;\n    fn get_f64_ne(&mut self) -> f64;\n    fn try_copy_to_slice(&mut self, mut dst: &mut [u8]) -> Result<(), TryGetError>;\n    fn try_get_u8(&mut self) -> Result<u8, TryGetError>;\n    fn try_get_i8(&mut self) -> Result<i8, TryGetError>;\n    fn try_get_u16(&mut self) -> Result<u16, TryGetError>;\n    fn try_get_u16_le(&mut self) -> Result<u16, TryGetError>;\n    fn try_get_u16_ne(&mut self) -> Result<u16, TryGetError>;\n    fn try_get_i16(&mut self) -> Result<i16, TryGetError>;\n    fn try_get_i16_le(&mut self) -> Result<i16, TryGetError>;\n    fn try_get_i16_ne(&mut self) -> Result<i16, TryGetError>;\n    fn try_get_u32(&mut self) -> Result<u32, TryGetError>;\n    fn try_get_u32_le(&mut self) -> Result<u32, TryGetError>;\n    fn try_get_u32_ne(&mut self) -> Result<u32, TryGetError>;\n    fn try_get_i32(&mut self) -> Result<i32, TryGetError>;\n    fn try_get_i32_le(&mut self) -> Result<i32, TryGetError>;\n    fn try_get_i32_ne(&mut self) -> Result<i32, TryGetError>;\n    fn try_get_u64(&mut self) -> Result<u64, TryGetError>;\n    fn try_get_u64_le(&mut self) -> Result<u64, TryGetError>;\n    fn try_get_u64_ne(&mut self) -> Result<u64, TryGetError>;\n    fn try_get_i64(&mut self) -> Result<i64, TryGetError>;\n    fn try_get_i64_le(&mut self) -> Result<i64, TryGetError>;\n    fn try_get_i64_ne(&mut self) -> Result<i64, TryGetError>;\n    fn try_get_u128(&mut self) -> Result<u128, TryGetError>;\n    fn try_get_u128_le(&mut self) -> Result<u128, TryGetError>;\n    fn try_get_u128_ne(&mut self) -> Result<u128, TryGetError>;\n    fn try_get_i128(&mut self) -> Result<i128, TryGetError>;\n    fn try_get_i128_le(&mut self) -> Result<i128, TryGetError>;\n    fn try_get_i128_ne(&mut self) -> Result<i128, TryGetError>;\n    fn try_get_uint(&mut self, nbytes: usize) -> Result<u64, TryGetError>;\n    fn try_get_uint_le(&mut self, nbytes: usize) -> Result<u64, TryGetError>;\n    fn try_get_uint_ne(&mut self, nbytes: usize) -> Result<u64, TryGetError>;\n    fn try_get_int(&mut self, nbytes: usize) -> Result<i64, TryGetError>;\n    fn try_get_int_le(&mut self, nbytes: usize) -> Result<i64, TryGetError>;\n    fn try_get_int_ne(&mut self, nbytes: usize) -> Result<i64, TryGetError>;\n    fn try_get_f32(&mut self) -> Result<f32, TryGetError>;\n    fn try_get_f32_le(&mut self) -> Result<f32, TryGetError>;\n    fn try_get_f32_ne(&mut self) -> Result<f32, TryGetError>;\n    fn try_get_f64(&mut self) -> Result<f64, TryGetError>;\n    fn try_get_f64_le(&mut self) -> Result<f64, TryGetError>;\n    fn try_get_f64_ne(&mut self) -> Result<f64, TryGetError>;\n    fn copy_to_bytes(&mut self, len: usize) -> crate::Bytes;\n    fn take(self, limit: usize) -> Take<Self>\n    where\n        Self: Sized,\n    {\n        take::new(self, limit)\n    }\n    fn chain<U: Buf>(self, next: U) -> Chain<Self, U>\n    where\n        Self: Sized,\n    {\n        Chain::new(self, next)\n    }\n    #[cfg(feature = \"std\")]\n    #[cfg_attr(docsrs, doc(cfg(feature = \"std\")))]\n    fn reader(self) -> Reader<Self>\n    where\n        Self: Sized,\n    {\n        reader::new(self)\n    }\n}\npub unsafe trait BufMut {\n    fn remaining_mut(&self) -> usize;\n    unsafe fn advance_mut(&mut self, cnt: usize);\n    #[inline]\n    fn has_remaining_mut(&self) -> bool;\n    #[cfg_attr(docsrs, doc(alias = \"bytes_mut\"))]\n    fn chunk_mut(&mut self) -> &mut UninitSlice;\n    #[inline]\n    fn put<T: super::Buf>(&mut self, mut src: T)\n    where\n        Self: Sized;\n    #[inline]\n    fn put_slice(&mut self, mut src: &[u8]);\n    #[inline]\n    fn put_bytes(&mut self, val: u8, mut cnt: usize);\n    #[inline]\n    fn put_u8(&mut self, n: u8);\n    #[inline]\n    fn put_i8(&mut self, n: i8);\n    #[inline]\n    fn put_u16(&mut self, n: u16);\n    #[inline]\n    fn put_u16_le(&mut self, n: u16);\n    #[inline]\n    fn put_u16_ne(&mut self, n: u16);\n    #[inline]\n    fn put_i16(&mut self, n: i16);\n    #[inline]\n    fn put_i16_le(&mut self, n: i16);\n    #[inline]\n    fn put_i16_ne(&mut self, n: i16);\n    #[inline]\n    fn put_u32(&mut self, n: u32);\n    #[inline]\n    fn put_u32_le(&mut self, n: u32);\n    #[inline]\n    fn put_u32_ne(&mut self, n: u32);\n    #[inline]\n    fn put_i32(&mut self, n: i32);\n    #[inline]\n    fn put_i32_le(&mut self, n: i32);\n    #[inline]\n    fn put_i32_ne(&mut self, n: i32);\n    #[inline]\n    fn put_u64(&mut self, n: u64);\n    #[inline]\n    fn put_u64_le(&mut self, n: u64);\n    #[inline]\n    fn put_u64_ne(&mut self, n: u64);\n    #[inline]\n    fn put_i64(&mut self, n: i64);\n    #[inline]\n    fn put_i64_le(&mut self, n: i64);\n    #[inline]\n    fn put_i64_ne(&mut self, n: i64);\n    #[inline]\n    fn put_u128(&mut self, n: u128);\n    #[inline]\n    fn put_u128_le(&mut self, n: u128);\n    #[inline]\n    fn put_u128_ne(&mut self, n: u128);\n    #[inline]\n    fn put_i128(&mut self, n: i128);\n    #[inline]\n    fn put_i128_le(&mut self, n: i128);\n    #[inline]\n    fn put_i128_ne(&mut self, n: i128);\n    #[inline]\n    fn put_uint(&mut self, n: u64, nbytes: usize);\n    #[inline]\n    fn put_uint_le(&mut self, n: u64, nbytes: usize);\n    #[inline]\n    fn put_uint_ne(&mut self, n: u64, nbytes: usize);\n    #[inline]\n    fn put_int(&mut self, n: i64, nbytes: usize);\n    #[inline]\n    fn put_int_le(&mut self, n: i64, nbytes: usize);\n    #[inline]\n    fn put_int_ne(&mut self, n: i64, nbytes: usize);\n    #[inline]\n    fn put_f32(&mut self, n: f32);\n    #[inline]\n    fn put_f32_le(&mut self, n: f32);\n    #[inline]\n    fn put_f32_ne(&mut self, n: f32);\n    #[inline]\n    fn put_f64(&mut self, n: f64);\n    #[inline]\n    fn put_f64_le(&mut self, n: f64);\n    #[inline]\n    fn put_f64_ne(&mut self, n: f64);\n    #[inline]\n    fn limit(self, limit: usize) -> Limit<Self>\n    where\n        Self: Sized,\n    {\n        limit::new(self, limit)\n    }\n    #[cfg(feature = \"std\")]\n    #[cfg_attr(docsrs, doc(cfg(feature = \"std\")))]\n    #[inline]\n    fn writer(self) -> Writer<Self>\n    where\n        Self: Sized,\n    {\n        writer::new(self)\n    }\n    #[inline]\n    fn chain_mut<U: BufMut>(self, next: U) -> Chain<Self, U>\n    where\n        Self: Sized,\n    {\n        Chain::new(self, next)\n    }\n}\npub struct Bytes {\n    ptr: *const u8,\n    len: usize,\n    data: AtomicPtr<()>,\n    vtable: &'static Vtable,\n}\nimpl PartialEq<BytesMut> for &str {\n    fn eq(&self, other: &BytesMut) -> bool {\n        *other == *self\n    }\n}\n\nThe function to be tested is presented with each line formatted as 'line number + code':\n842 fn eq(&self, other: &Bytes) -> bool {\n843     *other == *self\n844 }\n\nWhen inferring test input conditions or ranges, consider the following preconditions and expected return values or types:\n"
}