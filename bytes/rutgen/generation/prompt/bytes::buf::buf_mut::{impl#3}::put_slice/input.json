{
  "system_pt": "As a software testing expert, infer the test input conditions or ranges based on the provided information. Follow these guidelines:\n1. Provide test input conditions or ranges in one line in plain text only, without additional explanations or Markdown formatting\n2. Analyze the function under test, context, preconditions, and expected return values or types to determine appropriate test input conditions or ranges\n3. The inferred test input conditions or ranges should comprehensively satisfy all provided preconditions simultaneously.\n4. Ensure the test input conditions or ranges cover boundary cases and edge scenarios\n",
  "static_pt": "The context for the focal function is as follows:\n// src/buf/buf_mut.rs\n// crate name is bytes\nuse crate::buf::{limit, Chain, Limit, UninitSlice};\n#[cfg(feature = \"std\")]\nuse crate::buf::{writer, Writer};\nuse crate::{panic_advance, panic_does_not_fit, TryGetError};\nuse core::{mem, ptr, usize};\nuse alloc::{boxed::Box, vec::Vec};\npub unsafe trait BufMut {\n    fn remaining_mut(&self) -> usize;\n    unsafe fn advance_mut(&mut self, cnt: usize);\n    #[inline]\n    fn has_remaining_mut(&self) -> bool {\n        self.remaining_mut() > 0\n    }\n    #[cfg_attr(docsrs, doc(alias = \"bytes_mut\"))]\n    fn chunk_mut(&mut self) -> &mut UninitSlice;\n    #[inline]\n    fn put<T: super::Buf>(&mut self, mut src: T)\n    where\n        Self: Sized,\n    {\n        if self.remaining_mut() < src.remaining() {\n            panic_advance(\n                &TryGetError {\n                    requested: src.remaining(),\n                    available: self.remaining_mut(),\n                },\n            );\n        }\n        while src.has_remaining() {\n            let s = src.chunk();\n            let d = self.chunk_mut();\n            let cnt = usize::min(s.len(), d.len());\n            d[..cnt].copy_from_slice(&s[..cnt]);\n            unsafe { self.advance_mut(cnt) };\n            src.advance(cnt);\n        }\n    }\n    #[inline]\n    fn put_slice(&mut self, mut src: &[u8]) {\n        if self.remaining_mut() < src.len() {\n            panic_advance(\n                &TryGetError {\n                    requested: src.len(),\n                    available: self.remaining_mut(),\n                },\n            );\n        }\n        while !src.is_empty() {\n            let dst = self.chunk_mut();\n            let cnt = usize::min(src.len(), dst.len());\n            dst[..cnt].copy_from_slice(&src[..cnt]);\n            src = &src[cnt..];\n            unsafe { self.advance_mut(cnt) };\n        }\n    }\n    #[inline]\n    fn put_bytes(&mut self, val: u8, mut cnt: usize) {\n        if self.remaining_mut() < cnt {\n            panic_advance(\n                &TryGetError {\n                    requested: cnt,\n                    available: self.remaining_mut(),\n                },\n            )\n        }\n        while cnt > 0 {\n            let dst = self.chunk_mut();\n            let dst_len = usize::min(dst.len(), cnt);\n            unsafe { core::ptr::write_bytes(dst.as_mut_ptr(), val, dst_len) };\n            unsafe { self.advance_mut(dst_len) };\n            cnt -= dst_len;\n        }\n    }\n    #[inline]\n    fn put_u8(&mut self, n: u8) {\n        let src = [n];\n        self.put_slice(&src);\n    }\n    #[inline]\n    fn put_i8(&mut self, n: i8) {\n        let src = [n as u8];\n        self.put_slice(&src)\n    }\n    #[inline]\n    fn put_u16(&mut self, n: u16) {\n        self.put_slice(&n.to_be_bytes())\n    }\n    #[inline]\n    fn put_u16_le(&mut self, n: u16) {\n        self.put_slice(&n.to_le_bytes())\n    }\n    #[inline]\n    fn put_u16_ne(&mut self, n: u16) {\n        self.put_slice(&n.to_ne_bytes())\n    }\n    #[inline]\n    fn put_i16(&mut self, n: i16) {\n        self.put_slice(&n.to_be_bytes())\n    }\n    #[inline]\n    fn put_i16_le(&mut self, n: i16) {\n        self.put_slice(&n.to_le_bytes())\n    }\n    #[inline]\n    fn put_i16_ne(&mut self, n: i16) {\n        self.put_slice(&n.to_ne_bytes())\n    }\n    #[inline]\n    fn put_u32(&mut self, n: u32) {\n        self.put_slice(&n.to_be_bytes())\n    }\n    #[inline]\n    fn put_u32_le(&mut self, n: u32) {\n        self.put_slice(&n.to_le_bytes())\n    }\n    #[inline]\n    fn put_u32_ne(&mut self, n: u32) {\n        self.put_slice(&n.to_ne_bytes())\n    }\n    #[inline]\n    fn put_i32(&mut self, n: i32) {\n        self.put_slice(&n.to_be_bytes())\n    }\n    #[inline]\n    fn put_i32_le(&mut self, n: i32) {\n        self.put_slice(&n.to_le_bytes())\n    }\n    #[inline]\n    fn put_i32_ne(&mut self, n: i32) {\n        self.put_slice(&n.to_ne_bytes())\n    }\n    #[inline]\n    fn put_u64(&mut self, n: u64) {\n        self.put_slice(&n.to_be_bytes())\n    }\n    #[inline]\n    fn put_u64_le(&mut self, n: u64) {\n        self.put_slice(&n.to_le_bytes())\n    }\n    #[inline]\n    fn put_u64_ne(&mut self, n: u64) {\n        self.put_slice(&n.to_ne_bytes())\n    }\n    #[inline]\n    fn put_i64(&mut self, n: i64) {\n        self.put_slice(&n.to_be_bytes())\n    }\n    #[inline]\n    fn put_i64_le(&mut self, n: i64) {\n        self.put_slice(&n.to_le_bytes())\n    }\n    #[inline]\n    fn put_i64_ne(&mut self, n: i64) {\n        self.put_slice(&n.to_ne_bytes())\n    }\n    #[inline]\n    fn put_u128(&mut self, n: u128) {\n        self.put_slice(&n.to_be_bytes())\n    }\n    #[inline]\n    fn put_u128_le(&mut self, n: u128) {\n        self.put_slice(&n.to_le_bytes())\n    }\n    #[inline]\n    fn put_u128_ne(&mut self, n: u128) {\n        self.put_slice(&n.to_ne_bytes())\n    }\n    #[inline]\n    fn put_i128(&mut self, n: i128) {\n        self.put_slice(&n.to_be_bytes())\n    }\n    #[inline]\n    fn put_i128_le(&mut self, n: i128) {\n        self.put_slice(&n.to_le_bytes())\n    }\n    #[inline]\n    fn put_i128_ne(&mut self, n: i128) {\n        self.put_slice(&n.to_ne_bytes())\n    }\n    #[inline]\n    fn put_uint(&mut self, n: u64, nbytes: usize) {\n        let start = match mem::size_of_val(&n).checked_sub(nbytes) {\n            Some(start) => start,\n            None => panic_does_not_fit(nbytes, mem::size_of_val(&n)),\n        };\n        self.put_slice(&n.to_be_bytes()[start..]);\n    }\n    #[inline]\n    fn put_uint_le(&mut self, n: u64, nbytes: usize) {\n        let slice = n.to_le_bytes();\n        let slice = match slice.get(..nbytes) {\n            Some(slice) => slice,\n            None => panic_does_not_fit(nbytes, slice.len()),\n        };\n        self.put_slice(slice);\n    }\n    #[inline]\n    fn put_uint_ne(&mut self, n: u64, nbytes: usize) {\n        if cfg!(target_endian = \"big\") {\n            self.put_uint(n, nbytes)\n        } else {\n            self.put_uint_le(n, nbytes)\n        }\n    }\n    #[inline]\n    fn put_int(&mut self, n: i64, nbytes: usize) {\n        let start = match mem::size_of_val(&n).checked_sub(nbytes) {\n            Some(start) => start,\n            None => panic_does_not_fit(nbytes, mem::size_of_val(&n)),\n        };\n        self.put_slice(&n.to_be_bytes()[start..]);\n    }\n    #[inline]\n    fn put_int_le(&mut self, n: i64, nbytes: usize) {\n        let slice = n.to_le_bytes();\n        let slice = match slice.get(..nbytes) {\n            Some(slice) => slice,\n            None => panic_does_not_fit(nbytes, slice.len()),\n        };\n        self.put_slice(slice);\n    }\n    #[inline]\n    fn put_int_ne(&mut self, n: i64, nbytes: usize) {\n        if cfg!(target_endian = \"big\") {\n            self.put_int(n, nbytes)\n        } else {\n            self.put_int_le(n, nbytes)\n        }\n    }\n    #[inline]\n    fn put_f32(&mut self, n: f32) {\n        self.put_u32(n.to_bits());\n    }\n    #[inline]\n    fn put_f32_le(&mut self, n: f32) {\n        self.put_u32_le(n.to_bits());\n    }\n    #[inline]\n    fn put_f32_ne(&mut self, n: f32) {\n        self.put_u32_ne(n.to_bits());\n    }\n    #[inline]\n    fn put_f64(&mut self, n: f64) {\n        self.put_u64(n.to_bits());\n    }\n    #[inline]\n    fn put_f64_le(&mut self, n: f64) {\n        self.put_u64_le(n.to_bits());\n    }\n    #[inline]\n    fn put_f64_ne(&mut self, n: f64) {\n        self.put_u64_ne(n.to_bits());\n    }\n    #[inline]\n    fn limit(self, limit: usize) -> Limit<Self>\n    where\n        Self: Sized,\n    {\n        limit::new(self, limit)\n    }\n    #[cfg(feature = \"std\")]\n    #[cfg_attr(docsrs, doc(cfg(feature = \"std\")))]\n    #[inline]\n    fn writer(self) -> Writer<Self>\n    where\n        Self: Sized,\n    {\n        writer::new(self)\n    }\n    #[inline]\n    fn chain_mut<U: BufMut>(self, next: U) -> Chain<Self, U>\n    where\n        Self: Sized,\n    {\n        Chain::new(self, next)\n    }\n}\npub trait Buf {\n    fn remaining(&self) -> usize;\n    #[cfg_attr(docsrs, doc(alias = \"bytes\"))]\n    fn chunk(&self) -> &[u8];\n    #[cfg(feature = \"std\")]\n    #[cfg_attr(docsrs, doc(cfg(feature = \"std\")))]\n    fn chunks_vectored<'a>(&'a self, dst: &mut [IoSlice<'a>]) -> usize;\n    fn advance(&mut self, cnt: usize);\n    fn has_remaining(&self) -> bool;\n    fn copy_to_slice(&mut self, dst: &mut [u8]);\n    fn get_u8(&mut self) -> u8;\n    fn get_i8(&mut self) -> i8;\n    fn get_u16(&mut self) -> u16;\n    fn get_u16_le(&mut self) -> u16;\n    fn get_u16_ne(&mut self) -> u16;\n    fn get_i16(&mut self) -> i16;\n    fn get_i16_le(&mut self) -> i16;\n    fn get_i16_ne(&mut self) -> i16;\n    fn get_u32(&mut self) -> u32;\n    fn get_u32_le(&mut self) -> u32;\n    fn get_u32_ne(&mut self) -> u32;\n    fn get_i32(&mut self) -> i32;\n    fn get_i32_le(&mut self) -> i32;\n    fn get_i32_ne(&mut self) -> i32;\n    fn get_u64(&mut self) -> u64;\n    fn get_u64_le(&mut self) -> u64;\n    fn get_u64_ne(&mut self) -> u64;\n    fn get_i64(&mut self) -> i64;\n    fn get_i64_le(&mut self) -> i64;\n    fn get_i64_ne(&mut self) -> i64;\n    fn get_u128(&mut self) -> u128;\n    fn get_u128_le(&mut self) -> u128;\n    fn get_u128_ne(&mut self) -> u128;\n    fn get_i128(&mut self) -> i128;\n    fn get_i128_le(&mut self) -> i128;\n    fn get_i128_ne(&mut self) -> i128;\n    fn get_uint(&mut self, nbytes: usize) -> u64;\n    fn get_uint_le(&mut self, nbytes: usize) -> u64;\n    fn get_uint_ne(&mut self, nbytes: usize) -> u64;\n    fn get_int(&mut self, nbytes: usize) -> i64;\n    fn get_int_le(&mut self, nbytes: usize) -> i64;\n    fn get_int_ne(&mut self, nbytes: usize) -> i64;\n    fn get_f32(&mut self) -> f32;\n    fn get_f32_le(&mut self) -> f32;\n    fn get_f32_ne(&mut self) -> f32;\n    fn get_f64(&mut self) -> f64;\n    fn get_f64_le(&mut self) -> f64;\n    fn get_f64_ne(&mut self) -> f64;\n    fn try_copy_to_slice(&mut self, mut dst: &mut [u8]) -> Result<(), TryGetError>;\n    fn try_get_u8(&mut self) -> Result<u8, TryGetError>;\n    fn try_get_i8(&mut self) -> Result<i8, TryGetError>;\n    fn try_get_u16(&mut self) -> Result<u16, TryGetError>;\n    fn try_get_u16_le(&mut self) -> Result<u16, TryGetError>;\n    fn try_get_u16_ne(&mut self) -> Result<u16, TryGetError>;\n    fn try_get_i16(&mut self) -> Result<i16, TryGetError>;\n    fn try_get_i16_le(&mut self) -> Result<i16, TryGetError>;\n    fn try_get_i16_ne(&mut self) -> Result<i16, TryGetError>;\n    fn try_get_u32(&mut self) -> Result<u32, TryGetError>;\n    fn try_get_u32_le(&mut self) -> Result<u32, TryGetError>;\n    fn try_get_u32_ne(&mut self) -> Result<u32, TryGetError>;\n    fn try_get_i32(&mut self) -> Result<i32, TryGetError>;\n    fn try_get_i32_le(&mut self) -> Result<i32, TryGetError>;\n    fn try_get_i32_ne(&mut self) -> Result<i32, TryGetError>;\n    fn try_get_u64(&mut self) -> Result<u64, TryGetError>;\n    fn try_get_u64_le(&mut self) -> Result<u64, TryGetError>;\n    fn try_get_u64_ne(&mut self) -> Result<u64, TryGetError>;\n    fn try_get_i64(&mut self) -> Result<i64, TryGetError>;\n    fn try_get_i64_le(&mut self) -> Result<i64, TryGetError>;\n    fn try_get_i64_ne(&mut self) -> Result<i64, TryGetError>;\n    fn try_get_u128(&mut self) -> Result<u128, TryGetError>;\n    fn try_get_u128_le(&mut self) -> Result<u128, TryGetError>;\n    fn try_get_u128_ne(&mut self) -> Result<u128, TryGetError>;\n    fn try_get_i128(&mut self) -> Result<i128, TryGetError>;\n    fn try_get_i128_le(&mut self) -> Result<i128, TryGetError>;\n    fn try_get_i128_ne(&mut self) -> Result<i128, TryGetError>;\n    fn try_get_uint(&mut self, nbytes: usize) -> Result<u64, TryGetError>;\n    fn try_get_uint_le(&mut self, nbytes: usize) -> Result<u64, TryGetError>;\n    fn try_get_uint_ne(&mut self, nbytes: usize) -> Result<u64, TryGetError>;\n    fn try_get_int(&mut self, nbytes: usize) -> Result<i64, TryGetError>;\n    fn try_get_int_le(&mut self, nbytes: usize) -> Result<i64, TryGetError>;\n    fn try_get_int_ne(&mut self, nbytes: usize) -> Result<i64, TryGetError>;\n    fn try_get_f32(&mut self) -> Result<f32, TryGetError>;\n    fn try_get_f32_le(&mut self) -> Result<f32, TryGetError>;\n    fn try_get_f32_ne(&mut self) -> Result<f32, TryGetError>;\n    fn try_get_f64(&mut self) -> Result<f64, TryGetError>;\n    fn try_get_f64_le(&mut self) -> Result<f64, TryGetError>;\n    fn try_get_f64_ne(&mut self) -> Result<f64, TryGetError>;\n    fn copy_to_bytes(&mut self, len: usize) -> crate::Bytes;\n    fn take(self, limit: usize) -> Take<Self>\n    where\n        Self: Sized,\n    {\n        take::new(self, limit)\n    }\n    fn chain<U: Buf>(self, next: U) -> Chain<Self, U>\n    where\n        Self: Sized,\n    {\n        Chain::new(self, next)\n    }\n    #[cfg(feature = \"std\")]\n    #[cfg_attr(docsrs, doc(cfg(feature = \"std\")))]\n    fn reader(self) -> Reader<Self>\n    where\n        Self: Sized,\n    {\n        reader::new(self)\n    }\n}\n#[derive(Debug, PartialEq, Eq)]\npub struct TryGetError {\n    /// The number of bytes necessary to get the value\n    pub requested: usize,\n    /// The number of bytes available in the buffer\n    pub available: usize,\n}\nunsafe impl BufMut for &mut [core::mem::MaybeUninit<u8>] {\n    #[inline]\n    fn remaining_mut(&self) -> usize {}\n    #[inline]\n    fn chunk_mut(&mut self) -> &mut UninitSlice {}\n    #[inline]\n    unsafe fn advance_mut(&mut self, cnt: usize) {}\n    #[inline]\n    fn put_slice(&mut self, src: &[u8]) {\n        if self.len() < src.len() {\n            panic_advance(\n                &TryGetError {\n                    requested: src.len(),\n                    available: self.len(),\n                },\n            );\n        }\n        unsafe {\n            ptr::copy_nonoverlapping(src.as_ptr(), self.as_mut_ptr().cast(), src.len());\n            self.advance_mut(src.len());\n        }\n    }\n    #[inline]\n    fn put_bytes(&mut self, val: u8, cnt: usize) {}\n}\n#[cold]\nfn panic_advance(error_info: &TryGetError) -> ! {\n    panic!(\n        \"advance out of bounds: the len is {} but advancing by {}\", error_info.available,\n        error_info.requested\n    );\n}\n\nThe function to be tested is presented with each line formatted as 'line number + code':\n1567 fn put_slice(&mut self, src: &[u8]) {\n1568     if self.len() < src.len() {\n1569         panic_advance(&TryGetError {\n1570             requested: src.len(),\n1571             available: self.len(),\n1572         });\n1573     }\n1574 \n1575     // SAFETY: We just checked that the pointer is valid for `src.len()` bytes.\n1576     unsafe {\n1577         ptr::copy_nonoverlapping(src.as_ptr(), self.as_mut_ptr().cast(), src.len());\n1578         self.advance_mut(src.len());\n1579     }\n1580 }\n\nWhen inferring test input conditions or ranges, consider the following preconditions and expected return values or types:\n"
}