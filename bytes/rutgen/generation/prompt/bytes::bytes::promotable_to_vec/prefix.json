{
  "system_pt": "As a software testing expert, please generate Rust test functions based on the following guidelines, focusing solely on constructing test inputs and calling the functions under test:\n1. Provide the code in plain text format, without explanations or Markdown.\n2. If the method under test belongs to a trait, construct appropriate structs within the test function, but avoid method overrides. If the method under test uses generics, instantiate them with suitable types based on the context.\n3. Generate test code with minimal scope: avoid creating external structures or implementations. Instead, define any necessary helper structures or implementations directly within the test function when required.\n4. Whenever possible, initialize the corresponding data structures using the initialization methods provided in the context.\n5. Ensure the generated function is fully implemented and can be compiled and executed directly without any missing parts.\n6. Create a minimal yet complete set of test functions, ensuring they adhere to all provided preconditions and cover boundary conditions, and reference the inferred test input conditions or ranges.\n7. Ensure the test inputs are designed to cover the inferred test input conditions or ranges as comprehensively as possible, with particular emphasis on boundary cases.\n8. Focus on crafting test inputs that effectively reveal potential bugs while meeting the specified requirements.\n9. Omit test oracles and assertions; concentrate on generating test inputs and function calls.\n10. Do not create a test module, but include intrinsic attributes like #[test] or #[should_panic] where necessary.\n",
  "static_pt": "The context for the focal function is as follows:\n// src/bytes.rs\n// crate name is bytes\nuse core::iter::FromIterator;\nuse core::mem::{self, ManuallyDrop};\nuse core::ops::{Deref, RangeBounds};\nuse core::ptr::NonNull;\nuse core::{cmp, fmt, hash, ptr, slice, usize};\nuse alloc::{\n    alloc::{dealloc, Layout},\n    borrow::Borrow, boxed::Box, string::String, vec::Vec,\n};\nuse crate::buf::IntoIter;\n#[allow(unused)]\nuse crate::loom::sync::atomic::AtomicMut;\nuse crate::loom::sync::atomic::{AtomicPtr, AtomicUsize, Ordering};\nuse crate::{offset_from, Buf, BytesMut};\nstatic OWNED_VTABLE: Vtable = Vtable {\n    clone: owned_clone,\n    into_vec: owned_to_vec,\n    into_mut: owned_to_mut,\n    is_unique: owned_is_unique,\n    drop: owned_drop,\n};\nstatic PROMOTABLE_EVEN_VTABLE: Vtable = Vtable {\n    clone: promotable_even_clone,\n    into_vec: promotable_even_to_vec,\n    into_mut: promotable_even_to_mut,\n    is_unique: promotable_is_unique,\n    drop: promotable_even_drop,\n};\nstatic PROMOTABLE_ODD_VTABLE: Vtable = Vtable {\n    clone: promotable_odd_clone,\n    into_vec: promotable_odd_to_vec,\n    into_mut: promotable_odd_to_mut,\n    is_unique: promotable_is_unique,\n    drop: promotable_odd_drop,\n};\nstatic SHARED_VTABLE: Vtable = Vtable {\n    clone: shared_clone,\n    into_vec: shared_to_vec,\n    into_mut: shared_to_mut,\n    is_unique: shared_is_unique,\n    drop: shared_drop,\n};\nconst STATIC_VTABLE: Vtable = Vtable {\n    clone: static_clone,\n    into_vec: static_to_vec,\n    into_mut: static_to_mut,\n    is_unique: static_is_unique,\n    drop: static_drop,\n};\nconst _: [(); 0 - mem::align_of::<Shared>() % 2] = [];\nconst KIND_ARC: usize = 0b0;\nconst KIND_VEC: usize = 0b1;\nconst KIND_MASK: usize = 0b1;\nstruct Shared {\n    buf: *mut u8,\n    cap: usize,\n    ref_cnt: AtomicUsize,\n}\nunsafe fn promotable_to_vec(\n    data: &AtomicPtr<()>,\n    ptr: *const u8,\n    len: usize,\n    f: fn(*mut ()) -> *mut u8,\n) -> Vec<u8> {\n    let shared = data.load(Ordering::Acquire);\n    let kind = shared as usize & KIND_MASK;\n    if kind == KIND_ARC {\n        shared_to_vec_impl(shared.cast(), ptr, len)\n    } else {\n        debug_assert_eq!(kind, KIND_VEC);\n        let buf = f(shared);\n        let cap = offset_from(ptr, buf) + len;\n        ptr::copy(ptr, buf, len);\n        Vec::from_raw_parts(buf, len, cap)\n    }\n}\nunsafe fn shared_to_vec_impl(\n    shared: *mut Shared,\n    ptr: *const u8,\n    len: usize,\n) -> Vec<u8> {\n    if (*shared)\n        .ref_cnt\n        .compare_exchange(1, 0, Ordering::AcqRel, Ordering::Relaxed)\n        .is_ok()\n    {\n        let shared = *Box::from_raw(shared);\n        let shared = ManuallyDrop::new(shared);\n        let buf = shared.buf;\n        let cap = shared.cap;\n        ptr::copy(ptr, buf, len);\n        Vec::from_raw_parts(buf, len, cap)\n    } else {\n        let v = slice::from_raw_parts(ptr, len).to_vec();\n        release_shared(shared);\n        v\n    }\n}\n#[inline]\nfn offset_from(dst: *const u8, original: *const u8) -> usize {\n    dst as usize - original as usize\n}\n\nThe function to be tested is presented with each line formatted as 'line number + code':\n1221 unsafe fn promotable_to_vec(\n1222     data: &AtomicPtr<()>,\n1223     ptr: *const u8,\n1224     len: usize,\n1225     f: fn(*mut ()) -> *mut u8,\n1226 ) -> Vec<u8> {\n1227     let shared = data.load(Ordering::Acquire);\n1228     let kind = shared as usize & KIND_MASK;\n1229 \n1230     if kind == KIND_ARC {\n1231         shared_to_vec_impl(shared.cast(), ptr, len)\n1232     } else {\n1233         // If Bytes holds a Vec, then the offset must be 0.\n1234         debug_assert_eq!(kind, KIND_VEC);\n1235 \n1236         let buf = f(shared);\n1237 \n1238         let cap = offset_from(ptr, buf) + len;\n1239 \n1240         // Copy back buffer\n1241         ptr::copy(ptr, buf, len);\n1242 \n1243         Vec::from_raw_parts(buf, len, cap)\n1244     }\n1245 }\n\nGenerate each test function in such a manner that it concurrently satisfies all the following preconditions:\n",
  "depend_pt": ""
}