{
  "system_pt": "As a software testing expert, infer the test input conditions or ranges based on the provided information. Follow these guidelines:\n1. Provide test input conditions or ranges in one line in plain text only, without additional explanations or Markdown formatting\n2. Analyze the function under test, context, preconditions, and expected return values or types to determine appropriate test input conditions or ranges\n3. The inferred test input conditions or ranges should comprehensively satisfy all provided preconditions simultaneously.\n4. Ensure the test input conditions or ranges cover boundary cases and edge scenarios\n",
  "static_pt": "The context for the focal function is as follows:\n// src/buf/buf_mut.rs\n// crate name is bytes\nuse crate::buf::{limit, Chain, Limit, UninitSlice};\n#[cfg(feature = \"std\")]\nuse crate::buf::{writer, Writer};\nuse crate::{panic_advance, panic_does_not_fit, TryGetError};\nuse core::{mem, ptr, usize};\nuse alloc::{boxed::Box, vec::Vec};\npub unsafe trait BufMut {\n    fn remaining_mut(&self) -> usize;\n    unsafe fn advance_mut(&mut self, cnt: usize);\n    #[inline]\n    fn has_remaining_mut(&self) -> bool {\n        self.remaining_mut() > 0\n    }\n    #[cfg_attr(docsrs, doc(alias = \"bytes_mut\"))]\n    fn chunk_mut(&mut self) -> &mut UninitSlice;\n    #[inline]\n    fn put<T: super::Buf>(&mut self, mut src: T)\n    where\n        Self: Sized,\n    {\n        if self.remaining_mut() < src.remaining() {\n            panic_advance(\n                &TryGetError {\n                    requested: src.remaining(),\n                    available: self.remaining_mut(),\n                },\n            );\n        }\n        while src.has_remaining() {\n            let s = src.chunk();\n            let d = self.chunk_mut();\n            let cnt = usize::min(s.len(), d.len());\n            d[..cnt].copy_from_slice(&s[..cnt]);\n            unsafe { self.advance_mut(cnt) };\n            src.advance(cnt);\n        }\n    }\n    #[inline]\n    fn put_slice(&mut self, mut src: &[u8]) {\n        if self.remaining_mut() < src.len() {\n            panic_advance(\n                &TryGetError {\n                    requested: src.len(),\n                    available: self.remaining_mut(),\n                },\n            );\n        }\n        while !src.is_empty() {\n            let dst = self.chunk_mut();\n            let cnt = usize::min(src.len(), dst.len());\n            dst[..cnt].copy_from_slice(&src[..cnt]);\n            src = &src[cnt..];\n            unsafe { self.advance_mut(cnt) };\n        }\n    }\n    #[inline]\n    fn put_bytes(&mut self, val: u8, mut cnt: usize) {\n        if self.remaining_mut() < cnt {\n            panic_advance(\n                &TryGetError {\n                    requested: cnt,\n                    available: self.remaining_mut(),\n                },\n            )\n        }\n        while cnt > 0 {\n            let dst = self.chunk_mut();\n            let dst_len = usize::min(dst.len(), cnt);\n            unsafe { core::ptr::write_bytes(dst.as_mut_ptr(), val, dst_len) };\n            unsafe { self.advance_mut(dst_len) };\n            cnt -= dst_len;\n        }\n    }\n    #[inline]\n    fn put_u8(&mut self, n: u8) {\n        let src = [n];\n        self.put_slice(&src);\n    }\n    #[inline]\n    fn put_i8(&mut self, n: i8) {\n        let src = [n as u8];\n        self.put_slice(&src)\n    }\n    #[inline]\n    fn put_u16(&mut self, n: u16) {\n        self.put_slice(&n.to_be_bytes())\n    }\n    #[inline]\n    fn put_u16_le(&mut self, n: u16) {\n        self.put_slice(&n.to_le_bytes())\n    }\n    #[inline]\n    fn put_u16_ne(&mut self, n: u16) {\n        self.put_slice(&n.to_ne_bytes())\n    }\n    #[inline]\n    fn put_i16(&mut self, n: i16) {\n        self.put_slice(&n.to_be_bytes())\n    }\n    #[inline]\n    fn put_i16_le(&mut self, n: i16) {\n        self.put_slice(&n.to_le_bytes())\n    }\n    #[inline]\n    fn put_i16_ne(&mut self, n: i16) {\n        self.put_slice(&n.to_ne_bytes())\n    }\n    #[inline]\n    fn put_u32(&mut self, n: u32) {\n        self.put_slice(&n.to_be_bytes())\n    }\n    #[inline]\n    fn put_u32_le(&mut self, n: u32) {\n        self.put_slice(&n.to_le_bytes())\n    }\n    #[inline]\n    fn put_u32_ne(&mut self, n: u32) {\n        self.put_slice(&n.to_ne_bytes())\n    }\n    #[inline]\n    fn put_i32(&mut self, n: i32) {\n        self.put_slice(&n.to_be_bytes())\n    }\n    #[inline]\n    fn put_i32_le(&mut self, n: i32) {\n        self.put_slice(&n.to_le_bytes())\n    }\n    #[inline]\n    fn put_i32_ne(&mut self, n: i32) {\n        self.put_slice(&n.to_ne_bytes())\n    }\n    #[inline]\n    fn put_u64(&mut self, n: u64) {\n        self.put_slice(&n.to_be_bytes())\n    }\n    #[inline]\n    fn put_u64_le(&mut self, n: u64) {\n        self.put_slice(&n.to_le_bytes())\n    }\n    #[inline]\n    fn put_u64_ne(&mut self, n: u64) {\n        self.put_slice(&n.to_ne_bytes())\n    }\n    #[inline]\n    fn put_i64(&mut self, n: i64) {\n        self.put_slice(&n.to_be_bytes())\n    }\n    #[inline]\n    fn put_i64_le(&mut self, n: i64) {\n        self.put_slice(&n.to_le_bytes())\n    }\n    #[inline]\n    fn put_i64_ne(&mut self, n: i64) {\n        self.put_slice(&n.to_ne_bytes())\n    }\n    #[inline]\n    fn put_u128(&mut self, n: u128) {\n        self.put_slice(&n.to_be_bytes())\n    }\n    #[inline]\n    fn put_u128_le(&mut self, n: u128) {\n        self.put_slice(&n.to_le_bytes())\n    }\n    #[inline]\n    fn put_u128_ne(&mut self, n: u128) {\n        self.put_slice(&n.to_ne_bytes())\n    }\n    #[inline]\n    fn put_i128(&mut self, n: i128) {\n        self.put_slice(&n.to_be_bytes())\n    }\n    #[inline]\n    fn put_i128_le(&mut self, n: i128) {\n        self.put_slice(&n.to_le_bytes())\n    }\n    #[inline]\n    fn put_i128_ne(&mut self, n: i128) {\n        self.put_slice(&n.to_ne_bytes())\n    }\n    #[inline]\n    fn put_uint(&mut self, n: u64, nbytes: usize) {\n        let start = match mem::size_of_val(&n).checked_sub(nbytes) {\n            Some(start) => start,\n            None => panic_does_not_fit(nbytes, mem::size_of_val(&n)),\n        };\n        self.put_slice(&n.to_be_bytes()[start..]);\n    }\n    #[inline]\n    fn put_uint_le(&mut self, n: u64, nbytes: usize) {\n        let slice = n.to_le_bytes();\n        let slice = match slice.get(..nbytes) {\n            Some(slice) => slice,\n            None => panic_does_not_fit(nbytes, slice.len()),\n        };\n        self.put_slice(slice);\n    }\n    #[inline]\n    fn put_uint_ne(&mut self, n: u64, nbytes: usize) {\n        if cfg!(target_endian = \"big\") {\n            self.put_uint(n, nbytes)\n        } else {\n            self.put_uint_le(n, nbytes)\n        }\n    }\n    #[inline]\n    fn put_int(&mut self, n: i64, nbytes: usize) {\n        let start = match mem::size_of_val(&n).checked_sub(nbytes) {\n            Some(start) => start,\n            None => panic_does_not_fit(nbytes, mem::size_of_val(&n)),\n        };\n        self.put_slice(&n.to_be_bytes()[start..]);\n    }\n    #[inline]\n    fn put_int_le(&mut self, n: i64, nbytes: usize) {\n        let slice = n.to_le_bytes();\n        let slice = match slice.get(..nbytes) {\n            Some(slice) => slice,\n            None => panic_does_not_fit(nbytes, slice.len()),\n        };\n        self.put_slice(slice);\n    }\n    #[inline]\n    fn put_int_ne(&mut self, n: i64, nbytes: usize) {\n        if cfg!(target_endian = \"big\") {\n            self.put_int(n, nbytes)\n        } else {\n            self.put_int_le(n, nbytes)\n        }\n    }\n    #[inline]\n    fn put_f32(&mut self, n: f32) {\n        self.put_u32(n.to_bits());\n    }\n    #[inline]\n    fn put_f32_le(&mut self, n: f32) {\n        self.put_u32_le(n.to_bits());\n    }\n    #[inline]\n    fn put_f32_ne(&mut self, n: f32) {\n        self.put_u32_ne(n.to_bits());\n    }\n    #[inline]\n    fn put_f64(&mut self, n: f64) {\n        self.put_u64(n.to_bits());\n    }\n    #[inline]\n    fn put_f64_le(&mut self, n: f64) {\n        self.put_u64_le(n.to_bits());\n    }\n    #[inline]\n    fn put_f64_ne(&mut self, n: f64) {\n        self.put_u64_ne(n.to_bits());\n    }\n    #[inline]\n    fn limit(self, limit: usize) -> Limit<Self>\n    where\n        Self: Sized,\n    {\n        limit::new(self, limit)\n    }\n    #[cfg(feature = \"std\")]\n    #[cfg_attr(docsrs, doc(cfg(feature = \"std\")))]\n    #[inline]\n    fn writer(self) -> Writer<Self>\n    where\n        Self: Sized,\n    {\n        writer::new(self)\n    }\n    #[inline]\n    fn chain_mut<U: BufMut>(self, next: U) -> Chain<Self, U>\n    where\n        Self: Sized,\n    {\n        Chain::new(self, next)\n    }\n}\n#[repr(transparent)]\npub struct UninitSlice([MaybeUninit<u8>]);\nunsafe impl BufMut for Vec<u8> {\n    #[inline]\n    fn remaining_mut(&self) -> usize {}\n    #[inline]\n    unsafe fn advance_mut(&mut self, cnt: usize) {}\n    #[inline]\n    fn chunk_mut(&mut self) -> &mut UninitSlice {\n        if self.capacity() == self.len() {\n            self.reserve(64);\n        }\n        let cap = self.capacity();\n        let len = self.len();\n        let ptr = self.as_mut_ptr();\n        unsafe { UninitSlice::from_raw_parts_mut(ptr.add(len), cap - len) }\n    }\n    #[inline]\n    fn put<T: super::Buf>(&mut self, mut src: T)\n    where\n        Self: Sized,\n    {}\n    #[inline]\n    fn put_slice(&mut self, src: &[u8]) {}\n    #[inline]\n    fn put_bytes(&mut self, val: u8, cnt: usize) {}\n}\nimpl UninitSlice {\n    #[inline]\n    pub fn new(slice: &mut [u8]) -> &mut UninitSlice {}\n    #[inline]\n    pub fn uninit(slice: &mut [MaybeUninit<u8>]) -> &mut UninitSlice {}\n    fn uninit_ref(slice: &[MaybeUninit<u8>]) -> &UninitSlice {}\n    #[inline]\n    pub unsafe fn from_raw_parts_mut<'a>(\n        ptr: *mut u8,\n        len: usize,\n    ) -> &'a mut UninitSlice {\n        let maybe_init: &mut [MaybeUninit<u8>] = core::slice::from_raw_parts_mut(\n            ptr as *mut _,\n            len,\n        );\n        Self::uninit(maybe_init)\n    }\n    #[inline]\n    pub fn write_byte(&mut self, index: usize, byte: u8) {}\n    #[inline]\n    pub fn copy_from_slice(&mut self, src: &[u8]) {}\n    #[inline]\n    pub fn as_mut_ptr(&mut self) -> *mut u8 {}\n    #[inline]\n    pub unsafe fn as_uninit_slice_mut(&mut self) -> &mut [MaybeUninit<u8>] {}\n    #[inline]\n    pub fn len(&self) -> usize {}\n}\n\nThe function to be tested is presented with each line formatted as 'line number + code':\n1623 fn chunk_mut(&mut self) -> &mut UninitSlice {\n1624     if self.capacity() == self.len() {\n1625         self.reserve(64); // Grow the vec\n1626     }\n1627 \n1628     let cap = self.capacity();\n1629     let len = self.len();\n1630 \n1631     let ptr = self.as_mut_ptr();\n1632     // SAFETY: Since `ptr` is valid for `cap` bytes, `ptr.add(len)` must be\n1633     // valid for `cap - len` bytes. The subtraction will not underflow since\n1634     // `len <= cap`.\n1635     unsafe { UninitSlice::from_raw_parts_mut(ptr.add(len), cap - len) }\n1636 }\n\nWhen inferring test input conditions or ranges, consider the following preconditions and expected return values or types:\n"
}